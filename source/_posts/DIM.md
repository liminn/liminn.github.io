---
title: DIM
mathjax: true
date: 2019-04-10 22:26:50
categories: 
- [Matting]
tags:
---

# 摘要

- 对于图像抠图(Image matting)，当图像有着相似的前景色和背景色，或复杂的纹理结构(complicated textures)时，之前方法的表现均很差。主要的原因是：之前的方法只用到了低级别的特征(low-level features)，并且缺少高级别的上下文信息(high-level context)。Matting算法必须突破以颜色作为主要线索，并利用起结构和语义特征。
- 本文提出基于深度学习的算法，该深度模型由两部分组成：
 - 第一部分：一个深度卷积的编码-解码网络(encoder-decoder network)：以一张RGB图像和对应的trimap为输入，来预测图像的alpha蒙版(alpha matte)
 - 第二部分：一个小的卷积网络来精修alpha蒙版：以第一阶段输入的RGB图像和第一阶段输出的预测alpha蒙版为输入，使其有更精确的alpha值和更锐利的边缘(sharper edges)
- 另外，我们创建了一个大规模的图像抠图数据集：包含49300张训练图像和1000张测试图像
- 实验结果表明：该方法不仅优于之前的方法，并且能够显著地更好地泛化到真实图像中

<!-- more -->

# 创新点
## 崭新的matting数据集
之前的matting基准(benchmark)都是基于alphamatting.com数据集：该数据集只有27张训练图片和8张测试图片。

<img src="/images/DIM/1.png"  width = "400" height = "300"/>

本文通过从真实图像中合成物体进入新的背景，创建了一个更大的数据集：

- 首先，通过Photoshop，人工仔细地创建出alpha蒙版(如Fig2b)和纯净的前景颜色(如Fig2c)。因为这些物体有非常简单的背景，因此我们可以给出精确的蒙版。
- 然后，对于每一个alpha蒙版和前景图像，我们随机地从COCO和VOC数据集中采样$N$个背景图像，将物体合成进背景图像中。

通过上述方法创建起训练集和测试集：

- 训练集有493个唯一的前景物体和49300张图像($N=100$)
- 测试集有50个唯一的前景物体和1000张图像($N=20$)
- 对于每一张图像的trimap，通过对GT alpha蒙版随机地进行膨胀得到。
 - 疑问：随机是指如何随机

注：依作者给到的数据集，其中说明了以下几点：

- 对于训练集的前景图片数量：
 - 论文中称由493个前景构成数据集，实际上去除重复性后，只有455个前景
 - 此外，有24张训练集不能开源，故给到的训练集前景只有431张
- 对于训练集和测试集制作时的合成方式：
 - 对于训练集：对于每一前景图片，从COCO数据集中选取$N=100$张图片作为背景，通过alpha蒙版进行合成。
 - 对于测试集：对于每一前景图片，从VOC数据集中选取$N=20$张图片作为背景，通过alpha蒙版进行合成。
 - 合成时：若前景图片尺寸大于背景图片尺寸，则放大背景图片至前景图片尺寸；若前景图片尺寸小于背景图片尺寸，则取出背景图片中的$[0:h_f,0:w_f]$区域。

## DIM结构
<img src="/images/DIM/2.png"  width = "900" height = "300"/>
第一部分：Matting encoder-decoder stage
- **输入**：一块图像以及对应的trimap，串联成4通道的输入
- **编码网络**：有14个卷积层和5个最大池化层
- **解码网络**：有6个卷积层和5个unpooling层，最后为一个alpha预测层(a final alpha prediction layer)
- **损失函数**：由两个损失函数构成：
 - **第一个损失函数为alpha-prediction loss**：每个像素的GT的alpha值和预测alpha值之间的绝对差值
 - **第二个损失函数为compositional loss**：GT RGB颜色(由GT前景、GT背景和GT alpha蒙版合成)和预测RGB颜色(由GT前景、GT背景和预测alpha蒙版合成)之间的绝对差值：
 - 另外，只计算未知区域的loss

实施细节：

- 尽管训练数据有49300张图像，但只有493个唯一的物体。为了避免过拟合以及更有效地利用起训练数据，采用了几种训练策略：
 - 第一，以未知区域的像素为中心，进行随机剪裁320x320的(image,trimap)对，以增大采样空间
 - 第二，对训练(image,trimap)对，进行不同尺寸的剪裁((e.g. 480×480, 640×640))，然后缩放到320x320，使得网络对尺度更鲁邦
 - 第三，对每一个训练对，进行随机翻转
 - 第四，对GT alpha蒙版随机膨胀，得到trimaps
 - 最后，在每一个训练epoch后，训练输入被随机重建
- 对于编码网络：
 - 通过VGG-16的前14个卷积层进行初始化(第14个层是全连接层fc6，可以转换成卷积层)，
 - 因为网络为4通道输入，因此对于第一层的卷积核，用0初始化出一个额外的通道
- 对于解码网络：
 - 所有的参数均通过Xavier随机变量初始化 
- 对于测试阶段：
 - 图像和对应的trimap串联成输入，通过前向传播来输出预测的alpha蒙版
 
##### 第二部分：Matting refinement stage
xxxxxxxxxx

输入：一块图像和第一阶段得到的预测的alpha蒙版(归一化到0-255)，串联成4通道

结构：
- 4个卷积层，前三个卷积层施加ReLU非线性激活函数，没有下采样层
- 另外，使用“skip-model” structure，将第一阶段输出的alpha蒙版缩放到0-1，然后加给该网络的输出
- 该精修步骤的效果如Fig4所示。它并没有大规模的改变alpha蒙版，而只是使得alpha值更加精细和锐利。

损失函数：

- 结构较简单，只使用公式2所示的alpha prediction loss

实施细节：

- 采用同第一阶段一样的训练策略，除了第四个步骤

**总体实施细节：**

- 训练阶段：
 - 单独训练编码-解码网络，使得编码-解码网络拟合
 - 固定编码-解码网络的参数，训练精修网络，使得精修网络拟合
 - 整个网络一起进行微调(fine-tune)。在训练阶段，采用Adam优化器，采用恒定的小学习速率($10^{-5}$) （当然也只使用alpha prediction loss了）
- 测试阶段：
 - 首先，以一张图像和trimap为输入，通过编码-解码网络得到初始的预测alpha蒙版
 - 然后，以该图像和预测的alpha蒙版为输入，通过精修网络得到最终的预测alpha蒙版

# 参考文献
- [论文：Deep Image Matting](https://arxiv.org/pdf/1703.03872.pdf)
- [代码及注释：xx](xx)



