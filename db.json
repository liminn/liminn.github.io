{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/3.png","path":"images/MobileNetV2/3.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/4.png","path":"images/MobileNetV2/4.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/5.png","path":"images/MobileNetV2/5.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/images/Depthwise Separable Convolution/2.png","path":"images/Depthwise Separable Convolution/2.png","modified":1,"renderable":0},{"_id":"source/images/Depthwise Separable Convolution/3.png","path":"images/Depthwise Separable Convolution/3.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/2.png","path":"images/MobileNetV1/2.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/3.png","path":"images/MobileNetV1/3.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/4.png","path":"images/MobileNetV1/4.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/5.png","path":"images/MobileNetV1/5.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/6.png","path":"images/MobileNetV1/6.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/7.png","path":"images/MobileNetV1/7.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/8.png","path":"images/MobileNetV1/8.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/4.png","path":"images/ShuffleNetV1/4.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/5.png","path":"images/ShuffleNetV1/5.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/2.png","path":"images/ShuffleNetV2/2.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/3.png","path":"images/ShuffleNetV2/3.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/4.png","path":"images/ShuffleNetV2/4.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/5.png","path":"images/ShuffleNetV2/5.png","modified":1,"renderable":0},{"_id":"source/images/UNet/3.png","path":"images/UNet/3.png","modified":1,"renderable":0},{"_id":"source/images/Xception/1.png","path":"images/Xception/1.png","modified":1,"renderable":0},{"_id":"source/images/Xception/5.png","path":"images/Xception/5.png","modified":1,"renderable":0},{"_id":"source/images/Depthwise Separable Convolution/1.png","path":"images/Depthwise Separable Convolution/1.png","modified":1,"renderable":0},{"_id":"source/images/Depthwise Separable Convolution/4.png","path":"images/Depthwise Separable Convolution/4.png","modified":1,"renderable":0},{"_id":"source/images/FCN/3.png","path":"images/FCN/3.png","modified":1,"renderable":0},{"_id":"source/images/FCN/4.png","path":"images/FCN/4.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/1.png","path":"images/MobileNetV2/1.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/7.png","path":"images/MobileNetV2/7.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/6.png","path":"images/ShuffleNetV1/6.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/7.png","path":"images/ShuffleNetV1/7.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/8.png","path":"images/ShuffleNetV1/8.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/1.png","path":"images/ShuffleNetV2/1.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/6.png","path":"images/ShuffleNetV2/6.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/7.png","path":"images/ShuffleNetV2/7.png","modified":1,"renderable":0},{"_id":"source/images/SqueezeNet/1.png","path":"images/SqueezeNet/1.png","modified":1,"renderable":0},{"_id":"source/images/Xception/2.png","path":"images/Xception/2.png","modified":1,"renderable":0},{"_id":"source/images/Xception/4.png","path":"images/Xception/4.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"source/images/Depthwise Separable Convolution/5.png","path":"images/Depthwise Separable Convolution/5.png","modified":1,"renderable":0},{"_id":"source/images/Depthwise Separable Convolution/7.png","path":"images/Depthwise Separable Convolution/7.png","modified":1,"renderable":0},{"_id":"source/images/Depthwise Separable Convolution/8.png","path":"images/Depthwise Separable Convolution/8.png","modified":1,"renderable":0},{"_id":"source/images/SegNet/1.png","path":"images/SegNet/1.png","modified":1,"renderable":0},{"_id":"source/images/SegNet/4.png","path":"images/SegNet/4.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/1.png","path":"images/ShuffleNetV1/1.png","modified":1,"renderable":0},{"_id":"source/images/SqueezeNet/4.png","path":"images/SqueezeNet/4.png","modified":1,"renderable":0},{"_id":"source/images/UNet/1.png","path":"images/UNet/1.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"source/images/Depthwise Separable Convolution/6.png","path":"images/Depthwise Separable Convolution/6.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV1/1.png","path":"images/MobileNetV1/1.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/2.png","path":"images/MobileNetV2/2.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/6.png","path":"images/MobileNetV2/6.png","modified":1,"renderable":0},{"_id":"source/images/MobileNetV2/9.png","path":"images/MobileNetV2/9.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/2.png","path":"images/ShuffleNetV1/2.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV1/3.png","path":"images/ShuffleNetV1/3.png","modified":1,"renderable":0},{"_id":"source/images/ShuffleNetV2/8.png","path":"images/ShuffleNetV2/8.png","modified":1,"renderable":0},{"_id":"source/images/SqueezeNet/2.png","path":"images/SqueezeNet/2.png","modified":1,"renderable":0},{"_id":"source/images/SqueezeNet/3.png","path":"images/SqueezeNet/3.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"source/images/MobileNetV2/8.png","path":"images/MobileNetV2/8.png","modified":1,"renderable":0},{"_id":"source/images/SegNet/3.png","path":"images/SegNet/3.png","modified":1,"renderable":0},{"_id":"source/images/UNet/2.png","path":"images/UNet/2.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"source/images/Xception/3.png","path":"images/Xception/3.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"source/images/FCN/1.png","path":"images/FCN/1.png","modified":1,"renderable":0},{"_id":"source/images/FCN/2.png","path":"images/FCN/2.png","modified":1,"renderable":0},{"_id":"source/images/SegNet/2.png","path":"images/SegNet/2.png","modified":1,"renderable":0},{"_id":"themes/next/source/uploads/me.jpg","path":"uploads/me.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"1f1d60ea977704c7a3123e8b59859d18e48b19bb","modified":1535867626115},{"_id":"source/.DS_Store","hash":"47c6dd7230dbeab74cf2b4745fb4f73af4cbf945","modified":1546479496445},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1510819066000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1510819066000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1510819066000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1510819066000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1510819066000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1510819066000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1510819066000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1510819066000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1510819066000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1510819066000},{"_id":"themes/next/README.cn.md","hash":"02713071ef9e260b3fe77f4403942189d55a00e9","modified":1510819066000},{"_id":"themes/next/README.md","hash":"529d53dfa97678f8ce4c95620b26e61154162a29","modified":1510819066000},{"_id":"themes/next/bower.json","hash":"6d6ae7531cf3fedc97c58cdad664f5793eb3cc88","modified":1510819066000},{"_id":"themes/next/_config.yml","hash":"c72eaedd500821c652aa475f1463a239a66d0ae0","modified":1546759595575},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1510819066000},{"_id":"themes/next/package.json","hash":"93a74dbc0fe3a1208a02e9cec3c15c2375339cc1","modified":1510819066000},{"_id":"source/_posts/.DS_Store","hash":"77f14ee07e4f770240bf3218c32049420ec8c6d5","modified":1546937039639},{"_id":"source/_posts/Adaboost算法.md","hash":"78c92ba02c30ace2215c9b6b5c6c7dbdc54db333","modified":1519372715909},{"_id":"source/_posts/C++中const关键字总结.md","hash":"3c374c129fe2704b59081efddb3f7c11a5c111d5","modified":1511858969905},{"_id":"source/_posts/C++内存管理.md","hash":"f276bee2634d24a55940db9ab4bd75db26558ae6","modified":1512443222581},{"_id":"source/_posts/CART算法.md","hash":"cb43262915d3f8f13d521d87537da3c83b30f31c","modified":1517118740294},{"_id":"source/_posts/Depthwise Separable Convolution.md","hash":"f5f48d6fc86584022356df8d4030669610536881","modified":1546156190940},{"_id":"source/_posts/EM算法.md","hash":"60bd2d95910260e449e6152bdd1aa34fb841e361","modified":1520228222289},{"_id":"source/_posts/FCN.md","hash":"93f4687436750ca8c49461e10efb708218aaccc1","modified":1546942941403},{"_id":"source/_posts/GBDT模型.md","hash":"16a34c9ce4deca207a7bd411866ad115dd5489cd","modified":1519392593825},{"_id":"source/_posts/ID3和C4.5算法.md","hash":"d7a8b30ba0561d8825c0ad9071e9b60f63547fcf","modified":1517649204985},{"_id":"source/_posts/MobileNetV1.md","hash":"b1995c73f0b4f6b089e8907a4e53fffc660b436a","modified":1546069312723},{"_id":"source/_posts/MobileNetV2.md","hash":"c8533c3c808e2eb6dc7d29d523eea82ae144ff6a","modified":1546835764732},{"_id":"source/_posts/PCA算法.md","hash":"12763a30ed725cfd4a87a506aef85657ea1c58a3","modified":1512459109611},{"_id":"source/_posts/SegNet.md","hash":"b4f7e5261a4b708ec3515502c1a643763ee2b9f8","modified":1547546054330},{"_id":"source/_posts/ShuffleNetV1.md","hash":"445ceca409fddf961239b96e60ac8c340ca11cb8","modified":1546402147539},{"_id":"source/_posts/ShuffleNetV2.md","hash":"696fddc3c03d5852d92b45bc24c51af3860cd880","modified":1546598680482},{"_id":"source/_posts/Softmax回归模型.md","hash":"0d68855669f208891c3c72d29f4c168750a6eb4e","modified":1537510687665},{"_id":"source/_posts/SqueezeNet.md","hash":"849b610fb4a6adddb56a5cb86de9b8dfae2eb96c","modified":1546264692513},{"_id":"source/_posts/UNet.md","hash":"cf51b4a33619cbbefda0e88f3693b91d084f1f50","modified":1546941071511},{"_id":"source/_posts/XGBoost模型.md","hash":"2eb726c0954b6d52ae450be66bf2b0c794fbb8d6","modified":1513135092747},{"_id":"source/_posts/Xception.md","hash":"f21f22391c2d411eecaf2931f90709d87478c23f","modified":1546079341462},{"_id":"source/_posts/kNN算法.md","hash":"75a2627b1b0d66a10ff150c2fef6cdd78cbc16ef","modified":1517646333734},{"_id":"source/_posts/基本概念.md","hash":"f56ea95337cc250387be78efc0e6068e7b06be10","modified":1512286496987},{"_id":"source/_posts/排序算法.md","hash":"5b20667bf321bd4cee2f4d289b4aa9c73f6aca5d","modified":1517405988032},{"_id":"source/_posts/支持向量机.md","hash":"2d3587f252879f324bc3b895b232c8b4fd9550dc","modified":1542359353262},{"_id":"source/_posts/朴素贝叶斯分类器.md","hash":"a3008ac236b881d33733a9d811a59ce54c8d4b36","modified":1517653393500},{"_id":"source/_posts/栈与队列.md","hash":"27b2a9685c502e28d491df03fc22256a5ee65cd6","modified":1517466383463},{"_id":"source/_posts/树.md","hash":"7d4e7b4e87c3ed3a6811202c658751b5ee9dd4c1","modified":1516948816140},{"_id":"source/_posts/深度学习课程(一)神经网络与深度学习.md","hash":"a2874c066907a84db580316f46c8b6a3dc74cb07","modified":1517406069671},{"_id":"source/_posts/深度学习课程(三)构建机器学习项目.md","hash":"31cae9f5b562191c28e30e25bc1c02f8a764dc12","modified":1517304525962},{"_id":"source/_posts/线性回归模型.md","hash":"ac9120888f5084abf2a3c8e85830a554bd9218d4","modified":1517406268894},{"_id":"source/_posts/线性表.md","hash":"ab2df3c58369ab1b4fa0c10c0e3043137953c907","modified":1517054751390},{"_id":"source/_posts/计算机网络笔记.md","hash":"3ea90b562168d0752f61863d6f1d7b8ff7a90cd5","modified":1518682802289},{"_id":"source/_posts/逻辑回归模型.md","hash":"86937a221b54488afc3da38bb03626f048b9d269","modified":1542621737172},{"_id":"source/_posts/随机森林.md","hash":"b5ddd38b9feb7f3c60f564fc68c26fb25a274950","modified":1517118886133},{"_id":"source/about/index.md","hash":"948ad3f6a0f676a211bcd8eb673256f9a45bee21","modified":1546501019967},{"_id":"source/categories/index.md","hash":"0469bfafba3c2fc74cfa9c23468f6fab976ca5a1","modified":1512459590318},{"_id":"source/images/.DS_Store","hash":"8fda9e158f1802b2acfbb0aab2d02f84a937afe5","modified":1546937191783},{"_id":"source/tags/index.md","hash":"2be5a7b84a33245d913a9d69116c8a8457343f88","modified":1512459634839},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1510819066000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1510819066000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1510819066000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1510819066000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1510819066000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1510819066000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1510819066000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1510819066000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1510819066000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1510819066000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1510819066000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1510819066000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1510819066000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1510819066000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1510819066000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1510819066000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1510819066000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1510819066000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1510819066000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1510819066000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1510819066000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1510819066000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1510819066000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1510819066000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1510819066000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1510819066000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1510819066000},{"_id":"themes/next/scripts/merge-configs.js","hash":"cb617ddf692f56e6b6129564d52e302f50b28243","modified":1510819066000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1510819066000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1510819066000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1510819066000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1510819066000},{"_id":"source/_posts/剑指Offer解题记录.md","hash":"54bdf9dd43fad06ccb4e4234f783b3650e3b1346","modified":1519126678422},{"_id":"source/_posts/深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化.md","hash":"c4b5ae00679597f38e4f0968f66ffd5810f3fa33","modified":1517296570529},{"_id":"source/_posts/深度学习课程(四)卷积神经网络.md","hash":"d2ffa4c0e40f864381d1c2d61679ffca72877eb3","modified":1517406091271},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"source/images/Depthwise Separable Convolution/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1546052974881},{"_id":"source/images/MobileNetV2/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1546057170708},{"_id":"source/images/MobileNetV2/3.png","hash":"32b1490f6a7d9305f083601d46b326f0ccce8563","modified":1546057217540},{"_id":"source/images/MobileNetV2/4.png","hash":"34a9da935f09af38b20a635cfd10a60c15735be0","modified":1546057224741},{"_id":"source/images/MobileNetV2/5.png","hash":"88963b931fd589feb33eb23dfe4123955e1220dd","modified":1546057232200},{"_id":"source/images/ShuffleNetV2/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1546597718398},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1510819066000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1510819066000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1510819066000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1510819066000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1510819066000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1510819066000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9efc455894921a66bbc074055d3b39c8a34a48a4","modified":1510819066000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1510819066000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1510819066000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1510819066000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1510819066000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1510819066000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1510819066000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1510819066000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1510819066000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1510819066000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1510819066000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1510819066000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1510819066000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1510819066000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1510819066000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1510819066000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1510819066000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1510819066000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1510819066000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1510819066000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1510819066000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1510819066000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1510819066000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1510819066000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1510819066000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1510819066000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1510819066000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1510819066000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1510819066000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1510819066000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1510819066000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1510819066000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1510819066000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1510819066000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1510819066000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1510819066000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1510819066000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1510819066000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1510819066000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1510819066000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1510819066000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1510819066000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1510819066000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1510819066000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1510819066000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1510819066000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1510819066000},{"_id":"source/images/Depthwise Separable Convolution/2.png","hash":"54aa1afddd75a0daf6188585573d1f468f146cfa","modified":1546052791668},{"_id":"source/images/Depthwise Separable Convolution/3.png","hash":"e187726750b534adace09cc9d2ce5500f9e79324","modified":1546052854298},{"_id":"source/images/MobileNetV1/2.png","hash":"bd958ef0be582056de2b486ce666040b0244c02e","modified":1546056353106},{"_id":"source/images/MobileNetV1/3.png","hash":"ef9a1ff32bab84ed7376524045a157ef5ed61da1","modified":1546056365445},{"_id":"source/images/MobileNetV1/4.png","hash":"e5fcf2c7856fff1d093b8ab424fdaa6673c68470","modified":1546056375467},{"_id":"source/images/MobileNetV1/5.png","hash":"6f1bfb07c20594c17cbf96f69d464dbf46ad7125","modified":1546056383770},{"_id":"source/images/MobileNetV1/6.png","hash":"c1d3d6d3e46cc6ccb09397667e381816725a303d","modified":1546056393674},{"_id":"source/images/MobileNetV1/7.png","hash":"f3fca93ef55652063c78efc97a763e831a507ec2","modified":1546056405756},{"_id":"source/images/MobileNetV1/8.png","hash":"3afd780123310b2bc0d5a9e0cace31238afb365e","modified":1546056415615},{"_id":"source/images/ShuffleNetV1/4.png","hash":"d0ca27d624c0f7b46d273735c8c24c2405042e6d","modified":1546265347207},{"_id":"source/images/ShuffleNetV1/5.png","hash":"0fea01318670c3df04dd2f99874d24d83a856675","modified":1546265355538},{"_id":"source/images/ShuffleNetV2/2.png","hash":"aacc36e9b5b0c8f69a5c95d7432044ef8c0879b0","modified":1546509269871},{"_id":"source/images/ShuffleNetV2/3.png","hash":"4bd553fef3c71d9506f251a7da0e2955db3d608e","modified":1546509174440},{"_id":"source/images/ShuffleNetV2/4.png","hash":"2ebddcea4e3c5778022294fd47fa494a792efeab","modified":1546567945395},{"_id":"source/images/ShuffleNetV2/5.png","hash":"1b4fd51677444af5e1cc326915b982cbef6860b7","modified":1546567968258},{"_id":"source/images/UNet/3.png","hash":"5c70185434fa16c1798b43eac3480f65e9320676","modified":1546938457015},{"_id":"source/images/Xception/1.png","hash":"726e11fdc545c841da4f75d006a8fa1d6f77c564","modified":1546072743292},{"_id":"source/images/Xception/5.png","hash":"0c1038bc47fa2bcef0307ce60b7ae4a6485649e7","modified":1546072779541},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1510819066000},{"_id":"source/images/Depthwise Separable Convolution/1.png","hash":"95d0201688a01532636b0f4d56fa0fd60257e4af","modified":1546052979318},{"_id":"source/images/Depthwise Separable Convolution/4.png","hash":"d5a7ddd459f477fd7c6add7b80386ca98b2274f0","modified":1546052865113},{"_id":"source/images/FCN/3.png","hash":"b7ea23e3a89eef8f43f4d10019e1483d040dd6fa","modified":1546930189883},{"_id":"source/images/FCN/4.png","hash":"e2942c85c156c4d4632293a99f30b8f35992a32a","modified":1546930204275},{"_id":"source/images/MobileNetV2/1.png","hash":"b80d901617608776c91652bb4ef43a27d1e868e4","modified":1546057198712},{"_id":"source/images/MobileNetV2/7.png","hash":"30240afed3148a59da0479a443c3b6dd6a7f7d91","modified":1546057249692},{"_id":"source/images/ShuffleNetV1/6.png","hash":"5e119f6b1e79bcc5c46cfeee6c517b2d634afb74","modified":1546265363022},{"_id":"source/images/ShuffleNetV1/7.png","hash":"e69c63aa7552d8ecdc14b5704c090242f29d0791","modified":1546265370611},{"_id":"source/images/ShuffleNetV1/8.png","hash":"a8bdfb058ee245b8e6754e07a6075d113462b100","modified":1546265379142},{"_id":"source/images/ShuffleNetV2/1.png","hash":"eb2d3287f10d5267f4fc65c1a8495b01b9c752a6","modified":1546503144178},{"_id":"source/images/ShuffleNetV2/6.png","hash":"a5c691ad73965c588c4c6fab0953a7e5526a59b2","modified":1546568538421},{"_id":"source/images/ShuffleNetV2/7.png","hash":"995e01956cbad3703e8dc6dbbeb73f458b362ecf","modified":1546595637744},{"_id":"source/images/SqueezeNet/1.png","hash":"3c8e5c8d7458abb8991676679641b37b4e5813b7","modified":1546156330627},{"_id":"source/images/Xception/2.png","hash":"9f86c0c154f0c6ee9e56cda7c127f615f44bd42a","modified":1546072753200},{"_id":"source/images/Xception/4.png","hash":"1a0ccc86133a0e6dafb44318aaa6c1134a0196ba","modified":1546072771650},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1510819066000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1510819066000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1510819066000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1510819066000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1510819066000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1510819066000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1510819066000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1510819066000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1510819066000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1510819066000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1510819066000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1510819066000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1510819066000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1510819066000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1510819066000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1510819066000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1510819066000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1510819066000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1510819066000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1510819066000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1510819066000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1510819066000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1510819066000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1510819066000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"207d6da11fbb3f525cc1d5aad504bf50d060e2f4","modified":1512131425845},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1510819066000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1510819066000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1510819066000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1510819066000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1510819066000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1510819066000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1510819066000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1510819066000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1510819066000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1510819066000},{"_id":"themes/next/source/js/src/utils.js","hash":"dbdc3d1300eec7da9632608ebc0e5b697779dad7","modified":1510819066000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1510819066000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1510819066000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1510819066000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1510819066000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1510819066000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1510819066000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1510819066000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1510819066000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1510819066000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1510819066000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1510819066000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1510819066000},{"_id":"source/images/Depthwise Separable Convolution/5.png","hash":"3e148af8e4a7740f4475c6df40c856e82826ff56","modified":1546063961540},{"_id":"source/images/Depthwise Separable Convolution/7.png","hash":"8ff5c094e9f9f1922c223042c5669553492b50a1","modified":1546053072438},{"_id":"source/images/Depthwise Separable Convolution/8.png","hash":"1cf847ad79813541fb45b3e40cf14873853bf23b","modified":1546053083195},{"_id":"source/images/SegNet/1.png","hash":"f85944b95fad17ed078d1886de73aabd874781aa","modified":1547532494922},{"_id":"source/images/SegNet/4.png","hash":"e1603bcd1ebf55e1c619f3c5ecab050e9433588a","modified":1547541845929},{"_id":"source/images/ShuffleNetV1/1.png","hash":"d4153347d0fada203e4307ab4a0a52f4c7b62645","modified":1546265306207},{"_id":"source/images/SqueezeNet/4.png","hash":"fbee66744ed3c3dfdbd6247494654d1e3dae6f6d","modified":1546156360742},{"_id":"source/images/UNet/1.png","hash":"12a32b81f7722b22308521b419e11c5334c2d71e","modified":1546937215923},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1510819066000},{"_id":"source/images/Depthwise Separable Convolution/6.png","hash":"2bb8911bb2731c3ca29cd2b6054d1902caf0bbf6","modified":1546063971504},{"_id":"source/images/MobileNetV1/1.png","hash":"42f422ea73182de175db2bde089a1993592abb27","modified":1546056331125},{"_id":"source/images/MobileNetV2/2.png","hash":"e13d446eee187650ef618cbc5366e5a22ff044e6","modified":1546057208002},{"_id":"source/images/MobileNetV2/6.png","hash":"341e4915a0c2c03ab4569e61f5d7933c0c66665c","modified":1546057241146},{"_id":"source/images/MobileNetV2/9.png","hash":"879f519238722224cb99cf7e8565a3195e56e21e","modified":1546264748063},{"_id":"source/images/ShuffleNetV1/2.png","hash":"92ef09c44b7e3fc75fbac1103c3a5ccf14332370","modified":1546265329149},{"_id":"source/images/ShuffleNetV1/3.png","hash":"b3364caa799f7afb33208192d2fd6248aa03ed4b","modified":1546265339259},{"_id":"source/images/ShuffleNetV2/8.png","hash":"99e023a4ecb18451ab3aa93e269af57fec0274ac","modified":1546597710793},{"_id":"source/images/SqueezeNet/2.png","hash":"c9aa9a628a5e377fb07c472cb5121496032ea352","modified":1546156340670},{"_id":"source/images/SqueezeNet/3.png","hash":"0015128e8122fe10aebb0bf125bf45807d0bb527","modified":1546156350767},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1510819066000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1510819066000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1510819066000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"bcf52192942c0afc410c74a0fb458e7936ddc3d5","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1510819066000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1510819066000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1510819066000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1510819066000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1510819066000},{"_id":"source/images/MobileNetV2/8.png","hash":"df3c74208a871b3a81a2d00d74fcd928c510ded3","modified":1546057257667},{"_id":"source/images/SegNet/3.png","hash":"f1c6e556098c380c3baef9b814c455297451f398","modified":1547539929777},{"_id":"source/images/UNet/2.png","hash":"aadb3e83223177abb4b0addf7271b92b27d7a41c","modified":1546937232565},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1510819066000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1510819066000},{"_id":"source/images/Xception/3.png","hash":"44b8281ccc2298d7f3844ea4c8048ccfc00086a4","modified":1546072761143},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1510819066000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1510819066000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1510819066000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1510819066000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1510819066000},{"_id":"source/images/FCN/1.png","hash":"c600b6703f2b71cf74ff2d089c693a504619ec78","modified":1546930165247},{"_id":"source/images/FCN/2.png","hash":"f9b3b0706883c63730b54398489e09400a750977","modified":1546930179401},{"_id":"source/images/SegNet/2.png","hash":"c5b5a06aa66ebc02624b1ab5f5e61f6b4f4cc0ed","modified":1547532481887},{"_id":"themes/next/source/uploads/me.jpg","hash":"e45dafeab49d152abe73de394401c3f1e8448748","modified":1441366094230},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1510819066000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1510819066000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1510819066000},{"_id":"public/about/index.html","hash":"2ed189f5f4f397efb51e73c244a945d05730da92","modified":1547546348274},{"_id":"public/categories/index.html","hash":"ae21c8cd3ea8d634674fa7952f977939ce5f53e3","modified":1547546348274},{"_id":"public/tags/index.html","hash":"2000d9c46bdd8818dee157b19008a17c189b8922","modified":1547546348274},{"_id":"public/2019/01/09/SegNet/index.html","hash":"ccf28fb7aa2bc5801311de14e932cf84b2f601d3","modified":1547546348274},{"_id":"public/2019/01/08/UNet/index.html","hash":"c061c135e2378ad0c0c62142c2f9352c151e41c0","modified":1547546348274},{"_id":"public/2019/01/08/FCN/index.html","hash":"627d04e0ae8a728b9f01415b8d5a8529801b935a","modified":1547546348274},{"_id":"public/2018/12/30/ShuffleNetV2/index.html","hash":"afa2b4ed76095bcc44b20bde8b6ee7e0c5deeb38","modified":1547546348274},{"_id":"public/2018/12/30/ShuffleNetV1/index.html","hash":"a6a65a35271ea92d26bd18fd9add87b284690770","modified":1547546348274},{"_id":"public/2018/12/29/MobileNetV2/index.html","hash":"fadae6398ee03cfdcb59a0dee3543fff8235d029","modified":1547546348274},{"_id":"public/2018/12/29/MobileNetV1/index.html","hash":"866354e950e09c8c887e76e32c560e68f50f626d","modified":1547546348275},{"_id":"public/2018/12/29/Xception/index.html","hash":"dc7ea6d340c95bfd4efb06e3e2d7a8606d060734","modified":1547546348275},{"_id":"public/2018/12/29/Depthwise Separable Convolution/index.html","hash":"e9f53a537332303dbd8e095615399993bd53a572","modified":1547546348275},{"_id":"public/2018/12/28/SqueezeNet/index.html","hash":"0a42917806f86e3f55d7a23ebf3378926546977a","modified":1547546348275},{"_id":"public/2018/02/02/EM算法/index.html","hash":"f72eb2735d213a9260e1a9d4494f0e52a279fe69","modified":1547546348275},{"_id":"public/2018/01/11/深度学习课程(四)卷积神经网络/index.html","hash":"748d5359ecbcd029a8b3ee85b46287dae1122614","modified":1547546348275},{"_id":"public/2018/01/08/深度学习课程(三)构建机器学习项目/index.html","hash":"a427b1010861d83a18f6e770d775ea7406d202e5","modified":1547546348275},{"_id":"public/2017/12/28/计算机网络笔记/index.html","hash":"84e2d31e68ba6fb80eb5fadda6303ff118f0cb2d","modified":1547546348275},{"_id":"public/2017/12/27/深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化/index.html","hash":"7a427646e3da3ddcc641576e8b59899e9ead7bae","modified":1547546348275},{"_id":"public/2017/12/21/深度学习课程(一)神经网络与深度学习/index.html","hash":"08c8a832bc7117de28e81e67c0e229bc5a6a34e2","modified":1547546348275},{"_id":"public/2017/12/15/随机森林/index.html","hash":"2d8aa791be64b7ddbf5367ca22fe68887d11393a","modified":1547546348275},{"_id":"public/2017/12/14/XGBoost模型/index.html","hash":"922fa4ebfe4bc95956d77ac1a9b3c4ba3593eb03","modified":1547546348275},{"_id":"public/2017/12/13/GBDT模型/index.html","hash":"b33616f168f724aeea92cdbfe5bf9367a8948a17","modified":1547546348275},{"_id":"public/2017/12/13/Adaboost算法/index.html","hash":"c8a1253e0580b811ce8cfeecc1597bc145c6f522","modified":1547546348275},{"_id":"public/2017/12/12/支持向量机/index.html","hash":"fc80daa048946af24ac80f6287d7c712b16c453c","modified":1547546348275},{"_id":"public/2017/12/08/朴素贝叶斯分类器/index.html","hash":"a303627c270010244db610a723237211443bfed0","modified":1547546348275},{"_id":"public/2017/12/07/CART算法/index.html","hash":"bad7d886d4ef46563b7d74297d5ae3aa2d07eea4","modified":1547546348275},{"_id":"public/2017/12/06/ID3和C4.5算法/index.html","hash":"8825cbc8e3ce4169a8562f88e1fbb9be14c900da","modified":1547546348275},{"_id":"public/2017/12/05/PCA算法/index.html","hash":"c7393c4b28fb5486c3ee7ddca4137709e6490a66","modified":1547546348275},{"_id":"public/2017/12/05/kNN算法/index.html","hash":"dd39b94397f0899b34c1d858f6c7f5fc5fa96b9f","modified":1547546348275},{"_id":"public/2017/12/04/Softmax回归模型/index.html","hash":"79efd2ff71ef4dcf4122b99772f3cc730e746809","modified":1547546348275},{"_id":"public/2017/12/04/逻辑回归模型/index.html","hash":"8e17f5e218a0d28461f44adddfe532f351b5ae55","modified":1547546348275},{"_id":"public/2017/12/03/线性回归模型/index.html","hash":"e2399381fe3349316d5bf71f9799d367ec5a0d0e","modified":1547546348275},{"_id":"public/2017/12/02/基本概念/index.html","hash":"acc7289b507c8aa8a428f8beadf639d3ed328b6b","modified":1547546348276},{"_id":"public/2017/12/01/剑指Offer解题记录/index.html","hash":"69c63dbf76799fe1f564fd2d33574021d7d02b72","modified":1547546348276},{"_id":"public/2017/11/29/排序算法/index.html","hash":"a25b4799d0f511cf0d222bf36066e9cd4de6c2d0","modified":1547546348276},{"_id":"public/2017/11/28/C++中const关键字总结/index.html","hash":"bdac6d6d2343fe8d3f61bf8d79dac47156b4086c","modified":1547546348276},{"_id":"public/2017/11/26/C++内存管理/index.html","hash":"4ebc1c7e22b9d28d1649b50658678d90e117ffdf","modified":1547546348276},{"_id":"public/2017/11/26/树/index.html","hash":"8fd8ce8a8d44534220498905501f56cfa6bcfba8","modified":1547546348276},{"_id":"public/2017/11/22/栈与队列/index.html","hash":"9d55ba4f50a99d39e05160f643d1a44effe5281a","modified":1547546348276},{"_id":"public/2017/11/21/线性表/index.html","hash":"be815542e0a20e7d5b9458c32688de973d609390","modified":1547546348276},{"_id":"public/archives/index.html","hash":"ecaa63d226f3cacdaf7d37407adc921b22a7ee67","modified":1547546348276},{"_id":"public/archives/page/2/index.html","hash":"e8eb01d776d29105c8b278f77a2efca60d1e70e1","modified":1547546348276},{"_id":"public/archives/page/3/index.html","hash":"a009467d751d9f5e5bc1ef78112de07dd8e5b790","modified":1547546348276},{"_id":"public/archives/page/4/index.html","hash":"5a54f73bc05f865182d4a5eb266af7ead51188bd","modified":1547546348276},{"_id":"public/archives/2017/index.html","hash":"3f926c783387f9ae61dc6b9416c1b6284bf7e4db","modified":1547546348276},{"_id":"public/archives/2017/page/2/index.html","hash":"998ff95fbb1a413c0cf18d995fa0a2729ba559b8","modified":1547546348276},{"_id":"public/archives/2017/page/3/index.html","hash":"f11d0461879bb26964427bcede0be303706f6b76","modified":1547546348276},{"_id":"public/archives/2017/11/index.html","hash":"cf23916dee9a78e2338b09bb486b301a01ffe3e6","modified":1547546348276},{"_id":"public/archives/2017/12/index.html","hash":"583fed5def3067c4efa22a211eb823f32ff88f44","modified":1547546348276},{"_id":"public/archives/2017/12/page/2/index.html","hash":"a4498a41a1d82b3888e7264040f43d391add94b1","modified":1547546348276},{"_id":"public/archives/2018/index.html","hash":"b4cf0b260a00cc0aae1e959de18947882f2142be","modified":1547546348276},{"_id":"public/archives/2018/01/index.html","hash":"cc9df2b70a41709f779ee097bd60b82f795ce938","modified":1547546348276},{"_id":"public/archives/2018/02/index.html","hash":"2119178469da82367b1771cc5afd5246ceb7467c","modified":1547546348277},{"_id":"public/archives/2018/12/index.html","hash":"c41dc820e7421b97185c2c0029558fbc9f73fe73","modified":1547546348277},{"_id":"public/archives/2019/index.html","hash":"492695cb5830a79839e82af43c964d828e38b873","modified":1547546348277},{"_id":"public/archives/2019/01/index.html","hash":"a383f1017569d3ec383c28d15c85e2a42eeca46d","modified":1547546348277},{"_id":"public/categories/机器学习/index.html","hash":"ef68cb2fccae3131d2e899daa3ebc89f78b9f84a","modified":1547546348277},{"_id":"public/categories/机器学习/page/2/index.html","hash":"fc9eca20bd16da802d22a99503867f767c900c43","modified":1547546348277},{"_id":"public/categories/轻量型CNN/index.html","hash":"84449ae727422f1020e74a699a32d961bfa53b41","modified":1547546348277},{"_id":"public/categories/语义分割/index.html","hash":"4fb6ffecdf3a9468b8e034755697feef8e4191ab","modified":1547546348277},{"_id":"public/categories/C-C/index.html","hash":"818cfe5943f1cf88301b70237c46c62f3dc1186c","modified":1547546348277},{"_id":"public/categories/数据结构与算法/index.html","hash":"788a17658455ca7bb3ade2349bd2c63858da299f","modified":1547546348277},{"_id":"public/categories/深度学习/index.html","hash":"52c338a40df5aae6e427da2cabf88ceb6c7e6b32","modified":1547546348277},{"_id":"public/categories/计算机基础/index.html","hash":"33d96c5a2e8c618d1c52eee8bd71c21336505897","modified":1547546348277},{"_id":"public/index.html","hash":"aee8969becc88607588e2b6c80edd55a38be0b9d","modified":1547546348277},{"_id":"public/page/2/index.html","hash":"0b06dcc4671ecebc022a0a4ba83976fa618e2ed1","modified":1547546348277},{"_id":"public/page/3/index.html","hash":"48a751ed90c5ca30c9d76300b2d246ca36d7ee26","modified":1547546348277},{"_id":"public/page/4/index.html","hash":"97f7e841f59854e2c5620de42ae0a60dbda19a40","modified":1547546348277},{"_id":"public/tags/Boosting/index.html","hash":"26d96a97fd6a372c412906f484bc22af573fc8c5","modified":1547546348277},{"_id":"public/tags/AdaBoost/index.html","hash":"28c1536fcb3c7c6be3e58684cbcc3d48e6cbebc2","modified":1547546348277},{"_id":"public/tags/C/index.html","hash":"06b9937bee125bda07c64524152c81ef13c0166f","modified":1547546348277},{"_id":"public/tags/内存管理/index.html","hash":"b59e35b8cf8d3aa8a815ff0e9c15982f09aec592","modified":1547546348277},{"_id":"public/tags/堆/index.html","hash":"9ddec962d03769aa4f0decfe996611ff3720aab9","modified":1547546348277},{"_id":"public/tags/栈/index.html","hash":"0de7d35ed38d611d70b9efc73aa1c7fda006c40d","modified":1547546348277},{"_id":"public/tags/自由存储区/index.html","hash":"4df5de7821db1313a76bb9c1f4aa541e2b8127e2","modified":1547546348277},{"_id":"public/tags/malloc/index.html","hash":"8487e3d0a3d00ee0aa0e264ce8fab5a0b8b2feda","modified":1547546348277},{"_id":"public/tags/free/index.html","hash":"836120e6640b39b8f724347680bf4ac2c9a9fc58","modified":1547546348277},{"_id":"public/tags/new/index.html","hash":"82c525fe04b9bc81c2a76419be293204184dbd1c","modified":1547546348277},{"_id":"public/tags/delete/index.html","hash":"fb3e62aa79a282c751829dbd4e992ca9e1fc6e9a","modified":1547546348278},{"_id":"public/tags/softmax/index.html","hash":"91915779a686c3b6e86a2094e0240b20624662c3","modified":1547546348278},{"_id":"public/tags/多分类/index.html","hash":"af20bc755ab9681189c855c907994b7d4c77eedb","modified":1547546348278},{"_id":"public/tags/机器学习/index.html","hash":"f592318e24255fbaab5ccd13e4f2721a1859d625","modified":1547546348278},{"_id":"public/tags/线性回归/index.html","hash":"60e89b1a7a7393567e8706b852b9fbc06c33120e","modified":1547546348278},{"_id":"public/tags/linear-regression/index.html","hash":"a053a77ea36546b4348eb825a8886cfcf879c001","modified":1547546348278},{"_id":"public/tags/似然估计/index.html","hash":"f13341050b6ce6d934e9a1ca4cb275df5f507572","modified":1547546348278},{"_id":"public/tags/梯度下降/index.html","hash":"b1fd75111791dc26e6d540f63842e18a2933f070","modified":1547546348278},{"_id":"public/tags/正规方程/index.html","hash":"182b9346cb69976793a1f19159fd661aebbf31db","modified":1547546348278},{"_id":"public/tags/正则化/index.html","hash":"df7210aa4d652feab24f61dcf775e8048c8a07e0","modified":1547546348278},{"_id":"public/tags/CART/index.html","hash":"482f4377c388045c071f37e84f29fd9f77a31303","modified":1547546348278},{"_id":"public/tags/二叉树/index.html","hash":"95b170bced1876ef4f1b897b6e2901fd724b18c3","modified":1547546348278},{"_id":"public/tags/回归树/index.html","hash":"e86df2c983cbe9071b914a00ab608e9bcafd24d3","modified":1547546348278},{"_id":"public/tags/分类树/index.html","hash":"6fff9a709867d2168c6b4d9cfbb7f58e0798c871","modified":1547546348278},{"_id":"public/tags/平方误差/index.html","hash":"2dc4745914c401c52f248e09e9ac6692a065d781","modified":1547546348278},{"_id":"public/tags/基尼指数/index.html","hash":"34abffeabfd9b9440dd8f702f6b4b0bd4f45652b","modified":1547546348278},{"_id":"public/tags/提升树/index.html","hash":"55cfbf265c5df34a4efe11a6c4c410fb70ecd646","modified":1547546348278},{"_id":"public/tags/梯度提升树/index.html","hash":"3d32941082bbc35ee360276d0ef9b6d9f784076d","modified":1547546348278},{"_id":"public/tags/GBDT/index.html","hash":"05a112d242c83087b496c30edd57815d294fa289","modified":1547546348278},{"_id":"public/tags/决策树/index.html","hash":"9a97e65d20adfe32ed159cb765bf6229b17edf29","modified":1547546348278},{"_id":"public/tags/ID3/index.html","hash":"58c87d164488c9f360dabdda8891c6ba77bf79fa","modified":1547546348278},{"_id":"public/tags/C4-5/index.html","hash":"9efc2572e0f7f86315f0e0e852268b7c6a511633","modified":1547546348278},{"_id":"public/tags/熵/index.html","hash":"c8c945e19936b9f3220d1a173b0464f825da464f","modified":1547546348278},{"_id":"public/tags/条件熵/index.html","hash":"65072846862c912a9aea0d26a4734ea5d71bef41","modified":1547546348278},{"_id":"public/tags/信息增益/index.html","hash":"85aec04e73ad240ed6b22dd071d0bdc2f30d796d","modified":1547546348278},{"_id":"public/tags/信息增益比/index.html","hash":"5a108a2349b7445a2a577a355fad860cfcd3cf2a","modified":1547546348279},{"_id":"public/tags/预剪枝/index.html","hash":"685ae2031e505f05a9b0fb65eb10943f736af6ab","modified":1547546348279},{"_id":"public/tags/后剪枝/index.html","hash":"5f999b95a49aa864de91e08ad76ef698005b5c5a","modified":1547546348279},{"_id":"public/tags/连续值/index.html","hash":"7b5953cda809bad3ba0a0ddec0da2aa2f6363da5","modified":1547546348279},{"_id":"public/tags/缺失值/index.html","hash":"f1b25abdb5ad059cd890babdb099dd7a7cc9779e","modified":1547546348279},{"_id":"public/tags/线性表/index.html","hash":"af9245c3c951f52dc086543e51e386e8d7137730","modified":1547546348279},{"_id":"public/tags/顺序存储结构/index.html","hash":"8716da952b9be072f300dcc73f13a455e0e9b981","modified":1547546348279},{"_id":"public/tags/数组/index.html","hash":"ca8ecc4bb412685726080c579e4681f73f0b6079","modified":1547546348279},{"_id":"public/tags/链式存储结构/index.html","hash":"cbc21c3ac787bb32c21a5e21e0a2ab74ac04c4fa","modified":1547546348279},{"_id":"public/tags/链表/index.html","hash":"0c7846350297d84efbc24b53e53cb52e2dd8013f","modified":1547546348279},{"_id":"public/tags/单链表/index.html","hash":"a7100383da017fd10b6369ee92cde8c43dc151ab","modified":1547546348279},{"_id":"public/tags/双向链表/index.html","hash":"d3f437d79dfba20e5f5f4f3d00eb50bd56b236fc","modified":1547546348279},{"_id":"public/tags/循环链表/index.html","hash":"f92237cfd6288a40d34d0b022562c9948638cb5e","modified":1547546348279},{"_id":"public/tags/逻辑回归/index.html","hash":"75ef41f1619b9883b7929d52d4dc45e9648aa94f","modified":1547546348279},{"_id":"public/tags/Logistic-Regression/index.html","hash":"4fdf5993f71ac000ca3df7e938711956cd7239c9","modified":1547546348279},{"_id":"public/tags/sigmoid函数/index.html","hash":"b8b95b02a67bcd994d6800f2175c810936cbcf11","modified":1547546348279},{"_id":"public/tags/决策边界/index.html","hash":"cfb1c993516e4006c8feb5a97f32bd6e99883805","modified":1547546348279},{"_id":"public/tags/const/index.html","hash":"a8883039d9bab8b1026fcd118e440e76e74576ab","modified":1547546348279},{"_id":"public/tags/const对象/index.html","hash":"8a1dff5674c5f1fcda68b04c860c37563abc569f","modified":1547546348279},{"_id":"public/tags/const引用/index.html","hash":"a2749922c44de31fb018a0b9d63a95879944809a","modified":1547546348279},{"_id":"public/tags/常引用/index.html","hash":"5ed84b2be0ba7b988fa194cbc3653e5fb205e794","modified":1547546348279},{"_id":"public/tags/const指针/index.html","hash":"6506e5ff35b834e14b4f87e9a52ada2983a83f08","modified":1547546348280},{"_id":"public/tags/常量指针/index.html","hash":"7e97a9442747a44fb4374491225ed46195cc6668","modified":1547546348280},{"_id":"public/tags/指针常量/index.html","hash":"79c1b2d9f8b67a0a1b6239167afc9fe7de5e2b27","modified":1547546348280},{"_id":"public/tags/常成员函数/index.html","hash":"16045d58196b8ab48bdc1ea065fecfb8ea9445cf","modified":1547546348280},{"_id":"public/tags/const成员函数/index.html","hash":"ee4cbafc0c2b3a1f70402c732ef72abfa662b7b3","modified":1547546348280},{"_id":"public/tags/函数重载/index.html","hash":"e65e0efcb2043a5aecfda2695ae9b6bd2c6d0d6a","modified":1547546348280},{"_id":"public/tags/队列/index.html","hash":"75d08eadab5589a34332ed83cbb5e8d6876b9468","modified":1547546348280},{"_id":"public/tags/线性可分支持向量机/index.html","hash":"2f8a312d241f735209315d0f0539f5dd3b4f171b","modified":1547546348280},{"_id":"public/tags/线性支持向量机/index.html","hash":"12bb648fe9209a7aeb5eba79517771ee4199bf73","modified":1547546348280},{"_id":"public/tags/非线性支持向量机/index.html","hash":"7693ac9abdc02dbf49a523b6deed66879ff5d06c","modified":1547546348280},{"_id":"public/tags/核函数/index.html","hash":"e79a3b6d7f86f116b00382281daec63919767f19","modified":1547546348280},{"_id":"public/tags/smo算法/index.html","hash":"90dbfa773b919a1eb7e02d57ea2f6cd5fca66950","modified":1547546348280},{"_id":"public/CNAME","hash":"1f1d60ea977704c7a3123e8b59859d18e48b19bb","modified":1547546348308},{"_id":"public/images/MobileNetV2/3.png","hash":"32b1490f6a7d9305f083601d46b326f0ccce8563","modified":1547546348308},{"_id":"public/images/MobileNetV2/4.png","hash":"34a9da935f09af38b20a635cfd10a60c15735be0","modified":1547546348308},{"_id":"public/images/MobileNetV2/5.png","hash":"88963b931fd589feb33eb23dfe4123955e1220dd","modified":1547546348308},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1547546348308},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1547546348308},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1547546348308},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1547546348308},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1547546348308},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1547546348309},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1547546348309},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1547546348309},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1547546348309},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1547546348309},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1547546348309},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1547546348309},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1547546348309},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1547546348309},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1547546348309},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1547546348309},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1547546348309},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1547546348309},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1547546348309},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1547546348309},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1547546348309},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1547546348309},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1547546348309},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1547546348309},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1547546348309},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1547546348310},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1547546348310},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1547546348310},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1547546348310},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1547546348310},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1547546348310},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1547546348310},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1547546348310},{"_id":"public/images/Depthwise Separable Convolution/2.png","hash":"54aa1afddd75a0daf6188585573d1f468f146cfa","modified":1547546348746},{"_id":"public/images/Depthwise Separable Convolution/3.png","hash":"e187726750b534adace09cc9d2ce5500f9e79324","modified":1547546348747},{"_id":"public/images/MobileNetV1/2.png","hash":"bd958ef0be582056de2b486ce666040b0244c02e","modified":1547546348748},{"_id":"public/images/MobileNetV1/3.png","hash":"ef9a1ff32bab84ed7376524045a157ef5ed61da1","modified":1547546348748},{"_id":"public/images/MobileNetV1/4.png","hash":"e5fcf2c7856fff1d093b8ab424fdaa6673c68470","modified":1547546348748},{"_id":"public/images/MobileNetV1/5.png","hash":"6f1bfb07c20594c17cbf96f69d464dbf46ad7125","modified":1547546348748},{"_id":"public/images/MobileNetV1/6.png","hash":"c1d3d6d3e46cc6ccb09397667e381816725a303d","modified":1547546348748},{"_id":"public/images/MobileNetV1/7.png","hash":"f3fca93ef55652063c78efc97a763e831a507ec2","modified":1547546348748},{"_id":"public/images/MobileNetV1/8.png","hash":"3afd780123310b2bc0d5a9e0cace31238afb365e","modified":1547546348748},{"_id":"public/images/ShuffleNetV1/4.png","hash":"d0ca27d624c0f7b46d273735c8c24c2405042e6d","modified":1547546348748},{"_id":"public/images/ShuffleNetV1/5.png","hash":"0fea01318670c3df04dd2f99874d24d83a856675","modified":1547546348748},{"_id":"public/images/ShuffleNetV2/2.png","hash":"aacc36e9b5b0c8f69a5c95d7432044ef8c0879b0","modified":1547546348749},{"_id":"public/images/ShuffleNetV2/3.png","hash":"4bd553fef3c71d9506f251a7da0e2955db3d608e","modified":1547546348749},{"_id":"public/images/ShuffleNetV2/4.png","hash":"2ebddcea4e3c5778022294fd47fa494a792efeab","modified":1547546348749},{"_id":"public/images/UNet/3.png","hash":"5c70185434fa16c1798b43eac3480f65e9320676","modified":1547546348749},{"_id":"public/images/ShuffleNetV2/5.png","hash":"1b4fd51677444af5e1cc326915b982cbef6860b7","modified":1547546348749},{"_id":"public/images/Xception/1.png","hash":"726e11fdc545c841da4f75d006a8fa1d6f77c564","modified":1547546348749},{"_id":"public/images/Xception/5.png","hash":"0c1038bc47fa2bcef0307ce60b7ae4a6485649e7","modified":1547546348749},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1547546348749},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1547546348749},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1547546348760},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1547546348760},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1547546348761},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1547546348761},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1547546348761},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1547546348761},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1547546348761},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1547546348761},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1547546348762},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1547546348762},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1547546348762},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1547546348762},{"_id":"public/lib/fastclick/README.html","hash":"d6e90449a2c09f3033f7e43d68b0cc8208e22e09","modified":1547546348762},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1547546348762},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1547546348762},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1547546348762},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1547546348762},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1547546348762},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1547546348762},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1547546348762},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1547546348762},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1547546348763},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1547546348763},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1547546348763},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1547546348763},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1547546348763},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1547546348763},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1547546348763},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1547546348763},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1547546348763},{"_id":"public/css/main.css","hash":"73eb5ca35c037abef51a9be713d7c412b0e49a12","modified":1547546348763},{"_id":"public/images/Depthwise Separable Convolution/1.png","hash":"95d0201688a01532636b0f4d56fa0fd60257e4af","modified":1547546348763},{"_id":"public/images/Depthwise Separable Convolution/4.png","hash":"d5a7ddd459f477fd7c6add7b80386ca98b2274f0","modified":1547546348763},{"_id":"public/images/FCN/3.png","hash":"b7ea23e3a89eef8f43f4d10019e1483d040dd6fa","modified":1547546348763},{"_id":"public/images/FCN/4.png","hash":"e2942c85c156c4d4632293a99f30b8f35992a32a","modified":1547546348763},{"_id":"public/images/MobileNetV2/1.png","hash":"b80d901617608776c91652bb4ef43a27d1e868e4","modified":1547546348763},{"_id":"public/images/MobileNetV2/7.png","hash":"30240afed3148a59da0479a443c3b6dd6a7f7d91","modified":1547546348763},{"_id":"public/images/ShuffleNetV1/7.png","hash":"e69c63aa7552d8ecdc14b5704c090242f29d0791","modified":1547546348763},{"_id":"public/images/ShuffleNetV1/8.png","hash":"a8bdfb058ee245b8e6754e07a6075d113462b100","modified":1547546348763},{"_id":"public/images/ShuffleNetV1/6.png","hash":"5e119f6b1e79bcc5c46cfeee6c517b2d634afb74","modified":1547546348764},{"_id":"public/images/ShuffleNetV2/1.png","hash":"eb2d3287f10d5267f4fc65c1a8495b01b9c752a6","modified":1547546348764},{"_id":"public/images/ShuffleNetV2/6.png","hash":"a5c691ad73965c588c4c6fab0953a7e5526a59b2","modified":1547546348764},{"_id":"public/images/ShuffleNetV2/7.png","hash":"995e01956cbad3703e8dc6dbbeb73f458b362ecf","modified":1547546348764},{"_id":"public/images/SqueezeNet/1.png","hash":"3c8e5c8d7458abb8991676679641b37b4e5813b7","modified":1547546348764},{"_id":"public/images/Xception/2.png","hash":"9f86c0c154f0c6ee9e56cda7c127f615f44bd42a","modified":1547546348764},{"_id":"public/images/Xception/4.png","hash":"1a0ccc86133a0e6dafb44318aaa6c1134a0196ba","modified":1547546348764},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1547546348764},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1547546348765},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1547546348765},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1547546348787},{"_id":"public/js/src/utils.js","hash":"dbdc3d1300eec7da9632608ebc0e5b697779dad7","modified":1547546348787},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1547546348788},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1547546348788},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1547546348788},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1547546348788},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1547546348788},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1547546348788},{"_id":"public/images/Depthwise Separable Convolution/5.png","hash":"3e148af8e4a7740f4475c6df40c856e82826ff56","modified":1547546348788},{"_id":"public/images/Depthwise Separable Convolution/7.png","hash":"8ff5c094e9f9f1922c223042c5669553492b50a1","modified":1547546348788},{"_id":"public/images/Depthwise Separable Convolution/8.png","hash":"1cf847ad79813541fb45b3e40cf14873853bf23b","modified":1547546348788},{"_id":"public/images/SegNet/4.png","hash":"e1603bcd1ebf55e1c619f3c5ecab050e9433588a","modified":1547546348789},{"_id":"public/images/SegNet/1.png","hash":"f85944b95fad17ed078d1886de73aabd874781aa","modified":1547546348789},{"_id":"public/images/ShuffleNetV1/1.png","hash":"d4153347d0fada203e4307ab4a0a52f4c7b62645","modified":1547546348789},{"_id":"public/images/SqueezeNet/4.png","hash":"fbee66744ed3c3dfdbd6247494654d1e3dae6f6d","modified":1547546348789},{"_id":"public/images/UNet/1.png","hash":"12a32b81f7722b22308521b419e11c5334c2d71e","modified":1547546348789},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1547546348799},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1547546348799},{"_id":"public/images/Depthwise Separable Convolution/6.png","hash":"2bb8911bb2731c3ca29cd2b6054d1902caf0bbf6","modified":1547546348800},{"_id":"public/images/MobileNetV2/2.png","hash":"e13d446eee187650ef618cbc5366e5a22ff044e6","modified":1547546348800},{"_id":"public/images/ShuffleNetV2/8.png","hash":"99e023a4ecb18451ab3aa93e269af57fec0274ac","modified":1547546348800},{"_id":"public/images/ShuffleNetV1/2.png","hash":"92ef09c44b7e3fc75fbac1103c3a5ccf14332370","modified":1547546348802},{"_id":"public/images/MobileNetV2/9.png","hash":"879f519238722224cb99cf7e8565a3195e56e21e","modified":1547546348802},{"_id":"public/images/ShuffleNetV1/3.png","hash":"b3364caa799f7afb33208192d2fd6248aa03ed4b","modified":1547546348802},{"_id":"public/images/MobileNetV1/1.png","hash":"42f422ea73182de175db2bde089a1993592abb27","modified":1547546348803},{"_id":"public/images/SqueezeNet/2.png","hash":"c9aa9a628a5e377fb07c472cb5121496032ea352","modified":1547546348803},{"_id":"public/images/MobileNetV2/6.png","hash":"341e4915a0c2c03ab4569e61f5d7933c0c66665c","modified":1547546348803},{"_id":"public/images/SqueezeNet/3.png","hash":"0015128e8122fe10aebb0bf125bf45807d0bb527","modified":1547546348804},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1547546348811},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1547546348812},{"_id":"public/images/MobileNetV2/8.png","hash":"df3c74208a871b3a81a2d00d74fcd928c510ded3","modified":1547546348815},{"_id":"public/images/SegNet/3.png","hash":"f1c6e556098c380c3baef9b814c455297451f398","modified":1547546348815},{"_id":"public/images/UNet/2.png","hash":"aadb3e83223177abb4b0addf7271b92b27d7a41c","modified":1547546348815},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1547546348831},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1547546348831},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1547546348832},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1547546348832},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1547546348832},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1547546348832},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1547546348832},{"_id":"public/images/Xception/3.png","hash":"44b8281ccc2298d7f3844ea4c8048ccfc00086a4","modified":1547546348832},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1547546348832},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1547546348841},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1547546348841},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1547546348841},{"_id":"public/images/FCN/1.png","hash":"c600b6703f2b71cf74ff2d089c693a504619ec78","modified":1547546348841},{"_id":"public/images/SegNet/2.png","hash":"c5b5a06aa66ebc02624b1ab5f5e61f6b4f4cc0ed","modified":1547546348841},{"_id":"public/images/FCN/2.png","hash":"f9b3b0706883c63730b54398489e09400a750977","modified":1547546348842},{"_id":"public/uploads/me.jpg","hash":"e45dafeab49d152abe73de394401c3f1e8448748","modified":1547546348842},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1547546348845},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1547546348852},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1547546348854},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1547546348856},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1547546348862},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1547546348865}],"Category":[{"name":"机器学习","_id":"cjqxl4vur0004qslpfndmvizt"},{"name":"轻量型CNN","_id":"cjqxl4vv0000aqslprqpg4etn"},{"name":"语义分割","_id":"cjqxl4vva000mqslpgbfqyu2a"},{"name":"C/C++","_id":"cjqxl4vvd000sqslpfogvbgpt"},{"name":"数据结构与算法","_id":"cjqxl4w0b002xqslp1xp57vmp"},{"name":"深度学习","_id":"cjqxl4w2r005wqslp8x8k5dbd"},{"name":"计算机基础","_id":"cjqxl4w47006bqslp3ictv36t"}],"Data":[],"Page":[{"title":"关于我","date":"2017-11-21T01:03:23.000Z","_content":"  \n  None\n\n\n","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2017-11-21 09:03:23\n---\n  \n  None\n\n\n","updated":"2019-01-03T07:36:59.967Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjqxl4vul0001qslppx78jda8","content":"<p>  None</p>\n","site":{"data":{}},"excerpt":"","more":"<p>  None</p>\n"},{"title":"文章分类","date":"2017-11-20T07:12:58.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章分类\ndate: 2017-11-20 15:12:58\ntype: \"categories\"\n---\n","updated":"2017-12-05T07:39:50.318Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjqxl4vup0003qslpyoacm2rf","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2017-11-20T07:18:22.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2017-11-20 15:18:22\ntype: \"tags\"\n---\n","updated":"2017-12-05T07:40:34.839Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjqxl4vux0007qslpdh0r6dey","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"AdaBoost算法","mathjax":true,"top":true,"date":"2017-12-13T01:12:50.000Z","_content":"## 一、集成学习\n　　**集成学习**(ensemble learning)通过构建并结合多个学习器来完成学习任务。根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，一类为个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表为**Boosting**；一类为个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表为**Bagging和随机森林**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/%E6%A0%91%E7%9A%84%E5%8E%86%E5%8F%B2.JPG\" width=\"70%\" height=\"70%\"> 　　Boosting是一族可将弱学习器提升为强学习器的算法。Boosting族算法最著名的代表是AdaBoost。本文主要记录AdaBoost算法。\n<!-- more --> \n## 二、AdaBoost简介\n　　（1）AdaBoost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）；\n　　（2）AdaBoost在每一轮**如何改变训练数据的权值或概率分布**以及**如何将弱分类器组合成一个强分类器**的做法如下：\n- 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注；\n- AdaBoost采用加权多数表决的方法，具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。\n\n## 三、AdaBoost算法\n　　现叙述AdaBoost算法。假设给定一个二分类的训练数据集\n$$T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$$\n　　其中，每个样本点由实例与标记组成。实例$x_i\\in X\\in R^n$，标记`$y_i\\in Y=\\{-1,+1\\}$`，$X$是实例空间，$Y$是标记集合。AdaBoost利用以下算法，从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成为一个强分类器。\n**算法（AdaBoost）**\n**输入**：训练数据集$T$；弱学习算法\n**输出**：最终分类器$G(x)$\n**步骤1**.初始化训练数据的权值分布：\n$$D_1=(w_{11},...,w_{1i},...,w_{1N})，w_{1i}=\\frac{1}{N},i=1,2,...,N$$\n**说明**：假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同，这一假设保证第1步能够在原始数据上学习基本分类器$G_1(x)$.\n**步骤2**.AdaBoost反复学习基本分类器，在每一轮$m=1,2,...,M$顺次地执行下列操作：\n（a）使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$：\n$$G_m(x):X\\rightarrow \\{-1,+1\\}$$\n（b）计算基本分类器$G_m(x)$在加权训练数据集上的分类误差率：\n$$e_m=\\sum_{i=1}^{N}P(G_m(x_i)\\neq y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i)\\neq y_i)$$\n**说明**：这里，`$w_{mi}$`表示第$m$轮中第`$i$`个实例的权值，`$\\sum_{i=1}^{N}w_{mi}=1$`。这表明，**$G_m(x)$在加权的训练数据集上的分类误差率是被$G_m(x)$误分类样本的权值之和**，由此可以看出数据权值分布$D_m$与基本分类器$G_m(x)$的分类误差率的关系。\n（c）计算基本分类器$G_m(x)$的系数$\\alpha_m$（**分类误差率越小，权值越大**）:\n$$\\alpha_m=\\frac{1}{2}log(\\frac{1-e_m}{e_m})$$\n这里的对数是自然对数。\n**说明**：$\\alpha_m$表示$G_m(x)$在最终分类器中的重要性。由上式可知，当$e_m\\leq \\frac{1}{2}$时，$\\alpha_m\\geq 0$，并且$\\alpha_m$随着$e_m$的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。\n（d）更新训练数据集的权值分布：\n$$D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})$$\n$$w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),i=1,2,...,N$$\n可简化写成：\n$$w_{m+1,i}=\\left\\{\\begin{matrix}   \\frac{w_{mi}}{Z_m}e^{-\\alpha_m} ,&        G_m\\left(x_i\\right)=y_i\\\\   \\frac{w_{mi}}{Z_m}e^{\\alpha_m} ,&        G_m\\left(x_i\\right)\\ne y_i\\\\ \\end{matrix}\\right.$$\n这里，$Z_m$是规范化因子\n$$Z_m=\\sum_{i=1}^{N}w_{mi}exp(-\\alpha_my_iG_m(x_i))$$\n它使$D_{m+1}$成为一个概率分布。\n**说明**：被基本分类器$G_m(x)$误分类样本的权值得以扩大($\\alpha_m\\geq 0$,$e^{\\alpha_m}\\geq1$,乘以一个大于等于1的数)，而被正确分类样本的权值却得以缩小($\\alpha_m\\geq 0$,$0 \\leq e^{-\\alpha_m}\\leq1$,乘以一个大于0小于1的数)。因此，误分类样本在下一轮学习中起更大的作用。**不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点**。\n**步骤3**.构建基本分类器的线性组合：\n$$f(x)=\\sum_{m=1}^{M}\\alpha_mG_m(x)$$\n得到最终分类器：\n$$G(x)=sign(f(x))=sign(\\sum_{m=1}^{M}\\alpha_mG_m(x))$$\n**说明**：线性组合$f(x)$实现$M$个基本分类器的加权表决。系数$\\alpha_m$表示了基本分类器$G_m(x)$的重要性，这里，所有$\\alpha_m$之和不为1。$f(x)$的符号决定实例$x$的类，$f(x)$的绝对值表示分类的确信度。**利用基本分类器的线性组合构建最终分类器是AdaBoost的另一特点**。\n注1：AdaBoost模型可以看成模型为加法模型，损失函数为指数函数，学习算法为前向分步算法的二分类学习方法。\n注2：可以看出标准的AdaBoost模型只支持二分类问题。\n注3：做统计学习方法的例题和[Mit的例题](https://www.youtube.com/watch?v=gmok1h8wG-Q)，可以更好的理解。\n\n## 四、参考资料\n- 李航，统计学习方法\n- 周志华，机器学习\n- [MIT, Boosting(Adaboost)](https://www.youtube.com/watch?v=gmok1h8wG-Q)\n\n\n\n\n\n\n\n\n\n","source":"_posts/Adaboost算法.md","raw":"---\ntitle: AdaBoost算法\nmathjax: true\ntop: true\ndate: 2017-12-13 9:12:50\ncategories: \n- 机器学习\ntags:\n- Boosting\n- AdaBoost\n---\n## 一、集成学习\n　　**集成学习**(ensemble learning)通过构建并结合多个学习器来完成学习任务。根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，一类为个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表为**Boosting**；一类为个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表为**Bagging和随机森林**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/%E6%A0%91%E7%9A%84%E5%8E%86%E5%8F%B2.JPG\" width=\"70%\" height=\"70%\"> 　　Boosting是一族可将弱学习器提升为强学习器的算法。Boosting族算法最著名的代表是AdaBoost。本文主要记录AdaBoost算法。\n<!-- more --> \n## 二、AdaBoost简介\n　　（1）AdaBoost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）；\n　　（2）AdaBoost在每一轮**如何改变训练数据的权值或概率分布**以及**如何将弱分类器组合成一个强分类器**的做法如下：\n- 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注；\n- AdaBoost采用加权多数表决的方法，具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。\n\n## 三、AdaBoost算法\n　　现叙述AdaBoost算法。假设给定一个二分类的训练数据集\n$$T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$$\n　　其中，每个样本点由实例与标记组成。实例$x_i\\in X\\in R^n$，标记`$y_i\\in Y=\\{-1,+1\\}$`，$X$是实例空间，$Y$是标记集合。AdaBoost利用以下算法，从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成为一个强分类器。\n**算法（AdaBoost）**\n**输入**：训练数据集$T$；弱学习算法\n**输出**：最终分类器$G(x)$\n**步骤1**.初始化训练数据的权值分布：\n$$D_1=(w_{11},...,w_{1i},...,w_{1N})，w_{1i}=\\frac{1}{N},i=1,2,...,N$$\n**说明**：假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同，这一假设保证第1步能够在原始数据上学习基本分类器$G_1(x)$.\n**步骤2**.AdaBoost反复学习基本分类器，在每一轮$m=1,2,...,M$顺次地执行下列操作：\n（a）使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$：\n$$G_m(x):X\\rightarrow \\{-1,+1\\}$$\n（b）计算基本分类器$G_m(x)$在加权训练数据集上的分类误差率：\n$$e_m=\\sum_{i=1}^{N}P(G_m(x_i)\\neq y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i)\\neq y_i)$$\n**说明**：这里，`$w_{mi}$`表示第$m$轮中第`$i$`个实例的权值，`$\\sum_{i=1}^{N}w_{mi}=1$`。这表明，**$G_m(x)$在加权的训练数据集上的分类误差率是被$G_m(x)$误分类样本的权值之和**，由此可以看出数据权值分布$D_m$与基本分类器$G_m(x)$的分类误差率的关系。\n（c）计算基本分类器$G_m(x)$的系数$\\alpha_m$（**分类误差率越小，权值越大**）:\n$$\\alpha_m=\\frac{1}{2}log(\\frac{1-e_m}{e_m})$$\n这里的对数是自然对数。\n**说明**：$\\alpha_m$表示$G_m(x)$在最终分类器中的重要性。由上式可知，当$e_m\\leq \\frac{1}{2}$时，$\\alpha_m\\geq 0$，并且$\\alpha_m$随着$e_m$的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。\n（d）更新训练数据集的权值分布：\n$$D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})$$\n$$w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),i=1,2,...,N$$\n可简化写成：\n$$w_{m+1,i}=\\left\\{\\begin{matrix}   \\frac{w_{mi}}{Z_m}e^{-\\alpha_m} ,&        G_m\\left(x_i\\right)=y_i\\\\   \\frac{w_{mi}}{Z_m}e^{\\alpha_m} ,&        G_m\\left(x_i\\right)\\ne y_i\\\\ \\end{matrix}\\right.$$\n这里，$Z_m$是规范化因子\n$$Z_m=\\sum_{i=1}^{N}w_{mi}exp(-\\alpha_my_iG_m(x_i))$$\n它使$D_{m+1}$成为一个概率分布。\n**说明**：被基本分类器$G_m(x)$误分类样本的权值得以扩大($\\alpha_m\\geq 0$,$e^{\\alpha_m}\\geq1$,乘以一个大于等于1的数)，而被正确分类样本的权值却得以缩小($\\alpha_m\\geq 0$,$0 \\leq e^{-\\alpha_m}\\leq1$,乘以一个大于0小于1的数)。因此，误分类样本在下一轮学习中起更大的作用。**不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点**。\n**步骤3**.构建基本分类器的线性组合：\n$$f(x)=\\sum_{m=1}^{M}\\alpha_mG_m(x)$$\n得到最终分类器：\n$$G(x)=sign(f(x))=sign(\\sum_{m=1}^{M}\\alpha_mG_m(x))$$\n**说明**：线性组合$f(x)$实现$M$个基本分类器的加权表决。系数$\\alpha_m$表示了基本分类器$G_m(x)$的重要性，这里，所有$\\alpha_m$之和不为1。$f(x)$的符号决定实例$x$的类，$f(x)$的绝对值表示分类的确信度。**利用基本分类器的线性组合构建最终分类器是AdaBoost的另一特点**。\n注1：AdaBoost模型可以看成模型为加法模型，损失函数为指数函数，学习算法为前向分步算法的二分类学习方法。\n注2：可以看出标准的AdaBoost模型只支持二分类问题。\n注3：做统计学习方法的例题和[Mit的例题](https://www.youtube.com/watch?v=gmok1h8wG-Q)，可以更好的理解。\n\n## 四、参考资料\n- 李航，统计学习方法\n- 周志华，机器学习\n- [MIT, Boosting(Adaboost)](https://www.youtube.com/watch?v=gmok1h8wG-Q)\n\n\n\n\n\n\n\n\n\n","slug":"Adaboost算法","published":1,"updated":"2018-02-23T07:58:35.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vuf0000qslpvhrt3q3n","content":"<h2 id=\"一、集成学习\"><a href=\"#一、集成学习\" class=\"headerlink\" title=\"一、集成学习\"></a>一、集成学习</h2><p>　　<strong>集成学习</strong>(ensemble learning)通过构建并结合多个学习器来完成学习任务。根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，一类为个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表为<strong>Boosting</strong>；一类为个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表为<strong>Bagging和随机森林</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/%E6%A0%91%E7%9A%84%E5%8E%86%E5%8F%B2.JPG\" width=\"70%\" height=\"70%\"> 　　Boosting是一族可将弱学习器提升为强学习器的算法。Boosting族算法最著名的代表是AdaBoost。本文主要记录AdaBoost算法。<br><a id=\"more\"></a> </p>\n<h2 id=\"二、AdaBoost简介\"><a href=\"#二、AdaBoost简介\" class=\"headerlink\" title=\"二、AdaBoost简介\"></a>二、AdaBoost简介</h2><p>　　（1）AdaBoost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）；<br>　　（2）AdaBoost在每一轮<strong>如何改变训练数据的权值或概率分布</strong>以及<strong>如何将弱分类器组合成一个强分类器</strong>的做法如下：</p>\n<ul>\n<li>提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注；</li>\n<li>AdaBoost采用加权多数表决的方法，具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</li>\n</ul>\n<h2 id=\"三、AdaBoost算法\"><a href=\"#三、AdaBoost算法\" class=\"headerlink\" title=\"三、AdaBoost算法\"></a>三、AdaBoost算法</h2><p>　　现叙述AdaBoost算法。假设给定一个二分类的训练数据集</p>\n<script type=\"math/tex; mode=display\">T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}</script><p>　　其中，每个样本点由实例与标记组成。实例$x_i\\in X\\in R^n$，标记<script type=\"math/tex\">y_i\\in Y=\\{-1,+1\\}</script>，$X$是实例空间，$Y$是标记集合。AdaBoost利用以下算法，从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成为一个强分类器。<br><strong>算法（AdaBoost）</strong><br><strong>输入</strong>：训练数据集$T$；弱学习算法<br><strong>输出</strong>：最终分类器$G(x)$<br><strong>步骤1</strong>.初始化训练数据的权值分布：</p>\n<script type=\"math/tex; mode=display\">D_1=(w_{11},...,w_{1i},...,w_{1N})，w_{1i}=\\frac{1}{N},i=1,2,...,N</script><p><strong>说明</strong>：假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同，这一假设保证第1步能够在原始数据上学习基本分类器$G_1(x)$.<br><strong>步骤2</strong>.AdaBoost反复学习基本分类器，在每一轮$m=1,2,…,M$顺次地执行下列操作：<br>（a）使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$：</p>\n<script type=\"math/tex; mode=display\">G_m(x):X\\rightarrow \\{-1,+1\\}</script><p>（b）计算基本分类器$G_m(x)$在加权训练数据集上的分类误差率：</p>\n<script type=\"math/tex; mode=display\">e_m=\\sum_{i=1}^{N}P(G_m(x_i)\\neq y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i)\\neq y_i)</script><p><strong>说明</strong>：这里，<script type=\"math/tex\">w_{mi}</script>表示第$m$轮中第<script type=\"math/tex\">i</script>个实例的权值，<script type=\"math/tex\">\\sum_{i=1}^{N}w_{mi}=1</script>。这表明，<strong>$G_m(x)$在加权的训练数据集上的分类误差率是被$G_m(x)$误分类样本的权值之和</strong>，由此可以看出数据权值分布$D_m$与基本分类器$G_m(x)$的分类误差率的关系。<br>（c）计算基本分类器$G_m(x)$的系数$\\alpha_m$（<strong>分类误差率越小，权值越大</strong>）:</p>\n<script type=\"math/tex; mode=display\">\\alpha_m=\\frac{1}{2}log(\\frac{1-e_m}{e_m})</script><p>这里的对数是自然对数。<br><strong>说明</strong>：$\\alpha_m$表示$G_m(x)$在最终分类器中的重要性。由上式可知，当$e_m\\leq \\frac{1}{2}$时，$\\alpha_m\\geq 0$，并且$\\alpha_m$随着$e_m$的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。<br>（d）更新训练数据集的权值分布：</p>\n<script type=\"math/tex; mode=display\">D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})</script><script type=\"math/tex; mode=display\">w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),i=1,2,...,N</script><p>可简化写成：</p>\n<script type=\"math/tex; mode=display\">w_{m+1,i}=\\left\\{\\begin{matrix}   \\frac{w_{mi}}{Z_m}e^{-\\alpha_m} ,&        G_m\\left(x_i\\right)=y_i\\\\   \\frac{w_{mi}}{Z_m}e^{\\alpha_m} ,&        G_m\\left(x_i\\right)\\ne y_i\\\\ \\end{matrix}\\right.</script><p>这里，$Z_m$是规范化因子</p>\n<script type=\"math/tex; mode=display\">Z_m=\\sum_{i=1}^{N}w_{mi}exp(-\\alpha_my_iG_m(x_i))</script><p>它使$D_{m+1}$成为一个概率分布。<br><strong>说明</strong>：被基本分类器$G_m(x)$误分类样本的权值得以扩大($\\alpha_m\\geq 0$,$e^{\\alpha_m}\\geq1$,乘以一个大于等于1的数)，而被正确分类样本的权值却得以缩小($\\alpha_m\\geq 0$,$0 \\leq e^{-\\alpha_m}\\leq1$,乘以一个大于0小于1的数)。因此，误分类样本在下一轮学习中起更大的作用。<strong>不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点</strong>。<br><strong>步骤3</strong>.构建基本分类器的线性组合：</p>\n<script type=\"math/tex; mode=display\">f(x)=\\sum_{m=1}^{M}\\alpha_mG_m(x)</script><p>得到最终分类器：</p>\n<script type=\"math/tex; mode=display\">G(x)=sign(f(x))=sign(\\sum_{m=1}^{M}\\alpha_mG_m(x))</script><p><strong>说明</strong>：线性组合$f(x)$实现$M$个基本分类器的加权表决。系数$\\alpha_m$表示了基本分类器$G_m(x)$的重要性，这里，所有$\\alpha_m$之和不为1。$f(x)$的符号决定实例$x$的类，$f(x)$的绝对值表示分类的确信度。<strong>利用基本分类器的线性组合构建最终分类器是AdaBoost的另一特点</strong>。<br>注1：AdaBoost模型可以看成模型为加法模型，损失函数为指数函数，学习算法为前向分步算法的二分类学习方法。<br>注2：可以看出标准的AdaBoost模型只支持二分类问题。<br>注3：做统计学习方法的例题和<a href=\"https://www.youtube.com/watch?v=gmok1h8wG-Q\" target=\"_blank\" rel=\"noopener\">Mit的例题</a>，可以更好的理解。</p>\n<h2 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h2><ul>\n<li>李航，统计学习方法</li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/watch?v=gmok1h8wG-Q\" target=\"_blank\" rel=\"noopener\">MIT, Boosting(Adaboost)</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"一、集成学习\"><a href=\"#一、集成学习\" class=\"headerlink\" title=\"一、集成学习\"></a>一、集成学习</h2><p>　　<strong>集成学习</strong>(ensemble learning)通过构建并结合多个学习器来完成学习任务。根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，一类为个体学习器间存在强依赖关系、必须串行生成的序列化方法，代表为<strong>Boosting</strong>；一类为个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表为<strong>Bagging和随机森林</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95/%E6%A0%91%E7%9A%84%E5%8E%86%E5%8F%B2.JPG\" width=\"70%\" height=\"70%\"> 　　Boosting是一族可将弱学习器提升为强学习器的算法。Boosting族算法最著名的代表是AdaBoost。本文主要记录AdaBoost算法。<br>","more":"</p>\n<h2 id=\"二、AdaBoost简介\"><a href=\"#二、AdaBoost简介\" class=\"headerlink\" title=\"二、AdaBoost简介\"></a>二、AdaBoost简介</h2><p>　　（1）AdaBoost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）；<br>　　（2）AdaBoost在每一轮<strong>如何改变训练数据的权值或概率分布</strong>以及<strong>如何将弱分类器组合成一个强分类器</strong>的做法如下：</p>\n<ul>\n<li>提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注；</li>\n<li>AdaBoost采用加权多数表决的方法，具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。</li>\n</ul>\n<h2 id=\"三、AdaBoost算法\"><a href=\"#三、AdaBoost算法\" class=\"headerlink\" title=\"三、AdaBoost算法\"></a>三、AdaBoost算法</h2><p>　　现叙述AdaBoost算法。假设给定一个二分类的训练数据集</p>\n<script type=\"math/tex; mode=display\">T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}</script><p>　　其中，每个样本点由实例与标记组成。实例$x_i\\in X\\in R^n$，标记<script type=\"math/tex\">y_i\\in Y=\\{-1,+1\\}</script>，$X$是实例空间，$Y$是标记集合。AdaBoost利用以下算法，从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成为一个强分类器。<br><strong>算法（AdaBoost）</strong><br><strong>输入</strong>：训练数据集$T$；弱学习算法<br><strong>输出</strong>：最终分类器$G(x)$<br><strong>步骤1</strong>.初始化训练数据的权值分布：</p>\n<script type=\"math/tex; mode=display\">D_1=(w_{11},...,w_{1i},...,w_{1N})，w_{1i}=\\frac{1}{N},i=1,2,...,N</script><p><strong>说明</strong>：假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同，这一假设保证第1步能够在原始数据上学习基本分类器$G_1(x)$.<br><strong>步骤2</strong>.AdaBoost反复学习基本分类器，在每一轮$m=1,2,…,M$顺次地执行下列操作：<br>（a）使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$：</p>\n<script type=\"math/tex; mode=display\">G_m(x):X\\rightarrow \\{-1,+1\\}</script><p>（b）计算基本分类器$G_m(x)$在加权训练数据集上的分类误差率：</p>\n<script type=\"math/tex; mode=display\">e_m=\\sum_{i=1}^{N}P(G_m(x_i)\\neq y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i)\\neq y_i)</script><p><strong>说明</strong>：这里，<script type=\"math/tex\">w_{mi}</script>表示第$m$轮中第<script type=\"math/tex\">i</script>个实例的权值，<script type=\"math/tex\">\\sum_{i=1}^{N}w_{mi}=1</script>。这表明，<strong>$G_m(x)$在加权的训练数据集上的分类误差率是被$G_m(x)$误分类样本的权值之和</strong>，由此可以看出数据权值分布$D_m$与基本分类器$G_m(x)$的分类误差率的关系。<br>（c）计算基本分类器$G_m(x)$的系数$\\alpha_m$（<strong>分类误差率越小，权值越大</strong>）:</p>\n<script type=\"math/tex; mode=display\">\\alpha_m=\\frac{1}{2}log(\\frac{1-e_m}{e_m})</script><p>这里的对数是自然对数。<br><strong>说明</strong>：$\\alpha_m$表示$G_m(x)$在最终分类器中的重要性。由上式可知，当$e_m\\leq \\frac{1}{2}$时，$\\alpha_m\\geq 0$，并且$\\alpha_m$随着$e_m$的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。<br>（d）更新训练数据集的权值分布：</p>\n<script type=\"math/tex; mode=display\">D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})</script><script type=\"math/tex; mode=display\">w_{m+1,i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i)),i=1,2,...,N</script><p>可简化写成：</p>\n<script type=\"math/tex; mode=display\">w_{m+1,i}=\\left\\{\\begin{matrix}   \\frac{w_{mi}}{Z_m}e^{-\\alpha_m} ,&        G_m\\left(x_i\\right)=y_i\\\\   \\frac{w_{mi}}{Z_m}e^{\\alpha_m} ,&        G_m\\left(x_i\\right)\\ne y_i\\\\ \\end{matrix}\\right.</script><p>这里，$Z_m$是规范化因子</p>\n<script type=\"math/tex; mode=display\">Z_m=\\sum_{i=1}^{N}w_{mi}exp(-\\alpha_my_iG_m(x_i))</script><p>它使$D_{m+1}$成为一个概率分布。<br><strong>说明</strong>：被基本分类器$G_m(x)$误分类样本的权值得以扩大($\\alpha_m\\geq 0$,$e^{\\alpha_m}\\geq1$,乘以一个大于等于1的数)，而被正确分类样本的权值却得以缩小($\\alpha_m\\geq 0$,$0 \\leq e^{-\\alpha_m}\\leq1$,乘以一个大于0小于1的数)。因此，误分类样本在下一轮学习中起更大的作用。<strong>不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这是AdaBoost的一个特点</strong>。<br><strong>步骤3</strong>.构建基本分类器的线性组合：</p>\n<script type=\"math/tex; mode=display\">f(x)=\\sum_{m=1}^{M}\\alpha_mG_m(x)</script><p>得到最终分类器：</p>\n<script type=\"math/tex; mode=display\">G(x)=sign(f(x))=sign(\\sum_{m=1}^{M}\\alpha_mG_m(x))</script><p><strong>说明</strong>：线性组合$f(x)$实现$M$个基本分类器的加权表决。系数$\\alpha_m$表示了基本分类器$G_m(x)$的重要性，这里，所有$\\alpha_m$之和不为1。$f(x)$的符号决定实例$x$的类，$f(x)$的绝对值表示分类的确信度。<strong>利用基本分类器的线性组合构建最终分类器是AdaBoost的另一特点</strong>。<br>注1：AdaBoost模型可以看成模型为加法模型，损失函数为指数函数，学习算法为前向分步算法的二分类学习方法。<br>注2：可以看出标准的AdaBoost模型只支持二分类问题。<br>注3：做统计学习方法的例题和<a href=\"https://www.youtube.com/watch?v=gmok1h8wG-Q\" target=\"_blank\" rel=\"noopener\">Mit的例题</a>，可以更好的理解。</p>\n<h2 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h2><ul>\n<li>李航，统计学习方法</li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/watch?v=gmok1h8wG-Q\" target=\"_blank\" rel=\"noopener\">MIT, Boosting(Adaboost)</a></li>\n</ul>"},{"title":"Depthwise Separable Convolution","mathjax":true,"date":"2018-12-29T14:20:50.000Z","_content":"\n# 常规卷积\n**示例**：\n<img src=\"/images/Depthwise Separable Convolution/1.png\"  width = \"600\"/>\n\n- 上图为常规卷积示例，假设步长为1，same填充：\n - 单个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$\n - $N$个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times N$\n<!-- more -->\n\n**计算量**：\n<img src=\"/images/Depthwise Separable Convolution/2.png\"  width = \"600\"/>\n\n- 上图为常规卷积的计算量：\n - 单个核($D_k \\times D_k \\times M$)单次的乘法次数为${D_k}^2 \\times M$\n - 单个核($D_k \\times D_k \\times M$)的总体乘法次数为${D_G}^2 \\times {D_k}^2 \\times M$\n - $N$个核($D_k \\times D_k \\times M$)的总体乘法次数为$N \\times {D_G}^2 \\times {D_k}^2 \\times M$\n\n# 深度可分离卷积\n<img src=\"/images/Depthwise Separable Convolution/3.png\"  width = \"600\"/>\n\n- The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel. \n- The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new features through computing linear combinations of the input channels.\n- 上两段话摘自[MobileNetV2](https://arxiv.org/pdf/1801.04381.pdf)。\n \n**depthwise convolution**：\n<img src=\"/images/Depthwise Separable Convolution/4.png\"  width = \"600\"/>\n- 上图为depthwise convolution示例图，假设步长为1，same填充：\n - 单个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times 1$（只对输入的一个通道进行操作）\n - $M$个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times M$（每个核对输入的一个通道进行操作）\n\n**pointwise convolution**：\n<img src=\"/images/Depthwise Separable Convolution/5.png\"  width = \"600\"/>\n- 注：图中的Filtering Stage应改为Combination Stage\n- 上图为pointwise convolution的示例图，假设步长为1，same填充：\n - 单个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$\n - $M$个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times M$\n - 就是$1\\times1 $卷积\n\n**计算量**：\n<img src=\"/images/Depthwise Separable Convolution/6.png\"  width = \"600\"/>\n\n# 常规卷积与深度可分离卷积的计算量对比\n<img src=\"/images/Depthwise Separable Convolution/7.png\"  width = \"600\"/>\n- 以$N=1024$, $D_k=3$为例：\n - 深度可分离卷积的计算量约为常规卷积的$\\frac{1}{10}$\n\n# 常规卷积与深度可分离卷积的参数个数对比\n<img src=\"/images/Depthwise Separable Convolution/8.png\"  width = \"600\"/>\n- 参数个数对比同计算量对比\n\n# 参考文献\n- [视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!](https://www.youtube.com/watch?v=T7o3xvJLuHk&t=0s&list=LLPZqbzAbJOX-hE-IRAxB7sg&index=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Depthwise Separable Convolution.md","raw":"---\ntitle: Depthwise Separable Convolution\nmathjax: true\ndate: 2018-12-29 22:20:50\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 常规卷积\n**示例**：\n<img src=\"/images/Depthwise Separable Convolution/1.png\"  width = \"600\"/>\n\n- 上图为常规卷积示例，假设步长为1，same填充：\n - 单个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$\n - $N$个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times N$\n<!-- more -->\n\n**计算量**：\n<img src=\"/images/Depthwise Separable Convolution/2.png\"  width = \"600\"/>\n\n- 上图为常规卷积的计算量：\n - 单个核($D_k \\times D_k \\times M$)单次的乘法次数为${D_k}^2 \\times M$\n - 单个核($D_k \\times D_k \\times M$)的总体乘法次数为${D_G}^2 \\times {D_k}^2 \\times M$\n - $N$个核($D_k \\times D_k \\times M$)的总体乘法次数为$N \\times {D_G}^2 \\times {D_k}^2 \\times M$\n\n# 深度可分离卷积\n<img src=\"/images/Depthwise Separable Convolution/3.png\"  width = \"600\"/>\n\n- The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel. \n- The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new features through computing linear combinations of the input channels.\n- 上两段话摘自[MobileNetV2](https://arxiv.org/pdf/1801.04381.pdf)。\n \n**depthwise convolution**：\n<img src=\"/images/Depthwise Separable Convolution/4.png\"  width = \"600\"/>\n- 上图为depthwise convolution示例图，假设步长为1，same填充：\n - 单个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times 1$（只对输入的一个通道进行操作）\n - $M$个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times M$（每个核对输入的一个通道进行操作）\n\n**pointwise convolution**：\n<img src=\"/images/Depthwise Separable Convolution/5.png\"  width = \"600\"/>\n- 注：图中的Filtering Stage应改为Combination Stage\n- 上图为pointwise convolution的示例图，假设步长为1，same填充：\n - 单个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$\n - $M$个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times M$\n - 就是$1\\times1 $卷积\n\n**计算量**：\n<img src=\"/images/Depthwise Separable Convolution/6.png\"  width = \"600\"/>\n\n# 常规卷积与深度可分离卷积的计算量对比\n<img src=\"/images/Depthwise Separable Convolution/7.png\"  width = \"600\"/>\n- 以$N=1024$, $D_k=3$为例：\n - 深度可分离卷积的计算量约为常规卷积的$\\frac{1}{10}$\n\n# 常规卷积与深度可分离卷积的参数个数对比\n<img src=\"/images/Depthwise Separable Convolution/8.png\"  width = \"600\"/>\n- 参数个数对比同计算量对比\n\n# 参考文献\n- [视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!](https://www.youtube.com/watch?v=T7o3xvJLuHk&t=0s&list=LLPZqbzAbJOX-hE-IRAxB7sg&index=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Depthwise Separable Convolution","published":1,"updated":"2018-12-30T07:49:50.940Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vun0002qslp3fjiq25e","content":"<h1 id=\"常规卷积\"><a href=\"#常规卷积\" class=\"headerlink\" title=\"常规卷积\"></a>常规卷积</h1><p><strong>示例</strong>：<br><img src=\"/images/Depthwise Separable Convolution/1.png\" width=\"600\"></p>\n<ul>\n<li>上图为常规卷积示例，假设步长为1，same填充：<ul>\n<li>单个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$</li>\n<li>$N$个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times N$<a id=\"more\"></a>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>计算量</strong>：<br><img src=\"/images/Depthwise Separable Convolution/2.png\" width=\"600\"></p>\n<ul>\n<li>上图为常规卷积的计算量：<ul>\n<li>单个核($D_k \\times D_k \\times M$)单次的乘法次数为${D_k}^2 \\times M$</li>\n<li>单个核($D_k \\times D_k \\times M$)的总体乘法次数为${D_G}^2 \\times {D_k}^2 \\times M$</li>\n<li>$N$个核($D_k \\times D_k \\times M$)的总体乘法次数为$N \\times {D_G}^2 \\times {D_k}^2 \\times M$</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"深度可分离卷积\"><a href=\"#深度可分离卷积\" class=\"headerlink\" title=\"深度可分离卷积\"></a>深度可分离卷积</h1><p><img src=\"/images/Depthwise Separable Convolution/3.png\" width=\"600\"></p>\n<ul>\n<li>The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel. </li>\n<li>The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new features through computing linear combinations of the input channels.</li>\n<li>上两段话摘自<a href=\"https://arxiv.org/pdf/1801.04381.pdf\" target=\"_blank\" rel=\"noopener\">MobileNetV2</a>。</li>\n</ul>\n<p><strong>depthwise convolution</strong>：<br><img src=\"/images/Depthwise Separable Convolution/4.png\" width=\"600\"></p>\n<ul>\n<li>上图为depthwise convolution示例图，假设步长为1，same填充：<ul>\n<li>单个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times 1$（只对输入的一个通道进行操作）</li>\n<li>$M$个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times M$（每个核对输入的一个通道进行操作）</li>\n</ul>\n</li>\n</ul>\n<p><strong>pointwise convolution</strong>：<br><img src=\"/images/Depthwise Separable Convolution/5.png\" width=\"600\"></p>\n<ul>\n<li>注：图中的Filtering Stage应改为Combination Stage</li>\n<li>上图为pointwise convolution的示例图，假设步长为1，same填充：<ul>\n<li>单个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$</li>\n<li>$M$个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times M$</li>\n<li>就是$1\\times1 $卷积</li>\n</ul>\n</li>\n</ul>\n<p><strong>计算量</strong>：<br><img src=\"/images/Depthwise Separable Convolution/6.png\" width=\"600\"></p>\n<h1 id=\"常规卷积与深度可分离卷积的计算量对比\"><a href=\"#常规卷积与深度可分离卷积的计算量对比\" class=\"headerlink\" title=\"常规卷积与深度可分离卷积的计算量对比\"></a>常规卷积与深度可分离卷积的计算量对比</h1><p><img src=\"/images/Depthwise Separable Convolution/7.png\" width=\"600\"></p>\n<ul>\n<li>以$N=1024$, $D_k=3$为例：<ul>\n<li>深度可分离卷积的计算量约为常规卷积的$\\frac{1}{10}$</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"常规卷积与深度可分离卷积的参数个数对比\"><a href=\"#常规卷积与深度可分离卷积的参数个数对比\" class=\"headerlink\" title=\"常规卷积与深度可分离卷积的参数个数对比\"></a>常规卷积与深度可分离卷积的参数个数对比</h1><p><img src=\"/images/Depthwise Separable Convolution/8.png\" width=\"600\"></p>\n<ul>\n<li>参数个数对比同计算量对比</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://www.youtube.com/watch?v=T7o3xvJLuHk&amp;t=0s&amp;list=LLPZqbzAbJOX-hE-IRAxB7sg&amp;index=2\" target=\"_blank\" rel=\"noopener\">视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"常规卷积\"><a href=\"#常规卷积\" class=\"headerlink\" title=\"常规卷积\"></a>常规卷积</h1><p><strong>示例</strong>：<br><img src=\"/images/Depthwise Separable Convolution/1.png\" width=\"600\"></p>\n<ul>\n<li>上图为常规卷积示例，假设步长为1，same填充：<ul>\n<li>单个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$</li>\n<li>$N$个核($D_k \\times D_k \\times M$)进行卷积后的输出为$D_G \\times D_G \\times N$","more":"</li>\n</ul>\n</li>\n</ul>\n<p><strong>计算量</strong>：<br><img src=\"/images/Depthwise Separable Convolution/2.png\" width=\"600\"></p>\n<ul>\n<li>上图为常规卷积的计算量：<ul>\n<li>单个核($D_k \\times D_k \\times M$)单次的乘法次数为${D_k}^2 \\times M$</li>\n<li>单个核($D_k \\times D_k \\times M$)的总体乘法次数为${D_G}^2 \\times {D_k}^2 \\times M$</li>\n<li>$N$个核($D_k \\times D_k \\times M$)的总体乘法次数为$N \\times {D_G}^2 \\times {D_k}^2 \\times M$</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"深度可分离卷积\"><a href=\"#深度可分离卷积\" class=\"headerlink\" title=\"深度可分离卷积\"></a>深度可分离卷积</h1><p><img src=\"/images/Depthwise Separable Convolution/3.png\" width=\"600\"></p>\n<ul>\n<li>The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel. </li>\n<li>The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new features through computing linear combinations of the input channels.</li>\n<li>上两段话摘自<a href=\"https://arxiv.org/pdf/1801.04381.pdf\" target=\"_blank\" rel=\"noopener\">MobileNetV2</a>。</li>\n</ul>\n<p><strong>depthwise convolution</strong>：<br><img src=\"/images/Depthwise Separable Convolution/4.png\" width=\"600\"></p>\n<ul>\n<li>上图为depthwise convolution示例图，假设步长为1，same填充：<ul>\n<li>单个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times 1$（只对输入的一个通道进行操作）</li>\n<li>$M$个核($D_k \\times D_k \\times 1$)进行卷积后的输出为$D_G \\times D_G \\times M$（每个核对输入的一个通道进行操作）</li>\n</ul>\n</li>\n</ul>\n<p><strong>pointwise convolution</strong>：<br><img src=\"/images/Depthwise Separable Convolution/5.png\" width=\"600\"></p>\n<ul>\n<li>注：图中的Filtering Stage应改为Combination Stage</li>\n<li>上图为pointwise convolution的示例图，假设步长为1，same填充：<ul>\n<li>单个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times 1$</li>\n<li>$M$个核($1 \\times 1 \\times M$)进行卷积后的输出为$D_G \\times D_G \\times M$</li>\n<li>就是$1\\times1 $卷积</li>\n</ul>\n</li>\n</ul>\n<p><strong>计算量</strong>：<br><img src=\"/images/Depthwise Separable Convolution/6.png\" width=\"600\"></p>\n<h1 id=\"常规卷积与深度可分离卷积的计算量对比\"><a href=\"#常规卷积与深度可分离卷积的计算量对比\" class=\"headerlink\" title=\"常规卷积与深度可分离卷积的计算量对比\"></a>常规卷积与深度可分离卷积的计算量对比</h1><p><img src=\"/images/Depthwise Separable Convolution/7.png\" width=\"600\"></p>\n<ul>\n<li>以$N=1024$, $D_k=3$为例：<ul>\n<li>深度可分离卷积的计算量约为常规卷积的$\\frac{1}{10}$</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"常规卷积与深度可分离卷积的参数个数对比\"><a href=\"#常规卷积与深度可分离卷积的参数个数对比\" class=\"headerlink\" title=\"常规卷积与深度可分离卷积的参数个数对比\"></a>常规卷积与深度可分离卷积的参数个数对比</h1><p><img src=\"/images/Depthwise Separable Convolution/8.png\" width=\"600\"></p>\n<ul>\n<li>参数个数对比同计算量对比</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://www.youtube.com/watch?v=T7o3xvJLuHk&amp;t=0s&amp;list=LLPZqbzAbJOX-hE-IRAxB7sg&amp;index=2\" target=\"_blank\" rel=\"noopener\">视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!</a></li>\n</ul>"},{"title":"EM算法","mathjax":true,"top":true,"date":"2018-02-02T14:08:50.000Z","_content":"　　EM(expectation maximization)是一种迭代算法，求含有隐变量的概率模型参数的极大似然估计法。每次迭代包含两步：E步，求期望；M步，求极大化。\n<!-- more --> \n# 1.符号表示\n　　一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据。$Y$和$Z$连在一起称为完全数据，观测数据$Y$又称为不完全数据。\n　　假设给定观测数据$Y$，其概率分布是$P(Y|\\theta)$，其中$\\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\\theta)$，对数似然函数$L(\\theta)= logP(Y|\\theta)$。\n　　假设$Y$和$Z$的联合概率分布是$P(Y,Z|\\theta)$，那么完全数据的对数似然函数是$logP(Y,Z|\\theta)$。\n# 2.Q函数\n　　完全数据的对数似然函数$logP(Y,Z|\\theta)$关于在给定观测数据$Y$和当前参数$\\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\\theta^{(i)})$的期望称为Q函数，即：\n$$Q(θ,θ^{(i)}) = E_z[\\log P(Y,Z|θ) | Y, θ^{(i)}] = \\sum_Z \\log P(Y,Z|θ)P(Z|Y,θ^{(i)})$$\n# 3.EM算法\n输入: 观测变量$Y$，隐变量数据$Z$，联合分布$P(Y,Z|θ)$，条件分布$P(Z|Y,θ)$；\n输出: 模型参数$θ$\n(1) 选择参数的初始值$θ^{(0)}$，开始迭代。\n说明：参数的初值可以任意选择，但需注意EM算法对初值是敏感的。\n(2) E步: 记$\\theta^{(i)}$为第$i$次迭代参数$\\theta$的估计值, 在第$i+1$次迭代的E步，计算\n$$\\begin{align}\nQ(\\theta, \\theta^{(i)}) &= E_Z [log  P(Y, Z | \\theta) | Y, \\theta^{(i)}]\\\\ &= \\sum\\limits_Z log  P(Y, Z | \\theta) P(Z|Y,\\theta^{(i)} ) \n\\end{align} $$\n这里$P(Z|Y,θ^{(i)})$是在给定观测数据$Y$和当前的参数估计$θ^{(i)}$下隐变量数据$Z$的条件概率分布。\n说明：E步求$Q(\\theta, \\theta^{(i)})$，Q函数式中$Z$是未观测数据，$Y$是观测数据。注意，$Q(\\theta, \\theta^{(i)})$的第一个变元表示要极大化的参数，第2个变元表示参数的当前估计值。每次迭代实际在求Q函数及其极大。\n(3) M步: 求使$Q(θ,θ_i)$极大化的$\\theta$,确定第$i+1$次迭代的参数的估计值$θ^{(i+1)}$\n$$\\theta^{(i+1)} = arg\\max\\limits_\\theta Q(\\theta, \\theta^{(i)})$$\n说明：M步求$Q(\\theta, \\theta^{(i)})$的极大化，得到$\\theta^{(i+1)}$，完成一次迭代$\\theta^{(i)}$->$\\theta^{(i+1)}$。每次迭代使得似然函数增大或达到局部极值。\n(4) 重复(2), (3)两步, 直到收敛。\n说明：给出停止迭代条件，一般是对较小的正数$\\xi_1,\\xi_2$，若满足$||θ^{(i+1)}-θ^{(i)}||<\\xi_1$或者$||Q(θ^{(i+1)},θ^i)-Q(θ^{(i)},θ^{(i)})|| < \\xi_2$则停止迭代。\n# 4.Jensen不等式\n## 凸函数\n函数$f(x)$是凸函数：\n- 当定义域为实数，即$x\\in R$，对于所有$x$，$f(x)$的二阶导数$f^{''}(x) \\geq 0$；\n- 当$x$是向量时，该函数的$hessian$矩阵$H$是半正定，即$H\\geq 0$；\n\n函数$f(x)$是严格凸函数：\n- 当对于所有$x$，$f^{''}(x) > 0 (x \\in R)$或$H$正定，即$H>0$（$x$为向量）。\n\n## 凹函数\n函数$f(x)$是（严格）凹函数,当且仅当$-f(x)$是（严格）凸函数。\n## Jensen不等式\nJensen不等式：\n- 当$f$是凸函数，$X$是随机变量，则$E[f(X)] \\ge f(EX)$\n - 此外，当$f$是严格凸函数，$E[f(X)] = f(EX)$当且仅当$X=E(X)$的概率为1（例如$X$是一个常数）的时候成立。\n- 当$f$是凹函数，不等式方向反向:$E[f(X)] \\le f(EX)$\n\n示例（记忆方法）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/jensen%E4%B8%8D%E7%AD%89%E5%BC%8F.JPG\" width=\"50%\" height=\"50%\">  \n- 上图中，$f$是一个凸函数，在图中用实线表示。另外$X$是一个随机变量，有0.5的概率取值为$a$，另外有0.5的概率取值为$b$，已在图中$x$轴上标出。这样，$X$的期望值$E(X)$也就在图中所示的$a$和$b$的中点位置。\n- 图中在$y$轴上标出了$f(a)$、$f(b)$和$f(EX)$。接下来函数的期望值$E[f(x)]$在$y$轴上就处于$f(a)$和$f(b)$之间的中点的位置。\n- 如图所示，在这个例子中由于$f$是凸函数，很明显$E[f(X)] \\ge f(EX)$。\n\n# 5.Q函数推导\n面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\\theta$的对数似然函数，即极大化\n$$\\begin{align} L(\\theta) &= log  P(Y | \\theta) = log \\sum\\limits_Z P(Y, Z | \\theta) \\\\ &= log ( \\sum\\limits_Z   P(Y|Z,\\theta) P(Z |\\theta))  \\end{align}$$\n注意到这一极大化的主要困难是式中有未观测数据并有包含和（或积分）的对数。\n事实上，EM算法是通过迭代逐步近似极大化$L(\\theta)$的。假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$。我们希望新估计值$\\theta$能使$L(\\theta)$增加，即$L(\\theta)>L(\\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：\n$$\nL(\\theta) - L(\\theta^{(i)}) = log (\\sum\\limits_z P(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n$$\n利用Jensen不等式得到其下界：\n$$\\begin{split}\nL(\\theta) - L(\\theta^{(i)}) &= log (\\sum\\limits_zP(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n\\\\ &= log(\\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})}) - log  P(Y | \\theta^{(i)}) \\\\ &\\ge \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log\\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})} - log  P(Y | \\theta^{(i)}) \\\\ &= \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}\n\\end{split}\n$$\n令\n$$B(\\theta, \\theta^{(i)}) = L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \n\\tag{13}$$\n则\n$$L(\\theta)\\geq B(\\theta, \\theta^{(i)})$$\n即函数$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的一个下界，而且由式（13）可知，\n$$L(\\theta^{(i)})= B(\\theta^{(i)}, \\theta^{(i)})$$\n因此，任何可以使$B(\\theta, \\theta^{(i)})$增大的$\\theta$，也可以使$L(\\theta)$增大。为了使$L(\\theta)$有尽可能大的增长，选择$\\theta^{(i+1)}$使$B(\\theta, \\theta^{(i)})$达到极大，即\n$$\\theta^{(i+1)} = arg\\max\\limits_\\theta B(\\theta, \\theta^{(i)})$$\n现在求$\\theta^{(i+1)}$的表达式。省去对$\\theta$极大化而言是常数的项，有\n$$\\begin{split}\n\\theta^{(i+1)} &= arg\\max\\limits_\\theta\\ B(\\theta, \\theta^{(i)}) \\\\ \n&= arg\\max\\limits_\\theta \\ L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}  \\\\\n&=arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log(P(Y| Z, \\theta)P(Z|\\theta)) \\\\\n&= arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log  P(Y, Z | \\theta) \\\\ \n&= arg\\max\\limits_\\theta\\ Q(\\theta, \\theta^{(i)})\n\\end{split} $$\n上式等价于EM算法的一次迭代，即求Q函数及其极大化。**EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法**。\n\n# 6.参考资料\n- [Andrew Ng, CS229](http://open.163.com/movie/2008/1/O/T/M6SGF6VB4_M6SGKGMOT.html)\n- [CS229, notes8](http://cs229.stanford.edu/notes/cs229-notes8.pdf)\n- 李航，统计学习方法\n- [Richard Xu，Expectation Maximization](https://www.youtube.com/watch?v=Bq5s80ZCmC0&t=4s)\n\n\n","source":"_posts/EM算法.md","raw":"---\ntitle: EM算法\nmathjax: true\ntop: true\ndate: 2018-2-2 22:08:50\ncategories: \n- 机器学习\n---\n　　EM(expectation maximization)是一种迭代算法，求含有隐变量的概率模型参数的极大似然估计法。每次迭代包含两步：E步，求期望；M步，求极大化。\n<!-- more --> \n# 1.符号表示\n　　一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据。$Y$和$Z$连在一起称为完全数据，观测数据$Y$又称为不完全数据。\n　　假设给定观测数据$Y$，其概率分布是$P(Y|\\theta)$，其中$\\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\\theta)$，对数似然函数$L(\\theta)= logP(Y|\\theta)$。\n　　假设$Y$和$Z$的联合概率分布是$P(Y,Z|\\theta)$，那么完全数据的对数似然函数是$logP(Y,Z|\\theta)$。\n# 2.Q函数\n　　完全数据的对数似然函数$logP(Y,Z|\\theta)$关于在给定观测数据$Y$和当前参数$\\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\\theta^{(i)})$的期望称为Q函数，即：\n$$Q(θ,θ^{(i)}) = E_z[\\log P(Y,Z|θ) | Y, θ^{(i)}] = \\sum_Z \\log P(Y,Z|θ)P(Z|Y,θ^{(i)})$$\n# 3.EM算法\n输入: 观测变量$Y$，隐变量数据$Z$，联合分布$P(Y,Z|θ)$，条件分布$P(Z|Y,θ)$；\n输出: 模型参数$θ$\n(1) 选择参数的初始值$θ^{(0)}$，开始迭代。\n说明：参数的初值可以任意选择，但需注意EM算法对初值是敏感的。\n(2) E步: 记$\\theta^{(i)}$为第$i$次迭代参数$\\theta$的估计值, 在第$i+1$次迭代的E步，计算\n$$\\begin{align}\nQ(\\theta, \\theta^{(i)}) &= E_Z [log  P(Y, Z | \\theta) | Y, \\theta^{(i)}]\\\\ &= \\sum\\limits_Z log  P(Y, Z | \\theta) P(Z|Y,\\theta^{(i)} ) \n\\end{align} $$\n这里$P(Z|Y,θ^{(i)})$是在给定观测数据$Y$和当前的参数估计$θ^{(i)}$下隐变量数据$Z$的条件概率分布。\n说明：E步求$Q(\\theta, \\theta^{(i)})$，Q函数式中$Z$是未观测数据，$Y$是观测数据。注意，$Q(\\theta, \\theta^{(i)})$的第一个变元表示要极大化的参数，第2个变元表示参数的当前估计值。每次迭代实际在求Q函数及其极大。\n(3) M步: 求使$Q(θ,θ_i)$极大化的$\\theta$,确定第$i+1$次迭代的参数的估计值$θ^{(i+1)}$\n$$\\theta^{(i+1)} = arg\\max\\limits_\\theta Q(\\theta, \\theta^{(i)})$$\n说明：M步求$Q(\\theta, \\theta^{(i)})$的极大化，得到$\\theta^{(i+1)}$，完成一次迭代$\\theta^{(i)}$->$\\theta^{(i+1)}$。每次迭代使得似然函数增大或达到局部极值。\n(4) 重复(2), (3)两步, 直到收敛。\n说明：给出停止迭代条件，一般是对较小的正数$\\xi_1,\\xi_2$，若满足$||θ^{(i+1)}-θ^{(i)}||<\\xi_1$或者$||Q(θ^{(i+1)},θ^i)-Q(θ^{(i)},θ^{(i)})|| < \\xi_2$则停止迭代。\n# 4.Jensen不等式\n## 凸函数\n函数$f(x)$是凸函数：\n- 当定义域为实数，即$x\\in R$，对于所有$x$，$f(x)$的二阶导数$f^{''}(x) \\geq 0$；\n- 当$x$是向量时，该函数的$hessian$矩阵$H$是半正定，即$H\\geq 0$；\n\n函数$f(x)$是严格凸函数：\n- 当对于所有$x$，$f^{''}(x) > 0 (x \\in R)$或$H$正定，即$H>0$（$x$为向量）。\n\n## 凹函数\n函数$f(x)$是（严格）凹函数,当且仅当$-f(x)$是（严格）凸函数。\n## Jensen不等式\nJensen不等式：\n- 当$f$是凸函数，$X$是随机变量，则$E[f(X)] \\ge f(EX)$\n - 此外，当$f$是严格凸函数，$E[f(X)] = f(EX)$当且仅当$X=E(X)$的概率为1（例如$X$是一个常数）的时候成立。\n- 当$f$是凹函数，不等式方向反向:$E[f(X)] \\le f(EX)$\n\n示例（记忆方法）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/jensen%E4%B8%8D%E7%AD%89%E5%BC%8F.JPG\" width=\"50%\" height=\"50%\">  \n- 上图中，$f$是一个凸函数，在图中用实线表示。另外$X$是一个随机变量，有0.5的概率取值为$a$，另外有0.5的概率取值为$b$，已在图中$x$轴上标出。这样，$X$的期望值$E(X)$也就在图中所示的$a$和$b$的中点位置。\n- 图中在$y$轴上标出了$f(a)$、$f(b)$和$f(EX)$。接下来函数的期望值$E[f(x)]$在$y$轴上就处于$f(a)$和$f(b)$之间的中点的位置。\n- 如图所示，在这个例子中由于$f$是凸函数，很明显$E[f(X)] \\ge f(EX)$。\n\n# 5.Q函数推导\n面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\\theta$的对数似然函数，即极大化\n$$\\begin{align} L(\\theta) &= log  P(Y | \\theta) = log \\sum\\limits_Z P(Y, Z | \\theta) \\\\ &= log ( \\sum\\limits_Z   P(Y|Z,\\theta) P(Z |\\theta))  \\end{align}$$\n注意到这一极大化的主要困难是式中有未观测数据并有包含和（或积分）的对数。\n事实上，EM算法是通过迭代逐步近似极大化$L(\\theta)$的。假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$。我们希望新估计值$\\theta$能使$L(\\theta)$增加，即$L(\\theta)>L(\\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：\n$$\nL(\\theta) - L(\\theta^{(i)}) = log (\\sum\\limits_z P(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n$$\n利用Jensen不等式得到其下界：\n$$\\begin{split}\nL(\\theta) - L(\\theta^{(i)}) &= log (\\sum\\limits_zP(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n\\\\ &= log(\\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})}) - log  P(Y | \\theta^{(i)}) \\\\ &\\ge \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log\\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})} - log  P(Y | \\theta^{(i)}) \\\\ &= \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}\n\\end{split}\n$$\n令\n$$B(\\theta, \\theta^{(i)}) = L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \n\\tag{13}$$\n则\n$$L(\\theta)\\geq B(\\theta, \\theta^{(i)})$$\n即函数$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的一个下界，而且由式（13）可知，\n$$L(\\theta^{(i)})= B(\\theta^{(i)}, \\theta^{(i)})$$\n因此，任何可以使$B(\\theta, \\theta^{(i)})$增大的$\\theta$，也可以使$L(\\theta)$增大。为了使$L(\\theta)$有尽可能大的增长，选择$\\theta^{(i+1)}$使$B(\\theta, \\theta^{(i)})$达到极大，即\n$$\\theta^{(i+1)} = arg\\max\\limits_\\theta B(\\theta, \\theta^{(i)})$$\n现在求$\\theta^{(i+1)}$的表达式。省去对$\\theta$极大化而言是常数的项，有\n$$\\begin{split}\n\\theta^{(i+1)} &= arg\\max\\limits_\\theta\\ B(\\theta, \\theta^{(i)}) \\\\ \n&= arg\\max\\limits_\\theta \\ L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}  \\\\\n&=arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log(P(Y| Z, \\theta)P(Z|\\theta)) \\\\\n&= arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log  P(Y, Z | \\theta) \\\\ \n&= arg\\max\\limits_\\theta\\ Q(\\theta, \\theta^{(i)})\n\\end{split} $$\n上式等价于EM算法的一次迭代，即求Q函数及其极大化。**EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法**。\n\n# 6.参考资料\n- [Andrew Ng, CS229](http://open.163.com/movie/2008/1/O/T/M6SGF6VB4_M6SGKGMOT.html)\n- [CS229, notes8](http://cs229.stanford.edu/notes/cs229-notes8.pdf)\n- 李航，统计学习方法\n- [Richard Xu，Expectation Maximization](https://www.youtube.com/watch?v=Bq5s80ZCmC0&t=4s)\n\n\n","slug":"EM算法","published":1,"updated":"2018-03-05T05:37:02.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vuv0006qslp4z0ctwjx","content":"<p>　　EM(expectation maximization)是一种迭代算法，求含有隐变量的概率模型参数的极大似然估计法。每次迭代包含两步：E步，求期望；M步，求极大化。<br><a id=\"more\"></a> </p>\n<h1 id=\"1-符号表示\"><a href=\"#1-符号表示\" class=\"headerlink\" title=\"1.符号表示\"></a>1.符号表示</h1><p>　　一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据。$Y$和$Z$连在一起称为完全数据，观测数据$Y$又称为不完全数据。<br>　　假设给定观测数据$Y$，其概率分布是$P(Y|\\theta)$，其中$\\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\\theta)$，对数似然函数$L(\\theta)= logP(Y|\\theta)$。<br>　　假设$Y$和$Z$的联合概率分布是$P(Y,Z|\\theta)$，那么完全数据的对数似然函数是$logP(Y,Z|\\theta)$。</p>\n<h1 id=\"2-Q函数\"><a href=\"#2-Q函数\" class=\"headerlink\" title=\"2.Q函数\"></a>2.Q函数</h1><p>　　完全数据的对数似然函数$logP(Y,Z|\\theta)$关于在给定观测数据$Y$和当前参数$\\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\\theta^{(i)})$的期望称为Q函数，即：</p>\n<script type=\"math/tex; mode=display\">Q(θ,θ^{(i)}) = E_z[\\log P(Y,Z|θ) | Y, θ^{(i)}] = \\sum_Z \\log P(Y,Z|θ)P(Z|Y,θ^{(i)})</script><h1 id=\"3-EM算法\"><a href=\"#3-EM算法\" class=\"headerlink\" title=\"3.EM算法\"></a>3.EM算法</h1><p>输入: 观测变量$Y$，隐变量数据$Z$，联合分布$P(Y,Z|θ)$，条件分布$P(Z|Y,θ)$；<br>输出: 模型参数$θ$<br>(1) 选择参数的初始值$θ^{(0)}$，开始迭代。<br>说明：参数的初值可以任意选择，但需注意EM算法对初值是敏感的。<br>(2) E步: 记$\\theta^{(i)}$为第$i$次迭代参数$\\theta$的估计值, 在第$i+1$次迭代的E步，计算</p>\n<script type=\"math/tex; mode=display\">\\begin{align}\nQ(\\theta, \\theta^{(i)}) &= E_Z [log  P(Y, Z | \\theta) | Y, \\theta^{(i)}]\\\\ &= \\sum\\limits_Z log  P(Y, Z | \\theta) P(Z|Y,\\theta^{(i)} ) \n\\end{align}</script><p>这里$P(Z|Y,θ^{(i)})$是在给定观测数据$Y$和当前的参数估计$θ^{(i)}$下隐变量数据$Z$的条件概率分布。<br>说明：E步求$Q(\\theta, \\theta^{(i)})$，Q函数式中$Z$是未观测数据，$Y$是观测数据。注意，$Q(\\theta, \\theta^{(i)})$的第一个变元表示要极大化的参数，第2个变元表示参数的当前估计值。每次迭代实际在求Q函数及其极大。<br>(3) M步: 求使$Q(θ,θ_i)$极大化的$\\theta$,确定第$i+1$次迭代的参数的估计值$θ^{(i+1)}$</p>\n<script type=\"math/tex; mode=display\">\\theta^{(i+1)} = arg\\max\\limits_\\theta Q(\\theta, \\theta^{(i)})</script><p>说明：M步求$Q(\\theta, \\theta^{(i)})$的极大化，得到$\\theta^{(i+1)}$，完成一次迭代$\\theta^{(i)}$-&gt;$\\theta^{(i+1)}$。每次迭代使得似然函数增大或达到局部极值。<br>(4) 重复(2), (3)两步, 直到收敛。<br>说明：给出停止迭代条件，一般是对较小的正数$\\xi_1,\\xi_2$，若满足$||θ^{(i+1)}-θ^{(i)}||&lt;\\xi_1$或者$||Q(θ^{(i+1)},θ^i)-Q(θ^{(i)},θ^{(i)})|| &lt; \\xi_2$则停止迭代。</p>\n<h1 id=\"4-Jensen不等式\"><a href=\"#4-Jensen不等式\" class=\"headerlink\" title=\"4.Jensen不等式\"></a>4.Jensen不等式</h1><h2 id=\"凸函数\"><a href=\"#凸函数\" class=\"headerlink\" title=\"凸函数\"></a>凸函数</h2><p>函数$f(x)$是凸函数：</p>\n<ul>\n<li>当定义域为实数，即$x\\in R$，对于所有$x$，$f(x)$的二阶导数$f^{‘’}(x) \\geq 0$；</li>\n<li>当$x$是向量时，该函数的$hessian$矩阵$H$是半正定，即$H\\geq 0$；</li>\n</ul>\n<p>函数$f(x)$是严格凸函数：</p>\n<ul>\n<li>当对于所有$x$，$f^{‘’}(x) &gt; 0 (x \\in R)$或$H$正定，即$H&gt;0$（$x$为向量）。</li>\n</ul>\n<h2 id=\"凹函数\"><a href=\"#凹函数\" class=\"headerlink\" title=\"凹函数\"></a>凹函数</h2><p>函数$f(x)$是（严格）凹函数,当且仅当$-f(x)$是（严格）凸函数。</p>\n<h2 id=\"Jensen不等式\"><a href=\"#Jensen不等式\" class=\"headerlink\" title=\"Jensen不等式\"></a>Jensen不等式</h2><p>Jensen不等式：</p>\n<ul>\n<li>当$f$是凸函数，$X$是随机变量，则$E[f(X)] \\ge f(EX)$<ul>\n<li>此外，当$f$是严格凸函数，$E[f(X)] = f(EX)$当且仅当$X=E(X)$的概率为1（例如$X$是一个常数）的时候成立。</li>\n</ul>\n</li>\n<li>当$f$是凹函数，不等式方向反向:$E[f(X)] \\le f(EX)$</li>\n</ul>\n<p>示例（记忆方法）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/jensen%E4%B8%8D%E7%AD%89%E5%BC%8F.JPG\" width=\"50%\" height=\"50%\">  </p>\n<ul>\n<li>上图中，$f$是一个凸函数，在图中用实线表示。另外$X$是一个随机变量，有0.5的概率取值为$a$，另外有0.5的概率取值为$b$，已在图中$x$轴上标出。这样，$X$的期望值$E(X)$也就在图中所示的$a$和$b$的中点位置。</li>\n<li>图中在$y$轴上标出了$f(a)$、$f(b)$和$f(EX)$。接下来函数的期望值$E[f(x)]$在$y$轴上就处于$f(a)$和$f(b)$之间的中点的位置。</li>\n<li>如图所示，在这个例子中由于$f$是凸函数，很明显$E[f(X)] \\ge f(EX)$。</li>\n</ul>\n<h1 id=\"5-Q函数推导\"><a href=\"#5-Q函数推导\" class=\"headerlink\" title=\"5.Q函数推导\"></a>5.Q函数推导</h1><p>面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\\theta$的对数似然函数，即极大化</p>\n<script type=\"math/tex; mode=display\">\\begin{align} L(\\theta) &= log  P(Y | \\theta) = log \\sum\\limits_Z P(Y, Z | \\theta) \\\\ &= log ( \\sum\\limits_Z   P(Y|Z,\\theta) P(Z |\\theta))  \\end{align}</script><p>注意到这一极大化的主要困难是式中有未观测数据并有包含和（或积分）的对数。<br>事实上，EM算法是通过迭代逐步近似极大化$L(\\theta)$的。假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$。我们希望新估计值$\\theta$能使$L(\\theta)$增加，即$L(\\theta)&gt;L(\\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) - L(\\theta^{(i)}) = log (\\sum\\limits_z P(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)})</script><p>利用Jensen不等式得到其下界：</p>\n<script type=\"math/tex; mode=display\">\\begin{split}\nL(\\theta) - L(\\theta^{(i)}) &= log (\\sum\\limits_zP(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n\\\\ &= log(\\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})}) - log  P(Y | \\theta^{(i)}) \\\\ &\\ge \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log\\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})} - log  P(Y | \\theta^{(i)}) \\\\ &= \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}\n\\end{split}</script><p>令</p>\n<script type=\"math/tex; mode=display\">B(\\theta, \\theta^{(i)}) = L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \n\\tag{13}</script><p>则</p>\n<script type=\"math/tex; mode=display\">L(\\theta)\\geq B(\\theta, \\theta^{(i)})</script><p>即函数$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的一个下界，而且由式（13）可知，</p>\n<script type=\"math/tex; mode=display\">L(\\theta^{(i)})= B(\\theta^{(i)}, \\theta^{(i)})</script><p>因此，任何可以使$B(\\theta, \\theta^{(i)})$增大的$\\theta$，也可以使$L(\\theta)$增大。为了使$L(\\theta)$有尽可能大的增长，选择$\\theta^{(i+1)}$使$B(\\theta, \\theta^{(i)})$达到极大，即</p>\n<script type=\"math/tex; mode=display\">\\theta^{(i+1)} = arg\\max\\limits_\\theta B(\\theta, \\theta^{(i)})</script><p>现在求$\\theta^{(i+1)}$的表达式。省去对$\\theta$极大化而言是常数的项，有</p>\n<script type=\"math/tex; mode=display\">\\begin{split}\n\\theta^{(i+1)} &= arg\\max\\limits_\\theta\\ B(\\theta, \\theta^{(i)}) \\\\ \n&= arg\\max\\limits_\\theta \\ L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}  \\\\\n&=arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log(P(Y| Z, \\theta)P(Z|\\theta)) \\\\\n&= arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log  P(Y, Z | \\theta) \\\\ \n&= arg\\max\\limits_\\theta\\ Q(\\theta, \\theta^{(i)})\n\\end{split}</script><p>上式等价于EM算法的一次迭代，即求Q函数及其极大化。<strong>EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法</strong>。</p>\n<h1 id=\"6-参考资料\"><a href=\"#6-参考资料\" class=\"headerlink\" title=\"6.参考资料\"></a>6.参考资料</h1><ul>\n<li><a href=\"http://open.163.com/movie/2008/1/O/T/M6SGF6VB4_M6SGKGMOT.html\" target=\"_blank\" rel=\"noopener\">Andrew Ng, CS229</a></li>\n<li><a href=\"http://cs229.stanford.edu/notes/cs229-notes8.pdf\" target=\"_blank\" rel=\"noopener\">CS229, notes8</a></li>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/watch?v=Bq5s80ZCmC0&amp;t=4s\" target=\"_blank\" rel=\"noopener\">Richard Xu，Expectation Maximization</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　EM(expectation maximization)是一种迭代算法，求含有隐变量的概率模型参数的极大似然估计法。每次迭代包含两步：E步，求期望；M步，求极大化。<br>","more":"</p>\n<h1 id=\"1-符号表示\"><a href=\"#1-符号表示\" class=\"headerlink\" title=\"1.符号表示\"></a>1.符号表示</h1><p>　　一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据。$Y$和$Z$连在一起称为完全数据，观测数据$Y$又称为不完全数据。<br>　　假设给定观测数据$Y$，其概率分布是$P(Y|\\theta)$，其中$\\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\\theta)$，对数似然函数$L(\\theta)= logP(Y|\\theta)$。<br>　　假设$Y$和$Z$的联合概率分布是$P(Y,Z|\\theta)$，那么完全数据的对数似然函数是$logP(Y,Z|\\theta)$。</p>\n<h1 id=\"2-Q函数\"><a href=\"#2-Q函数\" class=\"headerlink\" title=\"2.Q函数\"></a>2.Q函数</h1><p>　　完全数据的对数似然函数$logP(Y,Z|\\theta)$关于在给定观测数据$Y$和当前参数$\\theta^{(i)}$下对未观测数据$Z$的条件概率分布$P(Z|Y,\\theta^{(i)})$的期望称为Q函数，即：</p>\n<script type=\"math/tex; mode=display\">Q(θ,θ^{(i)}) = E_z[\\log P(Y,Z|θ) | Y, θ^{(i)}] = \\sum_Z \\log P(Y,Z|θ)P(Z|Y,θ^{(i)})</script><h1 id=\"3-EM算法\"><a href=\"#3-EM算法\" class=\"headerlink\" title=\"3.EM算法\"></a>3.EM算法</h1><p>输入: 观测变量$Y$，隐变量数据$Z$，联合分布$P(Y,Z|θ)$，条件分布$P(Z|Y,θ)$；<br>输出: 模型参数$θ$<br>(1) 选择参数的初始值$θ^{(0)}$，开始迭代。<br>说明：参数的初值可以任意选择，但需注意EM算法对初值是敏感的。<br>(2) E步: 记$\\theta^{(i)}$为第$i$次迭代参数$\\theta$的估计值, 在第$i+1$次迭代的E步，计算</p>\n<script type=\"math/tex; mode=display\">\\begin{align}\nQ(\\theta, \\theta^{(i)}) &= E_Z [log  P(Y, Z | \\theta) | Y, \\theta^{(i)}]\\\\ &= \\sum\\limits_Z log  P(Y, Z | \\theta) P(Z|Y,\\theta^{(i)} ) \n\\end{align}</script><p>这里$P(Z|Y,θ^{(i)})$是在给定观测数据$Y$和当前的参数估计$θ^{(i)}$下隐变量数据$Z$的条件概率分布。<br>说明：E步求$Q(\\theta, \\theta^{(i)})$，Q函数式中$Z$是未观测数据，$Y$是观测数据。注意，$Q(\\theta, \\theta^{(i)})$的第一个变元表示要极大化的参数，第2个变元表示参数的当前估计值。每次迭代实际在求Q函数及其极大。<br>(3) M步: 求使$Q(θ,θ_i)$极大化的$\\theta$,确定第$i+1$次迭代的参数的估计值$θ^{(i+1)}$</p>\n<script type=\"math/tex; mode=display\">\\theta^{(i+1)} = arg\\max\\limits_\\theta Q(\\theta, \\theta^{(i)})</script><p>说明：M步求$Q(\\theta, \\theta^{(i)})$的极大化，得到$\\theta^{(i+1)}$，完成一次迭代$\\theta^{(i)}$-&gt;$\\theta^{(i+1)}$。每次迭代使得似然函数增大或达到局部极值。<br>(4) 重复(2), (3)两步, 直到收敛。<br>说明：给出停止迭代条件，一般是对较小的正数$\\xi_1,\\xi_2$，若满足$||θ^{(i+1)}-θ^{(i)}||&lt;\\xi_1$或者$||Q(θ^{(i+1)},θ^i)-Q(θ^{(i)},θ^{(i)})|| &lt; \\xi_2$则停止迭代。</p>\n<h1 id=\"4-Jensen不等式\"><a href=\"#4-Jensen不等式\" class=\"headerlink\" title=\"4.Jensen不等式\"></a>4.Jensen不等式</h1><h2 id=\"凸函数\"><a href=\"#凸函数\" class=\"headerlink\" title=\"凸函数\"></a>凸函数</h2><p>函数$f(x)$是凸函数：</p>\n<ul>\n<li>当定义域为实数，即$x\\in R$，对于所有$x$，$f(x)$的二阶导数$f^{‘’}(x) \\geq 0$；</li>\n<li>当$x$是向量时，该函数的$hessian$矩阵$H$是半正定，即$H\\geq 0$；</li>\n</ul>\n<p>函数$f(x)$是严格凸函数：</p>\n<ul>\n<li>当对于所有$x$，$f^{‘’}(x) &gt; 0 (x \\in R)$或$H$正定，即$H&gt;0$（$x$为向量）。</li>\n</ul>\n<h2 id=\"凹函数\"><a href=\"#凹函数\" class=\"headerlink\" title=\"凹函数\"></a>凹函数</h2><p>函数$f(x)$是（严格）凹函数,当且仅当$-f(x)$是（严格）凸函数。</p>\n<h2 id=\"Jensen不等式\"><a href=\"#Jensen不等式\" class=\"headerlink\" title=\"Jensen不等式\"></a>Jensen不等式</h2><p>Jensen不等式：</p>\n<ul>\n<li>当$f$是凸函数，$X$是随机变量，则$E[f(X)] \\ge f(EX)$<ul>\n<li>此外，当$f$是严格凸函数，$E[f(X)] = f(EX)$当且仅当$X=E(X)$的概率为1（例如$X$是一个常数）的时候成立。</li>\n</ul>\n</li>\n<li>当$f$是凹函数，不等式方向反向:$E[f(X)] \\le f(EX)$</li>\n</ul>\n<p>示例（记忆方法）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/jensen%E4%B8%8D%E7%AD%89%E5%BC%8F.JPG\" width=\"50%\" height=\"50%\">  </p>\n<ul>\n<li>上图中，$f$是一个凸函数，在图中用实线表示。另外$X$是一个随机变量，有0.5的概率取值为$a$，另外有0.5的概率取值为$b$，已在图中$x$轴上标出。这样，$X$的期望值$E(X)$也就在图中所示的$a$和$b$的中点位置。</li>\n<li>图中在$y$轴上标出了$f(a)$、$f(b)$和$f(EX)$。接下来函数的期望值$E[f(x)]$在$y$轴上就处于$f(a)$和$f(b)$之间的中点的位置。</li>\n<li>如图所示，在这个例子中由于$f$是凸函数，很明显$E[f(X)] \\ge f(EX)$。</li>\n</ul>\n<h1 id=\"5-Q函数推导\"><a href=\"#5-Q函数推导\" class=\"headerlink\" title=\"5.Q函数推导\"></a>5.Q函数推导</h1><p>面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）$Y$关于参数$\\theta$的对数似然函数，即极大化</p>\n<script type=\"math/tex; mode=display\">\\begin{align} L(\\theta) &= log  P(Y | \\theta) = log \\sum\\limits_Z P(Y, Z | \\theta) \\\\ &= log ( \\sum\\limits_Z   P(Y|Z,\\theta) P(Z |\\theta))  \\end{align}</script><p>注意到这一极大化的主要困难是式中有未观测数据并有包含和（或积分）的对数。<br>事实上，EM算法是通过迭代逐步近似极大化$L(\\theta)$的。假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$。我们希望新估计值$\\theta$能使$L(\\theta)$增加，即$L(\\theta)&gt;L(\\theta^{(i)})$，并逐步达到极大值。为此，考虑两者的差：</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) - L(\\theta^{(i)}) = log (\\sum\\limits_z P(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)})</script><p>利用Jensen不等式得到其下界：</p>\n<script type=\"math/tex; mode=display\">\\begin{split}\nL(\\theta) - L(\\theta^{(i)}) &= log (\\sum\\limits_zP(Y|Z,\\theta) P(Z |\\theta)) - log  P(Y | \\theta^{(i)}) \n\\\\ &= log(\\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})}) - log  P(Y | \\theta^{(i)}) \\\\ &\\ge \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log\\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)})} - log  P(Y | \\theta^{(i)}) \\\\ &= \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}\n\\end{split}</script><p>令</p>\n<script type=\"math/tex; mode=display\">B(\\theta, \\theta^{(i)}) = L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})} \n\\tag{13}</script><p>则</p>\n<script type=\"math/tex; mode=display\">L(\\theta)\\geq B(\\theta, \\theta^{(i)})</script><p>即函数$B(\\theta, \\theta^{(i)})$是$L(\\theta)$的一个下界，而且由式（13）可知，</p>\n<script type=\"math/tex; mode=display\">L(\\theta^{(i)})= B(\\theta^{(i)}, \\theta^{(i)})</script><p>因此，任何可以使$B(\\theta, \\theta^{(i)})$增大的$\\theta$，也可以使$L(\\theta)$增大。为了使$L(\\theta)$有尽可能大的增长，选择$\\theta^{(i+1)}$使$B(\\theta, \\theta^{(i)})$达到极大，即</p>\n<script type=\"math/tex; mode=display\">\\theta^{(i+1)} = arg\\max\\limits_\\theta B(\\theta, \\theta^{(i)})</script><p>现在求$\\theta^{(i+1)}$的表达式。省去对$\\theta$极大化而言是常数的项，有</p>\n<script type=\"math/tex; mode=display\">\\begin{split}\n\\theta^{(i+1)} &= arg\\max\\limits_\\theta\\ B(\\theta, \\theta^{(i)}) \\\\ \n&= arg\\max\\limits_\\theta \\ L(\\theta^{(i)}) + \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log \\frac {P(Y|Z,\\theta) P(Z |\\theta)}{P(Z|Y,\\theta^{(i)}) P(Y|\\theta^{(i)})}  \\\\\n&=arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log(P(Y| Z, \\theta)P(Z|\\theta)) \\\\\n&= arg\\max\\limits_\\theta\\ \\sum\\limits_Z P(Z|Y,\\theta^{(i)} ) log  P(Y, Z | \\theta) \\\\ \n&= arg\\max\\limits_\\theta\\ Q(\\theta, \\theta^{(i)})\n\\end{split}</script><p>上式等价于EM算法的一次迭代，即求Q函数及其极大化。<strong>EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法</strong>。</p>\n<h1 id=\"6-参考资料\"><a href=\"#6-参考资料\" class=\"headerlink\" title=\"6.参考资料\"></a>6.参考资料</h1><ul>\n<li><a href=\"http://open.163.com/movie/2008/1/O/T/M6SGF6VB4_M6SGKGMOT.html\" target=\"_blank\" rel=\"noopener\">Andrew Ng, CS229</a></li>\n<li><a href=\"http://cs229.stanford.edu/notes/cs229-notes8.pdf\" target=\"_blank\" rel=\"noopener\">CS229, notes8</a></li>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/watch?v=Bq5s80ZCmC0&amp;t=4s\" target=\"_blank\" rel=\"noopener\">Richard Xu，Expectation Maximization</a></li>\n</ul>"},{"title":"FCN","mathjax":true,"date":"2019-01-08T14:25:50.000Z","_content":"\n## 摘要\n\n- 针对语义分割任务，提出了全卷积网络(FCN, fully convolutional network)，使得对任意尺寸的输入，网络能够产生对应尺寸的输出。\n- 首先，修改当前的分类模型(如AlexNet、VGG及GoogleNet)成为全卷积网络，然后通过微调(fine-tuning)来对分割任务进行迁移学习。\n- 其中，定义了跳跃结构(skip architecture)，即将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合(元素级相加)。\n\n<!-- more -->\n\n## 创新点\n\n### 全卷积化分类网络\n<img src=\"/images/FCN/1.png\"  width = \"700\" height = \"100\"/>\n\n如上图所示，修改分类网络来进行密集预测(Adapting classifiers for dense prediction)：\n\n- 1.将分类网络最后的分类层抛弃，将全连接层卷积化：\n - 分类网络(如AlexNet、VGG及GoogleNet)中存在全连接层，而全连接层有着固定的维度，并且抛弃了空间坐标信息，故将全连接层进行卷积化\n- 2.增加$1\\times 1$卷积，使得通道数为分类数目，即21(20前景和1背景)\n- 3.双线性插值来上采样粗糙的输出特征(coarse outputs)成为像素级密集的输出特征(pixel-dense outputs)\n- 3.增加逐像素的loss(a pixelwise loss)\n\n注：\n\n- 疑问1：如何将全连接层卷积化的（需看源码）\n- 解答：见源码:\n - 以VGG16为例：Block5的输出尺寸为$7 \\times 7 \\times 512$，后接4096的全连接层；原VGG16中，是将$7 \\times 7 \\times 512$拉长成25088，然后和4096个神经元进行全连接。故原参数个数为：$25088 \\times 4096+4096 =  102764544$。\n - 在FCN中，以卷积核为$7\\times7$，步长为1，卷积核个数为4096，同时采用same卷积，使得该全连接层卷积化，该层的输出为$7 \\times7 \\times 4096$，即空间尺寸不变。\n- 疑问2：如何实现上采样（需看源码）\n- 解答：见源码，只是双线性插值 \n- 疑问3：上采样、双线性插值、转置卷积到底有什么区别，如何实现(概念性问题)\n- 解答：上采样的说法高于双线性插值/转置卷积；双线性插值不需学习；转置卷积带有参数，需要学习。\n    \n### 跳跃结构(skip architecture)\n<img src=\"/images/FCN/2.png\"  width = \"700\" height = \"100\"/>\n\n- 设计跳跃结构的原因：\n - 语义分割面临一个内在的语义和定位之间张力：全局信息解决了是什么，有利于语义；局部信息解决了在哪儿，有利于定位。\n - DCNN将位置信息和语义信息进行编码，成为一个局部到全局的金字塔。\n - 因此，定义一个跳跃结构来将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合。\n- 跳跃结构是端到端地进行学习，来改善输出的语义和定位精度\n- 如上图所示：\n - FCN-32s：基础的FCN称为FCN-32s。因为是从`pool5`输出的分辨率为$7 \\times 7$的特征图直接插值到分辨率为$224 \\times 224$的特征图，插值前后的分辨率比率为$1/32$。\n - FCN-16s：FCN-32s与`pool4`输出的特征图进行跳跃连接后的模型，称为FCN-16s。\n - FCN-8s：FCN-16s与`pool3`输出的特征图进行跳跃连接后的模型，称为FCN-8s。\n\n<img src=\"/images/FCN/3.png\"  width = \"500\" height = \"100\"/>\n\n如上图所示，为增加跳跃结构之后的语义分割结果对比。\n\n## 模型比较\n<img src=\"/images/FCN/4.png\"  width = \"500\" height = \"100\"/>\n\n## 训练策略及各超参数\n\n- 整体训练策略：加载VGG16模型在ImageNet上预训练的权重，基于VOC2011微调整个FCN网络：\n - 注1：加载VGG16的全连接层之前的层的权重\n - 注2：若只微调FCN的分类层，只能获得微调整个FCN网络70%的表现\n\n- 预处理及数据增强：无\n\n各超参数参考官方[`voc-fcn8s/solver.prototxt`](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/siftflow-fcn8s/solver.prototxt)及[voc-fcn8s/deploy.prototxt](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn8s/deploy.prototxt)：\n\n- 输入尺寸：$500\\times 500 \\times 3 $\n- 优化器：SGD\n- 动量：0.99\n- 初始学习率：1e-12\n- 学习率策略：采用固定学习率\n- 权重衰减：0.0005\n- 批量尺寸：1\n- 最大迭代次数：300000 \n\n## 参考文献\n\n- [论文：Fully Convolutional Networks for Semantic Segmentation,2015](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)\n- [视频：How FCN Fully Convolutional Networks Works for Semantic Segmentation](https://www.youtube.com/watch?v=UdZnhZrM2vQ)\n- [代码及注释：dhkim0225/keras-image-segmentation](https://github.com/liminn/keras-image-segmentation/blob/master/model/fcn.py)\n- [官方Caffe代码：shelhamer/fcn.berkeleyvision.org](https://github.com/shelhamer/fcn.berkeleyvision.org)\n\n\n\n\n","source":"_posts/FCN.md","raw":"---\ntitle: FCN\nmathjax: true\ndate: 2019-01-08 22:25:50\ncategories: \n- 语义分割\ntags:\n---\n\n## 摘要\n\n- 针对语义分割任务，提出了全卷积网络(FCN, fully convolutional network)，使得对任意尺寸的输入，网络能够产生对应尺寸的输出。\n- 首先，修改当前的分类模型(如AlexNet、VGG及GoogleNet)成为全卷积网络，然后通过微调(fine-tuning)来对分割任务进行迁移学习。\n- 其中，定义了跳跃结构(skip architecture)，即将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合(元素级相加)。\n\n<!-- more -->\n\n## 创新点\n\n### 全卷积化分类网络\n<img src=\"/images/FCN/1.png\"  width = \"700\" height = \"100\"/>\n\n如上图所示，修改分类网络来进行密集预测(Adapting classifiers for dense prediction)：\n\n- 1.将分类网络最后的分类层抛弃，将全连接层卷积化：\n - 分类网络(如AlexNet、VGG及GoogleNet)中存在全连接层，而全连接层有着固定的维度，并且抛弃了空间坐标信息，故将全连接层进行卷积化\n- 2.增加$1\\times 1$卷积，使得通道数为分类数目，即21(20前景和1背景)\n- 3.双线性插值来上采样粗糙的输出特征(coarse outputs)成为像素级密集的输出特征(pixel-dense outputs)\n- 3.增加逐像素的loss(a pixelwise loss)\n\n注：\n\n- 疑问1：如何将全连接层卷积化的（需看源码）\n- 解答：见源码:\n - 以VGG16为例：Block5的输出尺寸为$7 \\times 7 \\times 512$，后接4096的全连接层；原VGG16中，是将$7 \\times 7 \\times 512$拉长成25088，然后和4096个神经元进行全连接。故原参数个数为：$25088 \\times 4096+4096 =  102764544$。\n - 在FCN中，以卷积核为$7\\times7$，步长为1，卷积核个数为4096，同时采用same卷积，使得该全连接层卷积化，该层的输出为$7 \\times7 \\times 4096$，即空间尺寸不变。\n- 疑问2：如何实现上采样（需看源码）\n- 解答：见源码，只是双线性插值 \n- 疑问3：上采样、双线性插值、转置卷积到底有什么区别，如何实现(概念性问题)\n- 解答：上采样的说法高于双线性插值/转置卷积；双线性插值不需学习；转置卷积带有参数，需要学习。\n    \n### 跳跃结构(skip architecture)\n<img src=\"/images/FCN/2.png\"  width = \"700\" height = \"100\"/>\n\n- 设计跳跃结构的原因：\n - 语义分割面临一个内在的语义和定位之间张力：全局信息解决了是什么，有利于语义；局部信息解决了在哪儿，有利于定位。\n - DCNN将位置信息和语义信息进行编码，成为一个局部到全局的金字塔。\n - 因此，定义一个跳跃结构来将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合。\n- 跳跃结构是端到端地进行学习，来改善输出的语义和定位精度\n- 如上图所示：\n - FCN-32s：基础的FCN称为FCN-32s。因为是从`pool5`输出的分辨率为$7 \\times 7$的特征图直接插值到分辨率为$224 \\times 224$的特征图，插值前后的分辨率比率为$1/32$。\n - FCN-16s：FCN-32s与`pool4`输出的特征图进行跳跃连接后的模型，称为FCN-16s。\n - FCN-8s：FCN-16s与`pool3`输出的特征图进行跳跃连接后的模型，称为FCN-8s。\n\n<img src=\"/images/FCN/3.png\"  width = \"500\" height = \"100\"/>\n\n如上图所示，为增加跳跃结构之后的语义分割结果对比。\n\n## 模型比较\n<img src=\"/images/FCN/4.png\"  width = \"500\" height = \"100\"/>\n\n## 训练策略及各超参数\n\n- 整体训练策略：加载VGG16模型在ImageNet上预训练的权重，基于VOC2011微调整个FCN网络：\n - 注1：加载VGG16的全连接层之前的层的权重\n - 注2：若只微调FCN的分类层，只能获得微调整个FCN网络70%的表现\n\n- 预处理及数据增强：无\n\n各超参数参考官方[`voc-fcn8s/solver.prototxt`](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/siftflow-fcn8s/solver.prototxt)及[voc-fcn8s/deploy.prototxt](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn8s/deploy.prototxt)：\n\n- 输入尺寸：$500\\times 500 \\times 3 $\n- 优化器：SGD\n- 动量：0.99\n- 初始学习率：1e-12\n- 学习率策略：采用固定学习率\n- 权重衰减：0.0005\n- 批量尺寸：1\n- 最大迭代次数：300000 \n\n## 参考文献\n\n- [论文：Fully Convolutional Networks for Semantic Segmentation,2015](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)\n- [视频：How FCN Fully Convolutional Networks Works for Semantic Segmentation](https://www.youtube.com/watch?v=UdZnhZrM2vQ)\n- [代码及注释：dhkim0225/keras-image-segmentation](https://github.com/liminn/keras-image-segmentation/blob/master/model/fcn.py)\n- [官方Caffe代码：shelhamer/fcn.berkeleyvision.org](https://github.com/shelhamer/fcn.berkeleyvision.org)\n\n\n\n\n","slug":"FCN","published":1,"updated":"2019-01-08T10:22:21.403Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vuy0008qslphbwpqyyi","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><ul>\n<li>针对语义分割任务，提出了全卷积网络(FCN, fully convolutional network)，使得对任意尺寸的输入，网络能够产生对应尺寸的输出。</li>\n<li>首先，修改当前的分类模型(如AlexNet、VGG及GoogleNet)成为全卷积网络，然后通过微调(fine-tuning)来对分割任务进行迁移学习。</li>\n<li>其中，定义了跳跃结构(skip architecture)，即将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合(元素级相加)。</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h2><h3 id=\"全卷积化分类网络\"><a href=\"#全卷积化分类网络\" class=\"headerlink\" title=\"全卷积化分类网络\"></a>全卷积化分类网络</h3><p><img src=\"/images/FCN/1.png\" width=\"700\" height=\"100\"></p>\n<p>如上图所示，修改分类网络来进行密集预测(Adapting classifiers for dense prediction)：</p>\n<ul>\n<li>1.将分类网络最后的分类层抛弃，将全连接层卷积化：<ul>\n<li>分类网络(如AlexNet、VGG及GoogleNet)中存在全连接层，而全连接层有着固定的维度，并且抛弃了空间坐标信息，故将全连接层进行卷积化</li>\n</ul>\n</li>\n<li>2.增加$1\\times 1$卷积，使得通道数为分类数目，即21(20前景和1背景)</li>\n<li>3.双线性插值来上采样粗糙的输出特征(coarse outputs)成为像素级密集的输出特征(pixel-dense outputs)</li>\n<li>3.增加逐像素的loss(a pixelwise loss)</li>\n</ul>\n<p>注：</p>\n<ul>\n<li>疑问1：如何将全连接层卷积化的（需看源码）</li>\n<li>解答：见源码:<ul>\n<li>以VGG16为例：Block5的输出尺寸为$7 \\times 7 \\times 512$，后接4096的全连接层；原VGG16中，是将$7 \\times 7 \\times 512$拉长成25088，然后和4096个神经元进行全连接。故原参数个数为：$25088 \\times 4096+4096 =  102764544$。</li>\n<li>在FCN中，以卷积核为$7\\times7$，步长为1，卷积核个数为4096，同时采用same卷积，使得该全连接层卷积化，该层的输出为$7 \\times7 \\times 4096$，即空间尺寸不变。</li>\n</ul>\n</li>\n<li>疑问2：如何实现上采样（需看源码）</li>\n<li>解答：见源码，只是双线性插值 </li>\n<li>疑问3：上采样、双线性插值、转置卷积到底有什么区别，如何实现(概念性问题)</li>\n<li>解答：上采样的说法高于双线性插值/转置卷积；双线性插值不需学习；转置卷积带有参数，需要学习。</li>\n</ul>\n<h3 id=\"跳跃结构-skip-architecture\"><a href=\"#跳跃结构-skip-architecture\" class=\"headerlink\" title=\"跳跃结构(skip architecture)\"></a>跳跃结构(skip architecture)</h3><p><img src=\"/images/FCN/2.png\" width=\"700\" height=\"100\"></p>\n<ul>\n<li>设计跳跃结构的原因：<ul>\n<li>语义分割面临一个内在的语义和定位之间张力：全局信息解决了是什么，有利于语义；局部信息解决了在哪儿，有利于定位。</li>\n<li>DCNN将位置信息和语义信息进行编码，成为一个局部到全局的金字塔。</li>\n<li>因此，定义一个跳跃结构来将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合。</li>\n</ul>\n</li>\n<li>跳跃结构是端到端地进行学习，来改善输出的语义和定位精度</li>\n<li>如上图所示：<ul>\n<li>FCN-32s：基础的FCN称为FCN-32s。因为是从<code>pool5</code>输出的分辨率为$7 \\times 7$的特征图直接插值到分辨率为$224 \\times 224$的特征图，插值前后的分辨率比率为$1/32$。</li>\n<li>FCN-16s：FCN-32s与<code>pool4</code>输出的特征图进行跳跃连接后的模型，称为FCN-16s。</li>\n<li>FCN-8s：FCN-16s与<code>pool3</code>输出的特征图进行跳跃连接后的模型，称为FCN-8s。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/FCN/3.png\" width=\"500\" height=\"100\"></p>\n<p>如上图所示，为增加跳跃结构之后的语义分割结果对比。</p>\n<h2 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h2><p><img src=\"/images/FCN/4.png\" width=\"500\" height=\"100\"></p>\n<h2 id=\"训练策略及各超参数\"><a href=\"#训练策略及各超参数\" class=\"headerlink\" title=\"训练策略及各超参数\"></a>训练策略及各超参数</h2><ul>\n<li><p>整体训练策略：加载VGG16模型在ImageNet上预训练的权重，基于VOC2011微调整个FCN网络：</p>\n<ul>\n<li>注1：加载VGG16的全连接层之前的层的权重</li>\n<li>注2：若只微调FCN的分类层，只能获得微调整个FCN网络70%的表现</li>\n</ul>\n</li>\n<li><p>预处理及数据增强：无</p>\n</li>\n</ul>\n<p>各超参数参考官方<a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/siftflow-fcn8s/solver.prototxt\" target=\"_blank\" rel=\"noopener\"><code>voc-fcn8s/solver.prototxt</code></a>及<a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn8s/deploy.prototxt\" target=\"_blank\" rel=\"noopener\">voc-fcn8s/deploy.prototxt</a>：</p>\n<ul>\n<li>输入尺寸：$500\\times 500 \\times 3 $</li>\n<li>优化器：SGD</li>\n<li>动量：0.99</li>\n<li>初始学习率：1e-12</li>\n<li>学习率策略：采用固定学习率</li>\n<li>权重衰减：0.0005</li>\n<li>批量尺寸：1</li>\n<li>最大迭代次数：300000 </li>\n</ul>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><a href=\"https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\" target=\"_blank\" rel=\"noopener\">论文：Fully Convolutional Networks for Semantic Segmentation,2015</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=UdZnhZrM2vQ\" target=\"_blank\" rel=\"noopener\">视频：How FCN Fully Convolutional Networks Works for Semantic Segmentation</a></li>\n<li><a href=\"https://github.com/liminn/keras-image-segmentation/blob/master/model/fcn.py\" target=\"_blank\" rel=\"noopener\">代码及注释：dhkim0225/keras-image-segmentation</a></li>\n<li><a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org\" target=\"_blank\" rel=\"noopener\">官方Caffe代码：shelhamer/fcn.berkeleyvision.org</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><ul>\n<li>针对语义分割任务，提出了全卷积网络(FCN, fully convolutional network)，使得对任意尺寸的输入，网络能够产生对应尺寸的输出。</li>\n<li>首先，修改当前的分类模型(如AlexNet、VGG及GoogleNet)成为全卷积网络，然后通过微调(fine-tuning)来对分割任务进行迁移学习。</li>\n<li>其中，定义了跳跃结构(skip architecture)，即将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合(元素级相加)。</li>\n</ul>","more":"<h2 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h2><h3 id=\"全卷积化分类网络\"><a href=\"#全卷积化分类网络\" class=\"headerlink\" title=\"全卷积化分类网络\"></a>全卷积化分类网络</h3><p><img src=\"/images/FCN/1.png\" width=\"700\" height=\"100\"></p>\n<p>如上图所示，修改分类网络来进行密集预测(Adapting classifiers for dense prediction)：</p>\n<ul>\n<li>1.将分类网络最后的分类层抛弃，将全连接层卷积化：<ul>\n<li>分类网络(如AlexNet、VGG及GoogleNet)中存在全连接层，而全连接层有着固定的维度，并且抛弃了空间坐标信息，故将全连接层进行卷积化</li>\n</ul>\n</li>\n<li>2.增加$1\\times 1$卷积，使得通道数为分类数目，即21(20前景和1背景)</li>\n<li>3.双线性插值来上采样粗糙的输出特征(coarse outputs)成为像素级密集的输出特征(pixel-dense outputs)</li>\n<li>3.增加逐像素的loss(a pixelwise loss)</li>\n</ul>\n<p>注：</p>\n<ul>\n<li>疑问1：如何将全连接层卷积化的（需看源码）</li>\n<li>解答：见源码:<ul>\n<li>以VGG16为例：Block5的输出尺寸为$7 \\times 7 \\times 512$，后接4096的全连接层；原VGG16中，是将$7 \\times 7 \\times 512$拉长成25088，然后和4096个神经元进行全连接。故原参数个数为：$25088 \\times 4096+4096 =  102764544$。</li>\n<li>在FCN中，以卷积核为$7\\times7$，步长为1，卷积核个数为4096，同时采用same卷积，使得该全连接层卷积化，该层的输出为$7 \\times7 \\times 4096$，即空间尺寸不变。</li>\n</ul>\n</li>\n<li>疑问2：如何实现上采样（需看源码）</li>\n<li>解答：见源码，只是双线性插值 </li>\n<li>疑问3：上采样、双线性插值、转置卷积到底有什么区别，如何实现(概念性问题)</li>\n<li>解答：上采样的说法高于双线性插值/转置卷积；双线性插值不需学习；转置卷积带有参数，需要学习。</li>\n</ul>\n<h3 id=\"跳跃结构-skip-architecture\"><a href=\"#跳跃结构-skip-architecture\" class=\"headerlink\" title=\"跳跃结构(skip architecture)\"></a>跳跃结构(skip architecture)</h3><p><img src=\"/images/FCN/2.png\" width=\"700\" height=\"100\"></p>\n<ul>\n<li>设计跳跃结构的原因：<ul>\n<li>语义分割面临一个内在的语义和定位之间张力：全局信息解决了是什么，有利于语义；局部信息解决了在哪儿，有利于定位。</li>\n<li>DCNN将位置信息和语义信息进行编码，成为一个局部到全局的金字塔。</li>\n<li>因此，定义一个跳跃结构来将深层的粗糙的语义信息(deep,coarse,semantic information)和浅层的精细的轮廓信息(shallow,fine,appearance information)相结合。</li>\n</ul>\n</li>\n<li>跳跃结构是端到端地进行学习，来改善输出的语义和定位精度</li>\n<li>如上图所示：<ul>\n<li>FCN-32s：基础的FCN称为FCN-32s。因为是从<code>pool5</code>输出的分辨率为$7 \\times 7$的特征图直接插值到分辨率为$224 \\times 224$的特征图，插值前后的分辨率比率为$1/32$。</li>\n<li>FCN-16s：FCN-32s与<code>pool4</code>输出的特征图进行跳跃连接后的模型，称为FCN-16s。</li>\n<li>FCN-8s：FCN-16s与<code>pool3</code>输出的特征图进行跳跃连接后的模型，称为FCN-8s。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/FCN/3.png\" width=\"500\" height=\"100\"></p>\n<p>如上图所示，为增加跳跃结构之后的语义分割结果对比。</p>\n<h2 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h2><p><img src=\"/images/FCN/4.png\" width=\"500\" height=\"100\"></p>\n<h2 id=\"训练策略及各超参数\"><a href=\"#训练策略及各超参数\" class=\"headerlink\" title=\"训练策略及各超参数\"></a>训练策略及各超参数</h2><ul>\n<li><p>整体训练策略：加载VGG16模型在ImageNet上预训练的权重，基于VOC2011微调整个FCN网络：</p>\n<ul>\n<li>注1：加载VGG16的全连接层之前的层的权重</li>\n<li>注2：若只微调FCN的分类层，只能获得微调整个FCN网络70%的表现</li>\n</ul>\n</li>\n<li><p>预处理及数据增强：无</p>\n</li>\n</ul>\n<p>各超参数参考官方<a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/siftflow-fcn8s/solver.prototxt\" target=\"_blank\" rel=\"noopener\"><code>voc-fcn8s/solver.prototxt</code></a>及<a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn8s/deploy.prototxt\" target=\"_blank\" rel=\"noopener\">voc-fcn8s/deploy.prototxt</a>：</p>\n<ul>\n<li>输入尺寸：$500\\times 500 \\times 3 $</li>\n<li>优化器：SGD</li>\n<li>动量：0.99</li>\n<li>初始学习率：1e-12</li>\n<li>学习率策略：采用固定学习率</li>\n<li>权重衰减：0.0005</li>\n<li>批量尺寸：1</li>\n<li>最大迭代次数：300000 </li>\n</ul>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><a href=\"https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\" target=\"_blank\" rel=\"noopener\">论文：Fully Convolutional Networks for Semantic Segmentation,2015</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=UdZnhZrM2vQ\" target=\"_blank\" rel=\"noopener\">视频：How FCN Fully Convolutional Networks Works for Semantic Segmentation</a></li>\n<li><a href=\"https://github.com/liminn/keras-image-segmentation/blob/master/model/fcn.py\" target=\"_blank\" rel=\"noopener\">代码及注释：dhkim0225/keras-image-segmentation</a></li>\n<li><a href=\"https://github.com/shelhamer/fcn.berkeleyvision.org\" target=\"_blank\" rel=\"noopener\">官方Caffe代码：shelhamer/fcn.berkeleyvision.org</a></li>\n</ul>"},{"title":"C/C++内存管理","date":"2017-11-26T13:33:00.000Z","_content":"## 1.内存分配方式\n　　在C++中，内存分成5个区，它们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。\n\n - 栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。\n - 堆：从技术上来说，堆是C语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用`malloc`时就会从中分配，稍后调用`free`可把内存交还。\n - 自由存储区：而自由存储是C++中通过`new`和`delete`动态分配和释放对象的抽象概念，通过`new`来申请的内存区域可称为自由存储区。\n - 全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。\n - 常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。\n<!-- more --> \n\n## 2.malloc/free与new/delete的区别\n`malloc`/`free`是C/C++语言的标准库函数，`new`/`delete`是C++的运算符。它们都可用于申请动态内存和释放内存。\n\n - 申请的内存所在位置：`new`操作符从自由存储区（free store）上为对象动态分配内存空间，而`malloc`函数从堆上动态分配内存。\n - `new`/`delete`会调用构造函数/析构函数对对象进行初始化与销毁，而`malloc`则不会 。对于非内部数据类型的对象而言，光用`maloc/free`无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于`malloc/free`是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于`malloc/free`。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符`new`，以及一个能完成清理与释放内存工作的运算符`delete`。注意`new/delete`不是库函数。\n - 操作符`new`/`delete`可以进行重载\n\n \n## 3.delete与 delete []区别\n - `delete`只会调用一次析构函数，而`delete[]`会调用每一个成员的析构函数。在More Effective C++中：“当`delete`操作符用于数组时，它为每个数组元素调用析构函数，然后调用操作符`delete`来释放内存。”\n - 基本类型的对象没有析构函数，所以回收基本类型组成的数组空间用 `delete` 和 `delete[]`功能是相同的；但是对于类对象数组，只能用 `delete[]`；对于 `new` 的单个对象，只能用 `delete` 不能用 `delete[]` 回收空间。 \n - 总之，`delete`与`new`配套，`delete[]`与`new []`配套。\n\n \n## 参考\n1.[C++自由存储区是否等价于堆？](http://www.cnblogs.com/QG-whz/p/5060894.html)\n2.[细说new与malloc的10点区别](http://www.cnblogs.com/QG-whz/p/5140930.html)\n3.[C/C++内存管理详解，里面有错误](https://chenqx.github.io/2014/09/25/Cpp-Memory-Management/)\n4.[C++中delete和delete[]的区别](http://www.cnblogs.com/charley_yang/archive/2010/12/08/1899982.html)","source":"_posts/C++内存管理.md","raw":"---\ntitle: C/C++内存管理\ndate: 2017-11-26 21:33:00\ncategories: \n- C/C++\ntags:\n- C\n- C++\n- 内存管理\n- 堆\n- 栈\n- 自由存储区\n- malloc\n- free\n- new\n- delete\n- delete[]\n---\n## 1.内存分配方式\n　　在C++中，内存分成5个区，它们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。\n\n - 栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。\n - 堆：从技术上来说，堆是C语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用`malloc`时就会从中分配，稍后调用`free`可把内存交还。\n - 自由存储区：而自由存储是C++中通过`new`和`delete`动态分配和释放对象的抽象概念，通过`new`来申请的内存区域可称为自由存储区。\n - 全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。\n - 常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。\n<!-- more --> \n\n## 2.malloc/free与new/delete的区别\n`malloc`/`free`是C/C++语言的标准库函数，`new`/`delete`是C++的运算符。它们都可用于申请动态内存和释放内存。\n\n - 申请的内存所在位置：`new`操作符从自由存储区（free store）上为对象动态分配内存空间，而`malloc`函数从堆上动态分配内存。\n - `new`/`delete`会调用构造函数/析构函数对对象进行初始化与销毁，而`malloc`则不会 。对于非内部数据类型的对象而言，光用`maloc/free`无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于`malloc/free`是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于`malloc/free`。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符`new`，以及一个能完成清理与释放内存工作的运算符`delete`。注意`new/delete`不是库函数。\n - 操作符`new`/`delete`可以进行重载\n\n \n## 3.delete与 delete []区别\n - `delete`只会调用一次析构函数，而`delete[]`会调用每一个成员的析构函数。在More Effective C++中：“当`delete`操作符用于数组时，它为每个数组元素调用析构函数，然后调用操作符`delete`来释放内存。”\n - 基本类型的对象没有析构函数，所以回收基本类型组成的数组空间用 `delete` 和 `delete[]`功能是相同的；但是对于类对象数组，只能用 `delete[]`；对于 `new` 的单个对象，只能用 `delete` 不能用 `delete[]` 回收空间。 \n - 总之，`delete`与`new`配套，`delete[]`与`new []`配套。\n\n \n## 参考\n1.[C++自由存储区是否等价于堆？](http://www.cnblogs.com/QG-whz/p/5060894.html)\n2.[细说new与malloc的10点区别](http://www.cnblogs.com/QG-whz/p/5140930.html)\n3.[C/C++内存管理详解，里面有错误](https://chenqx.github.io/2014/09/25/Cpp-Memory-Management/)\n4.[C++中delete和delete[]的区别](http://www.cnblogs.com/charley_yang/archive/2010/12/08/1899982.html)","slug":"C++内存管理","published":1,"updated":"2017-12-05T03:07:02.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vuz0009qslpiuznh8bc","content":"<h2 id=\"1-内存分配方式\"><a href=\"#1-内存分配方式\" class=\"headerlink\" title=\"1.内存分配方式\"></a>1.内存分配方式</h2><p>　　在C++中，内存分成5个区，它们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。</p>\n<ul>\n<li>栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。</li>\n<li>堆：从技术上来说，堆是C语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用<code>malloc</code>时就会从中分配，稍后调用<code>free</code>可把内存交还。</li>\n<li>自由存储区：而自由存储是C++中通过<code>new</code>和<code>delete</code>动态分配和释放对象的抽象概念，通过<code>new</code>来申请的内存区域可称为自由存储区。</li>\n<li>全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。</li>\n<li>常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。<a id=\"more\"></a> \n</li>\n</ul>\n<h2 id=\"2-malloc-free与new-delete的区别\"><a href=\"#2-malloc-free与new-delete的区别\" class=\"headerlink\" title=\"2.malloc/free与new/delete的区别\"></a>2.malloc/free与new/delete的区别</h2><p><code>malloc</code>/<code>free</code>是C/C++语言的标准库函数，<code>new</code>/<code>delete</code>是C++的运算符。它们都可用于申请动态内存和释放内存。</p>\n<ul>\n<li>申请的内存所在位置：<code>new</code>操作符从自由存储区（free store）上为对象动态分配内存空间，而<code>malloc</code>函数从堆上动态分配内存。</li>\n<li><code>new</code>/<code>delete</code>会调用构造函数/析构函数对对象进行初始化与销毁，而<code>malloc</code>则不会 。对于非内部数据类型的对象而言，光用<code>maloc/free</code>无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于<code>malloc/free</code>是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于<code>malloc/free</code>。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符<code>new</code>，以及一个能完成清理与释放内存工作的运算符<code>delete</code>。注意<code>new/delete</code>不是库函数。</li>\n<li>操作符<code>new</code>/<code>delete</code>可以进行重载</li>\n</ul>\n<h2 id=\"3-delete与-delete-区别\"><a href=\"#3-delete与-delete-区别\" class=\"headerlink\" title=\"3.delete与 delete []区别\"></a>3.delete与 delete []区别</h2><ul>\n<li><code>delete</code>只会调用一次析构函数，而<code>delete[]</code>会调用每一个成员的析构函数。在More Effective C++中：“当<code>delete</code>操作符用于数组时，它为每个数组元素调用析构函数，然后调用操作符<code>delete</code>来释放内存。”</li>\n<li>基本类型的对象没有析构函数，所以回收基本类型组成的数组空间用 <code>delete</code> 和 <code>delete[]</code>功能是相同的；但是对于类对象数组，只能用 <code>delete[]</code>；对于 <code>new</code> 的单个对象，只能用 <code>delete</code> 不能用 <code>delete[]</code> 回收空间。 </li>\n<li>总之，<code>delete</code>与<code>new</code>配套，<code>delete[]</code>与<code>new []</code>配套。</li>\n</ul>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://www.cnblogs.com/QG-whz/p/5060894.html\" target=\"_blank\" rel=\"noopener\">C++自由存储区是否等价于堆？</a><br>2.<a href=\"http://www.cnblogs.com/QG-whz/p/5140930.html\" target=\"_blank\" rel=\"noopener\">细说new与malloc的10点区别</a><br>3.<a href=\"https://chenqx.github.io/2014/09/25/Cpp-Memory-Management/\" target=\"_blank\" rel=\"noopener\">C/C++内存管理详解，里面有错误</a><br>4.<a href=\"http://www.cnblogs.com/charley_yang/archive/2010/12/08/1899982.html\" target=\"_blank\" rel=\"noopener\">C++中delete和delete[]的区别</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-内存分配方式\"><a href=\"#1-内存分配方式\" class=\"headerlink\" title=\"1.内存分配方式\"></a>1.内存分配方式</h2><p>　　在C++中，内存分成5个区，它们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。</p>\n<ul>\n<li>栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。</li>\n<li>堆：从技术上来说，堆是C语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当运行程序调用<code>malloc</code>时就会从中分配，稍后调用<code>free</code>可把内存交还。</li>\n<li>自由存储区：而自由存储是C++中通过<code>new</code>和<code>delete</code>动态分配和释放对象的抽象概念，通过<code>new</code>来申请的内存区域可称为自由存储区。</li>\n<li>全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。</li>\n<li>常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。","more":"</li>\n</ul>\n<h2 id=\"2-malloc-free与new-delete的区别\"><a href=\"#2-malloc-free与new-delete的区别\" class=\"headerlink\" title=\"2.malloc/free与new/delete的区别\"></a>2.malloc/free与new/delete的区别</h2><p><code>malloc</code>/<code>free</code>是C/C++语言的标准库函数，<code>new</code>/<code>delete</code>是C++的运算符。它们都可用于申请动态内存和释放内存。</p>\n<ul>\n<li>申请的内存所在位置：<code>new</code>操作符从自由存储区（free store）上为对象动态分配内存空间，而<code>malloc</code>函数从堆上动态分配内存。</li>\n<li><code>new</code>/<code>delete</code>会调用构造函数/析构函数对对象进行初始化与销毁，而<code>malloc</code>则不会 。对于非内部数据类型的对象而言，光用<code>maloc/free</code>无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于<code>malloc/free</code>是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于<code>malloc/free</code>。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符<code>new</code>，以及一个能完成清理与释放内存工作的运算符<code>delete</code>。注意<code>new/delete</code>不是库函数。</li>\n<li>操作符<code>new</code>/<code>delete</code>可以进行重载</li>\n</ul>\n<h2 id=\"3-delete与-delete-区别\"><a href=\"#3-delete与-delete-区别\" class=\"headerlink\" title=\"3.delete与 delete []区别\"></a>3.delete与 delete []区别</h2><ul>\n<li><code>delete</code>只会调用一次析构函数，而<code>delete[]</code>会调用每一个成员的析构函数。在More Effective C++中：“当<code>delete</code>操作符用于数组时，它为每个数组元素调用析构函数，然后调用操作符<code>delete</code>来释放内存。”</li>\n<li>基本类型的对象没有析构函数，所以回收基本类型组成的数组空间用 <code>delete</code> 和 <code>delete[]</code>功能是相同的；但是对于类对象数组，只能用 <code>delete[]</code>；对于 <code>new</code> 的单个对象，只能用 <code>delete</code> 不能用 <code>delete[]</code> 回收空间。 </li>\n<li>总之，<code>delete</code>与<code>new</code>配套，<code>delete[]</code>与<code>new []</code>配套。</li>\n</ul>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>1.<a href=\"http://www.cnblogs.com/QG-whz/p/5060894.html\" target=\"_blank\" rel=\"noopener\">C++自由存储区是否等价于堆？</a><br>2.<a href=\"http://www.cnblogs.com/QG-whz/p/5140930.html\" target=\"_blank\" rel=\"noopener\">细说new与malloc的10点区别</a><br>3.<a href=\"https://chenqx.github.io/2014/09/25/Cpp-Memory-Management/\" target=\"_blank\" rel=\"noopener\">C/C++内存管理详解，里面有错误</a><br>4.<a href=\"http://www.cnblogs.com/charley_yang/archive/2010/12/08/1899982.html\" target=\"_blank\" rel=\"noopener\">C++中delete和delete[]的区别</a></p>"},{"title":"MobileNetV1","mathjax":true,"date":"2018-12-29T14:21:50.000Z","_content":"\n# 摘要\n- 针对移动端及嵌入式视觉应用，利用深度可分离卷积(depthwise separable convolutions)，构建轻量级的深度神经网络，即MobileNet。\n- 其中引进了两个简单的超参数(宽度乘子(Width Multiplier)和分辨率乘子(Resolution Multiplier))来有效地权衡延迟(latency)和精度。\n- 本质：只是用深度可分离卷积来替换常规CNN中的常规卷积\n<!-- more -->\n\n# 创新点\n##网络结构##\n\n<img src=\"/images/MobileNetV1/1.png\"  width = \"400\">\n<img src=\"/images/MobileNetV1/2.png\"  width = \"350\">\n<img src=\"/images/MobileNetV1/3.png\"  width = \"350\">\n\n- MobileNetV1结构如Table1所示：\n - **MobileNet基于深度可分离卷积构建，除了第一层为常规卷积以外**。\n - **如Fig3所示，所有层之后，均伴随BN和ReLU非线性操作**；除了最后的全连接层没有ReLU非线性，被喂给softmax层来进行分类。\n - **下采样操作通过depthwise卷积和第一层常规卷积中的带步长的卷积实现（注意这一点）**。\n - 最后的平均池化层使得空间分辨率在全连接层之前减小到1。\n - 若将depthwise卷积和pointwise卷积计为分离的层，那么MobileNet有28层。\n- 如Table2所示，MobileNet花费95%的计算时间在$1\\times 1$卷积上，并且$1\\times 1$卷积占据了75%的参数。所有的其它参数，几乎都集中在全连接层上。\n\n##宽度乘子(Width Multiplier)——更瘦的模型\n- 第一个超参数宽度乘子$\\alpha$,其作用是统一地使网络的每一层变瘦：\n - 对于一个给定层，在宽度乘子$\\alpha$的作用下，输入的通道数由$M$变为$\\alpha M$，输出的通道数由$N$变成$\\alpha N$。\n- 在宽度乘子$\\alpha$的作用下：\n - 深度可分离卷积的计算量变为：$\\alpha M \\times {D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times {D_G}^2 $。\n - $\\alpha \\in (0,1]$ ，$\\alpha$的典型设置为1，0.75，0.5和0.25。$\\alpha=1$ 即是基准的MobileNet，$\\alpha<1$即是简化的MobileNet。\n - 宽度乘子$\\alpha$能够平方级地减少计算量和参数量，即约$\\alpha ^2$。\n\n##分辨率乘子(Resolution Multiplier)——减少表征**\n- 第二个超参数分辨率乘子$\\rho$，其作用是减少网络的计算量：\n - 对输入图片施加分辨率乘子$\\rho$，那么网络每一层的中间表征都将随之减小相同的乘子。\n - 在实际操作中，通过设置输入分辨率，来隐式地设置$\\rho$。\n- 在宽度乘子$\\alpha$和分辨率乘子$\\rho$的作用下：\n - 深度可分离卷积的计算量变为：$\\alpha M \\times \\rho^2{D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times \\rho^2{D_G}^2 $。\n - $\\rho \\in (0,1]$ ，$\\rho$通常隐式地设置，故网络的输入分辨率典型设置为224，192，160或128。$\\rho=1$ 即是基准的MobileNet。\n - 分辨率乘子$\\rho$能够平方级地减少计算量，即约$\\rho ^2$。\n\n# 训练策略\n- MobileNet在TF上实现，通过和Inception V3相似的带有异步梯度下降的RMSprop实现。\n- 用更少的正则化和更少的数据增强技术，因为小的网络不易过拟合。\n- 用非常小或不使用权重衰减(L2正则)在depthwise卷积上很重要，因为它们只有过少的参数。\n\n\n# 模型比较\n<img src=\"/images/MobileNetV1/4.png\"  width = \"400\"/>\n \n - 如Table4所示，比较了MobileNet与其全卷积实现形式：在ImageNet上，只损失了1%的精度，但节约了大量的计算量和参数。\n\n<img src=\"/images/MobileNetV1/5.png\"  width = \"400\"/>\n\n- 如Table6所示，展示了通过不同的宽度乘子$\\alpha$来收缩MobileNet时，精度、计算量和参数量之间的权衡。精度平滑的下降，直到模型结构过小，即$\\alpha=0.25$时。\n- 注：在ImageNet基准上，无论模型尺寸的大小，所有模型均用相同的训练参数进行训练。\n\n<img src=\"/images/MobileNetV1/6.png\"  width = \"400\"/>\n\n- 如Table7所示，展示了通过施加不同的分辨率乘子$\\rho$，即用减小的输入分辨率来训练MobileNet时，精度、计算量和参数量之间的权衡。准确率依据分辨率平滑下降。\n\n<img src=\"/images/MobileNetV1/7.png\"  width = \"400\"/>\n\n- **如Table8所示，展示了完整MobileNet和GoogleNetV1、VGG16之间的比较**：\n - MobileNet精度接近于VGG16，同时参数量只是其$1/32$，计算量为其$1/27$。\n - MobileNet精度高于GoogleNetV1，同时参数量更少，计算量为其$1/2.7$。\n\n<img src=\"/images/MobileNetV1/8.png\"  width = \"400\"/>\n\n- 如Table9所示，展示了通过$\\alpha=0.5$且分辨率为$160\\times 160$简化的MobileNet与AlexNet和Squeezenet之间的比较：\n - 简化版MobileNet比AlexNet的精度高3%，同时参数量只是其$1/45$，计算量为其$1/9.4$。\n - 简化版MobileNet比Squeezenet的精度高3%，同时参数量相同，计算量为其$1/22$。\n\n此外，文中还展示了通过MobileNet，在细粒度分类(Fine Grained Recognition)、Large Scale Geolocalizaton、Face Attributes、目标检测(Object Detection)及Face Embeddings任务上的应用结果。\n\n# 参考文献\n- [论文：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)\n- [视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!](https://www.youtube.com/watch?v=T7o3xvJLuHk&t=0s&list=LLPZqbzAbJOX-hE-IRAxB7sg&index=2)\n\n\n","source":"_posts/MobileNetV1.md","raw":"---\ntitle: MobileNetV1\nmathjax: true\ndate: 2018-12-29 22:21:50\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 摘要\n- 针对移动端及嵌入式视觉应用，利用深度可分离卷积(depthwise separable convolutions)，构建轻量级的深度神经网络，即MobileNet。\n- 其中引进了两个简单的超参数(宽度乘子(Width Multiplier)和分辨率乘子(Resolution Multiplier))来有效地权衡延迟(latency)和精度。\n- 本质：只是用深度可分离卷积来替换常规CNN中的常规卷积\n<!-- more -->\n\n# 创新点\n##网络结构##\n\n<img src=\"/images/MobileNetV1/1.png\"  width = \"400\">\n<img src=\"/images/MobileNetV1/2.png\"  width = \"350\">\n<img src=\"/images/MobileNetV1/3.png\"  width = \"350\">\n\n- MobileNetV1结构如Table1所示：\n - **MobileNet基于深度可分离卷积构建，除了第一层为常规卷积以外**。\n - **如Fig3所示，所有层之后，均伴随BN和ReLU非线性操作**；除了最后的全连接层没有ReLU非线性，被喂给softmax层来进行分类。\n - **下采样操作通过depthwise卷积和第一层常规卷积中的带步长的卷积实现（注意这一点）**。\n - 最后的平均池化层使得空间分辨率在全连接层之前减小到1。\n - 若将depthwise卷积和pointwise卷积计为分离的层，那么MobileNet有28层。\n- 如Table2所示，MobileNet花费95%的计算时间在$1\\times 1$卷积上，并且$1\\times 1$卷积占据了75%的参数。所有的其它参数，几乎都集中在全连接层上。\n\n##宽度乘子(Width Multiplier)——更瘦的模型\n- 第一个超参数宽度乘子$\\alpha$,其作用是统一地使网络的每一层变瘦：\n - 对于一个给定层，在宽度乘子$\\alpha$的作用下，输入的通道数由$M$变为$\\alpha M$，输出的通道数由$N$变成$\\alpha N$。\n- 在宽度乘子$\\alpha$的作用下：\n - 深度可分离卷积的计算量变为：$\\alpha M \\times {D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times {D_G}^2 $。\n - $\\alpha \\in (0,1]$ ，$\\alpha$的典型设置为1，0.75，0.5和0.25。$\\alpha=1$ 即是基准的MobileNet，$\\alpha<1$即是简化的MobileNet。\n - 宽度乘子$\\alpha$能够平方级地减少计算量和参数量，即约$\\alpha ^2$。\n\n##分辨率乘子(Resolution Multiplier)——减少表征**\n- 第二个超参数分辨率乘子$\\rho$，其作用是减少网络的计算量：\n - 对输入图片施加分辨率乘子$\\rho$，那么网络每一层的中间表征都将随之减小相同的乘子。\n - 在实际操作中，通过设置输入分辨率，来隐式地设置$\\rho$。\n- 在宽度乘子$\\alpha$和分辨率乘子$\\rho$的作用下：\n - 深度可分离卷积的计算量变为：$\\alpha M \\times \\rho^2{D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times \\rho^2{D_G}^2 $。\n - $\\rho \\in (0,1]$ ，$\\rho$通常隐式地设置，故网络的输入分辨率典型设置为224，192，160或128。$\\rho=1$ 即是基准的MobileNet。\n - 分辨率乘子$\\rho$能够平方级地减少计算量，即约$\\rho ^2$。\n\n# 训练策略\n- MobileNet在TF上实现，通过和Inception V3相似的带有异步梯度下降的RMSprop实现。\n- 用更少的正则化和更少的数据增强技术，因为小的网络不易过拟合。\n- 用非常小或不使用权重衰减(L2正则)在depthwise卷积上很重要，因为它们只有过少的参数。\n\n\n# 模型比较\n<img src=\"/images/MobileNetV1/4.png\"  width = \"400\"/>\n \n - 如Table4所示，比较了MobileNet与其全卷积实现形式：在ImageNet上，只损失了1%的精度，但节约了大量的计算量和参数。\n\n<img src=\"/images/MobileNetV1/5.png\"  width = \"400\"/>\n\n- 如Table6所示，展示了通过不同的宽度乘子$\\alpha$来收缩MobileNet时，精度、计算量和参数量之间的权衡。精度平滑的下降，直到模型结构过小，即$\\alpha=0.25$时。\n- 注：在ImageNet基准上，无论模型尺寸的大小，所有模型均用相同的训练参数进行训练。\n\n<img src=\"/images/MobileNetV1/6.png\"  width = \"400\"/>\n\n- 如Table7所示，展示了通过施加不同的分辨率乘子$\\rho$，即用减小的输入分辨率来训练MobileNet时，精度、计算量和参数量之间的权衡。准确率依据分辨率平滑下降。\n\n<img src=\"/images/MobileNetV1/7.png\"  width = \"400\"/>\n\n- **如Table8所示，展示了完整MobileNet和GoogleNetV1、VGG16之间的比较**：\n - MobileNet精度接近于VGG16，同时参数量只是其$1/32$，计算量为其$1/27$。\n - MobileNet精度高于GoogleNetV1，同时参数量更少，计算量为其$1/2.7$。\n\n<img src=\"/images/MobileNetV1/8.png\"  width = \"400\"/>\n\n- 如Table9所示，展示了通过$\\alpha=0.5$且分辨率为$160\\times 160$简化的MobileNet与AlexNet和Squeezenet之间的比较：\n - 简化版MobileNet比AlexNet的精度高3%，同时参数量只是其$1/45$，计算量为其$1/9.4$。\n - 简化版MobileNet比Squeezenet的精度高3%，同时参数量相同，计算量为其$1/22$。\n\n此外，文中还展示了通过MobileNet，在细粒度分类(Fine Grained Recognition)、Large Scale Geolocalizaton、Face Attributes、目标检测(Object Detection)及Face Embeddings任务上的应用结果。\n\n# 参考文献\n- [论文：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)\n- [视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!](https://www.youtube.com/watch?v=T7o3xvJLuHk&t=0s&list=LLPZqbzAbJOX-hE-IRAxB7sg&index=2)\n\n\n","slug":"MobileNetV1","published":1,"updated":"2018-12-29T07:41:52.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vv1000cqslpjj6ea60i","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>针对移动端及嵌入式视觉应用，利用深度可分离卷积(depthwise separable convolutions)，构建轻量级的深度神经网络，即MobileNet。</li>\n<li>其中引进了两个简单的超参数(宽度乘子(Width Multiplier)和分辨率乘子(Resolution Multiplier))来有效地权衡延迟(latency)和精度。</li>\n<li>本质：只是用深度可分离卷积来替换常规CNN中的常规卷积<a id=\"more\"></a>\n</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"/images/MobileNetV1/1.png\" width=\"400\"><br><img src=\"/images/MobileNetV1/2.png\" width=\"350\"><br><img src=\"/images/MobileNetV1/3.png\" width=\"350\"></p>\n<ul>\n<li>MobileNetV1结构如Table1所示：<ul>\n<li><strong>MobileNet基于深度可分离卷积构建，除了第一层为常规卷积以外</strong>。</li>\n<li><strong>如Fig3所示，所有层之后，均伴随BN和ReLU非线性操作</strong>；除了最后的全连接层没有ReLU非线性，被喂给softmax层来进行分类。</li>\n<li><strong>下采样操作通过depthwise卷积和第一层常规卷积中的带步长的卷积实现（注意这一点）</strong>。</li>\n<li>最后的平均池化层使得空间分辨率在全连接层之前减小到1。</li>\n<li>若将depthwise卷积和pointwise卷积计为分离的层，那么MobileNet有28层。</li>\n</ul>\n</li>\n<li>如Table2所示，MobileNet花费95%的计算时间在$1\\times 1$卷积上，并且$1\\times 1$卷积占据了75%的参数。所有的其它参数，几乎都集中在全连接层上。</li>\n</ul>\n<h2 id=\"宽度乘子-Width-Multiplier-——更瘦的模型\"><a href=\"#宽度乘子-Width-Multiplier-——更瘦的模型\" class=\"headerlink\" title=\"宽度乘子(Width Multiplier)——更瘦的模型\"></a>宽度乘子(Width Multiplier)——更瘦的模型</h2><ul>\n<li>第一个超参数宽度乘子$\\alpha$,其作用是统一地使网络的每一层变瘦：<ul>\n<li>对于一个给定层，在宽度乘子$\\alpha$的作用下，输入的通道数由$M$变为$\\alpha M$，输出的通道数由$N$变成$\\alpha N$。</li>\n</ul>\n</li>\n<li>在宽度乘子$\\alpha$的作用下：<ul>\n<li>深度可分离卷积的计算量变为：$\\alpha M \\times {D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times {D_G}^2 $。</li>\n<li>$\\alpha \\in (0,1]$ ，$\\alpha$的典型设置为1，0.75，0.5和0.25。$\\alpha=1$ 即是基准的MobileNet，$\\alpha&lt;1$即是简化的MobileNet。</li>\n<li>宽度乘子$\\alpha$能够平方级地减少计算量和参数量，即约$\\alpha ^2$。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"分辨率乘子-Resolution-Multiplier-——减少表征\"><a href=\"#分辨率乘子-Resolution-Multiplier-——减少表征\" class=\"headerlink\" title=\"分辨率乘子(Resolution Multiplier)——减少表征**\"></a>分辨率乘子(Resolution Multiplier)——减少表征**</h2><ul>\n<li>第二个超参数分辨率乘子$\\rho$，其作用是减少网络的计算量：<ul>\n<li>对输入图片施加分辨率乘子$\\rho$，那么网络每一层的中间表征都将随之减小相同的乘子。</li>\n<li>在实际操作中，通过设置输入分辨率，来隐式地设置$\\rho$。</li>\n</ul>\n</li>\n<li>在宽度乘子$\\alpha$和分辨率乘子$\\rho$的作用下：<ul>\n<li>深度可分离卷积的计算量变为：$\\alpha M \\times \\rho^2{D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times \\rho^2{D_G}^2 $。</li>\n<li>$\\rho \\in (0,1]$ ，$\\rho$通常隐式地设置，故网络的输入分辨率典型设置为224，192，160或128。$\\rho=1$ 即是基准的MobileNet。</li>\n<li>分辨率乘子$\\rho$能够平方级地减少计算量，即约$\\rho ^2$。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><ul>\n<li>MobileNet在TF上实现，通过和Inception V3相似的带有异步梯度下降的RMSprop实现。</li>\n<li>用更少的正则化和更少的数据增强技术，因为小的网络不易过拟合。</li>\n<li>用非常小或不使用权重衰减(L2正则)在depthwise卷积上很重要，因为它们只有过少的参数。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/MobileNetV1/4.png\" width=\"400\"></p>\n<ul>\n<li>如Table4所示，比较了MobileNet与其全卷积实现形式：在ImageNet上，只损失了1%的精度，但节约了大量的计算量和参数。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/5.png\" width=\"400\"></p>\n<ul>\n<li>如Table6所示，展示了通过不同的宽度乘子$\\alpha$来收缩MobileNet时，精度、计算量和参数量之间的权衡。精度平滑的下降，直到模型结构过小，即$\\alpha=0.25$时。</li>\n<li>注：在ImageNet基准上，无论模型尺寸的大小，所有模型均用相同的训练参数进行训练。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/6.png\" width=\"400\"></p>\n<ul>\n<li>如Table7所示，展示了通过施加不同的分辨率乘子$\\rho$，即用减小的输入分辨率来训练MobileNet时，精度、计算量和参数量之间的权衡。准确率依据分辨率平滑下降。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/7.png\" width=\"400\"></p>\n<ul>\n<li><strong>如Table8所示，展示了完整MobileNet和GoogleNetV1、VGG16之间的比较</strong>：<ul>\n<li>MobileNet精度接近于VGG16，同时参数量只是其$1/32$，计算量为其$1/27$。</li>\n<li>MobileNet精度高于GoogleNetV1，同时参数量更少，计算量为其$1/2.7$。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/8.png\" width=\"400\"></p>\n<ul>\n<li>如Table9所示，展示了通过$\\alpha=0.5$且分辨率为$160\\times 160$简化的MobileNet与AlexNet和Squeezenet之间的比较：<ul>\n<li>简化版MobileNet比AlexNet的精度高3%，同时参数量只是其$1/45$，计算量为其$1/9.4$。</li>\n<li>简化版MobileNet比Squeezenet的精度高3%，同时参数量相同，计算量为其$1/22$。</li>\n</ul>\n</li>\n</ul>\n<p>此外，文中还展示了通过MobileNet，在细粒度分类(Fine Grained Recognition)、Large Scale Geolocalizaton、Face Attributes、目标检测(Object Detection)及Face Embeddings任务上的应用结果。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" target=\"_blank\" rel=\"noopener\">论文：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=T7o3xvJLuHk&amp;t=0s&amp;list=LLPZqbzAbJOX-hE-IRAxB7sg&amp;index=2\" target=\"_blank\" rel=\"noopener\">视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>针对移动端及嵌入式视觉应用，利用深度可分离卷积(depthwise separable convolutions)，构建轻量级的深度神经网络，即MobileNet。</li>\n<li>其中引进了两个简单的超参数(宽度乘子(Width Multiplier)和分辨率乘子(Resolution Multiplier))来有效地权衡延迟(latency)和精度。</li>\n<li>本质：只是用深度可分离卷积来替换常规CNN中的常规卷积","more":"</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"/images/MobileNetV1/1.png\" width=\"400\"><br><img src=\"/images/MobileNetV1/2.png\" width=\"350\"><br><img src=\"/images/MobileNetV1/3.png\" width=\"350\"></p>\n<ul>\n<li>MobileNetV1结构如Table1所示：<ul>\n<li><strong>MobileNet基于深度可分离卷积构建，除了第一层为常规卷积以外</strong>。</li>\n<li><strong>如Fig3所示，所有层之后，均伴随BN和ReLU非线性操作</strong>；除了最后的全连接层没有ReLU非线性，被喂给softmax层来进行分类。</li>\n<li><strong>下采样操作通过depthwise卷积和第一层常规卷积中的带步长的卷积实现（注意这一点）</strong>。</li>\n<li>最后的平均池化层使得空间分辨率在全连接层之前减小到1。</li>\n<li>若将depthwise卷积和pointwise卷积计为分离的层，那么MobileNet有28层。</li>\n</ul>\n</li>\n<li>如Table2所示，MobileNet花费95%的计算时间在$1\\times 1$卷积上，并且$1\\times 1$卷积占据了75%的参数。所有的其它参数，几乎都集中在全连接层上。</li>\n</ul>\n<h2 id=\"宽度乘子-Width-Multiplier-——更瘦的模型\"><a href=\"#宽度乘子-Width-Multiplier-——更瘦的模型\" class=\"headerlink\" title=\"宽度乘子(Width Multiplier)——更瘦的模型\"></a>宽度乘子(Width Multiplier)——更瘦的模型</h2><ul>\n<li>第一个超参数宽度乘子$\\alpha$,其作用是统一地使网络的每一层变瘦：<ul>\n<li>对于一个给定层，在宽度乘子$\\alpha$的作用下，输入的通道数由$M$变为$\\alpha M$，输出的通道数由$N$变成$\\alpha N$。</li>\n</ul>\n</li>\n<li>在宽度乘子$\\alpha$的作用下：<ul>\n<li>深度可分离卷积的计算量变为：$\\alpha M \\times {D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times {D_G}^2 $。</li>\n<li>$\\alpha \\in (0,1]$ ，$\\alpha$的典型设置为1，0.75，0.5和0.25。$\\alpha=1$ 即是基准的MobileNet，$\\alpha&lt;1$即是简化的MobileNet。</li>\n<li>宽度乘子$\\alpha$能够平方级地减少计算量和参数量，即约$\\alpha ^2$。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"分辨率乘子-Resolution-Multiplier-——减少表征\"><a href=\"#分辨率乘子-Resolution-Multiplier-——减少表征\" class=\"headerlink\" title=\"分辨率乘子(Resolution Multiplier)——减少表征**\"></a>分辨率乘子(Resolution Multiplier)——减少表征**</h2><ul>\n<li>第二个超参数分辨率乘子$\\rho$，其作用是减少网络的计算量：<ul>\n<li>对输入图片施加分辨率乘子$\\rho$，那么网络每一层的中间表征都将随之减小相同的乘子。</li>\n<li>在实际操作中，通过设置输入分辨率，来隐式地设置$\\rho$。</li>\n</ul>\n</li>\n<li>在宽度乘子$\\alpha$和分辨率乘子$\\rho$的作用下：<ul>\n<li>深度可分离卷积的计算量变为：$\\alpha M \\times \\rho^2{D_G}^2 \\times  {D_K}^2 + \\alpha M \\times \\alpha N \\times \\rho^2{D_G}^2 $。</li>\n<li>$\\rho \\in (0,1]$ ，$\\rho$通常隐式地设置，故网络的输入分辨率典型设置为224，192，160或128。$\\rho=1$ 即是基准的MobileNet。</li>\n<li>分辨率乘子$\\rho$能够平方级地减少计算量，即约$\\rho ^2$。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><ul>\n<li>MobileNet在TF上实现，通过和Inception V3相似的带有异步梯度下降的RMSprop实现。</li>\n<li>用更少的正则化和更少的数据增强技术，因为小的网络不易过拟合。</li>\n<li>用非常小或不使用权重衰减(L2正则)在depthwise卷积上很重要，因为它们只有过少的参数。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/MobileNetV1/4.png\" width=\"400\"></p>\n<ul>\n<li>如Table4所示，比较了MobileNet与其全卷积实现形式：在ImageNet上，只损失了1%的精度，但节约了大量的计算量和参数。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/5.png\" width=\"400\"></p>\n<ul>\n<li>如Table6所示，展示了通过不同的宽度乘子$\\alpha$来收缩MobileNet时，精度、计算量和参数量之间的权衡。精度平滑的下降，直到模型结构过小，即$\\alpha=0.25$时。</li>\n<li>注：在ImageNet基准上，无论模型尺寸的大小，所有模型均用相同的训练参数进行训练。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/6.png\" width=\"400\"></p>\n<ul>\n<li>如Table7所示，展示了通过施加不同的分辨率乘子$\\rho$，即用减小的输入分辨率来训练MobileNet时，精度、计算量和参数量之间的权衡。准确率依据分辨率平滑下降。</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/7.png\" width=\"400\"></p>\n<ul>\n<li><strong>如Table8所示，展示了完整MobileNet和GoogleNetV1、VGG16之间的比较</strong>：<ul>\n<li>MobileNet精度接近于VGG16，同时参数量只是其$1/32$，计算量为其$1/27$。</li>\n<li>MobileNet精度高于GoogleNetV1，同时参数量更少，计算量为其$1/2.7$。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV1/8.png\" width=\"400\"></p>\n<ul>\n<li>如Table9所示，展示了通过$\\alpha=0.5$且分辨率为$160\\times 160$简化的MobileNet与AlexNet和Squeezenet之间的比较：<ul>\n<li>简化版MobileNet比AlexNet的精度高3%，同时参数量只是其$1/45$，计算量为其$1/9.4$。</li>\n<li>简化版MobileNet比Squeezenet的精度高3%，同时参数量相同，计算量为其$1/22$。</li>\n</ul>\n</li>\n</ul>\n<p>此外，文中还展示了通过MobileNet，在细粒度分类(Fine Grained Recognition)、Large Scale Geolocalizaton、Face Attributes、目标检测(Object Detection)及Face Embeddings任务上的应用结果。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1704.04861.pdf\" target=\"_blank\" rel=\"noopener\">论文：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=T7o3xvJLuHk&amp;t=0s&amp;list=LLPZqbzAbJOX-hE-IRAxB7sg&amp;index=2\" target=\"_blank\" rel=\"noopener\">视频：Depthwise Separable Convolution - A FASTER CONVOLUTION!</a></li>\n</ul>"},{"title":"MobileNetV2","mathjax":true,"date":"2018-12-29T14:22:50.000Z","_content":"\n# 摘要\n\n- 提出新的移动端模型——MobileNetV2。相比于MobileNetV1，其改进之处即在于基础模块——线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)。\n- 并且，对MobileNetV2应用于目标检测和语义分割进行了应用及实验比较(见原文)。\n\n <!-- more -->\n\n# 创新点\n\n## 线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)\n\n<img src=\"/images/MobileNetV2/1.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table1所示，该模块将输入特征看作低维度的压缩特征：\n - 首先，扩展到高维度；\n - 然后，通过轻量的depthwise卷积进行滤波；\n - 然后，将特征映射回低维度并且采用线性卷积；\n - 最后，输入层和瓶颈层建立残差连接。\n\n<img src=\"/images/MobileNetV2/2.png\"  width = \"400\" height = \"100\"/>\n- 如Fig3所示，为典型残差模块和转置残差模块的区别：\n - 典型的残差模块是将输入层和高通道数的层建立残差连接，而转置残差模块是将输入层和瓶颈层建立残差连接。 \n - 注：但都是输入和输出做残差连接，没什么特殊的地方\n\n## MobileNetV1与MobileNetV2的基础模块比较\n<img src=\"/images/MobileNetV2/3.png\"  width = \"600\" height = \"100\"/>\n\n**相同点**：\n- **都采用depthwise(DW)卷积搭配pointwise(PW)卷积的方式来提特征**\n - 这两个操作合起来也被称为深度可分离卷积(depthwise separable convolution)，之前在Xception中被广泛使用。其优点是：理论上可以成倍的减少卷积层的时间复杂度和空间复杂度。\n \n - 下式为深度可分离卷积和常规卷积的复杂度比率(参数个数比率或乘加次数比率都如下式所示)：\n - <img src=\"/images/MobileNetV2/4.png\"  width = \"500\" height = \"100\"/>\n - 可以看出：由于卷积核的尺寸$K$通常远小于输出通道数$C_{out}$，因此标准卷积的计算复杂度近似为深度可分离卷积的$K^2$倍。\n\n**不同点**：\n- **MobileNetV2在DW卷积之前新加了一个PW卷积**\n - 这么做的原因，**是因为DW卷积由于本身的计算特性决定它自己没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。所以如果上一层给的通道数本身很少的话，DW卷积也只能很委屈的在低维空间提特征，因此效果不够好**。\n - 现在MobileNetV2为了改善这个问题，给每个DW卷积之前都配备了一个PW卷积，专门用来升维。定义升维系数$t = 6$，这样不管输入通道数$C_{in}$是多是少，经过第一个PW卷积升维之后，DW卷积都是在相对的更高维$( t \\cdot C_{in})$进行工作。\n - 该段解释了出现**转置残差模块**的原因：即需先增加一个PW卷积来升通道数，使得DW卷积更加有效，然后再通过PW卷积降通道数(当然也有通道重组的功能)。因此，便出现了所谓转置残差模块的现象。\n- **MobileNetV2去掉了第二个PW卷积的激活函数**(论文作者称其为**Linear Bottleneck**)\n - 这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。\n - 由于第二个PW卷积的主要功能就是降维，因此按照上面的理论，降维之后就不宜再使用ReLU6了。\n - 该段解释了所谓**线性瓶颈层**的原因。\n - 注意：Xception中是DW卷积之后不加非线性激活函数，因为Xception文中认为DW卷积只有1通道数，非线性激活函数变得有害，导致信息丢失。\n - 疑问：接上，那么，为什么MobileNetV2中DW卷积后还进行非线性激活？\n\n## ResNet与MobileNetV2的构造模块对比\n <img src=\"/images/MobileNetV2/5.png\"  width = \"600\" height = \"100\"/>\n\n- 相同点：\n - MobileNetV2借鉴ResNet，都采用了$1 \\times 1 \\to 3 \\times 3 \\to 1 \\times 1$的模式。\n - MobileNetV2借鉴ResNet，同样使用Shortcut将输出与输入相加(未在上图画出)。\n\n- 不同点：\n - ResNet使用**标准卷积**提取特征，MobileNet始终使用**DW卷积**提取特征。\n - ResNet**先降维** (0.25倍)、卷积、再升维，而 MobileNetV2则是**先升维**(6倍)、卷积、再降维。直观的形象上来看，ResNet的微结构是**沙漏形**，而MobileNetV2则是**纺锤形**，刚好相反。因此论文作者将MobileNetV2的结构称为Inverted Residual Block。这么做也是因为使用DW卷积而作的适配，希望特征提取能够在高维进行。\n\n##  MobileNetV2总体结构\n<img src=\"/images/MobileNetV2/6.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table2所示，为MobileNetV2结构，其中：\n - $t$是转置残差模块的扩张比率(expansion rate)\n - $n$是该模块重复次数\n - $c$是输出通道数\n - $s$是该阶段第一次重复时的第一个模块的DW卷积的步长(后面重复都是步长为1)（疑问：为啥不直接使用第一个PW卷积实现下采样？）\n- MobileNetV2主要由初始的常规卷积层和17个线性瓶颈层的转置残差模块构成。\n- 采用ReLU6作为非线性函数，因为在对于低精度计算时其更鲁棒。\n - 首先说明一下ReLU6，卷积之后通常会接一个ReLU非线性激活，在MobileV1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip），这是为了在移动端设备float16的低精度的时候，也能有很好的数值分辨率，如果对ReLU的激活范围不加限制，输出范围为0到正无穷，如果激活值非常大，分布在一个很大的范围内，则低精度的float16无法很好地精确描述如此大范围的数值，带来精度损失。\n- 只使用$3 \\times 3$的卷积核。\n- 除了第一层，在网络中采用恒等的扩张比率$t$：\n - 实验中发现，扩张比率$t$在5～10之间，可以得到几乎相等的表现曲线。\n - 较小的网络更适合采用较小的扩张比率;较大的网络更适合采用较大的扩张比率。\n - 文中实验均采用扩张比率为$t=6$。例如，对于一个线性瓶颈层的转置残差模块，输入为64通道的张量，输出为128通道的张量，其中间的扩张层的张量的通道数即为$64\\times 6 = 384$。\n \n<img src=\"/images/MobileNetV2/7.png\"  width = \"400\" height = \"100\"/>\n\n- 如Fig6(a)所示，实验结果表明：验证了线性瓶颈层的重要性，提供了对于非线性激活函数会破坏低维空间的信息的支持。\n- 如Fig6(b)所示，实验结果表明：对于残差连接，与瓶颈层进行残差连接的表现，优于与扩张层进行残差连接以及不使用残差连接。\n\n<img src=\"/images/MobileNetV2/8.png\"  width = \"400\" height = \"100\"/>\n\n- 如Fig4所示，为几种不同结构之间的构建模块比较。\n\n# 训练策略\n- 采用RMSProp优化器，动量系数设为0.9\n- 在每一层后面施加BN\n- 标准的权重衰减系数设为0.00004\n- 同MobileNetV1一样，采用初始学习率为0.045，学习速率衰减速率为每一opoch变为0.98\n- 采用16个GPU异步工作器，batch size为96\n\n# 模型比较\n<img src=\"/images/MobileNetV2/9.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table4所示，比较了MobileNetV1、ShuffleNet和NASNet-A模型。\n\n此外，文中有将MobileNetV2用于目标检测任务和语义分割任务的详细对比实验。\n\n# 参考文献\n\n- [论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf)\n- [博客(推荐)：MobileNet V2 论文初读](https://zhuanlan.zhihu.com/p/33075914)\n- [博客：轻量化网络：MobileNet-V2](https://blog.csdn.net/u011995719/article/details/79135818)\n- [代码](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)\n\n\n\n","source":"_posts/MobileNetV2.md","raw":"---\ntitle: MobileNetV2\nmathjax: true\ndate: 2018-12-29 22:22:50\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 摘要\n\n- 提出新的移动端模型——MobileNetV2。相比于MobileNetV1，其改进之处即在于基础模块——线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)。\n- 并且，对MobileNetV2应用于目标检测和语义分割进行了应用及实验比较(见原文)。\n\n <!-- more -->\n\n# 创新点\n\n## 线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)\n\n<img src=\"/images/MobileNetV2/1.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table1所示，该模块将输入特征看作低维度的压缩特征：\n - 首先，扩展到高维度；\n - 然后，通过轻量的depthwise卷积进行滤波；\n - 然后，将特征映射回低维度并且采用线性卷积；\n - 最后，输入层和瓶颈层建立残差连接。\n\n<img src=\"/images/MobileNetV2/2.png\"  width = \"400\" height = \"100\"/>\n- 如Fig3所示，为典型残差模块和转置残差模块的区别：\n - 典型的残差模块是将输入层和高通道数的层建立残差连接，而转置残差模块是将输入层和瓶颈层建立残差连接。 \n - 注：但都是输入和输出做残差连接，没什么特殊的地方\n\n## MobileNetV1与MobileNetV2的基础模块比较\n<img src=\"/images/MobileNetV2/3.png\"  width = \"600\" height = \"100\"/>\n\n**相同点**：\n- **都采用depthwise(DW)卷积搭配pointwise(PW)卷积的方式来提特征**\n - 这两个操作合起来也被称为深度可分离卷积(depthwise separable convolution)，之前在Xception中被广泛使用。其优点是：理论上可以成倍的减少卷积层的时间复杂度和空间复杂度。\n \n - 下式为深度可分离卷积和常规卷积的复杂度比率(参数个数比率或乘加次数比率都如下式所示)：\n - <img src=\"/images/MobileNetV2/4.png\"  width = \"500\" height = \"100\"/>\n - 可以看出：由于卷积核的尺寸$K$通常远小于输出通道数$C_{out}$，因此标准卷积的计算复杂度近似为深度可分离卷积的$K^2$倍。\n\n**不同点**：\n- **MobileNetV2在DW卷积之前新加了一个PW卷积**\n - 这么做的原因，**是因为DW卷积由于本身的计算特性决定它自己没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。所以如果上一层给的通道数本身很少的话，DW卷积也只能很委屈的在低维空间提特征，因此效果不够好**。\n - 现在MobileNetV2为了改善这个问题，给每个DW卷积之前都配备了一个PW卷积，专门用来升维。定义升维系数$t = 6$，这样不管输入通道数$C_{in}$是多是少，经过第一个PW卷积升维之后，DW卷积都是在相对的更高维$( t \\cdot C_{in})$进行工作。\n - 该段解释了出现**转置残差模块**的原因：即需先增加一个PW卷积来升通道数，使得DW卷积更加有效，然后再通过PW卷积降通道数(当然也有通道重组的功能)。因此，便出现了所谓转置残差模块的现象。\n- **MobileNetV2去掉了第二个PW卷积的激活函数**(论文作者称其为**Linear Bottleneck**)\n - 这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。\n - 由于第二个PW卷积的主要功能就是降维，因此按照上面的理论，降维之后就不宜再使用ReLU6了。\n - 该段解释了所谓**线性瓶颈层**的原因。\n - 注意：Xception中是DW卷积之后不加非线性激活函数，因为Xception文中认为DW卷积只有1通道数，非线性激活函数变得有害，导致信息丢失。\n - 疑问：接上，那么，为什么MobileNetV2中DW卷积后还进行非线性激活？\n\n## ResNet与MobileNetV2的构造模块对比\n <img src=\"/images/MobileNetV2/5.png\"  width = \"600\" height = \"100\"/>\n\n- 相同点：\n - MobileNetV2借鉴ResNet，都采用了$1 \\times 1 \\to 3 \\times 3 \\to 1 \\times 1$的模式。\n - MobileNetV2借鉴ResNet，同样使用Shortcut将输出与输入相加(未在上图画出)。\n\n- 不同点：\n - ResNet使用**标准卷积**提取特征，MobileNet始终使用**DW卷积**提取特征。\n - ResNet**先降维** (0.25倍)、卷积、再升维，而 MobileNetV2则是**先升维**(6倍)、卷积、再降维。直观的形象上来看，ResNet的微结构是**沙漏形**，而MobileNetV2则是**纺锤形**，刚好相反。因此论文作者将MobileNetV2的结构称为Inverted Residual Block。这么做也是因为使用DW卷积而作的适配，希望特征提取能够在高维进行。\n\n##  MobileNetV2总体结构\n<img src=\"/images/MobileNetV2/6.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table2所示，为MobileNetV2结构，其中：\n - $t$是转置残差模块的扩张比率(expansion rate)\n - $n$是该模块重复次数\n - $c$是输出通道数\n - $s$是该阶段第一次重复时的第一个模块的DW卷积的步长(后面重复都是步长为1)（疑问：为啥不直接使用第一个PW卷积实现下采样？）\n- MobileNetV2主要由初始的常规卷积层和17个线性瓶颈层的转置残差模块构成。\n- 采用ReLU6作为非线性函数，因为在对于低精度计算时其更鲁棒。\n - 首先说明一下ReLU6，卷积之后通常会接一个ReLU非线性激活，在MobileV1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip），这是为了在移动端设备float16的低精度的时候，也能有很好的数值分辨率，如果对ReLU的激活范围不加限制，输出范围为0到正无穷，如果激活值非常大，分布在一个很大的范围内，则低精度的float16无法很好地精确描述如此大范围的数值，带来精度损失。\n- 只使用$3 \\times 3$的卷积核。\n- 除了第一层，在网络中采用恒等的扩张比率$t$：\n - 实验中发现，扩张比率$t$在5～10之间，可以得到几乎相等的表现曲线。\n - 较小的网络更适合采用较小的扩张比率;较大的网络更适合采用较大的扩张比率。\n - 文中实验均采用扩张比率为$t=6$。例如，对于一个线性瓶颈层的转置残差模块，输入为64通道的张量，输出为128通道的张量，其中间的扩张层的张量的通道数即为$64\\times 6 = 384$。\n \n<img src=\"/images/MobileNetV2/7.png\"  width = \"400\" height = \"100\"/>\n\n- 如Fig6(a)所示，实验结果表明：验证了线性瓶颈层的重要性，提供了对于非线性激活函数会破坏低维空间的信息的支持。\n- 如Fig6(b)所示，实验结果表明：对于残差连接，与瓶颈层进行残差连接的表现，优于与扩张层进行残差连接以及不使用残差连接。\n\n<img src=\"/images/MobileNetV2/8.png\"  width = \"400\" height = \"100\"/>\n\n- 如Fig4所示，为几种不同结构之间的构建模块比较。\n\n# 训练策略\n- 采用RMSProp优化器，动量系数设为0.9\n- 在每一层后面施加BN\n- 标准的权重衰减系数设为0.00004\n- 同MobileNetV1一样，采用初始学习率为0.045，学习速率衰减速率为每一opoch变为0.98\n- 采用16个GPU异步工作器，batch size为96\n\n# 模型比较\n<img src=\"/images/MobileNetV2/9.png\"  width = \"400\" height = \"100\"/>\n\n- 如Table4所示，比较了MobileNetV1、ShuffleNet和NASNet-A模型。\n\n此外，文中有将MobileNetV2用于目标检测任务和语义分割任务的详细对比实验。\n\n# 参考文献\n\n- [论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf)\n- [博客(推荐)：MobileNet V2 论文初读](https://zhuanlan.zhihu.com/p/33075914)\n- [博客：轻量化网络：MobileNet-V2](https://blog.csdn.net/u011995719/article/details/79135818)\n- [代码](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)\n\n\n\n","slug":"MobileNetV2","published":1,"updated":"2019-01-07T04:36:04.732Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vv3000dqslpcnixclga","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出新的移动端模型——MobileNetV2。相比于MobileNetV1，其改进之处即在于基础模块——线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)。</li>\n<li><p>并且，对MobileNetV2应用于目标检测和语义分割进行了应用及实验比较(见原文)。</p>\n<a id=\"more\"></a>\n</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"线性瓶颈层的转置残差模块-the-inverted-residual-with-linear-bottleneck\"><a href=\"#线性瓶颈层的转置残差模块-the-inverted-residual-with-linear-bottleneck\" class=\"headerlink\" title=\"线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)\"></a>线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)</h2><p><img src=\"/images/MobileNetV2/1.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table1所示，该模块将输入特征看作低维度的压缩特征：<ul>\n<li>首先，扩展到高维度；</li>\n<li>然后，通过轻量的depthwise卷积进行滤波；</li>\n<li>然后，将特征映射回低维度并且采用线性卷积；</li>\n<li>最后，输入层和瓶颈层建立残差连接。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/2.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig3所示，为典型残差模块和转置残差模块的区别：<ul>\n<li>典型的残差模块是将输入层和高通道数的层建立残差连接，而转置残差模块是将输入层和瓶颈层建立残差连接。 </li>\n<li>注：但都是输入和输出做残差连接，没什么特殊的地方</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MobileNetV1与MobileNetV2的基础模块比较\"><a href=\"#MobileNetV1与MobileNetV2的基础模块比较\" class=\"headerlink\" title=\"MobileNetV1与MobileNetV2的基础模块比较\"></a>MobileNetV1与MobileNetV2的基础模块比较</h2><p><img src=\"/images/MobileNetV2/3.png\" width=\"600\" height=\"100\"></p>\n<p><strong>相同点</strong>：</p>\n<ul>\n<li><p><strong>都采用depthwise(DW)卷积搭配pointwise(PW)卷积的方式来提特征</strong></p>\n<ul>\n<li><p>这两个操作合起来也被称为深度可分离卷积(depthwise separable convolution)，之前在Xception中被广泛使用。其优点是：理论上可以成倍的减少卷积层的时间复杂度和空间复杂度。</p>\n</li>\n<li><p>下式为深度可分离卷积和常规卷积的复杂度比率(参数个数比率或乘加次数比率都如下式所示)：</p>\n</li>\n<li><img src=\"/images/MobileNetV2/4.png\" width=\"500\" height=\"100\"></li>\n<li>可以看出：由于卷积核的尺寸$K$通常远小于输出通道数$C_{out}$，因此标准卷积的计算复杂度近似为深度可分离卷积的$K^2$倍。</li>\n</ul>\n</li>\n</ul>\n<p><strong>不同点</strong>：</p>\n<ul>\n<li><strong>MobileNetV2在DW卷积之前新加了一个PW卷积</strong><ul>\n<li>这么做的原因，<strong>是因为DW卷积由于本身的计算特性决定它自己没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。所以如果上一层给的通道数本身很少的话，DW卷积也只能很委屈的在低维空间提特征，因此效果不够好</strong>。</li>\n<li>现在MobileNetV2为了改善这个问题，给每个DW卷积之前都配备了一个PW卷积，专门用来升维。定义升维系数$t = 6$，这样不管输入通道数$C_{in}$是多是少，经过第一个PW卷积升维之后，DW卷积都是在相对的更高维$( t \\cdot C_{in})$进行工作。</li>\n<li>该段解释了出现<strong>转置残差模块</strong>的原因：即需先增加一个PW卷积来升通道数，使得DW卷积更加有效，然后再通过PW卷积降通道数(当然也有通道重组的功能)。因此，便出现了所谓转置残差模块的现象。</li>\n</ul>\n</li>\n<li><strong>MobileNetV2去掉了第二个PW卷积的激活函数</strong>(论文作者称其为<strong>Linear Bottleneck</strong>)<ul>\n<li>这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。</li>\n<li>由于第二个PW卷积的主要功能就是降维，因此按照上面的理论，降维之后就不宜再使用ReLU6了。</li>\n<li>该段解释了所谓<strong>线性瓶颈层</strong>的原因。</li>\n<li>注意：Xception中是DW卷积之后不加非线性激活函数，因为Xception文中认为DW卷积只有1通道数，非线性激活函数变得有害，导致信息丢失。</li>\n<li>疑问：接上，那么，为什么MobileNetV2中DW卷积后还进行非线性激活？</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ResNet与MobileNetV2的构造模块对比\"><a href=\"#ResNet与MobileNetV2的构造模块对比\" class=\"headerlink\" title=\"ResNet与MobileNetV2的构造模块对比\"></a>ResNet与MobileNetV2的构造模块对比</h2><p> <img src=\"/images/MobileNetV2/5.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li><p>相同点：</p>\n<ul>\n<li>MobileNetV2借鉴ResNet，都采用了$1 \\times 1 \\to 3 \\times 3 \\to 1 \\times 1$的模式。</li>\n<li>MobileNetV2借鉴ResNet，同样使用Shortcut将输出与输入相加(未在上图画出)。</li>\n</ul>\n</li>\n<li><p>不同点：</p>\n<ul>\n<li>ResNet使用<strong>标准卷积</strong>提取特征，MobileNet始终使用<strong>DW卷积</strong>提取特征。</li>\n<li>ResNet<strong>先降维</strong> (0.25倍)、卷积、再升维，而 MobileNetV2则是<strong>先升维</strong>(6倍)、卷积、再降维。直观的形象上来看，ResNet的微结构是<strong>沙漏形</strong>，而MobileNetV2则是<strong>纺锤形</strong>，刚好相反。因此论文作者将MobileNetV2的结构称为Inverted Residual Block。这么做也是因为使用DW卷积而作的适配，希望特征提取能够在高维进行。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MobileNetV2总体结构\"><a href=\"#MobileNetV2总体结构\" class=\"headerlink\" title=\"MobileNetV2总体结构\"></a>MobileNetV2总体结构</h2><p><img src=\"/images/MobileNetV2/6.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table2所示，为MobileNetV2结构，其中：<ul>\n<li>$t$是转置残差模块的扩张比率(expansion rate)</li>\n<li>$n$是该模块重复次数</li>\n<li>$c$是输出通道数</li>\n<li>$s$是该阶段第一次重复时的第一个模块的DW卷积的步长(后面重复都是步长为1)（疑问：为啥不直接使用第一个PW卷积实现下采样？）</li>\n</ul>\n</li>\n<li>MobileNetV2主要由初始的常规卷积层和17个线性瓶颈层的转置残差模块构成。</li>\n<li>采用ReLU6作为非线性函数，因为在对于低精度计算时其更鲁棒。<ul>\n<li>首先说明一下ReLU6，卷积之后通常会接一个ReLU非线性激活，在MobileV1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip），这是为了在移动端设备float16的低精度的时候，也能有很好的数值分辨率，如果对ReLU的激活范围不加限制，输出范围为0到正无穷，如果激活值非常大，分布在一个很大的范围内，则低精度的float16无法很好地精确描述如此大范围的数值，带来精度损失。</li>\n</ul>\n</li>\n<li>只使用$3 \\times 3$的卷积核。</li>\n<li>除了第一层，在网络中采用恒等的扩张比率$t$：<ul>\n<li>实验中发现，扩张比率$t$在5～10之间，可以得到几乎相等的表现曲线。</li>\n<li>较小的网络更适合采用较小的扩张比率;较大的网络更适合采用较大的扩张比率。</li>\n<li>文中实验均采用扩张比率为$t=6$。例如，对于一个线性瓶颈层的转置残差模块，输入为64通道的张量，输出为128通道的张量，其中间的扩张层的张量的通道数即为$64\\times 6 = 384$。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/7.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig6(a)所示，实验结果表明：验证了线性瓶颈层的重要性，提供了对于非线性激活函数会破坏低维空间的信息的支持。</li>\n<li>如Fig6(b)所示，实验结果表明：对于残差连接，与瓶颈层进行残差连接的表现，优于与扩张层进行残差连接以及不使用残差连接。</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/8.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig4所示，为几种不同结构之间的构建模块比较。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><ul>\n<li>采用RMSProp优化器，动量系数设为0.9</li>\n<li>在每一层后面施加BN</li>\n<li>标准的权重衰减系数设为0.00004</li>\n<li>同MobileNetV1一样，采用初始学习率为0.045，学习速率衰减速率为每一opoch变为0.98</li>\n<li>采用16个GPU异步工作器，batch size为96</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/MobileNetV2/9.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table4所示，比较了MobileNetV1、ShuffleNet和NASNet-A模型。</li>\n</ul>\n<p>此外，文中有将MobileNetV2用于目标检测任务和语义分割任务的详细对比实验。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1801.04381.pdf\" target=\"_blank\" rel=\"noopener\">论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/33075914\" target=\"_blank\" rel=\"noopener\">博客(推荐)：MobileNet V2 论文初读</a></li>\n<li><a href=\"https://blog.csdn.net/u011995719/article/details/79135818\" target=\"_blank\" rel=\"noopener\">博客：轻量化网络：MobileNet-V2</a></li>\n<li><a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\" target=\"_blank\" rel=\"noopener\">代码</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出新的移动端模型——MobileNetV2。相比于MobileNetV1，其改进之处即在于基础模块——线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)。</li>\n<li><p>并且，对MobileNetV2应用于目标检测和语义分割进行了应用及实验比较(见原文)。</p>","more":"</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"线性瓶颈层的转置残差模块-the-inverted-residual-with-linear-bottleneck\"><a href=\"#线性瓶颈层的转置残差模块-the-inverted-residual-with-linear-bottleneck\" class=\"headerlink\" title=\"线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)\"></a>线性瓶颈层的转置残差模块(the inverted residual with linear bottleneck)</h2><p><img src=\"/images/MobileNetV2/1.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table1所示，该模块将输入特征看作低维度的压缩特征：<ul>\n<li>首先，扩展到高维度；</li>\n<li>然后，通过轻量的depthwise卷积进行滤波；</li>\n<li>然后，将特征映射回低维度并且采用线性卷积；</li>\n<li>最后，输入层和瓶颈层建立残差连接。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/2.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig3所示，为典型残差模块和转置残差模块的区别：<ul>\n<li>典型的残差模块是将输入层和高通道数的层建立残差连接，而转置残差模块是将输入层和瓶颈层建立残差连接。 </li>\n<li>注：但都是输入和输出做残差连接，没什么特殊的地方</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MobileNetV1与MobileNetV2的基础模块比较\"><a href=\"#MobileNetV1与MobileNetV2的基础模块比较\" class=\"headerlink\" title=\"MobileNetV1与MobileNetV2的基础模块比较\"></a>MobileNetV1与MobileNetV2的基础模块比较</h2><p><img src=\"/images/MobileNetV2/3.png\" width=\"600\" height=\"100\"></p>\n<p><strong>相同点</strong>：</p>\n<ul>\n<li><p><strong>都采用depthwise(DW)卷积搭配pointwise(PW)卷积的方式来提特征</strong></p>\n<ul>\n<li><p>这两个操作合起来也被称为深度可分离卷积(depthwise separable convolution)，之前在Xception中被广泛使用。其优点是：理论上可以成倍的减少卷积层的时间复杂度和空间复杂度。</p>\n</li>\n<li><p>下式为深度可分离卷积和常规卷积的复杂度比率(参数个数比率或乘加次数比率都如下式所示)：</p>\n</li>\n<li><img src=\"/images/MobileNetV2/4.png\" width=\"500\" height=\"100\"></li>\n<li>可以看出：由于卷积核的尺寸$K$通常远小于输出通道数$C_{out}$，因此标准卷积的计算复杂度近似为深度可分离卷积的$K^2$倍。</li>\n</ul>\n</li>\n</ul>\n<p><strong>不同点</strong>：</p>\n<ul>\n<li><strong>MobileNetV2在DW卷积之前新加了一个PW卷积</strong><ul>\n<li>这么做的原因，<strong>是因为DW卷积由于本身的计算特性决定它自己没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。所以如果上一层给的通道数本身很少的话，DW卷积也只能很委屈的在低维空间提特征，因此效果不够好</strong>。</li>\n<li>现在MobileNetV2为了改善这个问题，给每个DW卷积之前都配备了一个PW卷积，专门用来升维。定义升维系数$t = 6$，这样不管输入通道数$C_{in}$是多是少，经过第一个PW卷积升维之后，DW卷积都是在相对的更高维$( t \\cdot C_{in})$进行工作。</li>\n<li>该段解释了出现<strong>转置残差模块</strong>的原因：即需先增加一个PW卷积来升通道数，使得DW卷积更加有效，然后再通过PW卷积降通道数(当然也有通道重组的功能)。因此，便出现了所谓转置残差模块的现象。</li>\n</ul>\n</li>\n<li><strong>MobileNetV2去掉了第二个PW卷积的激活函数</strong>(论文作者称其为<strong>Linear Bottleneck</strong>)<ul>\n<li>这么做的原因，是因为作者认为激活函数在高维空间能够有效的增加非线性，而在低维空间时则会破坏特征，不如线性的效果好。</li>\n<li>由于第二个PW卷积的主要功能就是降维，因此按照上面的理论，降维之后就不宜再使用ReLU6了。</li>\n<li>该段解释了所谓<strong>线性瓶颈层</strong>的原因。</li>\n<li>注意：Xception中是DW卷积之后不加非线性激活函数，因为Xception文中认为DW卷积只有1通道数，非线性激活函数变得有害，导致信息丢失。</li>\n<li>疑问：接上，那么，为什么MobileNetV2中DW卷积后还进行非线性激活？</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ResNet与MobileNetV2的构造模块对比\"><a href=\"#ResNet与MobileNetV2的构造模块对比\" class=\"headerlink\" title=\"ResNet与MobileNetV2的构造模块对比\"></a>ResNet与MobileNetV2的构造模块对比</h2><p> <img src=\"/images/MobileNetV2/5.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li><p>相同点：</p>\n<ul>\n<li>MobileNetV2借鉴ResNet，都采用了$1 \\times 1 \\to 3 \\times 3 \\to 1 \\times 1$的模式。</li>\n<li>MobileNetV2借鉴ResNet，同样使用Shortcut将输出与输入相加(未在上图画出)。</li>\n</ul>\n</li>\n<li><p>不同点：</p>\n<ul>\n<li>ResNet使用<strong>标准卷积</strong>提取特征，MobileNet始终使用<strong>DW卷积</strong>提取特征。</li>\n<li>ResNet<strong>先降维</strong> (0.25倍)、卷积、再升维，而 MobileNetV2则是<strong>先升维</strong>(6倍)、卷积、再降维。直观的形象上来看，ResNet的微结构是<strong>沙漏形</strong>，而MobileNetV2则是<strong>纺锤形</strong>，刚好相反。因此论文作者将MobileNetV2的结构称为Inverted Residual Block。这么做也是因为使用DW卷积而作的适配，希望特征提取能够在高维进行。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MobileNetV2总体结构\"><a href=\"#MobileNetV2总体结构\" class=\"headerlink\" title=\"MobileNetV2总体结构\"></a>MobileNetV2总体结构</h2><p><img src=\"/images/MobileNetV2/6.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table2所示，为MobileNetV2结构，其中：<ul>\n<li>$t$是转置残差模块的扩张比率(expansion rate)</li>\n<li>$n$是该模块重复次数</li>\n<li>$c$是输出通道数</li>\n<li>$s$是该阶段第一次重复时的第一个模块的DW卷积的步长(后面重复都是步长为1)（疑问：为啥不直接使用第一个PW卷积实现下采样？）</li>\n</ul>\n</li>\n<li>MobileNetV2主要由初始的常规卷积层和17个线性瓶颈层的转置残差模块构成。</li>\n<li>采用ReLU6作为非线性函数，因为在对于低精度计算时其更鲁棒。<ul>\n<li>首先说明一下ReLU6，卷积之后通常会接一个ReLU非线性激活，在MobileV1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip），这是为了在移动端设备float16的低精度的时候，也能有很好的数值分辨率，如果对ReLU的激活范围不加限制，输出范围为0到正无穷，如果激活值非常大，分布在一个很大的范围内，则低精度的float16无法很好地精确描述如此大范围的数值，带来精度损失。</li>\n</ul>\n</li>\n<li>只使用$3 \\times 3$的卷积核。</li>\n<li>除了第一层，在网络中采用恒等的扩张比率$t$：<ul>\n<li>实验中发现，扩张比率$t$在5～10之间，可以得到几乎相等的表现曲线。</li>\n<li>较小的网络更适合采用较小的扩张比率;较大的网络更适合采用较大的扩张比率。</li>\n<li>文中实验均采用扩张比率为$t=6$。例如，对于一个线性瓶颈层的转置残差模块，输入为64通道的张量，输出为128通道的张量，其中间的扩张层的张量的通道数即为$64\\times 6 = 384$。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/7.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig6(a)所示，实验结果表明：验证了线性瓶颈层的重要性，提供了对于非线性激活函数会破坏低维空间的信息的支持。</li>\n<li>如Fig6(b)所示，实验结果表明：对于残差连接，与瓶颈层进行残差连接的表现，优于与扩张层进行残差连接以及不使用残差连接。</li>\n</ul>\n<p><img src=\"/images/MobileNetV2/8.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Fig4所示，为几种不同结构之间的构建模块比较。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><ul>\n<li>采用RMSProp优化器，动量系数设为0.9</li>\n<li>在每一层后面施加BN</li>\n<li>标准的权重衰减系数设为0.00004</li>\n<li>同MobileNetV1一样，采用初始学习率为0.045，学习速率衰减速率为每一opoch变为0.98</li>\n<li>采用16个GPU异步工作器，batch size为96</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/MobileNetV2/9.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如Table4所示，比较了MobileNetV1、ShuffleNet和NASNet-A模型。</li>\n</ul>\n<p>此外，文中有将MobileNetV2用于目标检测任务和语义分割任务的详细对比实验。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1801.04381.pdf\" target=\"_blank\" rel=\"noopener\">论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/33075914\" target=\"_blank\" rel=\"noopener\">博客(推荐)：MobileNet V2 论文初读</a></li>\n<li><a href=\"https://blog.csdn.net/u011995719/article/details/79135818\" target=\"_blank\" rel=\"noopener\">博客：轻量化网络：MobileNet-V2</a></li>\n<li><a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet\" target=\"_blank\" rel=\"noopener\">代码</a></li>\n</ul>"},{"title":"PCA算法","mathjax":true,"date":"2017-12-05T14:40:50.000Z","_content":"待","source":"_posts/PCA算法.md","raw":"---\ntitle: PCA算法\nmathjax: true\ndate: 2017-12-5 22:40:50\ncategories: \n- 机器学习\ntags:\n---\n待","slug":"PCA算法","published":1,"updated":"2017-12-05T07:31:49.611Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vv7000hqslpu9smfc4r","content":"<p>待</p>\n","site":{"data":{}},"excerpt":"","more":"<p>待</p>\n"},{"title":"SegNet","mathjax":true,"date":"2019-01-09T14:26:50.000Z","_content":"\n# 摘要\n\n- 针对道路场景理解(scene understanding)应用，为了在推理时的内存和计算时间方面都更有效率，设计了SegNet。\n- SegNet由编码器网络(an encoder network)和解码器网络(a corresponding decoder network)构成：\n - 编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层；\n - 解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling。\n\n<!-- more -->\n\n# 创新点\n\n## unpooling操作\n<img src=\"/images/SegNet/1.png\"  width = \"800\" height = \"200\"/>\n\n如Fig3所示，为unpooling操作示意图，从下往上看：\n\n- $a$,$b$,$c$,$d$对应于特征图的值，依据Max-pooling Indices，来对特征图进行上采样，得到稀疏的特征图，然后通过卷积(带有可学习的卷积核),来得到密集的特征特征图。\n\n\n## SegNet结构\n<img src=\"/images/SegNet/2.png\"  width = \"800\" height = \"200\"/>\n\n如Fig2所示，为SegNet结构：\n对于编码器网络，编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层：\n- 采用VGG16中的前13个卷积层，因此可以用分类任务中的预训练权重来初始化训练过程\n - 对于卷积层，只使用$f=3$，$s=1$，`same`填充,每一卷积层均为：`Conv`+`BN`+`ReLU`\n - 对于池化层，只使用$f=2$，$s=2$的最大池化层(没有重叠窗口)，使得空间尺寸减半\n- 抛弃全连接层的做法：\n - 不仅在编码器最深层的输出保持了更高的分辨率特征图\n  - 而且显著减少了SegNet编码网络中的参数(从134M到14.7M)\n\n对于解码器网络，解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling：\n- 解码器采用对应的编码器中的max-pooling操作计算得到的最大池化索引(max-pooling indices)，来对输入特征图执行非线性上采样(non-linear upsampling)；\n - 对编码器的每一个特征图，存储每一个池化窗口的最大特征值的位置;对于每一个2x2的池化窗口，只需要2bits；\n- 该上采样方法不需要学习，上采样得到的特征图是稀疏的，然后经过后续卷积(带有可训练的卷积核)来得到密集的特征图；\n- 上采样后的特征图是稀疏的(sparse)，然后通过可训练的卷积核进行卷积，来得到密集的(dense)特征图。\n- 在解码过程中，重用(reusing)max-pooling索引，有几个实际的优点：\n - 1.改善边缘描绘;\n - 2.减少了参数数量；\n - 3.该上采样方式可以施加在任意编码解码结构中\n\n相比于UNet： \n\n- UNet没有重用最大池化索引，而是将整个特征图（需要消耗更多的内存）传输给对应解码器，并和经过上采样(通过转置卷积)的解码器特征图进行串联。\n\n\n# 训练策略\n待补，class balancing等\n\n# 模型比较\n<img src=\"/images/SegNet/3.png\"  width = \"800\" height = \"200\"/>\n如Table3所示，在CamVid数据集上，比较了SegNet和其他网络的表现：\n- `40K`，`80K`及`>80K`意为迭代次数\n- DeconvNet的评价指标上的表现接近SegNet，但它的计算开销比SegNet更大。\n\n<img src=\"/images/SegNet/4.png\"  width = \"800\" height = \"200\"/>\n如Table6所示，为多种网络结构对于计算时间和硬件资源需求的统计对比：\n- SegNet在推理所占显存方面，最小。\n- DeepLabV1在前向传播时间、反向传播时间、训练所占显存以及模型大小方面，均为最优。\n- 疑问：SegNet的推理时间比FCN还大，这不是打自己脸吗？\n\n# 总结\n\n- FCN、UNet及SegNet本质上还是为了更好的效果，SegNet的效果确实是当时最优；在效率/性能方面，它们都不行。\n- 在效果方面：`SegNet` >= `DeconvNet` > `DeepLabV1` > `FCN`\n\n### 参考文献\n\n- [论文：SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/pdf/1511.00561.pdf)\n- [官方代码：alexgkendall/caffe-segnet](https://github.com/alexgkendall/caffe-segnet)\n- [代码及注释：xx](xx)\n\n\n","source":"_posts/SegNet.md","raw":"---\ntitle: SegNet\nmathjax: true\ndate: 2019-01-09 22:26:50\ncategories: \n- 语义分割\ntags:\n---\n\n# 摘要\n\n- 针对道路场景理解(scene understanding)应用，为了在推理时的内存和计算时间方面都更有效率，设计了SegNet。\n- SegNet由编码器网络(an encoder network)和解码器网络(a corresponding decoder network)构成：\n - 编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层；\n - 解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling。\n\n<!-- more -->\n\n# 创新点\n\n## unpooling操作\n<img src=\"/images/SegNet/1.png\"  width = \"800\" height = \"200\"/>\n\n如Fig3所示，为unpooling操作示意图，从下往上看：\n\n- $a$,$b$,$c$,$d$对应于特征图的值，依据Max-pooling Indices，来对特征图进行上采样，得到稀疏的特征图，然后通过卷积(带有可学习的卷积核),来得到密集的特征特征图。\n\n\n## SegNet结构\n<img src=\"/images/SegNet/2.png\"  width = \"800\" height = \"200\"/>\n\n如Fig2所示，为SegNet结构：\n对于编码器网络，编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层：\n- 采用VGG16中的前13个卷积层，因此可以用分类任务中的预训练权重来初始化训练过程\n - 对于卷积层，只使用$f=3$，$s=1$，`same`填充,每一卷积层均为：`Conv`+`BN`+`ReLU`\n - 对于池化层，只使用$f=2$，$s=2$的最大池化层(没有重叠窗口)，使得空间尺寸减半\n- 抛弃全连接层的做法：\n - 不仅在编码器最深层的输出保持了更高的分辨率特征图\n  - 而且显著减少了SegNet编码网络中的参数(从134M到14.7M)\n\n对于解码器网络，解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling：\n- 解码器采用对应的编码器中的max-pooling操作计算得到的最大池化索引(max-pooling indices)，来对输入特征图执行非线性上采样(non-linear upsampling)；\n - 对编码器的每一个特征图，存储每一个池化窗口的最大特征值的位置;对于每一个2x2的池化窗口，只需要2bits；\n- 该上采样方法不需要学习，上采样得到的特征图是稀疏的，然后经过后续卷积(带有可训练的卷积核)来得到密集的特征图；\n- 上采样后的特征图是稀疏的(sparse)，然后通过可训练的卷积核进行卷积，来得到密集的(dense)特征图。\n- 在解码过程中，重用(reusing)max-pooling索引，有几个实际的优点：\n - 1.改善边缘描绘;\n - 2.减少了参数数量；\n - 3.该上采样方式可以施加在任意编码解码结构中\n\n相比于UNet： \n\n- UNet没有重用最大池化索引，而是将整个特征图（需要消耗更多的内存）传输给对应解码器，并和经过上采样(通过转置卷积)的解码器特征图进行串联。\n\n\n# 训练策略\n待补，class balancing等\n\n# 模型比较\n<img src=\"/images/SegNet/3.png\"  width = \"800\" height = \"200\"/>\n如Table3所示，在CamVid数据集上，比较了SegNet和其他网络的表现：\n- `40K`，`80K`及`>80K`意为迭代次数\n- DeconvNet的评价指标上的表现接近SegNet，但它的计算开销比SegNet更大。\n\n<img src=\"/images/SegNet/4.png\"  width = \"800\" height = \"200\"/>\n如Table6所示，为多种网络结构对于计算时间和硬件资源需求的统计对比：\n- SegNet在推理所占显存方面，最小。\n- DeepLabV1在前向传播时间、反向传播时间、训练所占显存以及模型大小方面，均为最优。\n- 疑问：SegNet的推理时间比FCN还大，这不是打自己脸吗？\n\n# 总结\n\n- FCN、UNet及SegNet本质上还是为了更好的效果，SegNet的效果确实是当时最优；在效率/性能方面，它们都不行。\n- 在效果方面：`SegNet` >= `DeconvNet` > `DeepLabV1` > `FCN`\n\n### 参考文献\n\n- [论文：SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/pdf/1511.00561.pdf)\n- [官方代码：alexgkendall/caffe-segnet](https://github.com/alexgkendall/caffe-segnet)\n- [代码及注释：xx](xx)\n\n\n","slug":"SegNet","published":1,"updated":"2019-01-15T09:54:14.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vv9000jqslpys4de3c4","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>针对道路场景理解(scene understanding)应用，为了在推理时的内存和计算时间方面都更有效率，设计了SegNet。</li>\n<li>SegNet由编码器网络(an encoder network)和解码器网络(a corresponding decoder network)构成：<ul>\n<li>编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层；</li>\n<li>解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling。</li>\n</ul>\n</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"unpooling操作\"><a href=\"#unpooling操作\" class=\"headerlink\" title=\"unpooling操作\"></a>unpooling操作</h2><p><img src=\"/images/SegNet/1.png\" width=\"800\" height=\"200\"></p>\n<p>如Fig3所示，为unpooling操作示意图，从下往上看：</p>\n<ul>\n<li>$a$,$b$,$c$,$d$对应于特征图的值，依据Max-pooling Indices，来对特征图进行上采样，得到稀疏的特征图，然后通过卷积(带有可学习的卷积核),来得到密集的特征特征图。</li>\n</ul>\n<h2 id=\"SegNet结构\"><a href=\"#SegNet结构\" class=\"headerlink\" title=\"SegNet结构\"></a>SegNet结构</h2><p><img src=\"/images/SegNet/2.png\" width=\"800\" height=\"200\"></p>\n<p>如Fig2所示，为SegNet结构：<br>对于编码器网络，编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层：</p>\n<ul>\n<li>采用VGG16中的前13个卷积层，因此可以用分类任务中的预训练权重来初始化训练过程<ul>\n<li>对于卷积层，只使用$f=3$，$s=1$，<code>same</code>填充,每一卷积层均为：<code>Conv</code>+<code>BN</code>+<code>ReLU</code></li>\n<li>对于池化层，只使用$f=2$，$s=2$的最大池化层(没有重叠窗口)，使得空间尺寸减半</li>\n</ul>\n</li>\n<li>抛弃全连接层的做法：<ul>\n<li>不仅在编码器最深层的输出保持了更高的分辨率特征图</li>\n<li>而且显著减少了SegNet编码网络中的参数(从134M到14.7M)</li>\n</ul>\n</li>\n</ul>\n<p>对于解码器网络，解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling：</p>\n<ul>\n<li>解码器采用对应的编码器中的max-pooling操作计算得到的最大池化索引(max-pooling indices)，来对输入特征图执行非线性上采样(non-linear upsampling)；<ul>\n<li>对编码器的每一个特征图，存储每一个池化窗口的最大特征值的位置;对于每一个2x2的池化窗口，只需要2bits；</li>\n</ul>\n</li>\n<li>该上采样方法不需要学习，上采样得到的特征图是稀疏的，然后经过后续卷积(带有可训练的卷积核)来得到密集的特征图；</li>\n<li>上采样后的特征图是稀疏的(sparse)，然后通过可训练的卷积核进行卷积，来得到密集的(dense)特征图。</li>\n<li>在解码过程中，重用(reusing)max-pooling索引，有几个实际的优点：<ul>\n<li>1.改善边缘描绘;</li>\n<li>2.减少了参数数量；</li>\n<li>3.该上采样方式可以施加在任意编码解码结构中</li>\n</ul>\n</li>\n</ul>\n<p>相比于UNet： </p>\n<ul>\n<li>UNet没有重用最大池化索引，而是将整个特征图（需要消耗更多的内存）传输给对应解码器，并和经过上采样(通过转置卷积)的解码器特征图进行串联。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>待补，class balancing等</p>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/SegNet/3.png\" width=\"800\" height=\"200\"><br>如Table3所示，在CamVid数据集上，比较了SegNet和其他网络的表现：</p>\n<ul>\n<li><code>40K</code>，<code>80K</code>及<code>&gt;80K</code>意为迭代次数</li>\n<li>DeconvNet的评价指标上的表现接近SegNet，但它的计算开销比SegNet更大。</li>\n</ul>\n<p><img src=\"/images/SegNet/4.png\" width=\"800\" height=\"200\"><br>如Table6所示，为多种网络结构对于计算时间和硬件资源需求的统计对比：</p>\n<ul>\n<li>SegNet在推理所占显存方面，最小。</li>\n<li>DeepLabV1在前向传播时间、反向传播时间、训练所占显存以及模型大小方面，均为最优。</li>\n<li>疑问：SegNet的推理时间比FCN还大，这不是打自己脸吗？</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>FCN、UNet及SegNet本质上还是为了更好的效果，SegNet的效果确实是当时最优；在效率/性能方面，它们都不行。</li>\n<li>在效果方面：<code>SegNet</code> &gt;= <code>DeconvNet</code> &gt; <code>DeepLabV1</code> &gt; <code>FCN</code></li>\n</ul>\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ul>\n<li><a href=\"https://arxiv.org/pdf/1511.00561.pdf\" target=\"_blank\" rel=\"noopener\">论文：SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a></li>\n<li><a href=\"https://github.com/alexgkendall/caffe-segnet\" target=\"_blank\" rel=\"noopener\">官方代码：alexgkendall/caffe-segnet</a></li>\n<li><a href=\"xx\">代码及注释：xx</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>针对道路场景理解(scene understanding)应用，为了在推理时的内存和计算时间方面都更有效率，设计了SegNet。</li>\n<li>SegNet由编码器网络(an encoder network)和解码器网络(a corresponding decoder network)构成：<ul>\n<li>编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层；</li>\n<li>解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling。</li>\n</ul>\n</li>\n</ul>","more":"<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"unpooling操作\"><a href=\"#unpooling操作\" class=\"headerlink\" title=\"unpooling操作\"></a>unpooling操作</h2><p><img src=\"/images/SegNet/1.png\" width=\"800\" height=\"200\"></p>\n<p>如Fig3所示，为unpooling操作示意图，从下往上看：</p>\n<ul>\n<li>$a$,$b$,$c$,$d$对应于特征图的值，依据Max-pooling Indices，来对特征图进行上采样，得到稀疏的特征图，然后通过卷积(带有可学习的卷积核),来得到密集的特征特征图。</li>\n</ul>\n<h2 id=\"SegNet结构\"><a href=\"#SegNet结构\" class=\"headerlink\" title=\"SegNet结构\"></a>SegNet结构</h2><p><img src=\"/images/SegNet/2.png\" width=\"800\" height=\"200\"></p>\n<p>如Fig2所示，为SegNet结构：<br>对于编码器网络，编码网络为VGG16的前13个卷积层，移除了VGG16中的全连接层：</p>\n<ul>\n<li>采用VGG16中的前13个卷积层，因此可以用分类任务中的预训练权重来初始化训练过程<ul>\n<li>对于卷积层，只使用$f=3$，$s=1$，<code>same</code>填充,每一卷积层均为：<code>Conv</code>+<code>BN</code>+<code>ReLU</code></li>\n<li>对于池化层，只使用$f=2$，$s=2$的最大池化层(没有重叠窗口)，使得空间尺寸减半</li>\n</ul>\n</li>\n<li>抛弃全连接层的做法：<ul>\n<li>不仅在编码器最深层的输出保持了更高的分辨率特征图</li>\n<li>而且显著减少了SegNet编码网络中的参数(从134M到14.7M)</li>\n</ul>\n</li>\n</ul>\n<p>对于解码器网络，解码网络和编码网络的每一层一一对应，解码网络也有13层，解码网络中的上采样方式采用unpooling：</p>\n<ul>\n<li>解码器采用对应的编码器中的max-pooling操作计算得到的最大池化索引(max-pooling indices)，来对输入特征图执行非线性上采样(non-linear upsampling)；<ul>\n<li>对编码器的每一个特征图，存储每一个池化窗口的最大特征值的位置;对于每一个2x2的池化窗口，只需要2bits；</li>\n</ul>\n</li>\n<li>该上采样方法不需要学习，上采样得到的特征图是稀疏的，然后经过后续卷积(带有可训练的卷积核)来得到密集的特征图；</li>\n<li>上采样后的特征图是稀疏的(sparse)，然后通过可训练的卷积核进行卷积，来得到密集的(dense)特征图。</li>\n<li>在解码过程中，重用(reusing)max-pooling索引，有几个实际的优点：<ul>\n<li>1.改善边缘描绘;</li>\n<li>2.减少了参数数量；</li>\n<li>3.该上采样方式可以施加在任意编码解码结构中</li>\n</ul>\n</li>\n</ul>\n<p>相比于UNet： </p>\n<ul>\n<li>UNet没有重用最大池化索引，而是将整个特征图（需要消耗更多的内存）传输给对应解码器，并和经过上采样(通过转置卷积)的解码器特征图进行串联。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>待补，class balancing等</p>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/SegNet/3.png\" width=\"800\" height=\"200\"><br>如Table3所示，在CamVid数据集上，比较了SegNet和其他网络的表现：</p>\n<ul>\n<li><code>40K</code>，<code>80K</code>及<code>&gt;80K</code>意为迭代次数</li>\n<li>DeconvNet的评价指标上的表现接近SegNet，但它的计算开销比SegNet更大。</li>\n</ul>\n<p><img src=\"/images/SegNet/4.png\" width=\"800\" height=\"200\"><br>如Table6所示，为多种网络结构对于计算时间和硬件资源需求的统计对比：</p>\n<ul>\n<li>SegNet在推理所占显存方面，最小。</li>\n<li>DeepLabV1在前向传播时间、反向传播时间、训练所占显存以及模型大小方面，均为最优。</li>\n<li>疑问：SegNet的推理时间比FCN还大，这不是打自己脸吗？</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>FCN、UNet及SegNet本质上还是为了更好的效果，SegNet的效果确实是当时最优；在效率/性能方面，它们都不行。</li>\n<li>在效果方面：<code>SegNet</code> &gt;= <code>DeconvNet</code> &gt; <code>DeepLabV1</code> &gt; <code>FCN</code></li>\n</ul>\n<h3 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h3><ul>\n<li><a href=\"https://arxiv.org/pdf/1511.00561.pdf\" target=\"_blank\" rel=\"noopener\">论文：SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a></li>\n<li><a href=\"https://github.com/alexgkendall/caffe-segnet\" target=\"_blank\" rel=\"noopener\">官方代码：alexgkendall/caffe-segnet</a></li>\n<li><a href=\"xx\">代码及注释：xx</a></li>\n</ul>"},{"title":"Softmax回归模型","mathjax":true,"date":"2017-12-04T12:52:50.000Z","_content":"Softmax回归模型是逻辑回归模型在多分类问题上的推广，在多分类问题中，类别标签$y$可以取$k$个不同的值（而不是2个）。\nSoftmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字，故有$k=10$个不同的类别。\n# 1.模型\n## 1.1 假设函数\n假设函数：\n\n$$\n\\begin{align}\nh_\\theta(x^{(i)}) =\n\\begin{bmatrix}\np(y^{(i)} = 1 | x^{(i)}; \\theta) \\\\\n,\np(y^{(i)} = 2 | x^{(i)}; \\theta) \\\\\n,\n\\dotsc \\\\\n,\np(y^{(i)} = k | x^{(i)}; \\theta)\n\\end{bmatrix}\n=\n\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }\n\\begin{bmatrix}\ne^{ \\theta_1^T x^{(i)} } \\\\\n,\ne^{ \\theta_2^T x^{(i)} } \\\\\n,\n\\dotsc \\\\\n,\ne^{ \\theta_k^T x^{(i)} } \\\\\n\\end{bmatrix}\n\\end{align}\n$$\n\n<!-- more --> \n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项)；$\\theta_1, \\theta_2, \\ldots, \\theta_k \\in R^{n+1}$是模型的参数，即每一个输出单元对应一个$(n+1)$维的参数$\\theta$。\n注意，$\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }$这一项对概率分布进行归一化，使得所有概率之和为1。\n## 1.2 代价函数\n**训练集**：$\\{(x^{(1)},y^{(1)}),\\ldots,(x^{(m)},y^{(m)})\\}$，其中，$y^{(i)}\\in \\{ 1,2,\\ldots,k \\} $。（注意此处的类别下标从1开始，而不是0）。\n**代价函数**：\n\n$$\n\\begin{align}\nJ(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (-\\log p(y^{(i)}|x^{(i)};\\theta))\\\\\n=- \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k}  1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}\\right]\n\\end{align}\n$$\n\n其中，$$\\textstyle 1\\{\\cdot\\}$$是示性函数，其取值规则为：$$\\textstyle 1\\{ 值为真的表达式 \\textstyle \\}=1$$，$$\\textstyle 1\\{ 值为假的表达式 \\textstyle \\}=0$$。\n\n## 1.3 参数求解\n目的：$\\min\\limits_\\theta \\ J(\\theta)$\n对于$\\textstyle J(\\theta)$的最小化问题，目前还没有闭式解法。因此，使用迭代的优化算法（例如梯度下降法，或L-BFGS）。\n梯度公式如下：\n$$\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) \\right) \\right]  }\n\\end{align}\n$$\n其中，$$\\textstyle \\nabla_{\\theta_j} J(\\theta)$$本身是一个向量，它的第$\\textstyle l$个元素$$\\textstyle \\frac{\\partial J(\\theta)}{\\partial \\theta_{jl}}$$是$$\\textstyle J(\\theta)$$对$$\\textstyle \\theta_j$$的第$$\\textstyle l$$个分量的偏导数。\n参数更新：$$\\textstyle \\theta_j := \\theta_j - \\alpha \\nabla_{\\theta_j} J(\\theta)(\\textstyle j=1,\\ldots,k）$$。\n## 1.4 正则化\nL2正则化（权重衰减）：\n$$\n\\begin{align}\nJ(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}  \\right]\n              + \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^n \\theta_{ij}^2\n\\end{align}\n$$\n- 增加权重衰减项$$\\textstyle \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^{n} \\theta_{ij}^2$$后，代价函数变成了严格的凸函数，可保证得到唯一解。此时的Hessian矩阵变为可逆矩阵，并且因为$$\\textstyle J(\\theta)$$是凸函数，梯度下降法和L-BFGS等算法可以保证收敛到全局最优解。\n- 此时$$\\textstyle J(\\theta)$$的梯度计算，如下：\n$$\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} ( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) ) \\right]  } + \\lambda \\theta_j\n\\end{align}\n$$\n\n# 2.Softmax回归 vs k个二元分类器\n如果你在开发一个音乐分类的应用，需要对$k$种类型的音乐进行识别，那么是选择使用softmax分类器，还是使用logistic回归算法建立 $k$个独立的二元分类器呢？\n这一选择取决于你的**类别之间是否互斥**：\n- 情况1：如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签，即一首歌只能属于这四种音乐类型的其中一种。此时你应该使用类别数$k=4$的softmax回归。\n- 情况2：如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声。这种情况下，使用4个二分类的logistic回归分类器更为合适。这样，对于每个新的音乐作品，算法可以分别判断它是否属于各个类别。\n\n# 3.参考资料\n- [UFLDL Tutorial, Softmax回归](http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92)\n- [美团技术点评团队，Logistic Regression模型简介](https://tech.meituan.com/intro_to_logistic_regression.html)\n\n","source":"_posts/Softmax回归模型.md","raw":"---\ntitle: Softmax回归模型\nmathjax: true\ndate: 2017-12-4 20:52:50\ncategories: \n- 机器学习\ntags:\n- softmax\n- 多分类\n---\nSoftmax回归模型是逻辑回归模型在多分类问题上的推广，在多分类问题中，类别标签$y$可以取$k$个不同的值（而不是2个）。\nSoftmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字，故有$k=10$个不同的类别。\n# 1.模型\n## 1.1 假设函数\n假设函数：\n\n$$\n\\begin{align}\nh_\\theta(x^{(i)}) =\n\\begin{bmatrix}\np(y^{(i)} = 1 | x^{(i)}; \\theta) \\\\\n,\np(y^{(i)} = 2 | x^{(i)}; \\theta) \\\\\n,\n\\dotsc \\\\\n,\np(y^{(i)} = k | x^{(i)}; \\theta)\n\\end{bmatrix}\n=\n\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }\n\\begin{bmatrix}\ne^{ \\theta_1^T x^{(i)} } \\\\\n,\ne^{ \\theta_2^T x^{(i)} } \\\\\n,\n\\dotsc \\\\\n,\ne^{ \\theta_k^T x^{(i)} } \\\\\n\\end{bmatrix}\n\\end{align}\n$$\n\n<!-- more --> \n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项)；$\\theta_1, \\theta_2, \\ldots, \\theta_k \\in R^{n+1}$是模型的参数，即每一个输出单元对应一个$(n+1)$维的参数$\\theta$。\n注意，$\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }$这一项对概率分布进行归一化，使得所有概率之和为1。\n## 1.2 代价函数\n**训练集**：$\\{(x^{(1)},y^{(1)}),\\ldots,(x^{(m)},y^{(m)})\\}$，其中，$y^{(i)}\\in \\{ 1,2,\\ldots,k \\} $。（注意此处的类别下标从1开始，而不是0）。\n**代价函数**：\n\n$$\n\\begin{align}\nJ(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (-\\log p(y^{(i)}|x^{(i)};\\theta))\\\\\n=- \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k}  1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}\\right]\n\\end{align}\n$$\n\n其中，$$\\textstyle 1\\{\\cdot\\}$$是示性函数，其取值规则为：$$\\textstyle 1\\{ 值为真的表达式 \\textstyle \\}=1$$，$$\\textstyle 1\\{ 值为假的表达式 \\textstyle \\}=0$$。\n\n## 1.3 参数求解\n目的：$\\min\\limits_\\theta \\ J(\\theta)$\n对于$\\textstyle J(\\theta)$的最小化问题，目前还没有闭式解法。因此，使用迭代的优化算法（例如梯度下降法，或L-BFGS）。\n梯度公式如下：\n$$\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) \\right) \\right]  }\n\\end{align}\n$$\n其中，$$\\textstyle \\nabla_{\\theta_j} J(\\theta)$$本身是一个向量，它的第$\\textstyle l$个元素$$\\textstyle \\frac{\\partial J(\\theta)}{\\partial \\theta_{jl}}$$是$$\\textstyle J(\\theta)$$对$$\\textstyle \\theta_j$$的第$$\\textstyle l$$个分量的偏导数。\n参数更新：$$\\textstyle \\theta_j := \\theta_j - \\alpha \\nabla_{\\theta_j} J(\\theta)(\\textstyle j=1,\\ldots,k）$$。\n## 1.4 正则化\nL2正则化（权重衰减）：\n$$\n\\begin{align}\nJ(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}  \\right]\n              + \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^n \\theta_{ij}^2\n\\end{align}\n$$\n- 增加权重衰减项$$\\textstyle \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^{n} \\theta_{ij}^2$$后，代价函数变成了严格的凸函数，可保证得到唯一解。此时的Hessian矩阵变为可逆矩阵，并且因为$$\\textstyle J(\\theta)$$是凸函数，梯度下降法和L-BFGS等算法可以保证收敛到全局最优解。\n- 此时$$\\textstyle J(\\theta)$$的梯度计算，如下：\n$$\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} ( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) ) \\right]  } + \\lambda \\theta_j\n\\end{align}\n$$\n\n# 2.Softmax回归 vs k个二元分类器\n如果你在开发一个音乐分类的应用，需要对$k$种类型的音乐进行识别，那么是选择使用softmax分类器，还是使用logistic回归算法建立 $k$个独立的二元分类器呢？\n这一选择取决于你的**类别之间是否互斥**：\n- 情况1：如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签，即一首歌只能属于这四种音乐类型的其中一种。此时你应该使用类别数$k=4$的softmax回归。\n- 情况2：如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声。这种情况下，使用4个二分类的logistic回归分类器更为合适。这样，对于每个新的音乐作品，算法可以分别判断它是否属于各个类别。\n\n# 3.参考资料\n- [UFLDL Tutorial, Softmax回归](http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92)\n- [美团技术点评团队，Logistic Regression模型简介](https://tech.meituan.com/intro_to_logistic_regression.html)\n\n","slug":"Softmax回归模型","published":1,"updated":"2018-09-21T06:18:07.665Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvb000oqslpnsntcz41","content":"<p>Softmax回归模型是逻辑回归模型在多分类问题上的推广，在多分类问题中，类别标签$y$可以取$k$个不同的值（而不是2个）。<br>Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字，故有$k=10$个不同的类别。</p>\n<h1 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h1><h2 id=\"1-1-假设函数\"><a href=\"#1-1-假设函数\" class=\"headerlink\" title=\"1.1 假设函数\"></a>1.1 假设函数</h2><p>假设函数：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nh_\\theta(x^{(i)}) =\n\\begin{bmatrix}\np(y^{(i)} = 1 | x^{(i)}; \\theta) \\\\\n,\np(y^{(i)} = 2 | x^{(i)}; \\theta) \\\\\n,\n\\dotsc \\\\\n,\np(y^{(i)} = k | x^{(i)}; \\theta)\n\\end{bmatrix}\n=\n\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }\n\\begin{bmatrix}\ne^{ \\theta_1^T x^{(i)} } \\\\\n,\ne^{ \\theta_2^T x^{(i)} } \\\\\n,\n\\dotsc \\\\\n,\ne^{ \\theta_k^T x^{(i)} } \\\\\n\\end{bmatrix}\n\\end{align}</script><a id=\"more\"></a> \n<p>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项)；$\\theta_1, \\theta_2, \\ldots, \\theta_k \\in R^{n+1}$是模型的参数，即每一个输出单元对应一个$(n+1)$维的参数$\\theta$。<br>注意，$\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }$这一项对概率分布进行归一化，使得所有概率之和为1。</p>\n<h2 id=\"1-2-代价函数\"><a href=\"#1-2-代价函数\" class=\"headerlink\" title=\"1.2 代价函数\"></a>1.2 代价函数</h2><p><strong>训练集</strong>：$\\{(x^{(1)},y^{(1)}),\\ldots,(x^{(m)},y^{(m)})\\}$，其中，$y^{(i)}\\in \\{ 1,2,\\ldots,k \\} $。（注意此处的类别下标从1开始，而不是0）。<br><strong>代价函数</strong>：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nJ(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (-\\log p(y^{(i)}|x^{(i)};\\theta))\\\\\n=- \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k}  1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}\\right]\n\\end{align}</script><p>其中，<script type=\"math/tex\">\\textstyle 1\\{\\cdot\\}</script>是示性函数，其取值规则为：<script type=\"math/tex\">\\textstyle 1\\{ 值为真的表达式 \\textstyle \\}=1</script>，<script type=\"math/tex\">\\textstyle 1\\{ 值为假的表达式 \\textstyle \\}=0</script>。</p>\n<h2 id=\"1-3-参数求解\"><a href=\"#1-3-参数求解\" class=\"headerlink\" title=\"1.3 参数求解\"></a>1.3 参数求解</h2><p>目的：$\\min\\limits_\\theta \\ J(\\theta)$<br>对于$\\textstyle J(\\theta)$的最小化问题，目前还没有闭式解法。因此，使用迭代的优化算法（例如梯度下降法，或L-BFGS）。<br>梯度公式如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) \\right) \\right]  }\n\\end{align}</script><p>其中，<script type=\"math/tex\">\\textstyle \\nabla_{\\theta_j} J(\\theta)</script>本身是一个向量，它的第$\\textstyle l$个元素<script type=\"math/tex\">\\textstyle \\frac{\\partial J(\\theta)}{\\partial \\theta_{jl}}</script>是<script type=\"math/tex\">\\textstyle J(\\theta)</script>对<script type=\"math/tex\">\\textstyle \\theta_j</script>的第<script type=\"math/tex\">\\textstyle l</script>个分量的偏导数。<br>参数更新：<script type=\"math/tex\">\\textstyle \\theta_j := \\theta_j - \\alpha \\nabla_{\\theta_j} J(\\theta)(\\textstyle j=1,\\ldots,k）</script>。</p>\n<h2 id=\"1-4-正则化\"><a href=\"#1-4-正则化\" class=\"headerlink\" title=\"1.4 正则化\"></a>1.4 正则化</h2><p>L2正则化（权重衰减）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nJ(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}  \\right]\n              + \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^n \\theta_{ij}^2\n\\end{align}</script><ul>\n<li>增加权重衰减项<script type=\"math/tex\">\\textstyle \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^{n} \\theta_{ij}^2</script>后，代价函数变成了严格的凸函数，可保证得到唯一解。此时的Hessian矩阵变为可逆矩阵，并且因为<script type=\"math/tex\">\\textstyle J(\\theta)</script>是凸函数，梯度下降法和L-BFGS等算法可以保证收敛到全局最优解。</li>\n<li>此时<script type=\"math/tex\">\\textstyle J(\\theta)</script>的梯度计算，如下：<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} ( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) ) \\right]  } + \\lambda \\theta_j\n\\end{align}</script></li>\n</ul>\n<h1 id=\"2-Softmax回归-vs-k个二元分类器\"><a href=\"#2-Softmax回归-vs-k个二元分类器\" class=\"headerlink\" title=\"2.Softmax回归 vs k个二元分类器\"></a>2.Softmax回归 vs k个二元分类器</h1><p>如果你在开发一个音乐分类的应用，需要对$k$种类型的音乐进行识别，那么是选择使用softmax分类器，还是使用logistic回归算法建立 $k$个独立的二元分类器呢？<br>这一选择取决于你的<strong>类别之间是否互斥</strong>：</p>\n<ul>\n<li>情况1：如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签，即一首歌只能属于这四种音乐类型的其中一种。此时你应该使用类别数$k=4$的softmax回归。</li>\n<li>情况2：如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声。这种情况下，使用4个二分类的logistic回归分类器更为合适。这样，对于每个新的音乐作品，算法可以分别判断它是否属于各个类别。</li>\n</ul>\n<h1 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h1><ul>\n<li><a href=\"http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92\" target=\"_blank\" rel=\"noopener\">UFLDL Tutorial, Softmax回归</a></li>\n<li><a href=\"https://tech.meituan.com/intro_to_logistic_regression.html\" target=\"_blank\" rel=\"noopener\">美团技术点评团队，Logistic Regression模型简介</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>Softmax回归模型是逻辑回归模型在多分类问题上的推广，在多分类问题中，类别标签$y$可以取$k$个不同的值（而不是2个）。<br>Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字，故有$k=10$个不同的类别。</p>\n<h1 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h1><h2 id=\"1-1-假设函数\"><a href=\"#1-1-假设函数\" class=\"headerlink\" title=\"1.1 假设函数\"></a>1.1 假设函数</h2><p>假设函数：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nh_\\theta(x^{(i)}) =\n\\begin{bmatrix}\np(y^{(i)} = 1 | x^{(i)}; \\theta) \\\\\n,\np(y^{(i)} = 2 | x^{(i)}; \\theta) \\\\\n,\n\\dotsc \\\\\n,\np(y^{(i)} = k | x^{(i)}; \\theta)\n\\end{bmatrix}\n=\n\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }\n\\begin{bmatrix}\ne^{ \\theta_1^T x^{(i)} } \\\\\n,\ne^{ \\theta_2^T x^{(i)} } \\\\\n,\n\\dotsc \\\\\n,\ne^{ \\theta_k^T x^{(i)} } \\\\\n\\end{bmatrix}\n\\end{align}</script>","more":"<p>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项)；$\\theta_1, \\theta_2, \\ldots, \\theta_k \\in R^{n+1}$是模型的参数，即每一个输出单元对应一个$(n+1)$维的参数$\\theta$。<br>注意，$\\frac{1}{ \\sum_{j=1}^{k}{e^{ \\theta_j^T x^{(i)} }} }$这一项对概率分布进行归一化，使得所有概率之和为1。</p>\n<h2 id=\"1-2-代价函数\"><a href=\"#1-2-代价函数\" class=\"headerlink\" title=\"1.2 代价函数\"></a>1.2 代价函数</h2><p><strong>训练集</strong>：$\\{(x^{(1)},y^{(1)}),\\ldots,(x^{(m)},y^{(m)})\\}$，其中，$y^{(i)}\\in \\{ 1,2,\\ldots,k \\} $。（注意此处的类别下标从1开始，而不是0）。<br><strong>代价函数</strong>：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nJ(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (-\\log p(y^{(i)}|x^{(i)};\\theta))\\\\\n=- \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k}  1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}\\right]\n\\end{align}</script><p>其中，<script type=\"math/tex\">\\textstyle 1\\{\\cdot\\}</script>是示性函数，其取值规则为：<script type=\"math/tex\">\\textstyle 1\\{ 值为真的表达式 \\textstyle \\}=1</script>，<script type=\"math/tex\">\\textstyle 1\\{ 值为假的表达式 \\textstyle \\}=0</script>。</p>\n<h2 id=\"1-3-参数求解\"><a href=\"#1-3-参数求解\" class=\"headerlink\" title=\"1.3 参数求解\"></a>1.3 参数求解</h2><p>目的：$\\min\\limits_\\theta \\ J(\\theta)$<br>对于$\\textstyle J(\\theta)$的最小化问题，目前还没有闭式解法。因此，使用迭代的优化算法（例如梯度下降法，或L-BFGS）。<br>梯度公式如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} \\left( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) \\right) \\right]  }\n\\end{align}</script><p>其中，<script type=\"math/tex\">\\textstyle \\nabla_{\\theta_j} J(\\theta)</script>本身是一个向量，它的第$\\textstyle l$个元素<script type=\"math/tex\">\\textstyle \\frac{\\partial J(\\theta)}{\\partial \\theta_{jl}}</script>是<script type=\"math/tex\">\\textstyle J(\\theta)</script>对<script type=\"math/tex\">\\textstyle \\theta_j</script>的第<script type=\"math/tex\">\\textstyle l</script>个分量的偏导数。<br>参数更新：<script type=\"math/tex\">\\textstyle \\theta_j := \\theta_j - \\alpha \\nabla_{\\theta_j} J(\\theta)(\\textstyle j=1,\\ldots,k）</script>。</p>\n<h2 id=\"1-4-正则化\"><a href=\"#1-4-正则化\" class=\"headerlink\" title=\"1.4 正则化\"></a>1.4 正则化</h2><p>L2正则化（权重衰减）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align}\nJ(\\theta) = - \\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{k} 1\\left\\{y^{(i)} = j\\right\\} \\log \\frac{e^{\\theta_j^T x^{(i)}}}{\\sum_{l=1}^k e^{ \\theta_l^T x^{(i)} }}  \\right]\n              + \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^n \\theta_{ij}^2\n\\end{align}</script><ul>\n<li>增加权重衰减项<script type=\"math/tex\">\\textstyle \\frac{\\lambda}{2} \\sum_{i=1}^k \\sum_{j=0}^{n} \\theta_{ij}^2</script>后，代价函数变成了严格的凸函数，可保证得到唯一解。此时的Hessian矩阵变为可逆矩阵，并且因为<script type=\"math/tex\">\\textstyle J(\\theta)</script>是凸函数，梯度下降法和L-BFGS等算法可以保证收敛到全局最优解。</li>\n<li>此时<script type=\"math/tex\">\\textstyle J(\\theta)</script>的梯度计算，如下：<script type=\"math/tex; mode=display\">\n\\begin{align}\n\\nabla_{\\theta_j} J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m}{ \\left[ x^{(i)} ( 1\\{ y^{(i)} = j\\}  - p(y^{(i)} = j | x^{(i)}; \\theta) ) \\right]  } + \\lambda \\theta_j\n\\end{align}</script></li>\n</ul>\n<h1 id=\"2-Softmax回归-vs-k个二元分类器\"><a href=\"#2-Softmax回归-vs-k个二元分类器\" class=\"headerlink\" title=\"2.Softmax回归 vs k个二元分类器\"></a>2.Softmax回归 vs k个二元分类器</h1><p>如果你在开发一个音乐分类的应用，需要对$k$种类型的音乐进行识别，那么是选择使用softmax分类器，还是使用logistic回归算法建立 $k$个独立的二元分类器呢？<br>这一选择取决于你的<strong>类别之间是否互斥</strong>：</p>\n<ul>\n<li>情况1：如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签，即一首歌只能属于这四种音乐类型的其中一种。此时你应该使用类别数$k=4$的softmax回归。</li>\n<li>情况2：如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声。这种情况下，使用4个二分类的logistic回归分类器更为合适。这样，对于每个新的音乐作品，算法可以分别判断它是否属于各个类别。</li>\n</ul>\n<h1 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h1><ul>\n<li><a href=\"http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92\" target=\"_blank\" rel=\"noopener\">UFLDL Tutorial, Softmax回归</a></li>\n<li><a href=\"https://tech.meituan.com/intro_to_logistic_regression.html\" target=\"_blank\" rel=\"noopener\">美团技术点评团队，Logistic Regression模型简介</a></li>\n</ul>"},{"title":"SqueezeNet","mathjax":true,"date":"2018-12-28T14:22:50.000Z","_content":"\n# 摘要\n\n- 提出小CNN结构——SqueezeNet。\n- 在ImageNet上，SqueezeNet能够得到和AlexNet一样的精度，同时参数为其$1/50$。\n- 借助于模型压缩技术(model compression techniques)，可将SqueezeNet压缩到小于0.5MB(比AlexNet小510倍)。\n\n <!-- more -->\n\n# 创新点\n\n## 针对较少参数CNN结构的设计策略提纲\n\n为了设计出含有较少参数且维持较高精度的CNN结构，主要采用如下三点策略：\n\n- 策略1:用$1\\times 1$卷积替换$3\\times 3$卷积\n - $1\\times 1$卷积的参数比$3\\times 3$卷积少9倍 \n- 策略2:减少$3\\times 3$卷积的输入通道数\n - 对于$3\\times 3$卷积层，总的参数量是`(number of input channels) * (number of filters)*(3*3)`。\n - 策略1是为了减少$3\\times 3$卷积的数量，策略2是为了减少$3\\times 3$卷积的输入通道数。\n- 策略3:在网络中较晚地进行下采样，使得卷积层有更大尺寸的激活特征图\n - 激活特征图的尺寸由如下两个尺寸控制：1.输入数据的尺寸；2.选择在CNN结构中的哪个层进行下采样(即什么时候进行下采样，是早点还是晚点)\n - 在CNN结构中，下采样操作通常由步长大于1的卷积层或步长大于1的池化层完成。\n - 若网络前端的层用大的步长，那么大多数层将有小的特征图；相反地，若步长大于1的层集中在网络的末端，那么网络中的许多层将拥有较大的激活特征图。\n - 在保持其他设置相等的情况下，较大的特征图(由于较晚地下采样)可以得到更高的分类精度。\n\n \n## Fire模块(Fire module)\n\n<img src=\"/images/SqueezeNet/1.png\"  width = \"600\" height = \"100\"/>\n\n如Fig1所示，即为Fire模块：\n\n- Fire模块由squeeze卷积层和expand卷积层构成：\n - squeeze卷积层：由$1\\times 1$卷积构成。\n - expand卷积层：由$1\\times 1$卷积和$3\\times 3$卷积混合构成。\n - squeeze卷积层和expand卷积层两部分，分别压缩和扩展特征的通道数。expand卷积层中，两个不同尺寸核的输出经串联后作为最终输出。\n- Fire模块有三个可调参数： \n - $s_1$: squeeze层中的1×1卷积的通道数 \n - $e_1$: expand层中的1×1卷积的通道数 \n - $e_3$: expand层中的3×3卷积的通道数\n- Fire模块中$1\\times 1$卷积的大量使用，即遵循上述策略1。\n- 文中设置$s_1 <(e_1 + e_3)$，那么squeeze层即帮助限制了传给$3\\times 3$卷积的通道数，即遵循上述策略2。\n- 在SqueezeNet中，Fire模块采用的压缩比率(squeeze ratio)为0.125，意味着每一个squeeze层的输出通道数比expand层的输出通道数少8倍。\n- 输入输出尺寸相同。输入通道数不限，输出通道数为$e1+e3$。 \n- 在本文提出的SqueezeNet结构中，$e1=e3=4s1$。\n\n## SqueezeNet结构 \n<img src=\"/images/SqueezeNet/2.png\"  width = \"700\" height = \"100\"/>\n\n如Fig2所示，为SqueezeNet结构：\n\n- SqueezeNet起始是一个常规卷积(conv1)，接着跟随8个Fire模块(fire2-9)，最后为一个常规卷积(conv10)。\n- 在SqueezeNet中，每隔一个Fire模块，逐步地增加卷积核的个数。\n- 在SqueezeNet中，在conv1、fire4、fire8和conv10后，采用步长为2的max-pooling。\n - 这些相对延后放置的池化层遵循策略3。\n\n<img src=\"/images/SqueezeNet/3.png\"  width = \"700\" height = \"100\"/>\n\n- 如Table1所示，为SqueezeNet的详细信息。\n\n其他细节：\n- 在expand层中，对$3\\times3$卷积的输入增加了1像素边界的零填充，以使得$3\\times3$卷积与$1\\times1$卷积的输出激活函数的宽高相等。\n- 在Fire模块中，对squeeze层和expand层的激活函数均采用了ReLU。\n- 在fire9模块后，采用了比率为50%的Dropout\n- SqueezeNet未采用全连接层，由NIN启发。\n\n# 模型比较\n<img src=\"/images/SqueezeNet/4.png\"  width = \"650\" height = \"100\"/>\n\n如Table2所示，比较了AlexNet和SqueezeNet，以及在各模型压缩方法下的结果：\n\n- 对于AlexNet：\n - 基于SVD的模型压缩方法(SVD-based approach)，将AlexNet压缩了5倍，减少Top1准确率到56%。\n - 网络修剪(Network Pruning)的模型压缩方法，将AlexNet压缩了9倍，并维持Top1和Top5准确率。\n - 深度压缩(Deep Compression)将AlexNet压缩了35倍，并维持Top1和Top5准确率。\n- 相比于AlexNet的模型尺寸，SqueezeNet本身就比AlexNet小50倍，并且或维持或超过了AlexNet的Top1和Top5准确率。\n- 对SqueezeNet采用深度压缩(Deep Compression)，其中用33%的稀疏性(33% sparsity)和8比特的量化(8-bit quantization)：\n - 得到了0.66MB大小的模型(比32比特表示的AlexNet小363倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。\n-  对SqueezeNet采用深度压缩，其中用33%的稀疏性和6比特的量化：\n - 得到了0.47MB大小的模型(比32比特表示的AlexNet小510倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。\n- 深度压缩(Deep Compression)将SqueezeNet压缩了10倍，且维持基准精度。\n\n# 参考文献\n\n- [论文：SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and <0.5MB Model Size](https://arxiv.org/pdf/1602.07360.pdf)\n- [博客：超轻量级网络SqueezeNet算法详解](https://blog.csdn.net/shenxiaolu1984/article/details/51444525)\n- [代码：论文中给出的源码地址](https://github.com/DeepScale/SqueezeNet)\n\n","source":"_posts/SqueezeNet.md","raw":"---\ntitle: SqueezeNet\nmathjax: true\ndate: 2018-12-28 22:22:50\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 摘要\n\n- 提出小CNN结构——SqueezeNet。\n- 在ImageNet上，SqueezeNet能够得到和AlexNet一样的精度，同时参数为其$1/50$。\n- 借助于模型压缩技术(model compression techniques)，可将SqueezeNet压缩到小于0.5MB(比AlexNet小510倍)。\n\n <!-- more -->\n\n# 创新点\n\n## 针对较少参数CNN结构的设计策略提纲\n\n为了设计出含有较少参数且维持较高精度的CNN结构，主要采用如下三点策略：\n\n- 策略1:用$1\\times 1$卷积替换$3\\times 3$卷积\n - $1\\times 1$卷积的参数比$3\\times 3$卷积少9倍 \n- 策略2:减少$3\\times 3$卷积的输入通道数\n - 对于$3\\times 3$卷积层，总的参数量是`(number of input channels) * (number of filters)*(3*3)`。\n - 策略1是为了减少$3\\times 3$卷积的数量，策略2是为了减少$3\\times 3$卷积的输入通道数。\n- 策略3:在网络中较晚地进行下采样，使得卷积层有更大尺寸的激活特征图\n - 激活特征图的尺寸由如下两个尺寸控制：1.输入数据的尺寸；2.选择在CNN结构中的哪个层进行下采样(即什么时候进行下采样，是早点还是晚点)\n - 在CNN结构中，下采样操作通常由步长大于1的卷积层或步长大于1的池化层完成。\n - 若网络前端的层用大的步长，那么大多数层将有小的特征图；相反地，若步长大于1的层集中在网络的末端，那么网络中的许多层将拥有较大的激活特征图。\n - 在保持其他设置相等的情况下，较大的特征图(由于较晚地下采样)可以得到更高的分类精度。\n\n \n## Fire模块(Fire module)\n\n<img src=\"/images/SqueezeNet/1.png\"  width = \"600\" height = \"100\"/>\n\n如Fig1所示，即为Fire模块：\n\n- Fire模块由squeeze卷积层和expand卷积层构成：\n - squeeze卷积层：由$1\\times 1$卷积构成。\n - expand卷积层：由$1\\times 1$卷积和$3\\times 3$卷积混合构成。\n - squeeze卷积层和expand卷积层两部分，分别压缩和扩展特征的通道数。expand卷积层中，两个不同尺寸核的输出经串联后作为最终输出。\n- Fire模块有三个可调参数： \n - $s_1$: squeeze层中的1×1卷积的通道数 \n - $e_1$: expand层中的1×1卷积的通道数 \n - $e_3$: expand层中的3×3卷积的通道数\n- Fire模块中$1\\times 1$卷积的大量使用，即遵循上述策略1。\n- 文中设置$s_1 <(e_1 + e_3)$，那么squeeze层即帮助限制了传给$3\\times 3$卷积的通道数，即遵循上述策略2。\n- 在SqueezeNet中，Fire模块采用的压缩比率(squeeze ratio)为0.125，意味着每一个squeeze层的输出通道数比expand层的输出通道数少8倍。\n- 输入输出尺寸相同。输入通道数不限，输出通道数为$e1+e3$。 \n- 在本文提出的SqueezeNet结构中，$e1=e3=4s1$。\n\n## SqueezeNet结构 \n<img src=\"/images/SqueezeNet/2.png\"  width = \"700\" height = \"100\"/>\n\n如Fig2所示，为SqueezeNet结构：\n\n- SqueezeNet起始是一个常规卷积(conv1)，接着跟随8个Fire模块(fire2-9)，最后为一个常规卷积(conv10)。\n- 在SqueezeNet中，每隔一个Fire模块，逐步地增加卷积核的个数。\n- 在SqueezeNet中，在conv1、fire4、fire8和conv10后，采用步长为2的max-pooling。\n - 这些相对延后放置的池化层遵循策略3。\n\n<img src=\"/images/SqueezeNet/3.png\"  width = \"700\" height = \"100\"/>\n\n- 如Table1所示，为SqueezeNet的详细信息。\n\n其他细节：\n- 在expand层中，对$3\\times3$卷积的输入增加了1像素边界的零填充，以使得$3\\times3$卷积与$1\\times1$卷积的输出激活函数的宽高相等。\n- 在Fire模块中，对squeeze层和expand层的激活函数均采用了ReLU。\n- 在fire9模块后，采用了比率为50%的Dropout\n- SqueezeNet未采用全连接层，由NIN启发。\n\n# 模型比较\n<img src=\"/images/SqueezeNet/4.png\"  width = \"650\" height = \"100\"/>\n\n如Table2所示，比较了AlexNet和SqueezeNet，以及在各模型压缩方法下的结果：\n\n- 对于AlexNet：\n - 基于SVD的模型压缩方法(SVD-based approach)，将AlexNet压缩了5倍，减少Top1准确率到56%。\n - 网络修剪(Network Pruning)的模型压缩方法，将AlexNet压缩了9倍，并维持Top1和Top5准确率。\n - 深度压缩(Deep Compression)将AlexNet压缩了35倍，并维持Top1和Top5准确率。\n- 相比于AlexNet的模型尺寸，SqueezeNet本身就比AlexNet小50倍，并且或维持或超过了AlexNet的Top1和Top5准确率。\n- 对SqueezeNet采用深度压缩(Deep Compression)，其中用33%的稀疏性(33% sparsity)和8比特的量化(8-bit quantization)：\n - 得到了0.66MB大小的模型(比32比特表示的AlexNet小363倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。\n-  对SqueezeNet采用深度压缩，其中用33%的稀疏性和6比特的量化：\n - 得到了0.47MB大小的模型(比32比特表示的AlexNet小510倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。\n- 深度压缩(Deep Compression)将SqueezeNet压缩了10倍，且维持基准精度。\n\n# 参考文献\n\n- [论文：SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and <0.5MB Model Size](https://arxiv.org/pdf/1602.07360.pdf)\n- [博客：超轻量级网络SqueezeNet算法详解](https://blog.csdn.net/shenxiaolu1984/article/details/51444525)\n- [代码：论文中给出的源码地址](https://github.com/DeepScale/SqueezeNet)\n\n","slug":"SqueezeNet","published":1,"updated":"2018-12-31T13:58:12.513Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvc000qqslpe0gcb1qi","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出小CNN结构——SqueezeNet。</li>\n<li>在ImageNet上，SqueezeNet能够得到和AlexNet一样的精度，同时参数为其$1/50$。</li>\n<li><p>借助于模型压缩技术(model compression techniques)，可将SqueezeNet压缩到小于0.5MB(比AlexNet小510倍)。</p>\n<a id=\"more\"></a>\n</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"针对较少参数CNN结构的设计策略提纲\"><a href=\"#针对较少参数CNN结构的设计策略提纲\" class=\"headerlink\" title=\"针对较少参数CNN结构的设计策略提纲\"></a>针对较少参数CNN结构的设计策略提纲</h2><p>为了设计出含有较少参数且维持较高精度的CNN结构，主要采用如下三点策略：</p>\n<ul>\n<li>策略1:用$1\\times 1$卷积替换$3\\times 3$卷积<ul>\n<li>$1\\times 1$卷积的参数比$3\\times 3$卷积少9倍 </li>\n</ul>\n</li>\n<li>策略2:减少$3\\times 3$卷积的输入通道数<ul>\n<li>对于$3\\times 3$卷积层，总的参数量是<code>(number of input channels) * (number of filters)*(3*3)</code>。</li>\n<li>策略1是为了减少$3\\times 3$卷积的数量，策略2是为了减少$3\\times 3$卷积的输入通道数。</li>\n</ul>\n</li>\n<li>策略3:在网络中较晚地进行下采样，使得卷积层有更大尺寸的激活特征图<ul>\n<li>激活特征图的尺寸由如下两个尺寸控制：1.输入数据的尺寸；2.选择在CNN结构中的哪个层进行下采样(即什么时候进行下采样，是早点还是晚点)</li>\n<li>在CNN结构中，下采样操作通常由步长大于1的卷积层或步长大于1的池化层完成。</li>\n<li>若网络前端的层用大的步长，那么大多数层将有小的特征图；相反地，若步长大于1的层集中在网络的末端，那么网络中的许多层将拥有较大的激活特征图。</li>\n<li>在保持其他设置相等的情况下，较大的特征图(由于较晚地下采样)可以得到更高的分类精度。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Fire模块-Fire-module\"><a href=\"#Fire模块-Fire-module\" class=\"headerlink\" title=\"Fire模块(Fire module)\"></a>Fire模块(Fire module)</h2><p><img src=\"/images/SqueezeNet/1.png\" width=\"600\" height=\"100\"></p>\n<p>如Fig1所示，即为Fire模块：</p>\n<ul>\n<li>Fire模块由squeeze卷积层和expand卷积层构成：<ul>\n<li>squeeze卷积层：由$1\\times 1$卷积构成。</li>\n<li>expand卷积层：由$1\\times 1$卷积和$3\\times 3$卷积混合构成。</li>\n<li>squeeze卷积层和expand卷积层两部分，分别压缩和扩展特征的通道数。expand卷积层中，两个不同尺寸核的输出经串联后作为最终输出。</li>\n</ul>\n</li>\n<li>Fire模块有三个可调参数： <ul>\n<li>$s_1$: squeeze层中的1×1卷积的通道数 </li>\n<li>$e_1$: expand层中的1×1卷积的通道数 </li>\n<li>$e_3$: expand层中的3×3卷积的通道数</li>\n</ul>\n</li>\n<li>Fire模块中$1\\times 1$卷积的大量使用，即遵循上述策略1。</li>\n<li>文中设置$s_1 &lt;(e_1 + e_3)$，那么squeeze层即帮助限制了传给$3\\times 3$卷积的通道数，即遵循上述策略2。</li>\n<li>在SqueezeNet中，Fire模块采用的压缩比率(squeeze ratio)为0.125，意味着每一个squeeze层的输出通道数比expand层的输出通道数少8倍。</li>\n<li>输入输出尺寸相同。输入通道数不限，输出通道数为$e1+e3$。 </li>\n<li>在本文提出的SqueezeNet结构中，$e1=e3=4s1$。</li>\n</ul>\n<h2 id=\"SqueezeNet结构\"><a href=\"#SqueezeNet结构\" class=\"headerlink\" title=\"SqueezeNet结构\"></a>SqueezeNet结构</h2><p><img src=\"/images/SqueezeNet/2.png\" width=\"700\" height=\"100\"></p>\n<p>如Fig2所示，为SqueezeNet结构：</p>\n<ul>\n<li>SqueezeNet起始是一个常规卷积(conv1)，接着跟随8个Fire模块(fire2-9)，最后为一个常规卷积(conv10)。</li>\n<li>在SqueezeNet中，每隔一个Fire模块，逐步地增加卷积核的个数。</li>\n<li>在SqueezeNet中，在conv1、fire4、fire8和conv10后，采用步长为2的max-pooling。<ul>\n<li>这些相对延后放置的池化层遵循策略3。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/SqueezeNet/3.png\" width=\"700\" height=\"100\"></p>\n<ul>\n<li>如Table1所示，为SqueezeNet的详细信息。</li>\n</ul>\n<p>其他细节：</p>\n<ul>\n<li>在expand层中，对$3\\times3$卷积的输入增加了1像素边界的零填充，以使得$3\\times3$卷积与$1\\times1$卷积的输出激活函数的宽高相等。</li>\n<li>在Fire模块中，对squeeze层和expand层的激活函数均采用了ReLU。</li>\n<li>在fire9模块后，采用了比率为50%的Dropout</li>\n<li>SqueezeNet未采用全连接层，由NIN启发。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/SqueezeNet/4.png\" width=\"650\" height=\"100\"></p>\n<p>如Table2所示，比较了AlexNet和SqueezeNet，以及在各模型压缩方法下的结果：</p>\n<ul>\n<li>对于AlexNet：<ul>\n<li>基于SVD的模型压缩方法(SVD-based approach)，将AlexNet压缩了5倍，减少Top1准确率到56%。</li>\n<li>网络修剪(Network Pruning)的模型压缩方法，将AlexNet压缩了9倍，并维持Top1和Top5准确率。</li>\n<li>深度压缩(Deep Compression)将AlexNet压缩了35倍，并维持Top1和Top5准确率。</li>\n</ul>\n</li>\n<li>相比于AlexNet的模型尺寸，SqueezeNet本身就比AlexNet小50倍，并且或维持或超过了AlexNet的Top1和Top5准确率。</li>\n<li>对SqueezeNet采用深度压缩(Deep Compression)，其中用33%的稀疏性(33% sparsity)和8比特的量化(8-bit quantization)：<ul>\n<li>得到了0.66MB大小的模型(比32比特表示的AlexNet小363倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。</li>\n</ul>\n</li>\n<li>对SqueezeNet采用深度压缩，其中用33%的稀疏性和6比特的量化：<ul>\n<li>得到了0.47MB大小的模型(比32比特表示的AlexNet小510倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。</li>\n</ul>\n</li>\n<li>深度压缩(Deep Compression)将SqueezeNet压缩了10倍，且维持基准精度。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1602.07360.pdf\" target=\"_blank\" rel=\"noopener\">论文：SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and &lt;0.5MB Model Size</a></li>\n<li><a href=\"https://blog.csdn.net/shenxiaolu1984/article/details/51444525\" target=\"_blank\" rel=\"noopener\">博客：超轻量级网络SqueezeNet算法详解</a></li>\n<li><a href=\"https://github.com/DeepScale/SqueezeNet\" target=\"_blank\" rel=\"noopener\">代码：论文中给出的源码地址</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出小CNN结构——SqueezeNet。</li>\n<li>在ImageNet上，SqueezeNet能够得到和AlexNet一样的精度，同时参数为其$1/50$。</li>\n<li><p>借助于模型压缩技术(model compression techniques)，可将SqueezeNet压缩到小于0.5MB(比AlexNet小510倍)。</p>","more":"</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"针对较少参数CNN结构的设计策略提纲\"><a href=\"#针对较少参数CNN结构的设计策略提纲\" class=\"headerlink\" title=\"针对较少参数CNN结构的设计策略提纲\"></a>针对较少参数CNN结构的设计策略提纲</h2><p>为了设计出含有较少参数且维持较高精度的CNN结构，主要采用如下三点策略：</p>\n<ul>\n<li>策略1:用$1\\times 1$卷积替换$3\\times 3$卷积<ul>\n<li>$1\\times 1$卷积的参数比$3\\times 3$卷积少9倍 </li>\n</ul>\n</li>\n<li>策略2:减少$3\\times 3$卷积的输入通道数<ul>\n<li>对于$3\\times 3$卷积层，总的参数量是<code>(number of input channels) * (number of filters)*(3*3)</code>。</li>\n<li>策略1是为了减少$3\\times 3$卷积的数量，策略2是为了减少$3\\times 3$卷积的输入通道数。</li>\n</ul>\n</li>\n<li>策略3:在网络中较晚地进行下采样，使得卷积层有更大尺寸的激活特征图<ul>\n<li>激活特征图的尺寸由如下两个尺寸控制：1.输入数据的尺寸；2.选择在CNN结构中的哪个层进行下采样(即什么时候进行下采样，是早点还是晚点)</li>\n<li>在CNN结构中，下采样操作通常由步长大于1的卷积层或步长大于1的池化层完成。</li>\n<li>若网络前端的层用大的步长，那么大多数层将有小的特征图；相反地，若步长大于1的层集中在网络的末端，那么网络中的许多层将拥有较大的激活特征图。</li>\n<li>在保持其他设置相等的情况下，较大的特征图(由于较晚地下采样)可以得到更高的分类精度。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Fire模块-Fire-module\"><a href=\"#Fire模块-Fire-module\" class=\"headerlink\" title=\"Fire模块(Fire module)\"></a>Fire模块(Fire module)</h2><p><img src=\"/images/SqueezeNet/1.png\" width=\"600\" height=\"100\"></p>\n<p>如Fig1所示，即为Fire模块：</p>\n<ul>\n<li>Fire模块由squeeze卷积层和expand卷积层构成：<ul>\n<li>squeeze卷积层：由$1\\times 1$卷积构成。</li>\n<li>expand卷积层：由$1\\times 1$卷积和$3\\times 3$卷积混合构成。</li>\n<li>squeeze卷积层和expand卷积层两部分，分别压缩和扩展特征的通道数。expand卷积层中，两个不同尺寸核的输出经串联后作为最终输出。</li>\n</ul>\n</li>\n<li>Fire模块有三个可调参数： <ul>\n<li>$s_1$: squeeze层中的1×1卷积的通道数 </li>\n<li>$e_1$: expand层中的1×1卷积的通道数 </li>\n<li>$e_3$: expand层中的3×3卷积的通道数</li>\n</ul>\n</li>\n<li>Fire模块中$1\\times 1$卷积的大量使用，即遵循上述策略1。</li>\n<li>文中设置$s_1 &lt;(e_1 + e_3)$，那么squeeze层即帮助限制了传给$3\\times 3$卷积的通道数，即遵循上述策略2。</li>\n<li>在SqueezeNet中，Fire模块采用的压缩比率(squeeze ratio)为0.125，意味着每一个squeeze层的输出通道数比expand层的输出通道数少8倍。</li>\n<li>输入输出尺寸相同。输入通道数不限，输出通道数为$e1+e3$。 </li>\n<li>在本文提出的SqueezeNet结构中，$e1=e3=4s1$。</li>\n</ul>\n<h2 id=\"SqueezeNet结构\"><a href=\"#SqueezeNet结构\" class=\"headerlink\" title=\"SqueezeNet结构\"></a>SqueezeNet结构</h2><p><img src=\"/images/SqueezeNet/2.png\" width=\"700\" height=\"100\"></p>\n<p>如Fig2所示，为SqueezeNet结构：</p>\n<ul>\n<li>SqueezeNet起始是一个常规卷积(conv1)，接着跟随8个Fire模块(fire2-9)，最后为一个常规卷积(conv10)。</li>\n<li>在SqueezeNet中，每隔一个Fire模块，逐步地增加卷积核的个数。</li>\n<li>在SqueezeNet中，在conv1、fire4、fire8和conv10后，采用步长为2的max-pooling。<ul>\n<li>这些相对延后放置的池化层遵循策略3。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/SqueezeNet/3.png\" width=\"700\" height=\"100\"></p>\n<ul>\n<li>如Table1所示，为SqueezeNet的详细信息。</li>\n</ul>\n<p>其他细节：</p>\n<ul>\n<li>在expand层中，对$3\\times3$卷积的输入增加了1像素边界的零填充，以使得$3\\times3$卷积与$1\\times1$卷积的输出激活函数的宽高相等。</li>\n<li>在Fire模块中，对squeeze层和expand层的激活函数均采用了ReLU。</li>\n<li>在fire9模块后，采用了比率为50%的Dropout</li>\n<li>SqueezeNet未采用全连接层，由NIN启发。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/SqueezeNet/4.png\" width=\"650\" height=\"100\"></p>\n<p>如Table2所示，比较了AlexNet和SqueezeNet，以及在各模型压缩方法下的结果：</p>\n<ul>\n<li>对于AlexNet：<ul>\n<li>基于SVD的模型压缩方法(SVD-based approach)，将AlexNet压缩了5倍，减少Top1准确率到56%。</li>\n<li>网络修剪(Network Pruning)的模型压缩方法，将AlexNet压缩了9倍，并维持Top1和Top5准确率。</li>\n<li>深度压缩(Deep Compression)将AlexNet压缩了35倍，并维持Top1和Top5准确率。</li>\n</ul>\n</li>\n<li>相比于AlexNet的模型尺寸，SqueezeNet本身就比AlexNet小50倍，并且或维持或超过了AlexNet的Top1和Top5准确率。</li>\n<li>对SqueezeNet采用深度压缩(Deep Compression)，其中用33%的稀疏性(33% sparsity)和8比特的量化(8-bit quantization)：<ul>\n<li>得到了0.66MB大小的模型(比32比特表示的AlexNet小363倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。</li>\n</ul>\n</li>\n<li>对SqueezeNet采用深度压缩，其中用33%的稀疏性和6比特的量化：<ul>\n<li>得到了0.47MB大小的模型(比32比特表示的AlexNet小510倍)，且相比于基准SqueezeNet没有精度损失，且与AlexNet精度相当。</li>\n</ul>\n</li>\n<li>深度压缩(Deep Compression)将SqueezeNet压缩了10倍，且维持基准精度。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1602.07360.pdf\" target=\"_blank\" rel=\"noopener\">论文：SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters and &lt;0.5MB Model Size</a></li>\n<li><a href=\"https://blog.csdn.net/shenxiaolu1984/article/details/51444525\" target=\"_blank\" rel=\"noopener\">博客：超轻量级网络SqueezeNet算法详解</a></li>\n<li><a href=\"https://github.com/DeepScale/SqueezeNet\" target=\"_blank\" rel=\"noopener\">代码：论文中给出的源码地址</a></li>\n</ul>"},{"title":"UNet","mathjax":true,"date":"2019-01-08T14:26:50.000Z","_content":"\n## 摘要\n\n- 提出UNet，包含收缩路径(contracting path)和扩张路径(expanding path):\n - 收缩路径来捕捉语义信息；\n - 对称的扩张路径能够得到更精确的定位。\n- 提出了基于数据增广(data augmentation)的训练策略，更有效地利用起现有的标注样本。\n\n<!-- more -->\n\n## 创新点\n\n### U-Net结构\n\n<img src=\"/images/UNet/1.png\"  width = \"700\" height = \"200\"/>\n\n如Fig1所示，为U-Net的总体结构示意图：\n\n- 左侧为收缩路径(contracting path)，右侧为扩张路径(expanding path)\n- 收缩路径为典型的CNN结构：\n - 包含对两个堆叠$3\\times3$卷积(不填充)的重复使用；\n - 每一次重复都跟随ReLU和步长为2的$2\\times2$的最大池化操作；\n - 每一次下采样，都加倍特征的通道数。\n- 对于扩张路径：\n - 扩张路径中的每一阶层都包含上采样特征图的操作，由$2\\times2$的转置卷积实现，同时减半特征通道数；\n - 然后和对应的收缩路径中的剪裁过的特征图进行串联(concatenate)；剪裁是必要的，因为在每一次卷积中，边缘像素会丢失（注意该句话）；\n - 然后跟随两个$3\\times3$卷积，跟随ReLU。\n- 最后为$1\\times1$卷积层，用来将64通道数的特征映射到想要的分类数目维度。\n- U-Net总计有23个卷积层。\n\n注：\n\n - 疑问1：这里的上采样操作，是反卷积不？看源码解决疑问\n - 答：这里的上采样操作，是转置卷积/反卷积，是有参数的；不是简单的双线性插值操作。\n\n### 数据增广(Data Augmentation)\n\n当只有较少的训练样本时，数据增广至关重要，可以教导网络学习到我们想要的不变性和鲁棒特征：\n\n- 对训练数据施加弹性变形(elastic deformations):\n - 原因：这对于生物医学图片尤其重要，因为变形是组织结构中最常见的变化，并且这些变形可以被有效的仿真。\n - 效果：该数据增强操作可使得网络学习到对于这些变形的不变性，而不需要在标注数据集中看到这些变换。\n\n<img src=\"/images/UNet/2.png\"  width = \"500\" height = \"100\"/>\n \n- 施加带有权重的损失函数：$E =\\sum_{x\\in \\Omega} w(x)log(p_{l(x)}(x))$ \n - 如Fig3所示，对于细胞分割任务，许多相互接触的同类细胞个体需要被分离\n - 预先定义每一个GT的权重图，来强迫网络去学习接触细胞之间的小的分离边界\n - 对于互相接触的细胞的待分离背景，在损失函数中，会得到较大的权重\n \n## 模型比较\n\n<img src=\"/images/UNet/3.png\"  width = \"700\" height = \"100\"/>\n\n## 参考文献\n\n- [论文：U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)\n- [视频：U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n- [代码及注释：dhkim0225/keras-image-segmentation](https://github.com/liminn/keras-image-segmentation/blob/master/model/unet.py)\n\n","source":"_posts/UNet.md","raw":"---\ntitle: UNet\nmathjax: true\ndate: 2019-01-08 22:26:50\ncategories: \n- 语义分割\ntags:\n---\n\n## 摘要\n\n- 提出UNet，包含收缩路径(contracting path)和扩张路径(expanding path):\n - 收缩路径来捕捉语义信息；\n - 对称的扩张路径能够得到更精确的定位。\n- 提出了基于数据增广(data augmentation)的训练策略，更有效地利用起现有的标注样本。\n\n<!-- more -->\n\n## 创新点\n\n### U-Net结构\n\n<img src=\"/images/UNet/1.png\"  width = \"700\" height = \"200\"/>\n\n如Fig1所示，为U-Net的总体结构示意图：\n\n- 左侧为收缩路径(contracting path)，右侧为扩张路径(expanding path)\n- 收缩路径为典型的CNN结构：\n - 包含对两个堆叠$3\\times3$卷积(不填充)的重复使用；\n - 每一次重复都跟随ReLU和步长为2的$2\\times2$的最大池化操作；\n - 每一次下采样，都加倍特征的通道数。\n- 对于扩张路径：\n - 扩张路径中的每一阶层都包含上采样特征图的操作，由$2\\times2$的转置卷积实现，同时减半特征通道数；\n - 然后和对应的收缩路径中的剪裁过的特征图进行串联(concatenate)；剪裁是必要的，因为在每一次卷积中，边缘像素会丢失（注意该句话）；\n - 然后跟随两个$3\\times3$卷积，跟随ReLU。\n- 最后为$1\\times1$卷积层，用来将64通道数的特征映射到想要的分类数目维度。\n- U-Net总计有23个卷积层。\n\n注：\n\n - 疑问1：这里的上采样操作，是反卷积不？看源码解决疑问\n - 答：这里的上采样操作，是转置卷积/反卷积，是有参数的；不是简单的双线性插值操作。\n\n### 数据增广(Data Augmentation)\n\n当只有较少的训练样本时，数据增广至关重要，可以教导网络学习到我们想要的不变性和鲁棒特征：\n\n- 对训练数据施加弹性变形(elastic deformations):\n - 原因：这对于生物医学图片尤其重要，因为变形是组织结构中最常见的变化，并且这些变形可以被有效的仿真。\n - 效果：该数据增强操作可使得网络学习到对于这些变形的不变性，而不需要在标注数据集中看到这些变换。\n\n<img src=\"/images/UNet/2.png\"  width = \"500\" height = \"100\"/>\n \n- 施加带有权重的损失函数：$E =\\sum_{x\\in \\Omega} w(x)log(p_{l(x)}(x))$ \n - 如Fig3所示，对于细胞分割任务，许多相互接触的同类细胞个体需要被分离\n - 预先定义每一个GT的权重图，来强迫网络去学习接触细胞之间的小的分离边界\n - 对于互相接触的细胞的待分离背景，在损失函数中，会得到较大的权重\n \n## 模型比较\n\n<img src=\"/images/UNet/3.png\"  width = \"700\" height = \"100\"/>\n\n## 参考文献\n\n- [论文：U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)\n- [视频：U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n- [代码及注释：dhkim0225/keras-image-segmentation](https://github.com/liminn/keras-image-segmentation/blob/master/model/unet.py)\n\n","slug":"UNet","published":1,"updated":"2019-01-08T09:51:11.511Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvd000uqslpw54jq3ll","content":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><ul>\n<li>提出UNet，包含收缩路径(contracting path)和扩张路径(expanding path):<ul>\n<li>收缩路径来捕捉语义信息；</li>\n<li>对称的扩张路径能够得到更精确的定位。</li>\n</ul>\n</li>\n<li>提出了基于数据增广(data augmentation)的训练策略，更有效地利用起现有的标注样本。</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h2><h3 id=\"U-Net结构\"><a href=\"#U-Net结构\" class=\"headerlink\" title=\"U-Net结构\"></a>U-Net结构</h3><p><img src=\"/images/UNet/1.png\" width=\"700\" height=\"200\"></p>\n<p>如Fig1所示，为U-Net的总体结构示意图：</p>\n<ul>\n<li>左侧为收缩路径(contracting path)，右侧为扩张路径(expanding path)</li>\n<li>收缩路径为典型的CNN结构：<ul>\n<li>包含对两个堆叠$3\\times3$卷积(不填充)的重复使用；</li>\n<li>每一次重复都跟随ReLU和步长为2的$2\\times2$的最大池化操作；</li>\n<li>每一次下采样，都加倍特征的通道数。</li>\n</ul>\n</li>\n<li>对于扩张路径：<ul>\n<li>扩张路径中的每一阶层都包含上采样特征图的操作，由$2\\times2$的转置卷积实现，同时减半特征通道数；</li>\n<li>然后和对应的收缩路径中的剪裁过的特征图进行串联(concatenate)；剪裁是必要的，因为在每一次卷积中，边缘像素会丢失（注意该句话）；</li>\n<li>然后跟随两个$3\\times3$卷积，跟随ReLU。</li>\n</ul>\n</li>\n<li>最后为$1\\times1$卷积层，用来将64通道数的特征映射到想要的分类数目维度。</li>\n<li>U-Net总计有23个卷积层。</li>\n</ul>\n<p>注：</p>\n<ul>\n<li>疑问1：这里的上采样操作，是反卷积不？看源码解决疑问</li>\n<li>答：这里的上采样操作，是转置卷积/反卷积，是有参数的；不是简单的双线性插值操作。</li>\n</ul>\n<h3 id=\"数据增广-Data-Augmentation\"><a href=\"#数据增广-Data-Augmentation\" class=\"headerlink\" title=\"数据增广(Data Augmentation)\"></a>数据增广(Data Augmentation)</h3><p>当只有较少的训练样本时，数据增广至关重要，可以教导网络学习到我们想要的不变性和鲁棒特征：</p>\n<ul>\n<li>对训练数据施加弹性变形(elastic deformations):<ul>\n<li>原因：这对于生物医学图片尤其重要，因为变形是组织结构中最常见的变化，并且这些变形可以被有效的仿真。</li>\n<li>效果：该数据增强操作可使得网络学习到对于这些变形的不变性，而不需要在标注数据集中看到这些变换。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/UNet/2.png\" width=\"500\" height=\"100\"></p>\n<ul>\n<li>施加带有权重的损失函数：$E =\\sum_{x\\in \\Omega} w(x)log(p_{l(x)}(x))$ <ul>\n<li>如Fig3所示，对于细胞分割任务，许多相互接触的同类细胞个体需要被分离</li>\n<li>预先定义每一个GT的权重图，来强迫网络去学习接触细胞之间的小的分离边界</li>\n<li>对于互相接触的细胞的待分离背景，在损失函数中，会得到较大的权重</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h2><p><img src=\"/images/UNet/3.png\" width=\"700\" height=\"100\"></p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><a href=\"https://arxiv.org/pdf/1505.04597.pdf\" target=\"_blank\" rel=\"noopener\">论文：U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li>\n<li><a href=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\" target=\"_blank\" rel=\"noopener\">视频：U-Net</a></li>\n<li><a href=\"https://github.com/liminn/keras-image-segmentation/blob/master/model/unet.py\" target=\"_blank\" rel=\"noopener\">代码及注释：dhkim0225/keras-image-segmentation</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h2><ul>\n<li>提出UNet，包含收缩路径(contracting path)和扩张路径(expanding path):<ul>\n<li>收缩路径来捕捉语义信息；</li>\n<li>对称的扩张路径能够得到更精确的定位。</li>\n</ul>\n</li>\n<li>提出了基于数据增广(data augmentation)的训练策略，更有效地利用起现有的标注样本。</li>\n</ul>","more":"<h2 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h2><h3 id=\"U-Net结构\"><a href=\"#U-Net结构\" class=\"headerlink\" title=\"U-Net结构\"></a>U-Net结构</h3><p><img src=\"/images/UNet/1.png\" width=\"700\" height=\"200\"></p>\n<p>如Fig1所示，为U-Net的总体结构示意图：</p>\n<ul>\n<li>左侧为收缩路径(contracting path)，右侧为扩张路径(expanding path)</li>\n<li>收缩路径为典型的CNN结构：<ul>\n<li>包含对两个堆叠$3\\times3$卷积(不填充)的重复使用；</li>\n<li>每一次重复都跟随ReLU和步长为2的$2\\times2$的最大池化操作；</li>\n<li>每一次下采样，都加倍特征的通道数。</li>\n</ul>\n</li>\n<li>对于扩张路径：<ul>\n<li>扩张路径中的每一阶层都包含上采样特征图的操作，由$2\\times2$的转置卷积实现，同时减半特征通道数；</li>\n<li>然后和对应的收缩路径中的剪裁过的特征图进行串联(concatenate)；剪裁是必要的，因为在每一次卷积中，边缘像素会丢失（注意该句话）；</li>\n<li>然后跟随两个$3\\times3$卷积，跟随ReLU。</li>\n</ul>\n</li>\n<li>最后为$1\\times1$卷积层，用来将64通道数的特征映射到想要的分类数目维度。</li>\n<li>U-Net总计有23个卷积层。</li>\n</ul>\n<p>注：</p>\n<ul>\n<li>疑问1：这里的上采样操作，是反卷积不？看源码解决疑问</li>\n<li>答：这里的上采样操作，是转置卷积/反卷积，是有参数的；不是简单的双线性插值操作。</li>\n</ul>\n<h3 id=\"数据增广-Data-Augmentation\"><a href=\"#数据增广-Data-Augmentation\" class=\"headerlink\" title=\"数据增广(Data Augmentation)\"></a>数据增广(Data Augmentation)</h3><p>当只有较少的训练样本时，数据增广至关重要，可以教导网络学习到我们想要的不变性和鲁棒特征：</p>\n<ul>\n<li>对训练数据施加弹性变形(elastic deformations):<ul>\n<li>原因：这对于生物医学图片尤其重要，因为变形是组织结构中最常见的变化，并且这些变形可以被有效的仿真。</li>\n<li>效果：该数据增强操作可使得网络学习到对于这些变形的不变性，而不需要在标注数据集中看到这些变换。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/UNet/2.png\" width=\"500\" height=\"100\"></p>\n<ul>\n<li>施加带有权重的损失函数：$E =\\sum_{x\\in \\Omega} w(x)log(p_{l(x)}(x))$ <ul>\n<li>如Fig3所示，对于细胞分割任务，许多相互接触的同类细胞个体需要被分离</li>\n<li>预先定义每一个GT的权重图，来强迫网络去学习接触细胞之间的小的分离边界</li>\n<li>对于互相接触的细胞的待分离背景，在损失函数中，会得到较大的权重</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h2><p><img src=\"/images/UNet/3.png\" width=\"700\" height=\"100\"></p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><ul>\n<li><a href=\"https://arxiv.org/pdf/1505.04597.pdf\" target=\"_blank\" rel=\"noopener\">论文：U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li>\n<li><a href=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\" target=\"_blank\" rel=\"noopener\">视频：U-Net</a></li>\n<li><a href=\"https://github.com/liminn/keras-image-segmentation/blob/master/model/unet.py\" target=\"_blank\" rel=\"noopener\">代码及注释：dhkim0225/keras-image-segmentation</a></li>\n</ul>"},{"title":"XGBoost模型","mathjax":true,"date":"2017-12-14T14:20:50.000Z","_content":"待\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/XGBoost模型.md","raw":"---\ntitle: XGBoost模型\nmathjax: true\ndate: 2017-12-14 22:20:50\ncategories: \n- 机器学习\ntags:\n---\n待\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"XGBoost模型","published":1,"updated":"2017-12-13T03:18:12.747Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvf000wqslpbb8m37ea","content":"<p>待</p>\n","site":{"data":{}},"excerpt":"","more":"<p>待</p>\n"},{"title":"Xception","mathjax":true,"date":"2018-12-29T14:20:51.000Z","_content":"\n# 摘要\n\n- 首先，提出对Inception模块的一种解释：Inception模块是介于常规卷积(regular convolution)和深度可分离卷积(depthwise separable convolution)的中间步骤。\n- 然后，引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积(depthwise convolution)和逐点卷积(pointwise convolution)两部进行，有效地减少了计算量和参数量。\n- 然后，提出用深度可分离卷积来替代Inception模块的想法。\n- 最后，基于上述想法，提出Xception，意为\"Extreme Inception\"。\n- 在ImageNet数据集上，Xception的表现比Inception V3稍好；在更大的JFT数据集上，Xception的表现比Inception V3的优势扩大。\n- 注：Xception和Inception V3有这几乎相同的参数，因此，模型表现的提升不是因为参数增加，而是对于模型参数的更有效利用。\n- 本质：Xception是采用depthwise separable convolution来改进InceptionV3。\n\n <!-- more -->\n\n# 创新点\n\n## 对于Inception模块的假设\n<img src=\"/images/Xception/1.png\"  width = \"400\" height = \"100\"/>\n\n- 独立地看待跨通道相关性(cross-channel correlations)和空间相关性(spatial correlations)，如Fig1所示:\n - Inception模块的$1\\times 1$卷积即是关于跨通道相关性\n - Inception模块的$3\\times 3$或$5\\times 5$卷积即是关于跨通道相关性和空间相关性 \n - 提出假设：**在Inception模块中，跨通道相关性和空间相关性被充分地解耦(decoupled)了，跨通道相关性和空间相关性更适合不被共同映射**。\n - 因此，进一步提出一个比Inception模块假设**更强的假设**：**让跨通道相关性和空间相关性的映射完全分离**。\n\n## Inception模块的终极版本\n<img src=\"/images/Xception/2.png\"  width = \"400\" height = \"100\"/>\n\n- 基于**上述的更强假设**，设计出Inception模块的终极版本，如Fig4所示：\n - 首先，用$1\\times 1$卷积对跨通道相关性进行映射；\n - 然后，分别单独对每一个通道的空间相关性进行映射。\n- 注意到，这个Inception的终极形式，和深度可分离卷积的含义几乎相等，只有两点微小区别：\n - 1.操作的顺序：深度可分离卷积通常先进行逐通道的空间卷积，然后进行$1\\times 1$卷积。而Inception模块是先进行$1\\times 1$卷积。\n - 注：文中认为这第一个不同点不重要，尤其是这些操作会以堆叠的方式被使用。\n - 2.存不存在非线形激活函数：在Inception模块中，两个操作之后都会接一个ReLU非线性激活函数；然而，执行深度可分离卷积时，通常不用非线性激活函数。\n - 注：第二个不同点可能有影响，后续进行了实验验证（见下一小节，**文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现**）。\n- 因此，产生新的想法：**可以用深度可分离卷积来替换Inception模块，以此来改善Inception家族的表现**。\n\n## Xception结构\n<img src=\"/images/Xception/3.png\"  width = \"700\" >\n\nXception如Fig5所示：\n\n- Xception即代表\"Extreme Inception\"。\n- Xception结构含有36个卷积层构成，由14个模块构成，除了第一个和最后一个模块，所有模块均包含线性残差连接。\n- **对于深度可分离卷积**（先进行depthwise卷积，再进行pointwise卷积，中间没有非线性激活函数）：\n - **文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现。**\n - 对此，文中猜测：depthwise卷积的所施加在的中间特征空间的深度对于非线性激活函数的有效性至关重要：对于很深的特征空间(如Inception模块中的)，非线性激活函数很有帮助；但对于较浅的特征空间(如深度可分离卷积中的1通道深的特征空间)，非线性激活函数变得有害，可能是由于信息丢失导致。\n- **对于残差连接**：\n - 文中实验验证，残差连接在帮助Xception方面至关重要，不仅提升了拟合速度，而且提升了最终的表现。\n- 简而言之，Xception结构是带有残差连接的深度可分离卷积的线性堆叠。\n- 在Keras或TensorFlow-Slim上，只需要30至40行代码，即可完成Xception架构。\n- 基于Keras和TensorFlow的Xception开源实现，已经被提供为Keras应用模块的一部分，见[链接](https://keras.io/applications/#xception)。\n \n# 训练策略\n选择比较Xception和Inception V3，因为它们的尺寸相似，两者有几乎相同的参数。\n对两个分类任务进行比较，ImageNet和JFT。\n\n## 数据集\n- 1.1000类别的单标签的ImageNet数据集\n- 2.17000类别的多标签的JFT数据集\n -  谷歌内部数据集，由17000类别的超过350百万张高分辨率带标签图像构成\n\n## 最优化配置\n对于ImageNet和JFT采用不同的优化配置：\n\n- 对于ImageNet：\n - 优化器: SGD\n - 动量: 0.9\n - 初始学习率: 0.045\n - 学习率衰减: decay of rate 0.94 every 2 epochs\n- 对于JFT：\n - 优化器: RMSprop\n - 动量: 0.9\n - 初始学习率: 0.001\n - 学习率衰减: decay of rate 0.9 every 3,000,000 samples\n- 对Xception和Inception V3都采用如上的相同优化配置，如上的优化配置是为Inception V3调整出最佳表现的，没有尝试为Xception调整最优超参数。\n\n## 正则化配置\n\n- 权重衰减\n - Inception V3模型采用L2正则化系数为$4e^{-5}$(该参数是Inception V3针对ImageNet表现进行调整)\n - 经实验，上述系数对于Xception不适用，Xception调整为$1e^{-5}$\n- Dropout\n - 对于ImageNet，两个模型均在逻辑回归层之前，加上0.5的dropout层\n - 对于JFT，由于该数据集较大，模型在合理时间内不可能出现过拟合现象\n- 辅助loss\n - Inception V3中，会在网络前端施加辅助分类器，来反向传播分类器loss，做为另外的正则化机制。但为了简洁性，两模型均不采用辅助loss \n\n# 模型比较\n<img src=\"/images/Xception/4.png\"  width = \"400\" height = \"100\"/>\n\n- 如上图所示，在ImageNet上，Xception比Inception V3稍好，也比ResNet-152更好。\n\n<img src=\"/images/Xception/5.png\"  width = \"400\" height = \"100\"/>\n\n- 如上图所示，在JFT上，Xception相比于Inception V3的优势，比在ImageNet上更大了：\n - 文中猜测，这是由于Inception V3是专注于ImageNet而设计的，因此，对该特定任务有一些过拟合。\n - 另一方面，两个模型都没有在JFT上调整过，因此，对于Xception，在ImageNet上可能会有更好的超参数(尤其是最优化参数和正则化参数)，进一步让网络表现明显提升。\n\n# 参考文献\n- [论文：Xception: Deep Learning with Depthwise Separable Convolutions, 2017](https://arxiv.org/pdf/1610.02357.pdf)\n\n\n\n\n\n\n\n","source":"_posts/Xception.md","raw":"---\ntitle: Xception\nmathjax: true\ndate: 2018-12-29 22:20:51\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 摘要\n\n- 首先，提出对Inception模块的一种解释：Inception模块是介于常规卷积(regular convolution)和深度可分离卷积(depthwise separable convolution)的中间步骤。\n- 然后，引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积(depthwise convolution)和逐点卷积(pointwise convolution)两部进行，有效地减少了计算量和参数量。\n- 然后，提出用深度可分离卷积来替代Inception模块的想法。\n- 最后，基于上述想法，提出Xception，意为\"Extreme Inception\"。\n- 在ImageNet数据集上，Xception的表现比Inception V3稍好；在更大的JFT数据集上，Xception的表现比Inception V3的优势扩大。\n- 注：Xception和Inception V3有这几乎相同的参数，因此，模型表现的提升不是因为参数增加，而是对于模型参数的更有效利用。\n- 本质：Xception是采用depthwise separable convolution来改进InceptionV3。\n\n <!-- more -->\n\n# 创新点\n\n## 对于Inception模块的假设\n<img src=\"/images/Xception/1.png\"  width = \"400\" height = \"100\"/>\n\n- 独立地看待跨通道相关性(cross-channel correlations)和空间相关性(spatial correlations)，如Fig1所示:\n - Inception模块的$1\\times 1$卷积即是关于跨通道相关性\n - Inception模块的$3\\times 3$或$5\\times 5$卷积即是关于跨通道相关性和空间相关性 \n - 提出假设：**在Inception模块中，跨通道相关性和空间相关性被充分地解耦(decoupled)了，跨通道相关性和空间相关性更适合不被共同映射**。\n - 因此，进一步提出一个比Inception模块假设**更强的假设**：**让跨通道相关性和空间相关性的映射完全分离**。\n\n## Inception模块的终极版本\n<img src=\"/images/Xception/2.png\"  width = \"400\" height = \"100\"/>\n\n- 基于**上述的更强假设**，设计出Inception模块的终极版本，如Fig4所示：\n - 首先，用$1\\times 1$卷积对跨通道相关性进行映射；\n - 然后，分别单独对每一个通道的空间相关性进行映射。\n- 注意到，这个Inception的终极形式，和深度可分离卷积的含义几乎相等，只有两点微小区别：\n - 1.操作的顺序：深度可分离卷积通常先进行逐通道的空间卷积，然后进行$1\\times 1$卷积。而Inception模块是先进行$1\\times 1$卷积。\n - 注：文中认为这第一个不同点不重要，尤其是这些操作会以堆叠的方式被使用。\n - 2.存不存在非线形激活函数：在Inception模块中，两个操作之后都会接一个ReLU非线性激活函数；然而，执行深度可分离卷积时，通常不用非线性激活函数。\n - 注：第二个不同点可能有影响，后续进行了实验验证（见下一小节，**文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现**）。\n- 因此，产生新的想法：**可以用深度可分离卷积来替换Inception模块，以此来改善Inception家族的表现**。\n\n## Xception结构\n<img src=\"/images/Xception/3.png\"  width = \"700\" >\n\nXception如Fig5所示：\n\n- Xception即代表\"Extreme Inception\"。\n- Xception结构含有36个卷积层构成，由14个模块构成，除了第一个和最后一个模块，所有模块均包含线性残差连接。\n- **对于深度可分离卷积**（先进行depthwise卷积，再进行pointwise卷积，中间没有非线性激活函数）：\n - **文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现。**\n - 对此，文中猜测：depthwise卷积的所施加在的中间特征空间的深度对于非线性激活函数的有效性至关重要：对于很深的特征空间(如Inception模块中的)，非线性激活函数很有帮助；但对于较浅的特征空间(如深度可分离卷积中的1通道深的特征空间)，非线性激活函数变得有害，可能是由于信息丢失导致。\n- **对于残差连接**：\n - 文中实验验证，残差连接在帮助Xception方面至关重要，不仅提升了拟合速度，而且提升了最终的表现。\n- 简而言之，Xception结构是带有残差连接的深度可分离卷积的线性堆叠。\n- 在Keras或TensorFlow-Slim上，只需要30至40行代码，即可完成Xception架构。\n- 基于Keras和TensorFlow的Xception开源实现，已经被提供为Keras应用模块的一部分，见[链接](https://keras.io/applications/#xception)。\n \n# 训练策略\n选择比较Xception和Inception V3，因为它们的尺寸相似，两者有几乎相同的参数。\n对两个分类任务进行比较，ImageNet和JFT。\n\n## 数据集\n- 1.1000类别的单标签的ImageNet数据集\n- 2.17000类别的多标签的JFT数据集\n -  谷歌内部数据集，由17000类别的超过350百万张高分辨率带标签图像构成\n\n## 最优化配置\n对于ImageNet和JFT采用不同的优化配置：\n\n- 对于ImageNet：\n - 优化器: SGD\n - 动量: 0.9\n - 初始学习率: 0.045\n - 学习率衰减: decay of rate 0.94 every 2 epochs\n- 对于JFT：\n - 优化器: RMSprop\n - 动量: 0.9\n - 初始学习率: 0.001\n - 学习率衰减: decay of rate 0.9 every 3,000,000 samples\n- 对Xception和Inception V3都采用如上的相同优化配置，如上的优化配置是为Inception V3调整出最佳表现的，没有尝试为Xception调整最优超参数。\n\n## 正则化配置\n\n- 权重衰减\n - Inception V3模型采用L2正则化系数为$4e^{-5}$(该参数是Inception V3针对ImageNet表现进行调整)\n - 经实验，上述系数对于Xception不适用，Xception调整为$1e^{-5}$\n- Dropout\n - 对于ImageNet，两个模型均在逻辑回归层之前，加上0.5的dropout层\n - 对于JFT，由于该数据集较大，模型在合理时间内不可能出现过拟合现象\n- 辅助loss\n - Inception V3中，会在网络前端施加辅助分类器，来反向传播分类器loss，做为另外的正则化机制。但为了简洁性，两模型均不采用辅助loss \n\n# 模型比较\n<img src=\"/images/Xception/4.png\"  width = \"400\" height = \"100\"/>\n\n- 如上图所示，在ImageNet上，Xception比Inception V3稍好，也比ResNet-152更好。\n\n<img src=\"/images/Xception/5.png\"  width = \"400\" height = \"100\"/>\n\n- 如上图所示，在JFT上，Xception相比于Inception V3的优势，比在ImageNet上更大了：\n - 文中猜测，这是由于Inception V3是专注于ImageNet而设计的，因此，对该特定任务有一些过拟合。\n - 另一方面，两个模型都没有在JFT上调整过，因此，对于Xception，在ImageNet上可能会有更好的超参数(尤其是最优化参数和正则化参数)，进一步让网络表现明显提升。\n\n# 参考文献\n- [论文：Xception: Deep Learning with Depthwise Separable Convolutions, 2017](https://arxiv.org/pdf/1610.02357.pdf)\n\n\n\n\n\n\n\n","slug":"Xception","published":1,"updated":"2018-12-29T10:29:01.462Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvg000zqslpbm1miy2s","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>首先，提出对Inception模块的一种解释：Inception模块是介于常规卷积(regular convolution)和深度可分离卷积(depthwise separable convolution)的中间步骤。</li>\n<li>然后，引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积(depthwise convolution)和逐点卷积(pointwise convolution)两部进行，有效地减少了计算量和参数量。</li>\n<li>然后，提出用深度可分离卷积来替代Inception模块的想法。</li>\n<li>最后，基于上述想法，提出Xception，意为”Extreme Inception”。</li>\n<li>在ImageNet数据集上，Xception的表现比Inception V3稍好；在更大的JFT数据集上，Xception的表现比Inception V3的优势扩大。</li>\n<li>注：Xception和Inception V3有这几乎相同的参数，因此，模型表现的提升不是因为参数增加，而是对于模型参数的更有效利用。</li>\n<li><p>本质：Xception是采用depthwise separable convolution来改进InceptionV3。</p>\n<a id=\"more\"></a>\n</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"对于Inception模块的假设\"><a href=\"#对于Inception模块的假设\" class=\"headerlink\" title=\"对于Inception模块的假设\"></a>对于Inception模块的假设</h2><p><img src=\"/images/Xception/1.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>独立地看待跨通道相关性(cross-channel correlations)和空间相关性(spatial correlations)，如Fig1所示:<ul>\n<li>Inception模块的$1\\times 1$卷积即是关于跨通道相关性</li>\n<li>Inception模块的$3\\times 3$或$5\\times 5$卷积即是关于跨通道相关性和空间相关性 </li>\n<li>提出假设：<strong>在Inception模块中，跨通道相关性和空间相关性被充分地解耦(decoupled)了，跨通道相关性和空间相关性更适合不被共同映射</strong>。</li>\n<li>因此，进一步提出一个比Inception模块假设<strong>更强的假设</strong>：<strong>让跨通道相关性和空间相关性的映射完全分离</strong>。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Inception模块的终极版本\"><a href=\"#Inception模块的终极版本\" class=\"headerlink\" title=\"Inception模块的终极版本\"></a>Inception模块的终极版本</h2><p><img src=\"/images/Xception/2.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>基于<strong>上述的更强假设</strong>，设计出Inception模块的终极版本，如Fig4所示：<ul>\n<li>首先，用$1\\times 1$卷积对跨通道相关性进行映射；</li>\n<li>然后，分别单独对每一个通道的空间相关性进行映射。</li>\n</ul>\n</li>\n<li>注意到，这个Inception的终极形式，和深度可分离卷积的含义几乎相等，只有两点微小区别：<ul>\n<li>1.操作的顺序：深度可分离卷积通常先进行逐通道的空间卷积，然后进行$1\\times 1$卷积。而Inception模块是先进行$1\\times 1$卷积。</li>\n<li>注：文中认为这第一个不同点不重要，尤其是这些操作会以堆叠的方式被使用。</li>\n<li>2.存不存在非线形激活函数：在Inception模块中，两个操作之后都会接一个ReLU非线性激活函数；然而，执行深度可分离卷积时，通常不用非线性激活函数。</li>\n<li>注：第二个不同点可能有影响，后续进行了实验验证（见下一小节，<strong>文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现</strong>）。</li>\n</ul>\n</li>\n<li>因此，产生新的想法：<strong>可以用深度可分离卷积来替换Inception模块，以此来改善Inception家族的表现</strong>。</li>\n</ul>\n<h2 id=\"Xception结构\"><a href=\"#Xception结构\" class=\"headerlink\" title=\"Xception结构\"></a>Xception结构</h2><p><img src=\"/images/Xception/3.png\" width=\"700\"></p>\n<p>Xception如Fig5所示：</p>\n<ul>\n<li>Xception即代表”Extreme Inception”。</li>\n<li>Xception结构含有36个卷积层构成，由14个模块构成，除了第一个和最后一个模块，所有模块均包含线性残差连接。</li>\n<li><strong>对于深度可分离卷积</strong>（先进行depthwise卷积，再进行pointwise卷积，中间没有非线性激活函数）：<ul>\n<li><strong>文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现。</strong></li>\n<li>对此，文中猜测：depthwise卷积的所施加在的中间特征空间的深度对于非线性激活函数的有效性至关重要：对于很深的特征空间(如Inception模块中的)，非线性激活函数很有帮助；但对于较浅的特征空间(如深度可分离卷积中的1通道深的特征空间)，非线性激活函数变得有害，可能是由于信息丢失导致。</li>\n</ul>\n</li>\n<li><strong>对于残差连接</strong>：<ul>\n<li>文中实验验证，残差连接在帮助Xception方面至关重要，不仅提升了拟合速度，而且提升了最终的表现。</li>\n</ul>\n</li>\n<li>简而言之，Xception结构是带有残差连接的深度可分离卷积的线性堆叠。</li>\n<li>在Keras或TensorFlow-Slim上，只需要30至40行代码，即可完成Xception架构。</li>\n<li>基于Keras和TensorFlow的Xception开源实现，已经被提供为Keras应用模块的一部分，见<a href=\"https://keras.io/applications/#xception\" target=\"_blank\" rel=\"noopener\">链接</a>。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>选择比较Xception和Inception V3，因为它们的尺寸相似，两者有几乎相同的参数。<br>对两个分类任务进行比较，ImageNet和JFT。</p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h2><ul>\n<li>1.1000类别的单标签的ImageNet数据集</li>\n<li>2.17000类别的多标签的JFT数据集<ul>\n<li>谷歌内部数据集，由17000类别的超过350百万张高分辨率带标签图像构成</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"最优化配置\"><a href=\"#最优化配置\" class=\"headerlink\" title=\"最优化配置\"></a>最优化配置</h2><p>对于ImageNet和JFT采用不同的优化配置：</p>\n<ul>\n<li>对于ImageNet：<ul>\n<li>优化器: SGD</li>\n<li>动量: 0.9</li>\n<li>初始学习率: 0.045</li>\n<li>学习率衰减: decay of rate 0.94 every 2 epochs</li>\n</ul>\n</li>\n<li>对于JFT：<ul>\n<li>优化器: RMSprop</li>\n<li>动量: 0.9</li>\n<li>初始学习率: 0.001</li>\n<li>学习率衰减: decay of rate 0.9 every 3,000,000 samples</li>\n</ul>\n</li>\n<li>对Xception和Inception V3都采用如上的相同优化配置，如上的优化配置是为Inception V3调整出最佳表现的，没有尝试为Xception调整最优超参数。</li>\n</ul>\n<h2 id=\"正则化配置\"><a href=\"#正则化配置\" class=\"headerlink\" title=\"正则化配置\"></a>正则化配置</h2><ul>\n<li>权重衰减<ul>\n<li>Inception V3模型采用L2正则化系数为$4e^{-5}$(该参数是Inception V3针对ImageNet表现进行调整)</li>\n<li>经实验，上述系数对于Xception不适用，Xception调整为$1e^{-5}$</li>\n</ul>\n</li>\n<li>Dropout<ul>\n<li>对于ImageNet，两个模型均在逻辑回归层之前，加上0.5的dropout层</li>\n<li>对于JFT，由于该数据集较大，模型在合理时间内不可能出现过拟合现象</li>\n</ul>\n</li>\n<li>辅助loss<ul>\n<li>Inception V3中，会在网络前端施加辅助分类器，来反向传播分类器loss，做为另外的正则化机制。但为了简洁性，两模型均不采用辅助loss </li>\n</ul>\n</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/Xception/4.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如上图所示，在ImageNet上，Xception比Inception V3稍好，也比ResNet-152更好。</li>\n</ul>\n<p><img src=\"/images/Xception/5.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如上图所示，在JFT上，Xception相比于Inception V3的优势，比在ImageNet上更大了：<ul>\n<li>文中猜测，这是由于Inception V3是专注于ImageNet而设计的，因此，对该特定任务有一些过拟合。</li>\n<li>另一方面，两个模型都没有在JFT上调整过，因此，对于Xception，在ImageNet上可能会有更好的超参数(尤其是最优化参数和正则化参数)，进一步让网络表现明显提升。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1610.02357.pdf\" target=\"_blank\" rel=\"noopener\">论文：Xception: Deep Learning with Depthwise Separable Convolutions, 2017</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>首先，提出对Inception模块的一种解释：Inception模块是介于常规卷积(regular convolution)和深度可分离卷积(depthwise separable convolution)的中间步骤。</li>\n<li>然后，引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积(depthwise convolution)和逐点卷积(pointwise convolution)两部进行，有效地减少了计算量和参数量。</li>\n<li>然后，提出用深度可分离卷积来替代Inception模块的想法。</li>\n<li>最后，基于上述想法，提出Xception，意为”Extreme Inception”。</li>\n<li>在ImageNet数据集上，Xception的表现比Inception V3稍好；在更大的JFT数据集上，Xception的表现比Inception V3的优势扩大。</li>\n<li>注：Xception和Inception V3有这几乎相同的参数，因此，模型表现的提升不是因为参数增加，而是对于模型参数的更有效利用。</li>\n<li><p>本质：Xception是采用depthwise separable convolution来改进InceptionV3。</p>","more":"</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"对于Inception模块的假设\"><a href=\"#对于Inception模块的假设\" class=\"headerlink\" title=\"对于Inception模块的假设\"></a>对于Inception模块的假设</h2><p><img src=\"/images/Xception/1.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>独立地看待跨通道相关性(cross-channel correlations)和空间相关性(spatial correlations)，如Fig1所示:<ul>\n<li>Inception模块的$1\\times 1$卷积即是关于跨通道相关性</li>\n<li>Inception模块的$3\\times 3$或$5\\times 5$卷积即是关于跨通道相关性和空间相关性 </li>\n<li>提出假设：<strong>在Inception模块中，跨通道相关性和空间相关性被充分地解耦(decoupled)了，跨通道相关性和空间相关性更适合不被共同映射</strong>。</li>\n<li>因此，进一步提出一个比Inception模块假设<strong>更强的假设</strong>：<strong>让跨通道相关性和空间相关性的映射完全分离</strong>。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Inception模块的终极版本\"><a href=\"#Inception模块的终极版本\" class=\"headerlink\" title=\"Inception模块的终极版本\"></a>Inception模块的终极版本</h2><p><img src=\"/images/Xception/2.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>基于<strong>上述的更强假设</strong>，设计出Inception模块的终极版本，如Fig4所示：<ul>\n<li>首先，用$1\\times 1$卷积对跨通道相关性进行映射；</li>\n<li>然后，分别单独对每一个通道的空间相关性进行映射。</li>\n</ul>\n</li>\n<li>注意到，这个Inception的终极形式，和深度可分离卷积的含义几乎相等，只有两点微小区别：<ul>\n<li>1.操作的顺序：深度可分离卷积通常先进行逐通道的空间卷积，然后进行$1\\times 1$卷积。而Inception模块是先进行$1\\times 1$卷积。</li>\n<li>注：文中认为这第一个不同点不重要，尤其是这些操作会以堆叠的方式被使用。</li>\n<li>2.存不存在非线形激活函数：在Inception模块中，两个操作之后都会接一个ReLU非线性激活函数；然而，执行深度可分离卷积时，通常不用非线性激活函数。</li>\n<li>注：第二个不同点可能有影响，后续进行了实验验证（见下一小节，<strong>文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现</strong>）。</li>\n</ul>\n</li>\n<li>因此，产生新的想法：<strong>可以用深度可分离卷积来替换Inception模块，以此来改善Inception家族的表现</strong>。</li>\n</ul>\n<h2 id=\"Xception结构\"><a href=\"#Xception结构\" class=\"headerlink\" title=\"Xception结构\"></a>Xception结构</h2><p><img src=\"/images/Xception/3.png\" width=\"700\"></p>\n<p>Xception如Fig5所示：</p>\n<ul>\n<li>Xception即代表”Extreme Inception”。</li>\n<li>Xception结构含有36个卷积层构成，由14个模块构成，除了第一个和最后一个模块，所有模块均包含线性残差连接。</li>\n<li><strong>对于深度可分离卷积</strong>（先进行depthwise卷积，再进行pointwise卷积，中间没有非线性激活函数）：<ul>\n<li><strong>文中实验验证：depthwise卷积之后不加非线性激活函数，可以更快地拟合且得到更好的最终表现。</strong></li>\n<li>对此，文中猜测：depthwise卷积的所施加在的中间特征空间的深度对于非线性激活函数的有效性至关重要：对于很深的特征空间(如Inception模块中的)，非线性激活函数很有帮助；但对于较浅的特征空间(如深度可分离卷积中的1通道深的特征空间)，非线性激活函数变得有害，可能是由于信息丢失导致。</li>\n</ul>\n</li>\n<li><strong>对于残差连接</strong>：<ul>\n<li>文中实验验证，残差连接在帮助Xception方面至关重要，不仅提升了拟合速度，而且提升了最终的表现。</li>\n</ul>\n</li>\n<li>简而言之，Xception结构是带有残差连接的深度可分离卷积的线性堆叠。</li>\n<li>在Keras或TensorFlow-Slim上，只需要30至40行代码，即可完成Xception架构。</li>\n<li>基于Keras和TensorFlow的Xception开源实现，已经被提供为Keras应用模块的一部分，见<a href=\"https://keras.io/applications/#xception\" target=\"_blank\" rel=\"noopener\">链接</a>。</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>选择比较Xception和Inception V3，因为它们的尺寸相似，两者有几乎相同的参数。<br>对两个分类任务进行比较，ImageNet和JFT。</p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h2><ul>\n<li>1.1000类别的单标签的ImageNet数据集</li>\n<li>2.17000类别的多标签的JFT数据集<ul>\n<li>谷歌内部数据集，由17000类别的超过350百万张高分辨率带标签图像构成</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"最优化配置\"><a href=\"#最优化配置\" class=\"headerlink\" title=\"最优化配置\"></a>最优化配置</h2><p>对于ImageNet和JFT采用不同的优化配置：</p>\n<ul>\n<li>对于ImageNet：<ul>\n<li>优化器: SGD</li>\n<li>动量: 0.9</li>\n<li>初始学习率: 0.045</li>\n<li>学习率衰减: decay of rate 0.94 every 2 epochs</li>\n</ul>\n</li>\n<li>对于JFT：<ul>\n<li>优化器: RMSprop</li>\n<li>动量: 0.9</li>\n<li>初始学习率: 0.001</li>\n<li>学习率衰减: decay of rate 0.9 every 3,000,000 samples</li>\n</ul>\n</li>\n<li>对Xception和Inception V3都采用如上的相同优化配置，如上的优化配置是为Inception V3调整出最佳表现的，没有尝试为Xception调整最优超参数。</li>\n</ul>\n<h2 id=\"正则化配置\"><a href=\"#正则化配置\" class=\"headerlink\" title=\"正则化配置\"></a>正则化配置</h2><ul>\n<li>权重衰减<ul>\n<li>Inception V3模型采用L2正则化系数为$4e^{-5}$(该参数是Inception V3针对ImageNet表现进行调整)</li>\n<li>经实验，上述系数对于Xception不适用，Xception调整为$1e^{-5}$</li>\n</ul>\n</li>\n<li>Dropout<ul>\n<li>对于ImageNet，两个模型均在逻辑回归层之前，加上0.5的dropout层</li>\n<li>对于JFT，由于该数据集较大，模型在合理时间内不可能出现过拟合现象</li>\n</ul>\n</li>\n<li>辅助loss<ul>\n<li>Inception V3中，会在网络前端施加辅助分类器，来反向传播分类器loss，做为另外的正则化机制。但为了简洁性，两模型均不采用辅助loss </li>\n</ul>\n</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/Xception/4.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如上图所示，在ImageNet上，Xception比Inception V3稍好，也比ResNet-152更好。</li>\n</ul>\n<p><img src=\"/images/Xception/5.png\" width=\"400\" height=\"100\"></p>\n<ul>\n<li>如上图所示，在JFT上，Xception相比于Inception V3的优势，比在ImageNet上更大了：<ul>\n<li>文中猜测，这是由于Inception V3是专注于ImageNet而设计的，因此，对该特定任务有一些过拟合。</li>\n<li>另一方面，两个模型都没有在JFT上调整过，因此，对于Xception，在ImageNet上可能会有更好的超参数(尤其是最优化参数和正则化参数)，进一步让网络表现明显提升。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1610.02357.pdf\" target=\"_blank\" rel=\"noopener\">论文：Xception: Deep Learning with Depthwise Separable Convolutions, 2017</a></li>\n</ul>"},{"title":"kNN算法","mathjax":true,"date":"2017-12-05T12:52:50.000Z","_content":"k近邻法（k-nearest neighbor, kNN）是一种基本分类与回归方法。k近邻不具有显式的学习过程，k近邻实际上是利用训练数据集对特征空间进行划分，并作为其分类的“模型”。k近邻法的三个基本要素：$k$值的选择、距离度量及分类决策规则。\n本文记录分类问题中的kNN算法。\n<!-- more --> \n# 一、kNN算法\nkNN算法简单且直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的$k$个实例，这$k$个实例中的多数属于某个类，就把该输入实例分为这个类。\n## 1.1 kNN算法\n输入：训练数据集$T= \\lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \\rbrace$；实例特征向量$x$；\n输出：实例$x$所属的类$y$\n（1）根据所给的距离度量，在训练集$T$中找到与$x$最近的$k$个点，涵盖这$k$个点的$x$的邻域记作$N_k(x)$；\n（2）在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别$y$：\n$$y = arg\\max_{c_j} \\sum_{x_i \\in N_k(x)} I(y_i = c_j),\\ \\ i=1, 2,…, N;\\ \\ j=1, 2,…, K$$\n其中$I$为指示函数，即当$y_i = c_j$时$I$为1，否则为0。\n## 1.2 kNN的三大基本要素\n### 距离度量\n特征空间中两个实例点的距离是两个实例点相似程度的反映。\n一般最常用的距离函数是欧氏距离，也称作$L_2$距离。也可使用其他距离，如更一般的$L_p$距离。\n设特征空间$X$是$n$维实数向量空间$R^n$，$x_i,x_j \\in R^n$，$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，$x_j=(x_j^{(1)},x_j^{(2)},…, x_j^{(n)})^T$，则$x_i, x_j$的$L_p$距离定义为\n$$L_p(x_i,x_j)=(\\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|^p)^{\\frac{1}{p}}$$\n这里$p \\geq 1$。当$p=2$时称为欧氏距离，$p=1$时称为曼哈顿距离。\n不同的距离度量所确定的最近邻点是不同的。\n注：需对特征向量各维度进行归一化，否则数值较大的特征将占主导因素。\n### $k$值的选择\n$k$值较小意味着整体模型变得复杂，容易发生过拟合。\n$k$值较大意味着整体模型变得简单，容易发生欠拟合。\n在应用中，$k$值一般取一个比较小的数值。通常采用交叉验证法来选取最优的$k$值。\n### 分类决策规则\nkNN中的分类决策规则通常是多数表决，即由输入实例的$k$个近邻的训练实例中的多数类决定输入实例的类。\n多数表决规则等价于经验风险最小化。\n# 二、kd树\n## 2.1 kd树简介\n实现kNN算法的核心问题是如何对训练数据进行快速k近邻搜索，尤其是在特征空间的维数大及训练数据容量大的情况下。\nkNN算法最简单的实现方法是线性扫描，即计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，故此方法不可行。\n常用的有效方法是使用特殊的结构存储训练数据，以减少计算距离的次数，从而提高k近邻搜索的效率。如用kd树存储训练数据，然后搜索kd树。\nkd树是一种对$k$维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。**kd树是二叉树**，表示对$k$维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域。kd树的每个结点对应于一个$k$维超矩形区域。\n注：kd树是存储$k$维空间数据的树结构，这里的$k$与k近邻法的$k$意义不同。\n## 2.2 构造KD树\n输入：$k$维空间数据集$T= \\lbrace x_1, x_2,…, x_N \\rbrace$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T$,$i=1,2,…,N$\n输出：kd树\n（1）开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。选择$x^{(1)}$为坐标轴，以$T$中所有实例的$x^{(1)}$坐标的**中位数**为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。\n由根结点（深度为0）生成深度为1的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域，右子结点对应于坐标$x^{(1)}$大于切分点的子区域。\n将落在切分超平面上的实例点保存在根结点。\n注：中位数：一组数据按大小顺序排列起来，处在中间位置的一个树或者最中间两个数的平均值。\n（2）重复：**对于深度为$j$的结点，选择$x^{(l)}$为切分的坐标轴，$l=(j+1)\\ mod\\ k$**，以该结点区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。\n由该结点生成深度为$j+1$的左、右结点：左子结点对应坐标$x^{(l)}$小于切分点的子区域；右子结点对应坐标$x^{(l)}$大于切分点的子区域。\n将落在切分超平面上的实例点保存在该结点。\n（3）直到两个区域**没有实例存在时停止**。从而形成kd树的区域划分。\n\n示例见《统计学习方法书》中或[kd树算法之详细篇（推荐）](https://www.joinquant.com/post/2843)中。\n## 2.3 搜索KD树\n输入：已构造的kd树；目标点p；\n输出：p的k近邻\n（零）设$L$为一个有$k$个空位的列表，用于保存已搜寻到的最近点。\n（一）根据$p$的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是按照$x_r=a$进行切分，并且$p$的$r$坐标小于$a$，则向左枝进行搜索；反之则向右枝进行搜索）。\n（二）当达到一个底部节点时，将其标记为访问过。如果$L$里不足$k$个点，则将当前节点的特征坐标加入$L$；如果$L$满并且当前节点的特征与$p$的距离小于$L$里最长的距离，则用当前特征替换掉$L$中离$p$最远的点。\n（三）如果当前节点不是整棵树最顶端节点，执行（a）；反之，输出$L$，算法完成。\n　　（a）向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行（1）和（2）；如果当前节点被访问过，再次执行（a）。\n　　　　（1）如果此时$L$里不足$k$个点，则将节点特征加入$L$；如果$L$中已满$k$个点，且当前节点与$p$的距离小于$L$里最长的距离，则用节点特征替换掉$L$中离最远的点。\n　　　　（2）计算$p$和当前节点切分线的距离。如果该距离大于等于$L$中距离$p$最远的距离并且$L$中已有$k$个点，则在切分线另一边不会有更近的点，执行(三)；如果该距离小于$L$中最远的距离或者$L$中不足$k$个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从(一)开始执行。\n\n示例见《统计学习方法书》中或[kd树算法之详细篇（推荐）](https://www.joinquant.com/post/2843)中。\n# 三、KNN模型的优缺点（待改进）\n1.优点：\n（1）思想简单，理论成熟，既可以用来做分类也可以用来做回归\n（2）可用于非线性分类\n（3）训练时间复杂度为$O(n)$\n（4）准确度高，对数据没有假设，对异常值不敏感\n2.缺点：\n（1）计算量大\n（2）样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）\n（3）需要大量的内存\n# 四、参考资料\n- 李航，统计机器学习方法\n- [肖睿，一只兔子帮你理解KNN](https://www.joinquant.com/post/2227?f=study&m=math)\n- [肖睿，kd树算法之思路篇](https://www.joinquant.com/post/2627)\n- [肖睿，kd树算法之详细篇](https://www.joinquant.com/post/2843)\n\n\n\n\n\n","source":"_posts/kNN算法.md","raw":"---\ntitle: kNN算法\nmathjax: true\ndate: 2017-12-5 20:52:50\ncategories: \n- 机器学习\n---\nk近邻法（k-nearest neighbor, kNN）是一种基本分类与回归方法。k近邻不具有显式的学习过程，k近邻实际上是利用训练数据集对特征空间进行划分，并作为其分类的“模型”。k近邻法的三个基本要素：$k$值的选择、距离度量及分类决策规则。\n本文记录分类问题中的kNN算法。\n<!-- more --> \n# 一、kNN算法\nkNN算法简单且直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的$k$个实例，这$k$个实例中的多数属于某个类，就把该输入实例分为这个类。\n## 1.1 kNN算法\n输入：训练数据集$T= \\lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \\rbrace$；实例特征向量$x$；\n输出：实例$x$所属的类$y$\n（1）根据所给的距离度量，在训练集$T$中找到与$x$最近的$k$个点，涵盖这$k$个点的$x$的邻域记作$N_k(x)$；\n（2）在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别$y$：\n$$y = arg\\max_{c_j} \\sum_{x_i \\in N_k(x)} I(y_i = c_j),\\ \\ i=1, 2,…, N;\\ \\ j=1, 2,…, K$$\n其中$I$为指示函数，即当$y_i = c_j$时$I$为1，否则为0。\n## 1.2 kNN的三大基本要素\n### 距离度量\n特征空间中两个实例点的距离是两个实例点相似程度的反映。\n一般最常用的距离函数是欧氏距离，也称作$L_2$距离。也可使用其他距离，如更一般的$L_p$距离。\n设特征空间$X$是$n$维实数向量空间$R^n$，$x_i,x_j \\in R^n$，$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，$x_j=(x_j^{(1)},x_j^{(2)},…, x_j^{(n)})^T$，则$x_i, x_j$的$L_p$距离定义为\n$$L_p(x_i,x_j)=(\\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|^p)^{\\frac{1}{p}}$$\n这里$p \\geq 1$。当$p=2$时称为欧氏距离，$p=1$时称为曼哈顿距离。\n不同的距离度量所确定的最近邻点是不同的。\n注：需对特征向量各维度进行归一化，否则数值较大的特征将占主导因素。\n### $k$值的选择\n$k$值较小意味着整体模型变得复杂，容易发生过拟合。\n$k$值较大意味着整体模型变得简单，容易发生欠拟合。\n在应用中，$k$值一般取一个比较小的数值。通常采用交叉验证法来选取最优的$k$值。\n### 分类决策规则\nkNN中的分类决策规则通常是多数表决，即由输入实例的$k$个近邻的训练实例中的多数类决定输入实例的类。\n多数表决规则等价于经验风险最小化。\n# 二、kd树\n## 2.1 kd树简介\n实现kNN算法的核心问题是如何对训练数据进行快速k近邻搜索，尤其是在特征空间的维数大及训练数据容量大的情况下。\nkNN算法最简单的实现方法是线性扫描，即计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，故此方法不可行。\n常用的有效方法是使用特殊的结构存储训练数据，以减少计算距离的次数，从而提高k近邻搜索的效率。如用kd树存储训练数据，然后搜索kd树。\nkd树是一种对$k$维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。**kd树是二叉树**，表示对$k$维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域。kd树的每个结点对应于一个$k$维超矩形区域。\n注：kd树是存储$k$维空间数据的树结构，这里的$k$与k近邻法的$k$意义不同。\n## 2.2 构造KD树\n输入：$k$维空间数据集$T= \\lbrace x_1, x_2,…, x_N \\rbrace$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T$,$i=1,2,…,N$\n输出：kd树\n（1）开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。选择$x^{(1)}$为坐标轴，以$T$中所有实例的$x^{(1)}$坐标的**中位数**为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。\n由根结点（深度为0）生成深度为1的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域，右子结点对应于坐标$x^{(1)}$大于切分点的子区域。\n将落在切分超平面上的实例点保存在根结点。\n注：中位数：一组数据按大小顺序排列起来，处在中间位置的一个树或者最中间两个数的平均值。\n（2）重复：**对于深度为$j$的结点，选择$x^{(l)}$为切分的坐标轴，$l=(j+1)\\ mod\\ k$**，以该结点区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。\n由该结点生成深度为$j+1$的左、右结点：左子结点对应坐标$x^{(l)}$小于切分点的子区域；右子结点对应坐标$x^{(l)}$大于切分点的子区域。\n将落在切分超平面上的实例点保存在该结点。\n（3）直到两个区域**没有实例存在时停止**。从而形成kd树的区域划分。\n\n示例见《统计学习方法书》中或[kd树算法之详细篇（推荐）](https://www.joinquant.com/post/2843)中。\n## 2.3 搜索KD树\n输入：已构造的kd树；目标点p；\n输出：p的k近邻\n（零）设$L$为一个有$k$个空位的列表，用于保存已搜寻到的最近点。\n（一）根据$p$的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是按照$x_r=a$进行切分，并且$p$的$r$坐标小于$a$，则向左枝进行搜索；反之则向右枝进行搜索）。\n（二）当达到一个底部节点时，将其标记为访问过。如果$L$里不足$k$个点，则将当前节点的特征坐标加入$L$；如果$L$满并且当前节点的特征与$p$的距离小于$L$里最长的距离，则用当前特征替换掉$L$中离$p$最远的点。\n（三）如果当前节点不是整棵树最顶端节点，执行（a）；反之，输出$L$，算法完成。\n　　（a）向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行（1）和（2）；如果当前节点被访问过，再次执行（a）。\n　　　　（1）如果此时$L$里不足$k$个点，则将节点特征加入$L$；如果$L$中已满$k$个点，且当前节点与$p$的距离小于$L$里最长的距离，则用节点特征替换掉$L$中离最远的点。\n　　　　（2）计算$p$和当前节点切分线的距离。如果该距离大于等于$L$中距离$p$最远的距离并且$L$中已有$k$个点，则在切分线另一边不会有更近的点，执行(三)；如果该距离小于$L$中最远的距离或者$L$中不足$k$个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从(一)开始执行。\n\n示例见《统计学习方法书》中或[kd树算法之详细篇（推荐）](https://www.joinquant.com/post/2843)中。\n# 三、KNN模型的优缺点（待改进）\n1.优点：\n（1）思想简单，理论成熟，既可以用来做分类也可以用来做回归\n（2）可用于非线性分类\n（3）训练时间复杂度为$O(n)$\n（4）准确度高，对数据没有假设，对异常值不敏感\n2.缺点：\n（1）计算量大\n（2）样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）\n（3）需要大量的内存\n# 四、参考资料\n- 李航，统计机器学习方法\n- [肖睿，一只兔子帮你理解KNN](https://www.joinquant.com/post/2227?f=study&m=math)\n- [肖睿，kd树算法之思路篇](https://www.joinquant.com/post/2627)\n- [肖睿，kd树算法之详细篇](https://www.joinquant.com/post/2843)\n\n\n\n\n\n","slug":"kNN算法","published":1,"updated":"2018-02-03T08:25:33.734Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvi0012qslpy3m2d5nc","content":"<p>k近邻法（k-nearest neighbor, kNN）是一种基本分类与回归方法。k近邻不具有显式的学习过程，k近邻实际上是利用训练数据集对特征空间进行划分，并作为其分类的“模型”。k近邻法的三个基本要素：$k$值的选择、距离度量及分类决策规则。<br>本文记录分类问题中的kNN算法。<br><a id=\"more\"></a> </p>\n<h1 id=\"一、kNN算法\"><a href=\"#一、kNN算法\" class=\"headerlink\" title=\"一、kNN算法\"></a>一、kNN算法</h1><p>kNN算法简单且直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的$k$个实例，这$k$个实例中的多数属于某个类，就把该输入实例分为这个类。</p>\n<h2 id=\"1-1-kNN算法\"><a href=\"#1-1-kNN算法\" class=\"headerlink\" title=\"1.1 kNN算法\"></a>1.1 kNN算法</h2><p>输入：训练数据集$T= \\lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \\rbrace$；实例特征向量$x$；<br>输出：实例$x$所属的类$y$<br>（1）根据所给的距离度量，在训练集$T$中找到与$x$最近的$k$个点，涵盖这$k$个点的$x$的邻域记作$N_k(x)$；<br>（2）在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别$y$：</p>\n<script type=\"math/tex; mode=display\">y = arg\\max_{c_j} \\sum_{x_i \\in N_k(x)} I(y_i = c_j),\\ \\ i=1, 2,…, N;\\ \\ j=1, 2,…, K</script><p>其中$I$为指示函数，即当$y_i = c_j$时$I$为1，否则为0。</p>\n<h2 id=\"1-2-kNN的三大基本要素\"><a href=\"#1-2-kNN的三大基本要素\" class=\"headerlink\" title=\"1.2 kNN的三大基本要素\"></a>1.2 kNN的三大基本要素</h2><h3 id=\"距离度量\"><a href=\"#距离度量\" class=\"headerlink\" title=\"距离度量\"></a>距离度量</h3><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。<br>一般最常用的距离函数是欧氏距离，也称作$L_2$距离。也可使用其他距离，如更一般的$L_p$距离。<br>设特征空间$X$是$n$维实数向量空间$R^n$，$x_i,x_j \\in R^n$，$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，$x_j=(x_j^{(1)},x_j^{(2)},…, x_j^{(n)})^T$，则$x_i, x_j$的$L_p$距离定义为</p>\n<script type=\"math/tex; mode=display\">L_p(x_i,x_j)=(\\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|^p)^{\\frac{1}{p}}</script><p>这里$p \\geq 1$。当$p=2$时称为欧氏距离，$p=1$时称为曼哈顿距离。<br>不同的距离度量所确定的最近邻点是不同的。<br>注：需对特征向量各维度进行归一化，否则数值较大的特征将占主导因素。</p>\n<h3 id=\"k-值的选择\"><a href=\"#k-值的选择\" class=\"headerlink\" title=\"$k$值的选择\"></a>$k$值的选择</h3><p>$k$值较小意味着整体模型变得复杂，容易发生过拟合。<br>$k$值较大意味着整体模型变得简单，容易发生欠拟合。<br>在应用中，$k$值一般取一个比较小的数值。通常采用交叉验证法来选取最优的$k$值。</p>\n<h3 id=\"分类决策规则\"><a href=\"#分类决策规则\" class=\"headerlink\" title=\"分类决策规则\"></a>分类决策规则</h3><p>kNN中的分类决策规则通常是多数表决，即由输入实例的$k$个近邻的训练实例中的多数类决定输入实例的类。<br>多数表决规则等价于经验风险最小化。</p>\n<h1 id=\"二、kd树\"><a href=\"#二、kd树\" class=\"headerlink\" title=\"二、kd树\"></a>二、kd树</h1><h2 id=\"2-1-kd树简介\"><a href=\"#2-1-kd树简介\" class=\"headerlink\" title=\"2.1 kd树简介\"></a>2.1 kd树简介</h2><p>实现kNN算法的核心问题是如何对训练数据进行快速k近邻搜索，尤其是在特征空间的维数大及训练数据容量大的情况下。<br>kNN算法最简单的实现方法是线性扫描，即计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，故此方法不可行。<br>常用的有效方法是使用特殊的结构存储训练数据，以减少计算距离的次数，从而提高k近邻搜索的效率。如用kd树存储训练数据，然后搜索kd树。<br>kd树是一种对$k$维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。<strong>kd树是二叉树</strong>，表示对$k$维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域。kd树的每个结点对应于一个$k$维超矩形区域。<br>注：kd树是存储$k$维空间数据的树结构，这里的$k$与k近邻法的$k$意义不同。</p>\n<h2 id=\"2-2-构造KD树\"><a href=\"#2-2-构造KD树\" class=\"headerlink\" title=\"2.2 构造KD树\"></a>2.2 构造KD树</h2><p>输入：$k$维空间数据集$T= \\lbrace x_1, x_2,…, x_N \\rbrace$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T$,$i=1,2,…,N$<br>输出：kd树<br>（1）开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。选择$x^{(1)}$为坐标轴，以$T$中所有实例的$x^{(1)}$坐标的<strong>中位数</strong>为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。<br>由根结点（深度为0）生成深度为1的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域，右子结点对应于坐标$x^{(1)}$大于切分点的子区域。<br>将落在切分超平面上的实例点保存在根结点。<br>注：中位数：一组数据按大小顺序排列起来，处在中间位置的一个树或者最中间两个数的平均值。<br>（2）重复：<strong>对于深度为$j$的结点，选择$x^{(l)}$为切分的坐标轴，$l=(j+1)\\ mod\\ k$</strong>，以该结点区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。<br>由该结点生成深度为$j+1$的左、右结点：左子结点对应坐标$x^{(l)}$小于切分点的子区域；右子结点对应坐标$x^{(l)}$大于切分点的子区域。<br>将落在切分超平面上的实例点保存在该结点。<br>（3）直到两个区域<strong>没有实例存在时停止</strong>。从而形成kd树的区域划分。</p>\n<p>示例见《统计学习方法书》中或<a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">kd树算法之详细篇（推荐）</a>中。</p>\n<h2 id=\"2-3-搜索KD树\"><a href=\"#2-3-搜索KD树\" class=\"headerlink\" title=\"2.3 搜索KD树\"></a>2.3 搜索KD树</h2><p>输入：已构造的kd树；目标点p；<br>输出：p的k近邻<br>（零）设$L$为一个有$k$个空位的列表，用于保存已搜寻到的最近点。<br>（一）根据$p$的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是按照$x_r=a$进行切分，并且$p$的$r$坐标小于$a$，则向左枝进行搜索；反之则向右枝进行搜索）。<br>（二）当达到一个底部节点时，将其标记为访问过。如果$L$里不足$k$个点，则将当前节点的特征坐标加入$L$；如果$L$满并且当前节点的特征与$p$的距离小于$L$里最长的距离，则用当前特征替换掉$L$中离$p$最远的点。<br>（三）如果当前节点不是整棵树最顶端节点，执行（a）；反之，输出$L$，算法完成。<br>　　（a）向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行（1）和（2）；如果当前节点被访问过，再次执行（a）。<br>　　　　（1）如果此时$L$里不足$k$个点，则将节点特征加入$L$；如果$L$中已满$k$个点，且当前节点与$p$的距离小于$L$里最长的距离，则用节点特征替换掉$L$中离最远的点。<br>　　　　（2）计算$p$和当前节点切分线的距离。如果该距离大于等于$L$中距离$p$最远的距离并且$L$中已有$k$个点，则在切分线另一边不会有更近的点，执行(三)；如果该距离小于$L$中最远的距离或者$L$中不足$k$个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从(一)开始执行。</p>\n<p>示例见《统计学习方法书》中或<a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">kd树算法之详细篇（推荐）</a>中。</p>\n<h1 id=\"三、KNN模型的优缺点（待改进）\"><a href=\"#三、KNN模型的优缺点（待改进）\" class=\"headerlink\" title=\"三、KNN模型的优缺点（待改进）\"></a>三、KNN模型的优缺点（待改进）</h1><p>1.优点：<br>（1）思想简单，理论成熟，既可以用来做分类也可以用来做回归<br>（2）可用于非线性分类<br>（3）训练时间复杂度为$O(n)$<br>（4）准确度高，对数据没有假设，对异常值不敏感<br>2.缺点：<br>（1）计算量大<br>（2）样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）<br>（3）需要大量的内存</p>\n<h1 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h1><ul>\n<li>李航，统计机器学习方法</li>\n<li><a href=\"https://www.joinquant.com/post/2227?f=study&amp;m=math\" target=\"_blank\" rel=\"noopener\">肖睿，一只兔子帮你理解KNN</a></li>\n<li><a href=\"https://www.joinquant.com/post/2627\" target=\"_blank\" rel=\"noopener\">肖睿，kd树算法之思路篇</a></li>\n<li><a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">肖睿，kd树算法之详细篇</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>k近邻法（k-nearest neighbor, kNN）是一种基本分类与回归方法。k近邻不具有显式的学习过程，k近邻实际上是利用训练数据集对特征空间进行划分，并作为其分类的“模型”。k近邻法的三个基本要素：$k$值的选择、距离度量及分类决策规则。<br>本文记录分类问题中的kNN算法。<br>","more":"</p>\n<h1 id=\"一、kNN算法\"><a href=\"#一、kNN算法\" class=\"headerlink\" title=\"一、kNN算法\"></a>一、kNN算法</h1><p>kNN算法简单且直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的$k$个实例，这$k$个实例中的多数属于某个类，就把该输入实例分为这个类。</p>\n<h2 id=\"1-1-kNN算法\"><a href=\"#1-1-kNN算法\" class=\"headerlink\" title=\"1.1 kNN算法\"></a>1.1 kNN算法</h2><p>输入：训练数据集$T= \\lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \\rbrace$；实例特征向量$x$；<br>输出：实例$x$所属的类$y$<br>（1）根据所给的距离度量，在训练集$T$中找到与$x$最近的$k$个点，涵盖这$k$个点的$x$的邻域记作$N_k(x)$；<br>（2）在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别$y$：</p>\n<script type=\"math/tex; mode=display\">y = arg\\max_{c_j} \\sum_{x_i \\in N_k(x)} I(y_i = c_j),\\ \\ i=1, 2,…, N;\\ \\ j=1, 2,…, K</script><p>其中$I$为指示函数，即当$y_i = c_j$时$I$为1，否则为0。</p>\n<h2 id=\"1-2-kNN的三大基本要素\"><a href=\"#1-2-kNN的三大基本要素\" class=\"headerlink\" title=\"1.2 kNN的三大基本要素\"></a>1.2 kNN的三大基本要素</h2><h3 id=\"距离度量\"><a href=\"#距离度量\" class=\"headerlink\" title=\"距离度量\"></a>距离度量</h3><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。<br>一般最常用的距离函数是欧氏距离，也称作$L_2$距离。也可使用其他距离，如更一般的$L_p$距离。<br>设特征空间$X$是$n$维实数向量空间$R^n$，$x_i,x_j \\in R^n$，$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，$x_j=(x_j^{(1)},x_j^{(2)},…, x_j^{(n)})^T$，则$x_i, x_j$的$L_p$距离定义为</p>\n<script type=\"math/tex; mode=display\">L_p(x_i,x_j)=(\\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|^p)^{\\frac{1}{p}}</script><p>这里$p \\geq 1$。当$p=2$时称为欧氏距离，$p=1$时称为曼哈顿距离。<br>不同的距离度量所确定的最近邻点是不同的。<br>注：需对特征向量各维度进行归一化，否则数值较大的特征将占主导因素。</p>\n<h3 id=\"k-值的选择\"><a href=\"#k-值的选择\" class=\"headerlink\" title=\"$k$值的选择\"></a>$k$值的选择</h3><p>$k$值较小意味着整体模型变得复杂，容易发生过拟合。<br>$k$值较大意味着整体模型变得简单，容易发生欠拟合。<br>在应用中，$k$值一般取一个比较小的数值。通常采用交叉验证法来选取最优的$k$值。</p>\n<h3 id=\"分类决策规则\"><a href=\"#分类决策规则\" class=\"headerlink\" title=\"分类决策规则\"></a>分类决策规则</h3><p>kNN中的分类决策规则通常是多数表决，即由输入实例的$k$个近邻的训练实例中的多数类决定输入实例的类。<br>多数表决规则等价于经验风险最小化。</p>\n<h1 id=\"二、kd树\"><a href=\"#二、kd树\" class=\"headerlink\" title=\"二、kd树\"></a>二、kd树</h1><h2 id=\"2-1-kd树简介\"><a href=\"#2-1-kd树简介\" class=\"headerlink\" title=\"2.1 kd树简介\"></a>2.1 kd树简介</h2><p>实现kNN算法的核心问题是如何对训练数据进行快速k近邻搜索，尤其是在特征空间的维数大及训练数据容量大的情况下。<br>kNN算法最简单的实现方法是线性扫描，即计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，故此方法不可行。<br>常用的有效方法是使用特殊的结构存储训练数据，以减少计算距离的次数，从而提高k近邻搜索的效率。如用kd树存储训练数据，然后搜索kd树。<br>kd树是一种对$k$维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。<strong>kd树是二叉树</strong>，表示对$k$维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域。kd树的每个结点对应于一个$k$维超矩形区域。<br>注：kd树是存储$k$维空间数据的树结构，这里的$k$与k近邻法的$k$意义不同。</p>\n<h2 id=\"2-2-构造KD树\"><a href=\"#2-2-构造KD树\" class=\"headerlink\" title=\"2.2 构造KD树\"></a>2.2 构造KD树</h2><p>输入：$k$维空间数据集$T= \\lbrace x_1, x_2,…, x_N \\rbrace$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T$,$i=1,2,…,N$<br>输出：kd树<br>（1）开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。选择$x^{(1)}$为坐标轴，以$T$中所有实例的$x^{(1)}$坐标的<strong>中位数</strong>为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。<br>由根结点（深度为0）生成深度为1的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域，右子结点对应于坐标$x^{(1)}$大于切分点的子区域。<br>将落在切分超平面上的实例点保存在根结点。<br>注：中位数：一组数据按大小顺序排列起来，处在中间位置的一个树或者最中间两个数的平均值。<br>（2）重复：<strong>对于深度为$j$的结点，选择$x^{(l)}$为切分的坐标轴，$l=(j+1)\\ mod\\ k$</strong>，以该结点区域中所有实例的$x^{(l)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(l)}$垂直的超平面实现。<br>由该结点生成深度为$j+1$的左、右结点：左子结点对应坐标$x^{(l)}$小于切分点的子区域；右子结点对应坐标$x^{(l)}$大于切分点的子区域。<br>将落在切分超平面上的实例点保存在该结点。<br>（3）直到两个区域<strong>没有实例存在时停止</strong>。从而形成kd树的区域划分。</p>\n<p>示例见《统计学习方法书》中或<a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">kd树算法之详细篇（推荐）</a>中。</p>\n<h2 id=\"2-3-搜索KD树\"><a href=\"#2-3-搜索KD树\" class=\"headerlink\" title=\"2.3 搜索KD树\"></a>2.3 搜索KD树</h2><p>输入：已构造的kd树；目标点p；<br>输出：p的k近邻<br>（零）设$L$为一个有$k$个空位的列表，用于保存已搜寻到的最近点。<br>（一）根据$p$的坐标值和每个节点的切分向下搜索（也就是说，如果树的节点是按照$x_r=a$进行切分，并且$p$的$r$坐标小于$a$，则向左枝进行搜索；反之则向右枝进行搜索）。<br>（二）当达到一个底部节点时，将其标记为访问过。如果$L$里不足$k$个点，则将当前节点的特征坐标加入$L$；如果$L$满并且当前节点的特征与$p$的距离小于$L$里最长的距离，则用当前特征替换掉$L$中离$p$最远的点。<br>（三）如果当前节点不是整棵树最顶端节点，执行（a）；反之，输出$L$，算法完成。<br>　　（a）向上爬一个节点。如果当前（向上爬之后的）节点未曾被访问过，将其标记为被访问过，然后执行（1）和（2）；如果当前节点被访问过，再次执行（a）。<br>　　　　（1）如果此时$L$里不足$k$个点，则将节点特征加入$L$；如果$L$中已满$k$个点，且当前节点与$p$的距离小于$L$里最长的距离，则用节点特征替换掉$L$中离最远的点。<br>　　　　（2）计算$p$和当前节点切分线的距离。如果该距离大于等于$L$中距离$p$最远的距离并且$L$中已有$k$个点，则在切分线另一边不会有更近的点，执行(三)；如果该距离小于$L$中最远的距离或者$L$中不足$k$个点，则切分线另一边可能有更近的点，因此在当前节点的另一个枝从(一)开始执行。</p>\n<p>示例见《统计学习方法书》中或<a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">kd树算法之详细篇（推荐）</a>中。</p>\n<h1 id=\"三、KNN模型的优缺点（待改进）\"><a href=\"#三、KNN模型的优缺点（待改进）\" class=\"headerlink\" title=\"三、KNN模型的优缺点（待改进）\"></a>三、KNN模型的优缺点（待改进）</h1><p>1.优点：<br>（1）思想简单，理论成熟，既可以用来做分类也可以用来做回归<br>（2）可用于非线性分类<br>（3）训练时间复杂度为$O(n)$<br>（4）准确度高，对数据没有假设，对异常值不敏感<br>2.缺点：<br>（1）计算量大<br>（2）样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）<br>（3）需要大量的内存</p>\n<h1 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h1><ul>\n<li>李航，统计机器学习方法</li>\n<li><a href=\"https://www.joinquant.com/post/2227?f=study&amp;m=math\" target=\"_blank\" rel=\"noopener\">肖睿，一只兔子帮你理解KNN</a></li>\n<li><a href=\"https://www.joinquant.com/post/2627\" target=\"_blank\" rel=\"noopener\">肖睿，kd树算法之思路篇</a></li>\n<li><a href=\"https://www.joinquant.com/post/2843\" target=\"_blank\" rel=\"noopener\">肖睿，kd树算法之详细篇</a></li>\n</ul>"},{"title":"基本概念","date":"2017-12-02T07:22:50.000Z","_content":"待","source":"_posts/基本概念.md","raw":"---\ntitle: 基本概念\ndate: 2017-12-2 15:22:50\ncategories: \n- 机器学习\ntags:\n- 机器学习\n---\n待","slug":"基本概念","published":1,"updated":"2017-12-03T07:34:56.987Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvj0014qslp93pg7es3","content":"<p>待</p>\n","site":{"data":{}},"excerpt":"","more":"<p>待</p>\n"},{"title":"朴素贝叶斯分类器","mathjax":true,"date":"2017-12-08T13:41:50.000Z","top":true,"_content":"　　朴素贝叶斯法(naive Bayes)是基于贝叶斯定理与特征条件独立假设的分类方法。\n# 一、概念\n1.贝叶斯公式\n$$P(\\theta|x)=\\frac{P(\\theta)P(x|\\theta)}{P(x)}\\tag{1}$$\n　　式中，$x$为观察到的数据，$\\theta$为决定数据分布的参数，$P(\\theta|x)$为后验概率(posterior)，$P(x)$为迹象(evidence)，$P(\\theta)$为先验概率(prior)，$P(x|\\theta)$为似然估计(likelihood)。\n<!-- more --> \n2.特征条件独立假设\n　　特征条件独立假设意为：用于分类的特征在类确定的情况下都是条件独立的。\n$$P(x|c) = \\prod\\limits_{i=1}^dP(x_i|c)\\tag{2}$$\n　　式中，$d$为特征数目，$x_i$为$x$在第$i$个属性上的取值。\n# 二、朴素贝叶斯分类器\n　　基于贝叶斯定理，$P(c|x)$可写为：\n$$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\tag{3}$$\n　　不难发现，基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：**类条件概率$P(x|c)$是所有属性上的联合概率，难以从有限的训练样本直接估计而得**。\n　　**注**：条件概率分布$P(x|c)$有指数级数量的参数，其估计实际是不可行的。假设$$x_j$$可取值有$$S_j$$个，$$j=1,2,...,n$$，$y$可取值有$K$个，那么参数个数为$$K\\prod_{j=1}^n S_j$$。\n　　为避开这个障碍，朴素贝叶斯分类器采用了“**特征条件独立性假设**”，基于特征条件独立性假设，上式可重写为：\n$$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\prod\\limits_{i=1}^dP(x_i|c)\\tag{4}$$\n　　最终，**朴素贝叶斯分类器表达式**：\n$$h_{nb}(x)=\\mathop{argmax}\\limits_{c\\in{y}} P(c)\\prod\\limits_{i=1}^dP(x_i|c)\\tag{5}$$\n# 三、极大似然估计\n　　显然，朴素贝叶斯分类器的训练(学习)过程就是基于训练集$D$来估计**类先验概率**$P(c)$，并为**每个属性估计条件概率**$P(x_i|c)$。\n　　令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分部样本，则**类先验概率**的极大似然估计是\n$$P(c) = \\frac{|D_c|}{|D|}\\tag{6}$$\n　　对于**离散属性**而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则**条件概率**$P(x_i|c)$的极大似然估计是\n$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\tag{7}$$\n　　对于**连续属性**可考虑概率密度函数,假定`$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$`,其中`$\\mu_{c,i}$`和`$\\sigma_{c,i}^2$`分别是第$c$类样本在第$i$个属性上取值的均值和方差，则有\n$$P(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}}exp(-\\frac{(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\\tag{8}$$\n# 四、贝叶斯估计\n　　用极大似然估计可能会出现所要估计的概率值为0的情况。为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，即遇到$P(x_i|c)=0$的情况，这会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用**贝叶斯估计**(Bayesian estimation)。\n　　具体来说，令$K$表示训练集$D$中可能出现的类别数，$S_i$表示第$i$个属性可能的取值数，先验概率和条件概率的贝叶斯估计是\n$$\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+\\lambda}{|D|+K \\lambda}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+\\lambda}{|D_c|+S_i \\lambda}\\tag{10}\n\\end{eqnarray*}\n$$\n式中$\\lambda \\geq 0$。等价于在随机变量各个取值的频数上赋予一个正数$\\lambda>0$。当$\\lambda=0$时，就是极大似然估计。常取$\\lambda=1$,这时称为拉普拉斯平滑(Laplace smoothing)。则式$(9)$和$(10)$分别修正为：\n$$\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+1}{|D|+K}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+1}{|D_c|+S_i}\\tag{10}\n\\end{eqnarray*}\n$$\nps:做完《机器学习》和《统计学习方法》中贝叶斯分类器一章的例题，可全部理解。\n# 五、参考资料\n- 周志华，机器学习\n- 李航，统计学习方法\n- [朴素贝叶斯分类器](https://wizardforcel.gitbooks.io/dm-algo-top10/content/naive-bayes.html)\n- [分类算法之朴素贝叶斯分类](http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html)\n- [先验分布、后验分布、似然估计](https://www.zhihu.com/question/24261751/answer/158547500)","source":"_posts/朴素贝叶斯分类器.md","raw":"---\ntitle: 朴素贝叶斯分类器\nmathjax: true\ndate: 2017-12-8 21:41:50\ntop: true\ncategories: \n- 机器学习\ntags:\n---\n　　朴素贝叶斯法(naive Bayes)是基于贝叶斯定理与特征条件独立假设的分类方法。\n# 一、概念\n1.贝叶斯公式\n$$P(\\theta|x)=\\frac{P(\\theta)P(x|\\theta)}{P(x)}\\tag{1}$$\n　　式中，$x$为观察到的数据，$\\theta$为决定数据分布的参数，$P(\\theta|x)$为后验概率(posterior)，$P(x)$为迹象(evidence)，$P(\\theta)$为先验概率(prior)，$P(x|\\theta)$为似然估计(likelihood)。\n<!-- more --> \n2.特征条件独立假设\n　　特征条件独立假设意为：用于分类的特征在类确定的情况下都是条件独立的。\n$$P(x|c) = \\prod\\limits_{i=1}^dP(x_i|c)\\tag{2}$$\n　　式中，$d$为特征数目，$x_i$为$x$在第$i$个属性上的取值。\n# 二、朴素贝叶斯分类器\n　　基于贝叶斯定理，$P(c|x)$可写为：\n$$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\tag{3}$$\n　　不难发现，基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：**类条件概率$P(x|c)$是所有属性上的联合概率，难以从有限的训练样本直接估计而得**。\n　　**注**：条件概率分布$P(x|c)$有指数级数量的参数，其估计实际是不可行的。假设$$x_j$$可取值有$$S_j$$个，$$j=1,2,...,n$$，$y$可取值有$K$个，那么参数个数为$$K\\prod_{j=1}^n S_j$$。\n　　为避开这个障碍，朴素贝叶斯分类器采用了“**特征条件独立性假设**”，基于特征条件独立性假设，上式可重写为：\n$$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\prod\\limits_{i=1}^dP(x_i|c)\\tag{4}$$\n　　最终，**朴素贝叶斯分类器表达式**：\n$$h_{nb}(x)=\\mathop{argmax}\\limits_{c\\in{y}} P(c)\\prod\\limits_{i=1}^dP(x_i|c)\\tag{5}$$\n# 三、极大似然估计\n　　显然，朴素贝叶斯分类器的训练(学习)过程就是基于训练集$D$来估计**类先验概率**$P(c)$，并为**每个属性估计条件概率**$P(x_i|c)$。\n　　令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分部样本，则**类先验概率**的极大似然估计是\n$$P(c) = \\frac{|D_c|}{|D|}\\tag{6}$$\n　　对于**离散属性**而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则**条件概率**$P(x_i|c)$的极大似然估计是\n$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\tag{7}$$\n　　对于**连续属性**可考虑概率密度函数,假定`$p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)$`,其中`$\\mu_{c,i}$`和`$\\sigma_{c,i}^2$`分别是第$c$类样本在第$i$个属性上取值的均值和方差，则有\n$$P(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}}exp(-\\frac{(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\\tag{8}$$\n# 四、贝叶斯估计\n　　用极大似然估计可能会出现所要估计的概率值为0的情况。为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，即遇到$P(x_i|c)=0$的情况，这会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用**贝叶斯估计**(Bayesian estimation)。\n　　具体来说，令$K$表示训练集$D$中可能出现的类别数，$S_i$表示第$i$个属性可能的取值数，先验概率和条件概率的贝叶斯估计是\n$$\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+\\lambda}{|D|+K \\lambda}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+\\lambda}{|D_c|+S_i \\lambda}\\tag{10}\n\\end{eqnarray*}\n$$\n式中$\\lambda \\geq 0$。等价于在随机变量各个取值的频数上赋予一个正数$\\lambda>0$。当$\\lambda=0$时，就是极大似然估计。常取$\\lambda=1$,这时称为拉普拉斯平滑(Laplace smoothing)。则式$(9)$和$(10)$分别修正为：\n$$\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+1}{|D|+K}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+1}{|D_c|+S_i}\\tag{10}\n\\end{eqnarray*}\n$$\nps:做完《机器学习》和《统计学习方法》中贝叶斯分类器一章的例题，可全部理解。\n# 五、参考资料\n- 周志华，机器学习\n- 李航，统计学习方法\n- [朴素贝叶斯分类器](https://wizardforcel.gitbooks.io/dm-algo-top10/content/naive-bayes.html)\n- [分类算法之朴素贝叶斯分类](http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html)\n- [先验分布、后验分布、似然估计](https://www.zhihu.com/question/24261751/answer/158547500)","slug":"朴素贝叶斯分类器","published":1,"updated":"2018-02-03T10:23:13.500Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvl0017qslp9th7w79s","content":"<p>　　朴素贝叶斯法(naive Bayes)是基于贝叶斯定理与特征条件独立假设的分类方法。</p>\n<h1 id=\"一、概念\"><a href=\"#一、概念\" class=\"headerlink\" title=\"一、概念\"></a>一、概念</h1><p>1.贝叶斯公式</p>\n<script type=\"math/tex; mode=display\">P(\\theta|x)=\\frac{P(\\theta)P(x|\\theta)}{P(x)}\\tag{1}</script><p>　　式中，$x$为观察到的数据，$\\theta$为决定数据分布的参数，$P(\\theta|x)$为后验概率(posterior)，$P(x)$为迹象(evidence)，$P(\\theta)$为先验概率(prior)，$P(x|\\theta)$为似然估计(likelihood)。<br><a id=\"more\"></a><br>2.特征条件独立假设<br>　　特征条件独立假设意为：用于分类的特征在类确定的情况下都是条件独立的。</p>\n<script type=\"math/tex; mode=display\">P(x|c) = \\prod\\limits_{i=1}^dP(x_i|c)\\tag{2}</script><p>　　式中，$d$为特征数目，$x_i$为$x$在第$i$个属性上的取值。</p>\n<h1 id=\"二、朴素贝叶斯分类器\"><a href=\"#二、朴素贝叶斯分类器\" class=\"headerlink\" title=\"二、朴素贝叶斯分类器\"></a>二、朴素贝叶斯分类器</h1><p>　　基于贝叶斯定理，$P(c|x)$可写为：</p>\n<script type=\"math/tex; mode=display\">P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\tag{3}</script><p>　　不难发现，基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：<strong>类条件概率$P(x|c)$是所有属性上的联合概率，难以从有限的训练样本直接估计而得</strong>。<br>　　<strong>注</strong>：条件概率分布$P(x|c)$有指数级数量的参数，其估计实际是不可行的。假设<script type=\"math/tex\">x_j</script>可取值有<script type=\"math/tex\">S_j</script>个，<script type=\"math/tex\">j=1,2,...,n</script>，$y$可取值有$K$个，那么参数个数为<script type=\"math/tex\">K\\prod_{j=1}^n S_j</script>。<br>　　为避开这个障碍，朴素贝叶斯分类器采用了“<strong>特征条件独立性假设</strong>”，基于特征条件独立性假设，上式可重写为：</p>\n<script type=\"math/tex; mode=display\">P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\prod\\limits_{i=1}^dP(x_i|c)\\tag{4}</script><p>　　最终，<strong>朴素贝叶斯分类器表达式</strong>：</p>\n<script type=\"math/tex; mode=display\">h_{nb}(x)=\\mathop{argmax}\\limits_{c\\in{y}} P(c)\\prod\\limits_{i=1}^dP(x_i|c)\\tag{5}</script><h1 id=\"三、极大似然估计\"><a href=\"#三、极大似然估计\" class=\"headerlink\" title=\"三、极大似然估计\"></a>三、极大似然估计</h1><p>　　显然，朴素贝叶斯分类器的训练(学习)过程就是基于训练集$D$来估计<strong>类先验概率</strong>$P(c)$，并为<strong>每个属性估计条件概率</strong>$P(x_i|c)$。<br>　　令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分部样本，则<strong>类先验概率</strong>的极大似然估计是</p>\n<script type=\"math/tex; mode=display\">P(c) = \\frac{|D_c|}{|D|}\\tag{6}</script><p>　　对于<strong>离散属性</strong>而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则<strong>条件概率</strong>$P(x_i|c)$的极大似然估计是</p>\n<script type=\"math/tex; mode=display\">P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\tag{7}</script><p>　　对于<strong>连续属性</strong>可考虑概率密度函数,假定<script type=\"math/tex\">p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)</script>,其中<script type=\"math/tex\">\\mu_{c,i}</script>和<script type=\"math/tex\">\\sigma_{c,i}^2</script>分别是第$c$类样本在第$i$个属性上取值的均值和方差，则有</p>\n<script type=\"math/tex; mode=display\">P(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}}exp(-\\frac{(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\\tag{8}</script><h1 id=\"四、贝叶斯估计\"><a href=\"#四、贝叶斯估计\" class=\"headerlink\" title=\"四、贝叶斯估计\"></a>四、贝叶斯估计</h1><p>　　用极大似然估计可能会出现所要估计的概率值为0的情况。为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，即遇到$P(x_i|c)=0$的情况，这会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用<strong>贝叶斯估计</strong>(Bayesian estimation)。<br>　　具体来说，令$K$表示训练集$D$中可能出现的类别数，$S_i$表示第$i$个属性可能的取值数，先验概率和条件概率的贝叶斯估计是</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+\\lambda}{|D|+K \\lambda}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+\\lambda}{|D_c|+S_i \\lambda}\\tag{10}\n\\end{eqnarray*}</script><p>式中$\\lambda \\geq 0$。等价于在随机变量各个取值的频数上赋予一个正数$\\lambda&gt;0$。当$\\lambda=0$时，就是极大似然估计。常取$\\lambda=1$,这时称为拉普拉斯平滑(Laplace smoothing)。则式$(9)$和$(10)$分别修正为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+1}{|D|+K}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+1}{|D_c|+S_i}\\tag{10}\n\\end{eqnarray*}</script><p>ps:做完《机器学习》和《统计学习方法》中贝叶斯分类器一章的例题，可全部理解。</p>\n<h1 id=\"五、参考资料\"><a href=\"#五、参考资料\" class=\"headerlink\" title=\"五、参考资料\"></a>五、参考资料</h1><ul>\n<li>周志华，机器学习</li>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://wizardforcel.gitbooks.io/dm-algo-top10/content/naive-bayes.html\" target=\"_blank\" rel=\"noopener\">朴素贝叶斯分类器</a></li>\n<li><a href=\"http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html\" target=\"_blank\" rel=\"noopener\">分类算法之朴素贝叶斯分类</a></li>\n<li><a href=\"https://www.zhihu.com/question/24261751/answer/158547500\" target=\"_blank\" rel=\"noopener\">先验分布、后验分布、似然估计</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　朴素贝叶斯法(naive Bayes)是基于贝叶斯定理与特征条件独立假设的分类方法。</p>\n<h1 id=\"一、概念\"><a href=\"#一、概念\" class=\"headerlink\" title=\"一、概念\"></a>一、概念</h1><p>1.贝叶斯公式</p>\n<script type=\"math/tex; mode=display\">P(\\theta|x)=\\frac{P(\\theta)P(x|\\theta)}{P(x)}\\tag{1}</script><p>　　式中，$x$为观察到的数据，$\\theta$为决定数据分布的参数，$P(\\theta|x)$为后验概率(posterior)，$P(x)$为迹象(evidence)，$P(\\theta)$为先验概率(prior)，$P(x|\\theta)$为似然估计(likelihood)。<br>","more":"<br>2.特征条件独立假设<br>　　特征条件独立假设意为：用于分类的特征在类确定的情况下都是条件独立的。</p>\n<script type=\"math/tex; mode=display\">P(x|c) = \\prod\\limits_{i=1}^dP(x_i|c)\\tag{2}</script><p>　　式中，$d$为特征数目，$x_i$为$x$在第$i$个属性上的取值。</p>\n<h1 id=\"二、朴素贝叶斯分类器\"><a href=\"#二、朴素贝叶斯分类器\" class=\"headerlink\" title=\"二、朴素贝叶斯分类器\"></a>二、朴素贝叶斯分类器</h1><p>　　基于贝叶斯定理，$P(c|x)$可写为：</p>\n<script type=\"math/tex; mode=display\">P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\tag{3}</script><p>　　不难发现，基于贝叶斯公式来估计后验概率$P(c|x)$的主要困难在于：<strong>类条件概率$P(x|c)$是所有属性上的联合概率，难以从有限的训练样本直接估计而得</strong>。<br>　　<strong>注</strong>：条件概率分布$P(x|c)$有指数级数量的参数，其估计实际是不可行的。假设<script type=\"math/tex\">x_j</script>可取值有<script type=\"math/tex\">S_j</script>个，<script type=\"math/tex\">j=1,2,...,n</script>，$y$可取值有$K$个，那么参数个数为<script type=\"math/tex\">K\\prod_{j=1}^n S_j</script>。<br>　　为避开这个障碍，朴素贝叶斯分类器采用了“<strong>特征条件独立性假设</strong>”，基于特征条件独立性假设，上式可重写为：</p>\n<script type=\"math/tex; mode=display\">P(c|x)=\\frac{P(c)P(x|c)}{P(x)}=\\frac{P(c)}{P(x)}\\prod\\limits_{i=1}^dP(x_i|c)\\tag{4}</script><p>　　最终，<strong>朴素贝叶斯分类器表达式</strong>：</p>\n<script type=\"math/tex; mode=display\">h_{nb}(x)=\\mathop{argmax}\\limits_{c\\in{y}} P(c)\\prod\\limits_{i=1}^dP(x_i|c)\\tag{5}</script><h1 id=\"三、极大似然估计\"><a href=\"#三、极大似然估计\" class=\"headerlink\" title=\"三、极大似然估计\"></a>三、极大似然估计</h1><p>　　显然，朴素贝叶斯分类器的训练(学习)过程就是基于训练集$D$来估计<strong>类先验概率</strong>$P(c)$，并为<strong>每个属性估计条件概率</strong>$P(x_i|c)$。<br>　　令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分部样本，则<strong>类先验概率</strong>的极大似然估计是</p>\n<script type=\"math/tex; mode=display\">P(c) = \\frac{|D_c|}{|D|}\\tag{6}</script><p>　　对于<strong>离散属性</strong>而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则<strong>条件概率</strong>$P(x_i|c)$的极大似然估计是</p>\n<script type=\"math/tex; mode=display\">P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\tag{7}</script><p>　　对于<strong>连续属性</strong>可考虑概率密度函数,假定<script type=\"math/tex\">p(x_i|c)\\sim N(\\mu_{c,i},\\sigma_{c,i}^2)</script>,其中<script type=\"math/tex\">\\mu_{c,i}</script>和<script type=\"math/tex\">\\sigma_{c,i}^2</script>分别是第$c$类样本在第$i$个属性上取值的均值和方差，则有</p>\n<script type=\"math/tex; mode=display\">P(x_i|c)=\\frac{1}{\\sqrt{2\\pi}\\sigma_{c,i}}exp(-\\frac{(x-\\mu_{c,i})^2}{2\\sigma_{c,i}^2})\\tag{8}</script><h1 id=\"四、贝叶斯估计\"><a href=\"#四、贝叶斯估计\" class=\"headerlink\" title=\"四、贝叶斯估计\"></a>四、贝叶斯估计</h1><p>　　用极大似然估计可能会出现所要估计的概率值为0的情况。为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，即遇到$P(x_i|c)=0$的情况，这会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用<strong>贝叶斯估计</strong>(Bayesian estimation)。<br>　　具体来说，令$K$表示训练集$D$中可能出现的类别数，$S_i$表示第$i$个属性可能的取值数，先验概率和条件概率的贝叶斯估计是</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+\\lambda}{|D|+K \\lambda}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+\\lambda}{|D_c|+S_i \\lambda}\\tag{10}\n\\end{eqnarray*}</script><p>式中$\\lambda \\geq 0$。等价于在随机变量各个取值的频数上赋予一个正数$\\lambda&gt;0$。当$\\lambda=0$时，就是极大似然估计。常取$\\lambda=1$,这时称为拉普拉斯平滑(Laplace smoothing)。则式$(9)$和$(10)$分别修正为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\hat{P}(c) &=& \\frac{|D_c|+1}{|D|+K}\\tag{9}\\\\\n\\hat{P}(x_i|c)&=&\\frac{|D_{c,x_i}|+1}{|D_c|+S_i}\\tag{10}\n\\end{eqnarray*}</script><p>ps:做完《机器学习》和《统计学习方法》中贝叶斯分类器一章的例题，可全部理解。</p>\n<h1 id=\"五、参考资料\"><a href=\"#五、参考资料\" class=\"headerlink\" title=\"五、参考资料\"></a>五、参考资料</h1><ul>\n<li>周志华，机器学习</li>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://wizardforcel.gitbooks.io/dm-algo-top10/content/naive-bayes.html\" target=\"_blank\" rel=\"noopener\">朴素贝叶斯分类器</a></li>\n<li><a href=\"http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html\" target=\"_blank\" rel=\"noopener\">分类算法之朴素贝叶斯分类</a></li>\n<li><a href=\"https://www.zhihu.com/question/24261751/answer/158547500\" target=\"_blank\" rel=\"noopener\">先验分布、后验分布、似然估计</a></li>\n</ul>"},{"title":"线性回归模型","mathjax":true,"top":true,"date":"2017-12-03T07:35:50.000Z","_content":"线性回归(linear regression)属于监督学习(supervised learning)中的回归(regression)问题，模型输出为连续值。\n## 1.模型\n### 1.1 假设函数\n假设函数：`$h_\\theta(x)=\\sum\\limits_{i=0}^n\\theta_i x_i=\\theta^Tx$`\n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,...,\\theta_n]^T\\in R^{n+1}$\n### 1.2 代价函数\n对于训练集：`$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)},...,(x^{(m)},y^{(m)})\\}$`，其中$y^{(i)}\\in R$\n代价函数： `$J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2$`\n<!-- more --> \n### 1.3 参数求解\n目的：$\\min\\limits_\\theta \\ J(\\theta)$\n#### 1.3.1 梯度下降法\n$$\\begin{split}\n\\theta_j : &=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n\\frac{\\partial}{\\partial\\theta_j}J(\\theta)&=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=2\\cdot\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x^{(i)})-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(\\sum_{k=1}^n\\theta_kx^{(i)}_k-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\n\\end{split}\n$$ \n注1：对于每一轮迭代，进行参数更新时，对参数$\\theta$中的$j=0,1,...,n$项同时更新。\n注2：线性回归的代价函数$J(\\theta)$没有局部最小值，只有全局最小值。\n\n#### 1.3.2 梯度下降在实际应用中的技巧\n（1）特征缩放\n- 进行特征缩放，确保所有特征在一个相似的尺度内，可以加速梯度下降，避免因为某一个或多个特征远大于其他特征而造成的许多额外的迭代。\n- 特征缩放：$x_1 = \\frac{x_1-\\mu_1}{s_1}$，$\\mu_1$为均值，$s_1$为方差或标准差或特征范围(特征中最大值减最小值)。\n- 建议：让每一个特征缩放到$-1\\leq x_i \\leq 1(x_0=1)$，上限为$-3$~$3$，下限为$\\frac{1}{3}$~$\\frac{1}{3}$。\n\n（2）学习率\n- 对于调试：对于足够小的学习率$\\alpha$，$J(\\theta)$应该每一次迭代都减小；太小的$\\alpha$会导致收敛过慢；太大的$\\alpha$会导致$J(\\theta)$不减小或不收敛。\n- 对于学习率选择：确定一个不能再小的$\\alpha_0$，确定一个不能再大的$\\alpha_1$，选择比$\\alpha_1$小一点的尽量大的$\\alpha$。\n建议：尝试 $...,0.001,0.003,0.01,0.03,0.1,0.3,1,...$\n\n#### 1.3.3 正规方程\n$$\n\\begin{eqnarray*}\nJ(\\theta)&=&\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=&\\frac{1}{2}(y-X\\theta)^T(y-X\\theta)\n\\end{eqnarray*}$$\n式中，`$X_{m\\times(n+1)}= \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\ \\vdots\\\\ {x^{(m)}}^T\\end{bmatrix}$`，`$y_{m\\times 1}= \\begin{bmatrix} {y^{(1)}} \\\\ {y^{(2)}} \\\\ \\vdots\\\\ {y^{(m)}}\\end{bmatrix}$`，`$\\theta_{(n+1)\\times 1}=\\begin{bmatrix} \\theta_0 \\\\  \\theta_1 \\\\ \\vdots\\\\  \\theta_n \\end{bmatrix}$`，`$x_{(n+1)\\times 1}=\\begin{bmatrix} x_0 \\\\  x_1 \\\\ \\vdots\\\\  x_n \\end{bmatrix}$`\n矩阵微分中有如下结论：$\\frac{\\partial A\\theta}{\\partial\\theta}=A^T$和$\\frac{\\partial\\theta^TA\\theta}{\\partial\\theta}=2A^T\\theta$。\n$$\n\\begin{eqnarray*}\n\\frac{\\partial J(\\theta)}{\\partial\\theta}&=&\\frac{\\partial}{\\partial\\theta}(y^Ty+\\theta^TX^TX\\theta-2y^TX\\theta)\\\\\n&=&2X^TX\\theta-2X^Ty\n\\end{eqnarray*}$$\n上式中$y^TX\\theta$是标量，令$\\frac{\\partial J(\\theta)}{\\partial\\theta}=0$，得：\n$$X^TX\\theta=X^Ty$$\n上式也称为正规方程。\n$$\\theta=(X^TX)^{-1}X^Ty$$\n注：$X^TX$是可逆的，只要$X^TX$的列线性无关。\n## 2.概率解释\n1.假设每一个标签$y^{(i)}$符合均值为$\\theta^Tx^{(i)}$及方差为$\\sigma^2$的高斯分布：\n$$y^{(i)}=N(\\theta^Tx^{(i)},\\sigma^2)=\\theta^Tx^{(i)}+N(0,\\sigma^2)$$\n2.已知输入及参数，预测值的概率分步如下：\n$$P(y^{(i)}|x^{(i)};\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$$\n3.似然函数如下：\n$$\n\\begin{eqnarray*}\nL(\\theta)&=&\\prod\\limits_{i=1}^mP(y^{(i)}|x^{(i)},\\theta)\\\\\n&=&\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\n\\end{eqnarray*}\n$$\n4.似然函数的$log$形式如下：\n$$\\begin{eqnarray*}\nl(\\theta)&=&logL(\\theta)\\\\\n&=&log\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&\\sum\\limits_{i=1}^mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2\n\\end{eqnarray*}$$\n最大化似然函数$l(\\theta)$等价于最小化代价函数`$J(\\theta)=\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2$`\n注：一维正态分布PDF：$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$ \n对数函数和差性质：`$log_\\alpha AB=log_\\alpha A+log_\\alpha B$`；`$log_\\alpha\\frac{A}{B}=log_\\alpha A-log_\\alpha B$`\n## 3.正则化\n### 3.1 岭回归（L2范数正则化）\n$$\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||^2_2$$\n式中，`$||\\theta||^2_2=\\sum\\limits_{j=1}^n\\theta^2_j=\\theta^T\\theta$`\n### 3.2 lasso回归(L1范数正则化)\n$$\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||_1$$\n式中，`$||\\theta||_1=\\sum\\limits_{j=1}^n|\\theta_j|$`\n注1:\n- L0：计算非零个数，用于产生稀疏性，但是在实际研究中很少用，因为L0范数很难优化求解，是一个NP-hard问题，因此更多情况下使用L1范数近似；\n- L1：计算绝对值之和，用以产生稀疏性，因为它是L0范式的一个最优凸近似，容易优化求解；\n- L2：计算平方和再开根号，L2范数更多是防止过拟合，并且让优化求解变得稳定很快速（这是因为加入了L2范式之后，满足了强凸）。\n\n注2：对于向量范数：\n- p范数：`$||x||_p=(\\sum\\limits_{i=1}^n |x_i|^p)^{\\frac{1}{p}}$`\n- L1范数：`$||x||_1=\\sum\\limits_{i=1}^n |x_i|$`\n- L2范数：`$||x||_2=\\sqrt{\\sum\\limits_{i=1}^n x^2_i}$`\n\n## 4.参考资料\n- [ Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- [林轩田，机器学习基石](https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf)\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- 周志华，机器学习\n\n\n\n","source":"_posts/线性回归模型.md","raw":"---\ntitle: 线性回归模型\nmathjax: true\ntop: true\ndate: 2017-12-3 15:35:50\ncategories: \n- 机器学习\ntags:\n- 线性回归\n- linear regression\n- 似然估计\n- 梯度下降\n- 正规方程\n- 正则化\n---\n线性回归(linear regression)属于监督学习(supervised learning)中的回归(regression)问题，模型输出为连续值。\n## 1.模型\n### 1.1 假设函数\n假设函数：`$h_\\theta(x)=\\sum\\limits_{i=0}^n\\theta_i x_i=\\theta^Tx$`\n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,...,\\theta_n]^T\\in R^{n+1}$\n### 1.2 代价函数\n对于训练集：`$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)},...,(x^{(m)},y^{(m)})\\}$`，其中$y^{(i)}\\in R$\n代价函数： `$J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2$`\n<!-- more --> \n### 1.3 参数求解\n目的：$\\min\\limits_\\theta \\ J(\\theta)$\n#### 1.3.1 梯度下降法\n$$\\begin{split}\n\\theta_j : &=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n\\frac{\\partial}{\\partial\\theta_j}J(\\theta)&=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=2\\cdot\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x^{(i)})-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(\\sum_{k=1}^n\\theta_kx^{(i)}_k-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\n\\end{split}\n$$ \n注1：对于每一轮迭代，进行参数更新时，对参数$\\theta$中的$j=0,1,...,n$项同时更新。\n注2：线性回归的代价函数$J(\\theta)$没有局部最小值，只有全局最小值。\n\n#### 1.3.2 梯度下降在实际应用中的技巧\n（1）特征缩放\n- 进行特征缩放，确保所有特征在一个相似的尺度内，可以加速梯度下降，避免因为某一个或多个特征远大于其他特征而造成的许多额外的迭代。\n- 特征缩放：$x_1 = \\frac{x_1-\\mu_1}{s_1}$，$\\mu_1$为均值，$s_1$为方差或标准差或特征范围(特征中最大值减最小值)。\n- 建议：让每一个特征缩放到$-1\\leq x_i \\leq 1(x_0=1)$，上限为$-3$~$3$，下限为$\\frac{1}{3}$~$\\frac{1}{3}$。\n\n（2）学习率\n- 对于调试：对于足够小的学习率$\\alpha$，$J(\\theta)$应该每一次迭代都减小；太小的$\\alpha$会导致收敛过慢；太大的$\\alpha$会导致$J(\\theta)$不减小或不收敛。\n- 对于学习率选择：确定一个不能再小的$\\alpha_0$，确定一个不能再大的$\\alpha_1$，选择比$\\alpha_1$小一点的尽量大的$\\alpha$。\n建议：尝试 $...,0.001,0.003,0.01,0.03,0.1,0.3,1,...$\n\n#### 1.3.3 正规方程\n$$\n\\begin{eqnarray*}\nJ(\\theta)&=&\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=&\\frac{1}{2}(y-X\\theta)^T(y-X\\theta)\n\\end{eqnarray*}$$\n式中，`$X_{m\\times(n+1)}= \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\ \\vdots\\\\ {x^{(m)}}^T\\end{bmatrix}$`，`$y_{m\\times 1}= \\begin{bmatrix} {y^{(1)}} \\\\ {y^{(2)}} \\\\ \\vdots\\\\ {y^{(m)}}\\end{bmatrix}$`，`$\\theta_{(n+1)\\times 1}=\\begin{bmatrix} \\theta_0 \\\\  \\theta_1 \\\\ \\vdots\\\\  \\theta_n \\end{bmatrix}$`，`$x_{(n+1)\\times 1}=\\begin{bmatrix} x_0 \\\\  x_1 \\\\ \\vdots\\\\  x_n \\end{bmatrix}$`\n矩阵微分中有如下结论：$\\frac{\\partial A\\theta}{\\partial\\theta}=A^T$和$\\frac{\\partial\\theta^TA\\theta}{\\partial\\theta}=2A^T\\theta$。\n$$\n\\begin{eqnarray*}\n\\frac{\\partial J(\\theta)}{\\partial\\theta}&=&\\frac{\\partial}{\\partial\\theta}(y^Ty+\\theta^TX^TX\\theta-2y^TX\\theta)\\\\\n&=&2X^TX\\theta-2X^Ty\n\\end{eqnarray*}$$\n上式中$y^TX\\theta$是标量，令$\\frac{\\partial J(\\theta)}{\\partial\\theta}=0$，得：\n$$X^TX\\theta=X^Ty$$\n上式也称为正规方程。\n$$\\theta=(X^TX)^{-1}X^Ty$$\n注：$X^TX$是可逆的，只要$X^TX$的列线性无关。\n## 2.概率解释\n1.假设每一个标签$y^{(i)}$符合均值为$\\theta^Tx^{(i)}$及方差为$\\sigma^2$的高斯分布：\n$$y^{(i)}=N(\\theta^Tx^{(i)},\\sigma^2)=\\theta^Tx^{(i)}+N(0,\\sigma^2)$$\n2.已知输入及参数，预测值的概率分步如下：\n$$P(y^{(i)}|x^{(i)};\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})$$\n3.似然函数如下：\n$$\n\\begin{eqnarray*}\nL(\\theta)&=&\\prod\\limits_{i=1}^mP(y^{(i)}|x^{(i)},\\theta)\\\\\n&=&\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\n\\end{eqnarray*}\n$$\n4.似然函数的$log$形式如下：\n$$\\begin{eqnarray*}\nl(\\theta)&=&logL(\\theta)\\\\\n&=&log\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&\\sum\\limits_{i=1}^mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2\n\\end{eqnarray*}$$\n最大化似然函数$l(\\theta)$等价于最小化代价函数`$J(\\theta)=\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2$`\n注：一维正态分布PDF：$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$ \n对数函数和差性质：`$log_\\alpha AB=log_\\alpha A+log_\\alpha B$`；`$log_\\alpha\\frac{A}{B}=log_\\alpha A-log_\\alpha B$`\n## 3.正则化\n### 3.1 岭回归（L2范数正则化）\n$$\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||^2_2$$\n式中，`$||\\theta||^2_2=\\sum\\limits_{j=1}^n\\theta^2_j=\\theta^T\\theta$`\n### 3.2 lasso回归(L1范数正则化)\n$$\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||_1$$\n式中，`$||\\theta||_1=\\sum\\limits_{j=1}^n|\\theta_j|$`\n注1:\n- L0：计算非零个数，用于产生稀疏性，但是在实际研究中很少用，因为L0范数很难优化求解，是一个NP-hard问题，因此更多情况下使用L1范数近似；\n- L1：计算绝对值之和，用以产生稀疏性，因为它是L0范式的一个最优凸近似，容易优化求解；\n- L2：计算平方和再开根号，L2范数更多是防止过拟合，并且让优化求解变得稳定很快速（这是因为加入了L2范式之后，满足了强凸）。\n\n注2：对于向量范数：\n- p范数：`$||x||_p=(\\sum\\limits_{i=1}^n |x_i|^p)^{\\frac{1}{p}}$`\n- L1范数：`$||x||_1=\\sum\\limits_{i=1}^n |x_i|$`\n- L2范数：`$||x||_2=\\sqrt{\\sum\\limits_{i=1}^n x^2_i}$`\n\n## 4.参考资料\n- [ Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- [林轩田，机器学习基石](https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf)\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- 周志华，机器学习\n\n\n\n","slug":"线性回归模型","published":1,"updated":"2018-01-31T13:44:28.894Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvm0019qslpjlnb44gj","content":"<p>线性回归(linear regression)属于监督学习(supervised learning)中的回归(regression)问题，模型输出为连续值。</p>\n<h2 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h2><h3 id=\"1-1-假设函数\"><a href=\"#1-1-假设函数\" class=\"headerlink\" title=\"1.1 假设函数\"></a>1.1 假设函数</h3><p>假设函数：<script type=\"math/tex\">h_\\theta(x)=\\sum\\limits_{i=0}^n\\theta_i x_i=\\theta^Tx</script><br>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,…,\\theta_n]^T\\in R^{n+1}$</p>\n<h3 id=\"1-2-代价函数\"><a href=\"#1-2-代价函数\" class=\"headerlink\" title=\"1.2 代价函数\"></a>1.2 代价函数</h3><p>对于训练集：<script type=\"math/tex\">\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)},...,(x^{(m)},y^{(m)})\\}</script>，其中$y^{(i)}\\in R$<br>代价函数： <script type=\"math/tex\">J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2</script><br><a id=\"more\"></a> </p>\n<h3 id=\"1-3-参数求解\"><a href=\"#1-3-参数求解\" class=\"headerlink\" title=\"1.3 参数求解\"></a>1.3 参数求解</h3><p>目的：$\\min\\limits_\\theta \\ J(\\theta)$</p>\n<h4 id=\"1-3-1-梯度下降法\"><a href=\"#1-3-1-梯度下降法\" class=\"headerlink\" title=\"1.3.1 梯度下降法\"></a>1.3.1 梯度下降法</h4><script type=\"math/tex; mode=display\">\\begin{split}\n\\theta_j : &=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n\\frac{\\partial}{\\partial\\theta_j}J(\\theta)&=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=2\\cdot\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x^{(i)})-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(\\sum_{k=1}^n\\theta_kx^{(i)}_k-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\n\\end{split}</script><p>注1：对于每一轮迭代，进行参数更新时，对参数$\\theta$中的$j=0,1,…,n$项同时更新。<br>注2：线性回归的代价函数$J(\\theta)$没有局部最小值，只有全局最小值。</p>\n<h4 id=\"1-3-2-梯度下降在实际应用中的技巧\"><a href=\"#1-3-2-梯度下降在实际应用中的技巧\" class=\"headerlink\" title=\"1.3.2 梯度下降在实际应用中的技巧\"></a>1.3.2 梯度下降在实际应用中的技巧</h4><p>（1）特征缩放</p>\n<ul>\n<li>进行特征缩放，确保所有特征在一个相似的尺度内，可以加速梯度下降，避免因为某一个或多个特征远大于其他特征而造成的许多额外的迭代。</li>\n<li>特征缩放：$x_1 = \\frac{x_1-\\mu_1}{s_1}$，$\\mu_1$为均值，$s_1$为方差或标准差或特征范围(特征中最大值减最小值)。</li>\n<li>建议：让每一个特征缩放到$-1\\leq x_i \\leq 1(x_0=1)$，上限为$-3$~$3$，下限为$\\frac{1}{3}$~$\\frac{1}{3}$。</li>\n</ul>\n<p>（2）学习率</p>\n<ul>\n<li>对于调试：对于足够小的学习率$\\alpha$，$J(\\theta)$应该每一次迭代都减小；太小的$\\alpha$会导致收敛过慢；太大的$\\alpha$会导致$J(\\theta)$不减小或不收敛。</li>\n<li>对于学习率选择：确定一个不能再小的$\\alpha_0$，确定一个不能再大的$\\alpha_1$，选择比$\\alpha_1$小一点的尽量大的$\\alpha$。<br>建议：尝试 $…,0.001,0.003,0.01,0.03,0.1,0.3,1,…$</li>\n</ul>\n<h4 id=\"1-3-3-正规方程\"><a href=\"#1-3-3-正规方程\" class=\"headerlink\" title=\"1.3.3 正规方程\"></a>1.3.3 正规方程</h4><script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nJ(\\theta)&=&\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=&\\frac{1}{2}(y-X\\theta)^T(y-X\\theta)\n\\end{eqnarray*}</script><p>式中，<script type=\"math/tex\">X_{m\\times(n+1)}= \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\ \\vdots\\\\ {x^{(m)}}^T\\end{bmatrix}</script>，<script type=\"math/tex\">y_{m\\times 1}= \\begin{bmatrix} {y^{(1)}} \\\\ {y^{(2)}} \\\\ \\vdots\\\\ {y^{(m)}}\\end{bmatrix}</script>，<script type=\"math/tex\">\\theta_{(n+1)\\times 1}=\\begin{bmatrix} \\theta_0 \\\\  \\theta_1 \\\\ \\vdots\\\\  \\theta_n \\end{bmatrix}</script>，<script type=\"math/tex\">x_{(n+1)\\times 1}=\\begin{bmatrix} x_0 \\\\  x_1 \\\\ \\vdots\\\\  x_n \\end{bmatrix}</script><br>矩阵微分中有如下结论：$\\frac{\\partial A\\theta}{\\partial\\theta}=A^T$和$\\frac{\\partial\\theta^TA\\theta}{\\partial\\theta}=2A^T\\theta$。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\frac{\\partial J(\\theta)}{\\partial\\theta}&=&\\frac{\\partial}{\\partial\\theta}(y^Ty+\\theta^TX^TX\\theta-2y^TX\\theta)\\\\\n&=&2X^TX\\theta-2X^Ty\n\\end{eqnarray*}</script><p>上式中$y^TX\\theta$是标量，令$\\frac{\\partial J(\\theta)}{\\partial\\theta}=0$，得：</p>\n<script type=\"math/tex; mode=display\">X^TX\\theta=X^Ty</script><p>上式也称为正规方程。</p>\n<script type=\"math/tex; mode=display\">\\theta=(X^TX)^{-1}X^Ty</script><p>注：$X^TX$是可逆的，只要$X^TX$的列线性无关。</p>\n<h2 id=\"2-概率解释\"><a href=\"#2-概率解释\" class=\"headerlink\" title=\"2.概率解释\"></a>2.概率解释</h2><p>1.假设每一个标签$y^{(i)}$符合均值为$\\theta^Tx^{(i)}$及方差为$\\sigma^2$的高斯分布：</p>\n<script type=\"math/tex; mode=display\">y^{(i)}=N(\\theta^Tx^{(i)},\\sigma^2)=\\theta^Tx^{(i)}+N(0,\\sigma^2)</script><p>2.已知输入及参数，预测值的概率分步如下：</p>\n<script type=\"math/tex; mode=display\">P(y^{(i)}|x^{(i)};\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})</script><p>3.似然函数如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nL(\\theta)&=&\\prod\\limits_{i=1}^mP(y^{(i)}|x^{(i)},\\theta)\\\\\n&=&\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\n\\end{eqnarray*}</script><p>4.似然函数的$log$形式如下：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nl(\\theta)&=&logL(\\theta)\\\\\n&=&log\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&\\sum\\limits_{i=1}^mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2\n\\end{eqnarray*}</script><p>最大化似然函数$l(\\theta)$等价于最小化代价函数<script type=\"math/tex\">J(\\theta)=\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2</script><br>注：一维正态分布PDF：$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$<br>对数函数和差性质：<script type=\"math/tex\">log_\\alpha AB=log_\\alpha A+log_\\alpha B</script>；<script type=\"math/tex\">log_\\alpha\\frac{A}{B}=log_\\alpha A-log_\\alpha B</script></p>\n<h2 id=\"3-正则化\"><a href=\"#3-正则化\" class=\"headerlink\" title=\"3.正则化\"></a>3.正则化</h2><h3 id=\"3-1-岭回归（L2范数正则化）\"><a href=\"#3-1-岭回归（L2范数正则化）\" class=\"headerlink\" title=\"3.1 岭回归（L2范数正则化）\"></a>3.1 岭回归（L2范数正则化）</h3><script type=\"math/tex; mode=display\">\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||^2_2</script><p>式中，<script type=\"math/tex\">||\\theta||^2_2=\\sum\\limits_{j=1}^n\\theta^2_j=\\theta^T\\theta</script></p>\n<h3 id=\"3-2-lasso回归-L1范数正则化\"><a href=\"#3-2-lasso回归-L1范数正则化\" class=\"headerlink\" title=\"3.2 lasso回归(L1范数正则化)\"></a>3.2 lasso回归(L1范数正则化)</h3><script type=\"math/tex; mode=display\">\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||_1</script><p>式中，<script type=\"math/tex\">||\\theta||_1=\\sum\\limits_{j=1}^n|\\theta_j|</script><br>注1:</p>\n<ul>\n<li>L0：计算非零个数，用于产生稀疏性，但是在实际研究中很少用，因为L0范数很难优化求解，是一个NP-hard问题，因此更多情况下使用L1范数近似；</li>\n<li>L1：计算绝对值之和，用以产生稀疏性，因为它是L0范式的一个最优凸近似，容易优化求解；</li>\n<li>L2：计算平方和再开根号，L2范数更多是防止过拟合，并且让优化求解变得稳定很快速（这是因为加入了L2范式之后，满足了强凸）。</li>\n</ul>\n<p>注2：对于向量范数：</p>\n<ul>\n<li>p范数：<script type=\"math/tex\">||x||_p=(\\sum\\limits_{i=1}^n |x_i|^p)^{\\frac{1}{p}}</script></li>\n<li>L1范数：<script type=\"math/tex\">||x||_1=\\sum\\limits_{i=1}^n |x_i|</script></li>\n<li>L2范数：<script type=\"math/tex\">||x||_2=\\sqrt{\\sum\\limits_{i=1}^n x^2_i}</script></li>\n</ul>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\"> Andrew Ng, Machine Learning</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习基石</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li>周志华，机器学习</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>线性回归(linear regression)属于监督学习(supervised learning)中的回归(regression)问题，模型输出为连续值。</p>\n<h2 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h2><h3 id=\"1-1-假设函数\"><a href=\"#1-1-假设函数\" class=\"headerlink\" title=\"1.1 假设函数\"></a>1.1 假设函数</h3><p>假设函数：<script type=\"math/tex\">h_\\theta(x)=\\sum\\limits_{i=0}^n\\theta_i x_i=\\theta^Tx</script><br>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,…,\\theta_n]^T\\in R^{n+1}$</p>\n<h3 id=\"1-2-代价函数\"><a href=\"#1-2-代价函数\" class=\"headerlink\" title=\"1.2 代价函数\"></a>1.2 代价函数</h3><p>对于训练集：<script type=\"math/tex\">\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)},...,(x^{(m)},y^{(m)})\\}</script>，其中$y^{(i)}\\in R$<br>代价函数： <script type=\"math/tex\">J(\\theta)=\\frac{1}{2m}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2</script><br>","more":"</p>\n<h3 id=\"1-3-参数求解\"><a href=\"#1-3-参数求解\" class=\"headerlink\" title=\"1.3 参数求解\"></a>1.3 参数求解</h3><p>目的：$\\min\\limits_\\theta \\ J(\\theta)$</p>\n<h4 id=\"1-3-1-梯度下降法\"><a href=\"#1-3-1-梯度下降法\" class=\"headerlink\" title=\"1.3.1 梯度下降法\"></a>1.3.1 梯度下降法</h4><script type=\"math/tex; mode=display\">\\begin{split}\n\\theta_j : &=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n\\frac{\\partial}{\\partial\\theta_j}J(\\theta)&=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=2\\cdot\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x^{(i)})-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})\\cdot\\frac{\\partial}{\\partial\\theta_j}(\\sum_{k=1}^n\\theta_kx^{(i)}_k-y^{(i)})\\\\\n&=\\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\n\\end{split}</script><p>注1：对于每一轮迭代，进行参数更新时，对参数$\\theta$中的$j=0,1,…,n$项同时更新。<br>注2：线性回归的代价函数$J(\\theta)$没有局部最小值，只有全局最小值。</p>\n<h4 id=\"1-3-2-梯度下降在实际应用中的技巧\"><a href=\"#1-3-2-梯度下降在实际应用中的技巧\" class=\"headerlink\" title=\"1.3.2 梯度下降在实际应用中的技巧\"></a>1.3.2 梯度下降在实际应用中的技巧</h4><p>（1）特征缩放</p>\n<ul>\n<li>进行特征缩放，确保所有特征在一个相似的尺度内，可以加速梯度下降，避免因为某一个或多个特征远大于其他特征而造成的许多额外的迭代。</li>\n<li>特征缩放：$x_1 = \\frac{x_1-\\mu_1}{s_1}$，$\\mu_1$为均值，$s_1$为方差或标准差或特征范围(特征中最大值减最小值)。</li>\n<li>建议：让每一个特征缩放到$-1\\leq x_i \\leq 1(x_0=1)$，上限为$-3$~$3$，下限为$\\frac{1}{3}$~$\\frac{1}{3}$。</li>\n</ul>\n<p>（2）学习率</p>\n<ul>\n<li>对于调试：对于足够小的学习率$\\alpha$，$J(\\theta)$应该每一次迭代都减小；太小的$\\alpha$会导致收敛过慢；太大的$\\alpha$会导致$J(\\theta)$不减小或不收敛。</li>\n<li>对于学习率选择：确定一个不能再小的$\\alpha_0$，确定一个不能再大的$\\alpha_1$，选择比$\\alpha_1$小一点的尽量大的$\\alpha$。<br>建议：尝试 $…,0.001,0.003,0.01,0.03,0.1,0.3,1,…$</li>\n</ul>\n<h4 id=\"1-3-3-正规方程\"><a href=\"#1-3-3-正规方程\" class=\"headerlink\" title=\"1.3.3 正规方程\"></a>1.3.3 正规方程</h4><script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nJ(\\theta)&=&\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2\\\\\n&=&\\frac{1}{2}(y-X\\theta)^T(y-X\\theta)\n\\end{eqnarray*}</script><p>式中，<script type=\"math/tex\">X_{m\\times(n+1)}= \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\ \\vdots\\\\ {x^{(m)}}^T\\end{bmatrix}</script>，<script type=\"math/tex\">y_{m\\times 1}= \\begin{bmatrix} {y^{(1)}} \\\\ {y^{(2)}} \\\\ \\vdots\\\\ {y^{(m)}}\\end{bmatrix}</script>，<script type=\"math/tex\">\\theta_{(n+1)\\times 1}=\\begin{bmatrix} \\theta_0 \\\\  \\theta_1 \\\\ \\vdots\\\\  \\theta_n \\end{bmatrix}</script>，<script type=\"math/tex\">x_{(n+1)\\times 1}=\\begin{bmatrix} x_0 \\\\  x_1 \\\\ \\vdots\\\\  x_n \\end{bmatrix}</script><br>矩阵微分中有如下结论：$\\frac{\\partial A\\theta}{\\partial\\theta}=A^T$和$\\frac{\\partial\\theta^TA\\theta}{\\partial\\theta}=2A^T\\theta$。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\n\\frac{\\partial J(\\theta)}{\\partial\\theta}&=&\\frac{\\partial}{\\partial\\theta}(y^Ty+\\theta^TX^TX\\theta-2y^TX\\theta)\\\\\n&=&2X^TX\\theta-2X^Ty\n\\end{eqnarray*}</script><p>上式中$y^TX\\theta$是标量，令$\\frac{\\partial J(\\theta)}{\\partial\\theta}=0$，得：</p>\n<script type=\"math/tex; mode=display\">X^TX\\theta=X^Ty</script><p>上式也称为正规方程。</p>\n<script type=\"math/tex; mode=display\">\\theta=(X^TX)^{-1}X^Ty</script><p>注：$X^TX$是可逆的，只要$X^TX$的列线性无关。</p>\n<h2 id=\"2-概率解释\"><a href=\"#2-概率解释\" class=\"headerlink\" title=\"2.概率解释\"></a>2.概率解释</h2><p>1.假设每一个标签$y^{(i)}$符合均值为$\\theta^Tx^{(i)}$及方差为$\\sigma^2$的高斯分布：</p>\n<script type=\"math/tex; mode=display\">y^{(i)}=N(\\theta^Tx^{(i)},\\sigma^2)=\\theta^Tx^{(i)}+N(0,\\sigma^2)</script><p>2.已知输入及参数，预测值的概率分步如下：</p>\n<script type=\"math/tex; mode=display\">P(y^{(i)}|x^{(i)};\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})</script><p>3.似然函数如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nL(\\theta)&=&\\prod\\limits_{i=1}^mP(y^{(i)}|x^{(i)},\\theta)\\\\\n&=&\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\n\\end{eqnarray*}</script><p>4.似然函数的$log$形式如下：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nl(\\theta)&=&logL(\\theta)\\\\\n&=&log\\prod\\limits_{i=1}^m\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&\\sum\\limits_{i=1}^mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2})\\\\\n&=&mlog\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{1}{\\sigma^2}\\cdot\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2\n\\end{eqnarray*}</script><p>最大化似然函数$l(\\theta)$等价于最小化代价函数<script type=\"math/tex\">J(\\theta)=\\frac{1}{2}\\sum\\limits_{i=1}^m(y^{(i)}-\\theta^Tx^{(i)})^2</script><br>注：一维正态分布PDF：$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$<br>对数函数和差性质：<script type=\"math/tex\">log_\\alpha AB=log_\\alpha A+log_\\alpha B</script>；<script type=\"math/tex\">log_\\alpha\\frac{A}{B}=log_\\alpha A-log_\\alpha B</script></p>\n<h2 id=\"3-正则化\"><a href=\"#3-正则化\" class=\"headerlink\" title=\"3.正则化\"></a>3.正则化</h2><h3 id=\"3-1-岭回归（L2范数正则化）\"><a href=\"#3-1-岭回归（L2范数正则化）\" class=\"headerlink\" title=\"3.1 岭回归（L2范数正则化）\"></a>3.1 岭回归（L2范数正则化）</h3><script type=\"math/tex; mode=display\">\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||^2_2</script><p>式中，<script type=\"math/tex\">||\\theta||^2_2=\\sum\\limits_{j=1}^n\\theta^2_j=\\theta^T\\theta</script></p>\n<h3 id=\"3-2-lasso回归-L1范数正则化\"><a href=\"#3-2-lasso回归-L1范数正则化\" class=\"headerlink\" title=\"3.2 lasso回归(L1范数正则化)\"></a>3.2 lasso回归(L1范数正则化)</h3><script type=\"math/tex; mode=display\">\\min_{\\theta}\\frac{1}{2}\\sum\\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2+\\lambda||\\theta||_1</script><p>式中，<script type=\"math/tex\">||\\theta||_1=\\sum\\limits_{j=1}^n|\\theta_j|</script><br>注1:</p>\n<ul>\n<li>L0：计算非零个数，用于产生稀疏性，但是在实际研究中很少用，因为L0范数很难优化求解，是一个NP-hard问题，因此更多情况下使用L1范数近似；</li>\n<li>L1：计算绝对值之和，用以产生稀疏性，因为它是L0范式的一个最优凸近似，容易优化求解；</li>\n<li>L2：计算平方和再开根号，L2范数更多是防止过拟合，并且让优化求解变得稳定很快速（这是因为加入了L2范式之后，满足了强凸）。</li>\n</ul>\n<p>注2：对于向量范数：</p>\n<ul>\n<li>p范数：<script type=\"math/tex\">||x||_p=(\\sum\\limits_{i=1}^n |x_i|^p)^{\\frac{1}{p}}</script></li>\n<li>L1范数：<script type=\"math/tex\">||x||_1=\\sum\\limits_{i=1}^n |x_i|</script></li>\n<li>L2范数：<script type=\"math/tex\">||x||_2=\\sqrt{\\sum\\limits_{i=1}^n x^2_i}</script></li>\n</ul>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\"> Andrew Ng, Machine Learning</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习基石</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li>周志华，机器学习</li>\n</ul>"},{"title":"随机森林","mathjax":true,"date":"2017-12-15T12:20:50.000Z","_content":"# 1.Bagging\nBagging是并行式集成学习方法最著名的带代表。Bagging的基本流程：\n- Bagging通过自主采样法(bootstrap sampling)在给定$m$个样本的数据集中，经过$m$次随机采样操作，得到含$m$个样本的采样集（有放回，初始训练集中有的样本在采样集里多次出现，有的则从未出现，初始训练集中约有63.2%的样本出现在采样集中）。\n- 照这样，采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练出一个基学习器。\n- 再将这$T$个基学习器进行结合。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。\n\n此外：\n- 可以证明：Bagging可以降低模型的方差。\n- 与标准Adaboost只适用于二分类任务不同，Bagging能不经修改地用于多分类、回归等任务。\n\n<!-- more --> \n# 2.随机森林\n随机森林(Random Forest, RF)是Bagging的一个扩展变体。**RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择**。\n**随机森林的建立**:基本就是两个步骤，随机采样与完全分裂。\n（1）随机采样\n　　首先是两个随机采样的过程，RF对输入的数据要进行行、列的采样。\n对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为$m$个，那么采样的样本也为$m$个，这选择好了的$m$个样本用来训练一个决策树，作为决策树根节点处的样本，同时使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现过拟合。\n- 注：只进行Bagging得到的多颗树，由于只是训练数据有一些不同，故得到的多颗树是高度相关的，因此带来的方差减少有限。故进一步采用随机选择一部分特征的方式，降低树的相关性。\n\n　　对于列采样，从$d$个属性中，选择$k$个($k << d$)，即：当每个样本有$d$个属性时，在决策树的每个节点需要分裂时，随机从这$d$个属性中选取出$k$个属性，满足条件$k << d$。\n（2）完全分裂\n　　对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。分裂的办法是：采用上面说的列采样的过程从这$k$个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。\n　　决策树形成过程中每个节点都要按完全分裂的方式来分裂，一直到不能够再分裂为止（如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。\n（3）其他\n　　首先，以上是未剪枝决策树的生成过程，一般很多的决策树算法都会包含剪枝过程来避免过拟合。但是由于随机森林的两个随机采样的过程保证了随机性，所以就算不剪枝也不容易出现过拟合，这也是随机森林的优势之一。\n　　此外，随机森林有2个参数需要人为控制，一个是森林中树的数量，一般建议取很大。另一个是$k$的大小，推荐$k$的值为$log_2d$。\n\n# 3.参考资料\n- 周志华，机器学习\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- [holybin，机器学习中的算法：决策树模型组合之随机森林](http://blog.csdn.net/holybin/article/details/25653597)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/随机森林.md","raw":"---\ntitle: 随机森林\nmathjax: true\ndate: 2017-12-15 20:20:50\ncategories: \n- 机器学习\ntags:\n---\n# 1.Bagging\nBagging是并行式集成学习方法最著名的带代表。Bagging的基本流程：\n- Bagging通过自主采样法(bootstrap sampling)在给定$m$个样本的数据集中，经过$m$次随机采样操作，得到含$m$个样本的采样集（有放回，初始训练集中有的样本在采样集里多次出现，有的则从未出现，初始训练集中约有63.2%的样本出现在采样集中）。\n- 照这样，采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练出一个基学习器。\n- 再将这$T$个基学习器进行结合。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。\n\n此外：\n- 可以证明：Bagging可以降低模型的方差。\n- 与标准Adaboost只适用于二分类任务不同，Bagging能不经修改地用于多分类、回归等任务。\n\n<!-- more --> \n# 2.随机森林\n随机森林(Random Forest, RF)是Bagging的一个扩展变体。**RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择**。\n**随机森林的建立**:基本就是两个步骤，随机采样与完全分裂。\n（1）随机采样\n　　首先是两个随机采样的过程，RF对输入的数据要进行行、列的采样。\n对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为$m$个，那么采样的样本也为$m$个，这选择好了的$m$个样本用来训练一个决策树，作为决策树根节点处的样本，同时使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现过拟合。\n- 注：只进行Bagging得到的多颗树，由于只是训练数据有一些不同，故得到的多颗树是高度相关的，因此带来的方差减少有限。故进一步采用随机选择一部分特征的方式，降低树的相关性。\n\n　　对于列采样，从$d$个属性中，选择$k$个($k << d$)，即：当每个样本有$d$个属性时，在决策树的每个节点需要分裂时，随机从这$d$个属性中选取出$k$个属性，满足条件$k << d$。\n（2）完全分裂\n　　对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。分裂的办法是：采用上面说的列采样的过程从这$k$个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。\n　　决策树形成过程中每个节点都要按完全分裂的方式来分裂，一直到不能够再分裂为止（如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。\n（3）其他\n　　首先，以上是未剪枝决策树的生成过程，一般很多的决策树算法都会包含剪枝过程来避免过拟合。但是由于随机森林的两个随机采样的过程保证了随机性，所以就算不剪枝也不容易出现过拟合，这也是随机森林的优势之一。\n　　此外，随机森林有2个参数需要人为控制，一个是森林中树的数量，一般建议取很大。另一个是$k$的大小，推荐$k$的值为$log_2d$。\n\n# 3.参考资料\n- 周志华，机器学习\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- [holybin，机器学习中的算法：决策树模型组合之随机森林](http://blog.csdn.net/holybin/article/details/25653597)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"随机森林","published":1,"updated":"2018-01-28T05:54:46.133Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4vvo001cqslplvulxu8p","content":"<h1 id=\"1-Bagging\"><a href=\"#1-Bagging\" class=\"headerlink\" title=\"1.Bagging\"></a>1.Bagging</h1><p>Bagging是并行式集成学习方法最著名的带代表。Bagging的基本流程：</p>\n<ul>\n<li>Bagging通过自主采样法(bootstrap sampling)在给定$m$个样本的数据集中，经过$m$次随机采样操作，得到含$m$个样本的采样集（有放回，初始训练集中有的样本在采样集里多次出现，有的则从未出现，初始训练集中约有63.2%的样本出现在采样集中）。</li>\n<li>照这样，采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练出一个基学习器。</li>\n<li>再将这$T$个基学习器进行结合。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。</li>\n</ul>\n<p>此外：</p>\n<ul>\n<li>可以证明：Bagging可以降低模型的方差。</li>\n<li>与标准Adaboost只适用于二分类任务不同，Bagging能不经修改地用于多分类、回归等任务。</li>\n</ul>\n<a id=\"more\"></a> \n<h1 id=\"2-随机森林\"><a href=\"#2-随机森林\" class=\"headerlink\" title=\"2.随机森林\"></a>2.随机森林</h1><p>随机森林(Random Forest, RF)是Bagging的一个扩展变体。<strong>RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择</strong>。<br><strong>随机森林的建立</strong>:基本就是两个步骤，随机采样与完全分裂。<br>（1）随机采样<br>　　首先是两个随机采样的过程，RF对输入的数据要进行行、列的采样。<br>对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为$m$个，那么采样的样本也为$m$个，这选择好了的$m$个样本用来训练一个决策树，作为决策树根节点处的样本，同时使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现过拟合。</p>\n<ul>\n<li>注：只进行Bagging得到的多颗树，由于只是训练数据有一些不同，故得到的多颗树是高度相关的，因此带来的方差减少有限。故进一步采用随机选择一部分特征的方式，降低树的相关性。</li>\n</ul>\n<p>　　对于列采样，从$d$个属性中，选择$k$个($k &lt;&lt; d$)，即：当每个样本有$d$个属性时，在决策树的每个节点需要分裂时，随机从这$d$个属性中选取出$k$个属性，满足条件$k &lt;&lt; d$。<br>（2）完全分裂<br>　　对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。分裂的办法是：采用上面说的列采样的过程从这$k$个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。<br>　　决策树形成过程中每个节点都要按完全分裂的方式来分裂，一直到不能够再分裂为止（如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。<br>（3）其他<br>　　首先，以上是未剪枝决策树的生成过程，一般很多的决策树算法都会包含剪枝过程来避免过拟合。但是由于随机森林的两个随机采样的过程保证了随机性，所以就算不剪枝也不容易出现过拟合，这也是随机森林的优势之一。<br>　　此外，随机森林有2个参数需要人为控制，一个是森林中树的数量，一般建议取很大。另一个是$k$的大小，推荐$k$的值为$log_2d$。</p>\n<h1 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h1><ul>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li><a href=\"http://blog.csdn.net/holybin/article/details/25653597\" target=\"_blank\" rel=\"noopener\">holybin，机器学习中的算法：决策树模型组合之随机森林</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-Bagging\"><a href=\"#1-Bagging\" class=\"headerlink\" title=\"1.Bagging\"></a>1.Bagging</h1><p>Bagging是并行式集成学习方法最著名的带代表。Bagging的基本流程：</p>\n<ul>\n<li>Bagging通过自主采样法(bootstrap sampling)在给定$m$个样本的数据集中，经过$m$次随机采样操作，得到含$m$个样本的采样集（有放回，初始训练集中有的样本在采样集里多次出现，有的则从未出现，初始训练集中约有63.2%的样本出现在采样集中）。</li>\n<li>照这样，采样出$T$个含$m$个训练样本的采样集，然后基于每个采样集训练出一个基学习器。</li>\n<li>再将这$T$个基学习器进行结合。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。</li>\n</ul>\n<p>此外：</p>\n<ul>\n<li>可以证明：Bagging可以降低模型的方差。</li>\n<li>与标准Adaboost只适用于二分类任务不同，Bagging能不经修改地用于多分类、回归等任务。</li>\n</ul>","more":"<h1 id=\"2-随机森林\"><a href=\"#2-随机森林\" class=\"headerlink\" title=\"2.随机森林\"></a>2.随机森林</h1><p>随机森林(Random Forest, RF)是Bagging的一个扩展变体。<strong>RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择</strong>。<br><strong>随机森林的建立</strong>:基本就是两个步骤，随机采样与完全分裂。<br>（1）随机采样<br>　　首先是两个随机采样的过程，RF对输入的数据要进行行、列的采样。<br>对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为$m$个，那么采样的样本也为$m$个，这选择好了的$m$个样本用来训练一个决策树，作为决策树根节点处的样本，同时使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现过拟合。</p>\n<ul>\n<li>注：只进行Bagging得到的多颗树，由于只是训练数据有一些不同，故得到的多颗树是高度相关的，因此带来的方差减少有限。故进一步采用随机选择一部分特征的方式，降低树的相关性。</li>\n</ul>\n<p>　　对于列采样，从$d$个属性中，选择$k$个($k &lt;&lt; d$)，即：当每个样本有$d$个属性时，在决策树的每个节点需要分裂时，随机从这$d$个属性中选取出$k$个属性，满足条件$k &lt;&lt; d$。<br>（2）完全分裂<br>　　对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。分裂的办法是：采用上面说的列采样的过程从这$k$个属性中采用某种策略（比如说信息增益）来选择1个属性作为该节点的分裂属性。<br>　　决策树形成过程中每个节点都要按完全分裂的方式来分裂，一直到不能够再分裂为止（如果下一次该节点选出来的那一个属性是刚刚其父节点分裂时用过的属性，则该节点已经达到了叶子节点，无须继续分裂了）。<br>（3）其他<br>　　首先，以上是未剪枝决策树的生成过程，一般很多的决策树算法都会包含剪枝过程来避免过拟合。但是由于随机森林的两个随机采样的过程保证了随机性，所以就算不剪枝也不容易出现过拟合，这也是随机森林的优势之一。<br>　　此外，随机森林有2个参数需要人为控制，一个是森林中树的数量，一般建议取很大。另一个是$k$的大小，推荐$k$的值为$log_2d$。</p>\n<h1 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h1><ul>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li><a href=\"http://blog.csdn.net/holybin/article/details/25653597\" target=\"_blank\" rel=\"noopener\">holybin，机器学习中的算法：决策树模型组合之随机森林</a></li>\n</ul>"},{"title":"CART算法","mathjax":true,"date":"2017-12-07T14:30:50.000Z","_content":"　　CART(classification and regression tree)是广泛应用的决策树学习方法，既可以用于分类也可以用于回归。\n## 一、简介\n（1）CART决策树的定义：CART假设决策树是**二叉树**，内部结点特征的取值只有“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。\n- 注：ID3/C4.5算法中决策树的每个叶子结点对应一个决策。CART算法中分类回归树的每个叶子结点给出一个预测分数(score)。\n\n（2）CART决策树的生成：CART决策树的生成就是递归地构建二叉决策树的过程，对**回归树**用**平方误差最小化准则**，对**分类树**用**基尼指数最小化准则**，进行特征选择，生成二叉树。\n（3）CART决策树的学习：同样包括三个步骤，特征选择、树的生成及剪枝。\n<!-- more --> \n## 二、回归树的生成\n　　**一个回归树**对应着**特征空间的一个划分**以及在**划分的单元上的输出值**；假设已将输入空间划分为$M$个单元$R_1,R_2,...,R_m$，并且在每个单元$R_m$上都有一个固定的输出值$c_m$，于是回归树的模型可表示为：\n$$f(x) = \\sum_{m=1}^Mc_m I(x\\in R_m)$$\n　　当输入空间的划分确定时，CART回归树用平方误差$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$来表示回归树对于训练集的预测误差，用平方误差最小的准则求解每个单元上的最优输出值$\\hat{c}_m$。\n- **注**：$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$即为求解单元$R_m$上的最优输出值$\\hat{c}_m$时的代价函数。\n\n　　易知，单元$R_m$上的$c_m$的最优值$\\hat{c}_m$是$R_m$上的所有输入实例$x_i$对应的输出$y_i$的均值，即\n$$\\hat{c}_m=ave(y_i|x_i \\in R_m)$$\n### 2.1 最小二乘回归树生成算法\n输入：训练数据集$D$\n输出：回归树$f(x)$\n在训练数据集所在的特征空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；\n（1）选择最优切分变量 $j$ 和切分点$s$ ，求解：\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式预测误差（平方误差）达到最小值的对$(j，s)$；其中$R_m$是被划分的输入空间，$c_m$是空间$R_m$对应的固定输出值。\n- **注**：$$[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$即为确定变量$j$上的切分点$s$时的代价函数。\n\n（2）用选定的对$(j,s)$划分区域并决定相应的输出值：\n$$R_1(j,s)=\\lbrace x\\mid x^{(j)} \\le s \\rbrace , \\quad R_2(j,s)=\\lbrace x\\mid x^{(j)}\\gt s \\rbrace\\\\\n\\hat c_m = {1\\over N_m}\\sum_{x_i\\in R_m(j,s)}y_i , \\quad x\\in R_m ,\\quad m=1,2$$\n（3）继续对两个子区域调用步骤（1），（2），直至满足停止条件。\n（4）将输入空间划分为$M$个区域$R_1,R_2,\\ldots,R_M$，生成决策树：\n$$f(x) = \\sum_{m=1}^M\\hat c_m I(x\\in R_m)$$\n\n### 2.2 回归树示例\n　　书和网络资料中，关于CART回归树的讲解极少，举例解释回归树生成算法。本题改编自《统计学习方法》的“提升树”章节中，求回归树也是回归问题的提升树算法的第一个步骤。\n　　题目描述：训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的CART回归树**树桩**模型。\n　　注：(1)该题为了简化计算过程，训练样本只有一个特征变量，即$j=1$，故省去了遍历变量$j$的步骤；(2)该题只需求一个CART回归树的树桩，即只需对数据集划分一次，产生一个内部结点和两个叶结点即可。\n\n|$x_i$|1|2|3|4|5|6|7|8|9|10|\n|:--:|:--:|:--:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$y_i$|5.56|\t5.70|\t5.91|\t6.40|\t6.80|\t7.05|\t8.90|\t8.70|\t9.00|\t9.05|\n\n首先通过以下优化问题：\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n求解训练数据的切分点$s$:\n$$R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace$$\n容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：\n$$c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i$$\n这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。\n求训练数据的切分点，根据所给数据，考虑如下切分点：\n$$1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5$$\n对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72$$\n现将$s$及$m(s)$的计算结果列表如下：\n\n|$s$| \t1.5|\t2.5|\t3.5|\t4.5|\t5.5|\t6.5|\t7.5|\t8.5|\t9.5|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$m(s)$|\t15.72|\t12.07|\t8.36|\t5.78|\t3.91|\t1.93|\t8.01|\t11.73|\t15.74|\n\n由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：\n$$T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}$$\n$$f(x) = \\sum_{m=1}^2c_m I(x\\in R_m)$$\n\n## 三、分类树的生成\n分类数用基尼系数选择最优特征，同时决定该特征的最优二值切分点。\n###3.1 基尼指数\n分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为:\n$$Gini(p) = \\sum\\limits^{K}_{k = 1} p_k(1-p_k)= 1 -  \\sum\\limits^{K}_{k = 1}p_k^2 $$\n对于二分类问题，若样本点属于第1个类的概率是$p$，则概率分布的基尼指数为\n$$Gini(p)=2p(1-p)$$\n对于给定的样本集合$D$，其基尼指数为\n$$Gini(D)= 1 -  \\sum\\limits^{K}_{k = 1} (\\frac{|C_k|}{|D|})^2$$\n这里，$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。\n如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分，即\n$$D_1=\\{(x,y)\\in D|A(x)=a\\}, \\quad D_2=D-D_1$$\n则在特征$A$的条件下，集合$D$的基尼指数定义为\n$$Gini(D, A) =  \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2)\\tag{2.1}$$\n基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后，集合$D$的不确定性。**基尼指数值越大，样本集合的不确定性也越大，这一点与熵相似**。\n### 3.2 CART分类树生成算法\n输入：训练集$D$，停止计算的条件\n输出：CART决策树\n（1）设结点的训练数据集为$D$，计算现有特征对该数据集的基尼指数，此时对每一个特征$A$，对其可能取得每个值$a$，根据样本点对$A=a$的测试为“是”或者“否”将$D$分割为$D_1$和$D_2$两部分，利用式（2.1）计算$A=a$时的基尼指数；\n（2）在所有可能的特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练集依特征分配到两个子结点中去；\n（3）对两个子结点递归地调用（1），（2）直至满足停止条件；\n（4）生成CART决策树；\n算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值（也就是样本基本属于同一类），或者没有更多特征。\n###3.3 示例\n见李航的《统计学习方法》书中。\n## 四、剪枝\n暂略，参照另一篇总结:[ID3/C4.5算法](http://zhanglimin.com/2017/12/06/ID3%E5%92%8CC4.5%E7%AE%97%E6%B3%95/)。\n## 五、树模型的优缺点\n树模型的优点：\n- 容易解释\n- 不要求对特征做预处理\n – 能处理离散值和连续值混合的输入\n – 对特征的单调变换不敏感(只与数据的排序有关)\n – 能自动进行特征选择\n – 可处理缺失数据\n- 可扩展到大数据规模\n\n树模型的缺点：\n- 正确率不高：建树过程过于贪心\n – 可作为Boosting的弱学习器（深度不太深）\n- 模型不稳定（方差大）：输入数据小的变化会带来树结构的变化\n – Bagging：随机森林\n- 当特征数目相对样本数目太多时，容易过拟合\n\n## 六、参考\n- 李航，统计学习方法\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- 周志华，机器学习\n- [mathematicalmonk, Machine Learning(2.1-2.5)](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA)\n\n\n\n\n\n","source":"_posts/CART算法.md","raw":"---\ntitle: CART算法\nmathjax: true\ndate: 2017-12-7 22:30:50\ncategories: \n- 机器学习\ntags:\n- CART\n- 二叉树\n- 回归树\n- 分类树\n- 平方误差\n- 基尼指数\n---\n　　CART(classification and regression tree)是广泛应用的决策树学习方法，既可以用于分类也可以用于回归。\n## 一、简介\n（1）CART决策树的定义：CART假设决策树是**二叉树**，内部结点特征的取值只有“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。\n- 注：ID3/C4.5算法中决策树的每个叶子结点对应一个决策。CART算法中分类回归树的每个叶子结点给出一个预测分数(score)。\n\n（2）CART决策树的生成：CART决策树的生成就是递归地构建二叉决策树的过程，对**回归树**用**平方误差最小化准则**，对**分类树**用**基尼指数最小化准则**，进行特征选择，生成二叉树。\n（3）CART决策树的学习：同样包括三个步骤，特征选择、树的生成及剪枝。\n<!-- more --> \n## 二、回归树的生成\n　　**一个回归树**对应着**特征空间的一个划分**以及在**划分的单元上的输出值**；假设已将输入空间划分为$M$个单元$R_1,R_2,...,R_m$，并且在每个单元$R_m$上都有一个固定的输出值$c_m$，于是回归树的模型可表示为：\n$$f(x) = \\sum_{m=1}^Mc_m I(x\\in R_m)$$\n　　当输入空间的划分确定时，CART回归树用平方误差$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$来表示回归树对于训练集的预测误差，用平方误差最小的准则求解每个单元上的最优输出值$\\hat{c}_m$。\n- **注**：$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$即为求解单元$R_m$上的最优输出值$\\hat{c}_m$时的代价函数。\n\n　　易知，单元$R_m$上的$c_m$的最优值$\\hat{c}_m$是$R_m$上的所有输入实例$x_i$对应的输出$y_i$的均值，即\n$$\\hat{c}_m=ave(y_i|x_i \\in R_m)$$\n### 2.1 最小二乘回归树生成算法\n输入：训练数据集$D$\n输出：回归树$f(x)$\n在训练数据集所在的特征空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；\n（1）选择最优切分变量 $j$ 和切分点$s$ ，求解：\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式预测误差（平方误差）达到最小值的对$(j，s)$；其中$R_m$是被划分的输入空间，$c_m$是空间$R_m$对应的固定输出值。\n- **注**：$$[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$即为确定变量$j$上的切分点$s$时的代价函数。\n\n（2）用选定的对$(j,s)$划分区域并决定相应的输出值：\n$$R_1(j,s)=\\lbrace x\\mid x^{(j)} \\le s \\rbrace , \\quad R_2(j,s)=\\lbrace x\\mid x^{(j)}\\gt s \\rbrace\\\\\n\\hat c_m = {1\\over N_m}\\sum_{x_i\\in R_m(j,s)}y_i , \\quad x\\in R_m ,\\quad m=1,2$$\n（3）继续对两个子区域调用步骤（1），（2），直至满足停止条件。\n（4）将输入空间划分为$M$个区域$R_1,R_2,\\ldots,R_M$，生成决策树：\n$$f(x) = \\sum_{m=1}^M\\hat c_m I(x\\in R_m)$$\n\n### 2.2 回归树示例\n　　书和网络资料中，关于CART回归树的讲解极少，举例解释回归树生成算法。本题改编自《统计学习方法》的“提升树”章节中，求回归树也是回归问题的提升树算法的第一个步骤。\n　　题目描述：训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的CART回归树**树桩**模型。\n　　注：(1)该题为了简化计算过程，训练样本只有一个特征变量，即$j=1$，故省去了遍历变量$j$的步骤；(2)该题只需求一个CART回归树的树桩，即只需对数据集划分一次，产生一个内部结点和两个叶结点即可。\n\n|$x_i$|1|2|3|4|5|6|7|8|9|10|\n|:--:|:--:|:--:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$y_i$|5.56|\t5.70|\t5.91|\t6.40|\t6.80|\t7.05|\t8.90|\t8.70|\t9.00|\t9.05|\n\n首先通过以下优化问题：\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n求解训练数据的切分点$s$:\n$$R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace$$\n容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：\n$$c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i$$\n这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。\n求训练数据的切分点，根据所给数据，考虑如下切分点：\n$$1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5$$\n对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72$$\n现将$s$及$m(s)$的计算结果列表如下：\n\n|$s$| \t1.5|\t2.5|\t3.5|\t4.5|\t5.5|\t6.5|\t7.5|\t8.5|\t9.5|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$m(s)$|\t15.72|\t12.07|\t8.36|\t5.78|\t3.91|\t1.93|\t8.01|\t11.73|\t15.74|\n\n由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：\n$$T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}$$\n$$f(x) = \\sum_{m=1}^2c_m I(x\\in R_m)$$\n\n## 三、分类树的生成\n分类数用基尼系数选择最优特征，同时决定该特征的最优二值切分点。\n###3.1 基尼指数\n分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为:\n$$Gini(p) = \\sum\\limits^{K}_{k = 1} p_k(1-p_k)= 1 -  \\sum\\limits^{K}_{k = 1}p_k^2 $$\n对于二分类问题，若样本点属于第1个类的概率是$p$，则概率分布的基尼指数为\n$$Gini(p)=2p(1-p)$$\n对于给定的样本集合$D$，其基尼指数为\n$$Gini(D)= 1 -  \\sum\\limits^{K}_{k = 1} (\\frac{|C_k|}{|D|})^2$$\n这里，$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。\n如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分，即\n$$D_1=\\{(x,y)\\in D|A(x)=a\\}, \\quad D_2=D-D_1$$\n则在特征$A$的条件下，集合$D$的基尼指数定义为\n$$Gini(D, A) =  \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2)\\tag{2.1}$$\n基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后，集合$D$的不确定性。**基尼指数值越大，样本集合的不确定性也越大，这一点与熵相似**。\n### 3.2 CART分类树生成算法\n输入：训练集$D$，停止计算的条件\n输出：CART决策树\n（1）设结点的训练数据集为$D$，计算现有特征对该数据集的基尼指数，此时对每一个特征$A$，对其可能取得每个值$a$，根据样本点对$A=a$的测试为“是”或者“否”将$D$分割为$D_1$和$D_2$两部分，利用式（2.1）计算$A=a$时的基尼指数；\n（2）在所有可能的特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练集依特征分配到两个子结点中去；\n（3）对两个子结点递归地调用（1），（2）直至满足停止条件；\n（4）生成CART决策树；\n算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值（也就是样本基本属于同一类），或者没有更多特征。\n###3.3 示例\n见李航的《统计学习方法》书中。\n## 四、剪枝\n暂略，参照另一篇总结:[ID3/C4.5算法](http://zhanglimin.com/2017/12/06/ID3%E5%92%8CC4.5%E7%AE%97%E6%B3%95/)。\n## 五、树模型的优缺点\n树模型的优点：\n- 容易解释\n- 不要求对特征做预处理\n – 能处理离散值和连续值混合的输入\n – 对特征的单调变换不敏感(只与数据的排序有关)\n – 能自动进行特征选择\n – 可处理缺失数据\n- 可扩展到大数据规模\n\n树模型的缺点：\n- 正确率不高：建树过程过于贪心\n – 可作为Boosting的弱学习器（深度不太深）\n- 模型不稳定（方差大）：输入数据小的变化会带来树结构的变化\n – Bagging：随机森林\n- 当特征数目相对样本数目太多时，容易过拟合\n\n## 六、参考\n- 李航，统计学习方法\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- 周志华，机器学习\n- [mathematicalmonk, Machine Learning(2.1-2.5)](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA)\n\n\n\n\n\n","slug":"CART算法","published":1,"updated":"2018-01-28T05:52:20.294Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w00002jqslpml5o2c63","content":"<p>　　CART(classification and regression tree)是广泛应用的决策树学习方法，既可以用于分类也可以用于回归。</p>\n<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>（1）CART决策树的定义：CART假设决策树是<strong>二叉树</strong>，内部结点特征的取值只有“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>\n<ul>\n<li>注：ID3/C4.5算法中决策树的每个叶子结点对应一个决策。CART算法中分类回归树的每个叶子结点给出一个预测分数(score)。</li>\n</ul>\n<p>（2）CART决策树的生成：CART决策树的生成就是递归地构建二叉决策树的过程，对<strong>回归树</strong>用<strong>平方误差最小化准则</strong>，对<strong>分类树</strong>用<strong>基尼指数最小化准则</strong>，进行特征选择，生成二叉树。<br>（3）CART决策树的学习：同样包括三个步骤，特征选择、树的生成及剪枝。<br><a id=\"more\"></a> </p>\n<h2 id=\"二、回归树的生成\"><a href=\"#二、回归树的生成\" class=\"headerlink\" title=\"二、回归树的生成\"></a>二、回归树的生成</h2><p>　　<strong>一个回归树</strong>对应着<strong>特征空间的一个划分</strong>以及在<strong>划分的单元上的输出值</strong>；假设已将输入空间划分为$M$个单元$R_1,R_2,…,R_m$，并且在每个单元$R_m$上都有一个固定的输出值$c_m$，于是回归树的模型可表示为：</p>\n<script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^Mc_m I(x\\in R_m)</script><p>　　当输入空间的划分确定时，CART回归树用平方误差$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$来表示回归树对于训练集的预测误差，用平方误差最小的准则求解每个单元上的最优输出值$\\hat{c}_m$。</p>\n<ul>\n<li><strong>注</strong>：$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$即为求解单元$R_m$上的最优输出值$\\hat{c}_m$时的代价函数。</li>\n</ul>\n<p>　　易知，单元$R_m$上的$c_m$的最优值$\\hat{c}_m$是$R_m$上的所有输入实例$x_i$对应的输出$y_i$的均值，即</p>\n<script type=\"math/tex; mode=display\">\\hat{c}_m=ave(y_i|x_i \\in R_m)</script><h3 id=\"2-1-最小二乘回归树生成算法\"><a href=\"#2-1-最小二乘回归树生成算法\" class=\"headerlink\" title=\"2.1 最小二乘回归树生成算法\"></a>2.1 最小二乘回归树生成算法</h3><p>输入：训练数据集$D$<br>输出：回归树$f(x)$<br>在训练数据集所在的特征空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；<br>（1）选择最优切分变量 $j$ 和切分点$s$ ，求解：</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式预测误差（平方误差）达到最小值的对$(j，s)$；其中$R_m$是被划分的输入空间，$c_m$是空间$R_m$对应的固定输出值。</p>\n<ul>\n<li><strong>注</strong>：<script type=\"math/tex\">[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script>即为确定变量$j$上的切分点$s$时的代价函数。</li>\n</ul>\n<p>（2）用选定的对$(j,s)$划分区域并决定相应的输出值：</p>\n<script type=\"math/tex; mode=display\">R_1(j,s)=\\lbrace x\\mid x^{(j)} \\le s \\rbrace , \\quad R_2(j,s)=\\lbrace x\\mid x^{(j)}\\gt s \\rbrace\\\\\n\\hat c_m = {1\\over N_m}\\sum_{x_i\\in R_m(j,s)}y_i , \\quad x\\in R_m ,\\quad m=1,2</script><p>（3）继续对两个子区域调用步骤（1），（2），直至满足停止条件。<br>（4）将输入空间划分为$M$个区域$R_1,R_2,\\ldots,R_M$，生成决策树：</p>\n<script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^M\\hat c_m I(x\\in R_m)</script><h3 id=\"2-2-回归树示例\"><a href=\"#2-2-回归树示例\" class=\"headerlink\" title=\"2.2 回归树示例\"></a>2.2 回归树示例</h3><p>　　书和网络资料中，关于CART回归树的讲解极少，举例解释回归树生成算法。本题改编自《统计学习方法》的“提升树”章节中，求回归树也是回归问题的提升树算法的第一个步骤。<br>　　题目描述：训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的CART回归树<strong>树桩</strong>模型。<br>　　注：(1)该题为了简化计算过程，训练样本只有一个特征变量，即$j=1$，故省去了遍历变量$j$的步骤；(2)该题只需求一个CART回归树的树桩，即只需对数据集划分一次，产生一个内部结点和两个叶结点即可。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th style=\"text-align:center\">10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">5.56</td>\n<td style=\"text-align:center\">5.70</td>\n<td style=\"text-align:center\">5.91</td>\n<td style=\"text-align:center\">6.40</td>\n<td style=\"text-align:center\">6.80</td>\n<td style=\"text-align:center\">7.05</td>\n<td style=\"text-align:center\">8.90</td>\n<td style=\"text-align:center\">8.70</td>\n<td style=\"text-align:center\">9.00</td>\n<td style=\"text-align:center\">9.05</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>首先通过以下优化问题：</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>求解训练数据的切分点$s$:</p>\n<script type=\"math/tex; mode=display\">R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace</script><p>容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：</p>\n<script type=\"math/tex; mode=display\">c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i</script><p>这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。<br>求训练数据的切分点，根据所给数据，考虑如下切分点：</p>\n<script type=\"math/tex; mode=display\">1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5</script><p>对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72</script><p>现将$s$及$m(s)$的计算结果列表如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$s$</th>\n<th style=\"text-align:center\">1.5</th>\n<th style=\"text-align:center\">2.5</th>\n<th style=\"text-align:center\">3.5</th>\n<th style=\"text-align:center\">4.5</th>\n<th style=\"text-align:center\">5.5</th>\n<th style=\"text-align:center\">6.5</th>\n<th style=\"text-align:center\">7.5</th>\n<th>8.5</th>\n<th>9.5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$m(s)$</td>\n<td style=\"text-align:center\">15.72</td>\n<td style=\"text-align:center\">12.07</td>\n<td style=\"text-align:center\">8.36</td>\n<td style=\"text-align:center\">5.78</td>\n<td style=\"text-align:center\">3.91</td>\n<td style=\"text-align:center\">1.93</td>\n<td style=\"text-align:center\">8.01</td>\n<td>11.73</td>\n<td>15.74</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：</p>\n<script type=\"math/tex; mode=display\">T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^2c_m I(x\\in R_m)</script><h2 id=\"三、分类树的生成\"><a href=\"#三、分类树的生成\" class=\"headerlink\" title=\"三、分类树的生成\"></a>三、分类树的生成</h2><p>分类数用基尼系数选择最优特征，同时决定该特征的最优二值切分点。</p>\n<h3 id=\"3-1-基尼指数\"><a href=\"#3-1-基尼指数\" class=\"headerlink\" title=\"3.1 基尼指数\"></a>3.1 基尼指数</h3><p>分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为:</p>\n<script type=\"math/tex; mode=display\">Gini(p) = \\sum\\limits^{K}_{k = 1} p_k(1-p_k)= 1 -  \\sum\\limits^{K}_{k = 1}p_k^2</script><p>对于二分类问题，若样本点属于第1个类的概率是$p$，则概率分布的基尼指数为</p>\n<script type=\"math/tex; mode=display\">Gini(p)=2p(1-p)</script><p>对于给定的样本集合$D$，其基尼指数为</p>\n<script type=\"math/tex; mode=display\">Gini(D)= 1 -  \\sum\\limits^{K}_{k = 1} (\\frac{|C_k|}{|D|})^2</script><p>这里，$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。<br>如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分，即</p>\n<script type=\"math/tex; mode=display\">D_1=\\{(x,y)\\in D|A(x)=a\\}, \\quad D_2=D-D_1</script><p>则在特征$A$的条件下，集合$D$的基尼指数定义为</p>\n<script type=\"math/tex; mode=display\">Gini(D, A) =  \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2)\\tag{2.1}</script><p>基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后，集合$D$的不确定性。<strong>基尼指数值越大，样本集合的不确定性也越大，这一点与熵相似</strong>。</p>\n<h3 id=\"3-2-CART分类树生成算法\"><a href=\"#3-2-CART分类树生成算法\" class=\"headerlink\" title=\"3.2 CART分类树生成算法\"></a>3.2 CART分类树生成算法</h3><p>输入：训练集$D$，停止计算的条件<br>输出：CART决策树<br>（1）设结点的训练数据集为$D$，计算现有特征对该数据集的基尼指数，此时对每一个特征$A$，对其可能取得每个值$a$，根据样本点对$A=a$的测试为“是”或者“否”将$D$分割为$D_1$和$D_2$两部分，利用式（2.1）计算$A=a$时的基尼指数；<br>（2）在所有可能的特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练集依特征分配到两个子结点中去；<br>（3）对两个子结点递归地调用（1），（2）直至满足停止条件；<br>（4）生成CART决策树；<br>算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值（也就是样本基本属于同一类），或者没有更多特征。</p>\n<h3 id=\"3-3-示例\"><a href=\"#3-3-示例\" class=\"headerlink\" title=\"3.3 示例\"></a>3.3 示例</h3><p>见李航的《统计学习方法》书中。</p>\n<h2 id=\"四、剪枝\"><a href=\"#四、剪枝\" class=\"headerlink\" title=\"四、剪枝\"></a>四、剪枝</h2><p>暂略，参照另一篇总结:<a href=\"http://zhanglimin.com/2017/12/06/ID3%E5%92%8CC4.5%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">ID3/C4.5算法</a>。</p>\n<h2 id=\"五、树模型的优缺点\"><a href=\"#五、树模型的优缺点\" class=\"headerlink\" title=\"五、树模型的优缺点\"></a>五、树模型的优缺点</h2><p>树模型的优点：</p>\n<ul>\n<li>容易解释</li>\n<li>不要求对特征做预处理<br>– 能处理离散值和连续值混合的输入<br>– 对特征的单调变换不敏感(只与数据的排序有关)<br>– 能自动进行特征选择<br>– 可处理缺失数据</li>\n<li>可扩展到大数据规模</li>\n</ul>\n<p>树模型的缺点：</p>\n<ul>\n<li>正确率不高：建树过程过于贪心<br>– 可作为Boosting的弱学习器（深度不太深）</li>\n<li>模型不稳定（方差大）：输入数据小的变化会带来树结构的变化<br>– Bagging：随机森林</li>\n<li>当特征数目相对样本数目太多时，容易过拟合</li>\n</ul>\n<h2 id=\"六、参考\"><a href=\"#六、参考\" class=\"headerlink\" title=\"六、参考\"></a>六、参考</h2><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA\" target=\"_blank\" rel=\"noopener\">mathematicalmonk, Machine Learning(2.1-2.5)</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　CART(classification and regression tree)是广泛应用的决策树学习方法，既可以用于分类也可以用于回归。</p>\n<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>（1）CART决策树的定义：CART假设决策树是<strong>二叉树</strong>，内部结点特征的取值只有“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>\n<ul>\n<li>注：ID3/C4.5算法中决策树的每个叶子结点对应一个决策。CART算法中分类回归树的每个叶子结点给出一个预测分数(score)。</li>\n</ul>\n<p>（2）CART决策树的生成：CART决策树的生成就是递归地构建二叉决策树的过程，对<strong>回归树</strong>用<strong>平方误差最小化准则</strong>，对<strong>分类树</strong>用<strong>基尼指数最小化准则</strong>，进行特征选择，生成二叉树。<br>（3）CART决策树的学习：同样包括三个步骤，特征选择、树的生成及剪枝。<br>","more":"</p>\n<h2 id=\"二、回归树的生成\"><a href=\"#二、回归树的生成\" class=\"headerlink\" title=\"二、回归树的生成\"></a>二、回归树的生成</h2><p>　　<strong>一个回归树</strong>对应着<strong>特征空间的一个划分</strong>以及在<strong>划分的单元上的输出值</strong>；假设已将输入空间划分为$M$个单元$R_1,R_2,…,R_m$，并且在每个单元$R_m$上都有一个固定的输出值$c_m$，于是回归树的模型可表示为：</p>\n<script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^Mc_m I(x\\in R_m)</script><p>　　当输入空间的划分确定时，CART回归树用平方误差$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$来表示回归树对于训练集的预测误差，用平方误差最小的准则求解每个单元上的最优输出值$\\hat{c}_m$。</p>\n<ul>\n<li><strong>注</strong>：$\\sum\\limits_{x_i\\in R_m}(y_i-f(x_i))^2$即为求解单元$R_m$上的最优输出值$\\hat{c}_m$时的代价函数。</li>\n</ul>\n<p>　　易知，单元$R_m$上的$c_m$的最优值$\\hat{c}_m$是$R_m$上的所有输入实例$x_i$对应的输出$y_i$的均值，即</p>\n<script type=\"math/tex; mode=display\">\\hat{c}_m=ave(y_i|x_i \\in R_m)</script><h3 id=\"2-1-最小二乘回归树生成算法\"><a href=\"#2-1-最小二乘回归树生成算法\" class=\"headerlink\" title=\"2.1 最小二乘回归树生成算法\"></a>2.1 最小二乘回归树生成算法</h3><p>输入：训练数据集$D$<br>输出：回归树$f(x)$<br>在训练数据集所在的特征空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；<br>（1）选择最优切分变量 $j$ 和切分点$s$ ，求解：</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使上式预测误差（平方误差）达到最小值的对$(j，s)$；其中$R_m$是被划分的输入空间，$c_m$是空间$R_m$对应的固定输出值。</p>\n<ul>\n<li><strong>注</strong>：<script type=\"math/tex\">[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script>即为确定变量$j$上的切分点$s$时的代价函数。</li>\n</ul>\n<p>（2）用选定的对$(j,s)$划分区域并决定相应的输出值：</p>\n<script type=\"math/tex; mode=display\">R_1(j,s)=\\lbrace x\\mid x^{(j)} \\le s \\rbrace , \\quad R_2(j,s)=\\lbrace x\\mid x^{(j)}\\gt s \\rbrace\\\\\n\\hat c_m = {1\\over N_m}\\sum_{x_i\\in R_m(j,s)}y_i , \\quad x\\in R_m ,\\quad m=1,2</script><p>（3）继续对两个子区域调用步骤（1），（2），直至满足停止条件。<br>（4）将输入空间划分为$M$个区域$R_1,R_2,\\ldots,R_M$，生成决策树：</p>\n<script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^M\\hat c_m I(x\\in R_m)</script><h3 id=\"2-2-回归树示例\"><a href=\"#2-2-回归树示例\" class=\"headerlink\" title=\"2.2 回归树示例\"></a>2.2 回归树示例</h3><p>　　书和网络资料中，关于CART回归树的讲解极少，举例解释回归树生成算法。本题改编自《统计学习方法》的“提升树”章节中，求回归树也是回归问题的提升树算法的第一个步骤。<br>　　题目描述：训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的CART回归树<strong>树桩</strong>模型。<br>　　注：(1)该题为了简化计算过程，训练样本只有一个特征变量，即$j=1$，故省去了遍历变量$j$的步骤；(2)该题只需求一个CART回归树的树桩，即只需对数据集划分一次，产生一个内部结点和两个叶结点即可。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th style=\"text-align:center\">10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">5.56</td>\n<td style=\"text-align:center\">5.70</td>\n<td style=\"text-align:center\">5.91</td>\n<td style=\"text-align:center\">6.40</td>\n<td style=\"text-align:center\">6.80</td>\n<td style=\"text-align:center\">7.05</td>\n<td style=\"text-align:center\">8.90</td>\n<td style=\"text-align:center\">8.70</td>\n<td style=\"text-align:center\">9.00</td>\n<td style=\"text-align:center\">9.05</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>首先通过以下优化问题：</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>求解训练数据的切分点$s$:</p>\n<script type=\"math/tex; mode=display\">R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace</script><p>容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：</p>\n<script type=\"math/tex; mode=display\">c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i</script><p>这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。<br>求训练数据的切分点，根据所给数据，考虑如下切分点：</p>\n<script type=\"math/tex; mode=display\">1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5</script><p>对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72</script><p>现将$s$及$m(s)$的计算结果列表如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$s$</th>\n<th style=\"text-align:center\">1.5</th>\n<th style=\"text-align:center\">2.5</th>\n<th style=\"text-align:center\">3.5</th>\n<th style=\"text-align:center\">4.5</th>\n<th style=\"text-align:center\">5.5</th>\n<th style=\"text-align:center\">6.5</th>\n<th style=\"text-align:center\">7.5</th>\n<th>8.5</th>\n<th>9.5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$m(s)$</td>\n<td style=\"text-align:center\">15.72</td>\n<td style=\"text-align:center\">12.07</td>\n<td style=\"text-align:center\">8.36</td>\n<td style=\"text-align:center\">5.78</td>\n<td style=\"text-align:center\">3.91</td>\n<td style=\"text-align:center\">1.93</td>\n<td style=\"text-align:center\">8.01</td>\n<td>11.73</td>\n<td>15.74</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：</p>\n<script type=\"math/tex; mode=display\">T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f(x) = \\sum_{m=1}^2c_m I(x\\in R_m)</script><h2 id=\"三、分类树的生成\"><a href=\"#三、分类树的生成\" class=\"headerlink\" title=\"三、分类树的生成\"></a>三、分类树的生成</h2><p>分类数用基尼系数选择最优特征，同时决定该特征的最优二值切分点。</p>\n<h3 id=\"3-1-基尼指数\"><a href=\"#3-1-基尼指数\" class=\"headerlink\" title=\"3.1 基尼指数\"></a>3.1 基尼指数</h3><p>分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为:</p>\n<script type=\"math/tex; mode=display\">Gini(p) = \\sum\\limits^{K}_{k = 1} p_k(1-p_k)= 1 -  \\sum\\limits^{K}_{k = 1}p_k^2</script><p>对于二分类问题，若样本点属于第1个类的概率是$p$，则概率分布的基尼指数为</p>\n<script type=\"math/tex; mode=display\">Gini(p)=2p(1-p)</script><p>对于给定的样本集合$D$，其基尼指数为</p>\n<script type=\"math/tex; mode=display\">Gini(D)= 1 -  \\sum\\limits^{K}_{k = 1} (\\frac{|C_k|}{|D|})^2</script><p>这里，$C_k$是$D$中属于第$k$类的样本子集，$K$是类的个数。<br>如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分，即</p>\n<script type=\"math/tex; mode=display\">D_1=\\{(x,y)\\in D|A(x)=a\\}, \\quad D_2=D-D_1</script><p>则在特征$A$的条件下，集合$D$的基尼指数定义为</p>\n<script type=\"math/tex; mode=display\">Gini(D, A) =  \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2)\\tag{2.1}</script><p>基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$Gini(D,A)$表示经$A=a$分割后，集合$D$的不确定性。<strong>基尼指数值越大，样本集合的不确定性也越大，这一点与熵相似</strong>。</p>\n<h3 id=\"3-2-CART分类树生成算法\"><a href=\"#3-2-CART分类树生成算法\" class=\"headerlink\" title=\"3.2 CART分类树生成算法\"></a>3.2 CART分类树生成算法</h3><p>输入：训练集$D$，停止计算的条件<br>输出：CART决策树<br>（1）设结点的训练数据集为$D$，计算现有特征对该数据集的基尼指数，此时对每一个特征$A$，对其可能取得每个值$a$，根据样本点对$A=a$的测试为“是”或者“否”将$D$分割为$D_1$和$D_2$两部分，利用式（2.1）计算$A=a$时的基尼指数；<br>（2）在所有可能的特征$A$以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练集依特征分配到两个子结点中去；<br>（3）对两个子结点递归地调用（1），（2）直至满足停止条件；<br>（4）生成CART决策树；<br>算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值（也就是样本基本属于同一类），或者没有更多特征。</p>\n<h3 id=\"3-3-示例\"><a href=\"#3-3-示例\" class=\"headerlink\" title=\"3.3 示例\"></a>3.3 示例</h3><p>见李航的《统计学习方法》书中。</p>\n<h2 id=\"四、剪枝\"><a href=\"#四、剪枝\" class=\"headerlink\" title=\"四、剪枝\"></a>四、剪枝</h2><p>暂略，参照另一篇总结:<a href=\"http://zhanglimin.com/2017/12/06/ID3%E5%92%8CC4.5%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">ID3/C4.5算法</a>。</p>\n<h2 id=\"五、树模型的优缺点\"><a href=\"#五、树模型的优缺点\" class=\"headerlink\" title=\"五、树模型的优缺点\"></a>五、树模型的优缺点</h2><p>树模型的优点：</p>\n<ul>\n<li>容易解释</li>\n<li>不要求对特征做预处理<br>– 能处理离散值和连续值混合的输入<br>– 对特征的单调变换不敏感(只与数据的排序有关)<br>– 能自动进行特征选择<br>– 可处理缺失数据</li>\n<li>可扩展到大数据规模</li>\n</ul>\n<p>树模型的缺点：</p>\n<ul>\n<li>正确率不高：建树过程过于贪心<br>– 可作为Boosting的弱学习器（深度不太深）</li>\n<li>模型不稳定（方差大）：输入数据小的变化会带来树结构的变化<br>– Bagging：随机森林</li>\n<li>当特征数目相对样本数目太多时，容易过拟合</li>\n</ul>\n<h2 id=\"六、参考\"><a href=\"#六、参考\" class=\"headerlink\" title=\"六、参考\"></a>六、参考</h2><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA\" target=\"_blank\" rel=\"noopener\">mathematicalmonk, Machine Learning(2.1-2.5)</a></li>\n</ul>"},{"title":"GBDT模型","mathjax":true,"top":true,"date":"2017-12-13T13:20:50.000Z","_content":"　　**提升(Boosting)方法**实际采用加法模型（即基函数的线性组合）与前向分布算法。\n　　**提升树(boosting tree)**：以**决策树为基函数**的**提升方法**称为提升树。对分类问题，决策树是二叉分类树，对回归问题，决策树是二叉回归树。 \n　　本文先记录回归问题的提升树算法，后记录回归问题的梯度提升树(gradient boosting decision tree,GBDT)算法。\n<!-- more --> \n# 一、提升树\n## 1. 回归问题的提升树算法\n### 1.1 基本分类器：回归树 (同[CART回归树](http://zhanglimin.com/2017/12/07/CART%E6%A8%A1%E5%9E%8B/))\n　　已知一个训练数据集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$X$为输入空间，$y_i\\in Y \\in R$，$Y$为输出空间。如果将输入空间$X$划分为$J$个互不相交的区域$R_1,R_2,...,R_j$，并且在每个区域上确定输出的常量$c_j$，那么树可表示为\n$$T\\left(x;\\varTheta\\right)=\\sum_{j=1}^Jc_jI(x\\in R_j)$$\n　　其中，参数$\\varTheta=\\{(R_1,c_1),(R_2,c_2),...,(R_J,c_J)\\}$表示树的区域划分和各区域上的常数。$J$是回归树的复杂度即叶结点个数。\n### 1.2 提升树模型\n　　提升树模型可以表示为决策树的加法模型：\n$$f_M(x)=\\sum_{m=1}^{M}T(x;\\theta_m)$$\n　　其中，$T(x;\\Theta_m)$表示决策树；$\\Theta_m$为决策树的参数；$M$为树的个数。\n### 1.3 代价函数：平方误差损失函数\n$$L(y,f(x))=(y-f(x))^2$$\n### 1.4 学习算法：前向分步算法\n回归问题提升树使用以下前向分布算法：\n$$\n\\begin{eqnarray*}\nf_0(x)&=&0\\\\\nf_m(x)&=&f_{m-1}(x)+T(x;\\Theta_m), \\quad m=1,2,...,M\\\\\nf_M(x)&=&\\sum_{m=1}^{M}T(x;\\theta_m)\n\\end{eqnarray*}\n$$\n在前向分步算法的第$m$步，给定当前模型$f_{m-1}(x)$，需求解\n$$\\hat{\\Theta}_m=arg\\min_{\\Theta_m}\\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+T(x_i;\\Theta_m))$$\n得到$\\hat{\\Theta}_m$，即第$m$颗树的参数。\n当采用平方误差损失函数时，\n$$L(y,f(x))=(y-f(x))^2$$\n其损失变为\n$$L(y,f_{m-1}(x)+T(x;\\Theta_m))\\\\\n=[(y-f_{m-1}(x)-T(x;\\Theta_m))]^2\\\\\n=[r-T(x;\\Theta_m)]^2$$\n这里\n$$r=y-f_{m-1}(x)$$\n是当前模型拟合数据的残差。所以，**对回归问题的提升树算法来说，只需要简单地拟合当前模型的残差**。\n### 1.5 回归问题的提升树算法\n输入：训练数据集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$, $x_i \\in X \\in R^n$，$y_i\\in Y \\in R$\n输出：提升树$f_M(x)$\n（1）初始化$f_0(x)=0$\n（2）对$m=1,2,...,M$\n（a）计算残差\n$$r_{mi}=y_i−f_{m−1}(x_i),\\ i=1,2,...,N$$\n（b）拟合残差`$r_{mi}$`学习一个回归树，得到 `$T(x;\\Theta_m)$`\n（c）更新`$f_m(x)=f_{m−1}(x)+T(x;\\Theta_m)$`\n（3）得到回归问题提升树\n$$f_M(x)=\\sum_{m=1}^MT(x;\\Theta_m)$$\n\n### 1.6 例题\n训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的最小二叉回归树。\n\n|$x_i$| 1|\t2\t|3\t|4\t|5\t|6\t|7\t|8\t|9\t|10|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$y_i$|\t5.56|\t5.70|\t5.91|\t6.40|\t6.80|\t7.05|\t8.90|\t8.70|\t9.00|\t9.05|\n\n首先来看这个优化问题\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n求解训练数据的切分点$s$:\n$$R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace$$\n容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：\n$$c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i$$\n这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。\n求训练数据的切分点，根据所给数据，考虑如下切分点：\n$$1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5$$\n对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72$$\n现将$s$及$m(s)$的计算结果列表如下：\n\n|$s$| \t1.5|\t2.5|\t3.5|\t4.5|\t5.5|\t6.5|\t7.5|\t8.5|\t9.5|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$m(s)$|\t15.72|\t12.07|\t8.36|\t5.78|\t3.91|\t1.93|\t8.01|\t11.73|\t15.74|\n\n由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：\n$$T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}$$\n$$f_1(x) = T_1(x)$$\n用`$f_1(x)$`拟合训练数据的残差见下表，表中`$r_{2i} = y_i - f_1(x_i),i=1,2,\\ldots , 10$`\n\n|$x_i$| \t1|\t2|\t3|\t4|\t5|\t6|\t7|\t8|\t9|\t10|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|$y_i$|\t-0.68|\t-0.54|\t-0.33|\t0.16|\t0.56|\t0.81|\t-0.01|\t-0.21|\t0.09|\t0.14|\n\n用$f_1(x)$拟合训练数据的平方误差：\n$$L(y,f_1(x)) = \\sum_{i=1}^{10}(y_i-f_1(x_i))^2 = 1.93$$\n第2步求$T_2(x)$.方法与求$T_1(x)$一样，只是拟合的数据是上表的残差，可以得到：\n$$T_2(x) =\n\\begin{cases}\n-0.52, & x\\lt 3.5 \\\\\n0.22, & x \\ge 3.5 \\\\\n\\end{cases}$$\n$$f_2(x) = f_1(x) + T_2(x)=\n\\begin{cases}\n5.72, & x\\lt 3.5 \\\\\n6.46, & 3.5\\le x \\lt 6.5 \\\\\n9.13, & x\\ge 6.5 \\\\\n\\end{cases}$$\n用$f_2(x)$拟合训练数据的平方误差是：\n$$L(y,f_2(x)) = \\sum_{i=1}^{10}(y_i-f_2(x_i))^2 = 0.79$$\n继续求得\n$$T_3(x) =\n\\begin{cases}\n0.15, & x\\lt 6.5 \\\\\n-0.22, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.47 ,$$\n$$T_4(x) =\n\\begin{cases}\n-0.16, & x\\lt 4.5 \\\\\n0.11, & x \\ge 4.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.30 ,$$\n$$T_5(x) =\n\\begin{cases}\n0.07, & x\\lt 6.5 \\\\\n-0.11, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.23 ,$$\n$$T_6(x) =\n\\begin{cases}\n-0.15, & x\\lt 2.5 \\\\\n0.04, & x \\ge 2.5 \\\\\n\\end{cases}$$\n$$f_6(x) = f_5(x)+T_6(x) =T_1(x)+ \\ldots + T_5(x) + T_6(x)=\n\\begin{cases}\n5.63, & x\\lt 2.5 \\\\\n5.82, & 2.5 \\le x\\lt 3.5 \\\\\n6.56, & 3.5 \\le x\\lt 4.5 \\\\\n6.83, & 4.5 \\le x\\lt 6.5 \\\\\n8.95, & x\\ge 6.5 \\\\\n\\end{cases}$$\n用$f_6(x)$拟合训练数据的平方损失误差是\n$$L(y,f_6(x)) = \\sum_{i=1}^{10}(y_i-f_6(x_i))^2 = 0.17$$\n假设此时已经满足误差要求，那么$f(x) = f_6(x)$即为所求的回归树。\n\n## 2.分类问题的提升树算法\n　　对于二分类问题，提升树算法只需将[AdaBoost算法](http://zhanglimin.com/2017/12/13/Adaboost%E7%AE%97%E6%B3%95/)中的基本分类器限制为二类分类树即可(如[CART分类树](http://zhanglimin.com/2017/12/07/CART%E7%AE%97%E6%B3%95/))。\n　　故略。\n\n# 二、梯度提升树决策模型\n　　提升树利用加法模型与前向分布算法实现学习的优化过程。**当损失函数是平方损失函数时，每一步优化是很简单的，只需简单地拟合当前模型的残差**；**但对于一般损失函数而言，往往每一步优化并不那么容易**，针对这一问题，梯度提升算法(gradient boosting)被提出。\n## 2.1 核心思想\n　　**用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值**，拟合一个回归树： \n$$-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}$$\n## 2.2 梯度提升算法\n**输入**：训练数据集 $T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$y_i\\in Y \\in R$，损失函数$L(y,f(x))$\n**输出**：回归树$\\hat{f}(x)$\n**步骤1**：初始化\n$$f_0\\left(x\\right)=arg\\min_c\\sum_{i=1}^N{L\\left(y_i,c\\right)}$$\n**说明**：算法第一步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树。\n**步骤2**：对 $m=1,2,...,M$\n（a）对 $i=1,2,...,N$，计算\n$$r_{mi}=-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}$$\n**说明**：计算损失函数的负梯度在当前模型的值，将它作为残差的估计。**对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值**。\n（b）对`$r_{mi}$`拟合一个回归树，得到第$m$颗树的叶结点区域`$R_{mj}$`，`$j=1,2,...,J$`\n**说明**：估计回归树叶结点区域，以拟合残差的近似值。\n（c）对`$j=1,2,...,J$`，计算\n$$c_{mj}=arg\\min_c\\sum_{x_i\\in R_{mj}}{L\\left(y_i,f_{m-1}\\left(x_i\\right)+c\\right)}$$\n**说明**：利用线性搜索估计叶结点区域的值，使损失函数极小化。\n（d）更新\n$$f_m\\left(x\\right)=f_{m-1}\\left(x\\right)+\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}$$\n**说明**：更新回归树。\n**步骤3**：得到回归树\n$$\\hat{f}\\left(x\\right)=f_M\\left(x\\right)=\\sum_{m=1}^M{\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}}$$\n**说明**：得到输出的最终模型 $\\hat{f}(x)$\n\n## 2.3 GBDT的特点（待补）\nGBDT中的树是回归树，不是分类树；\n优点：GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。\nRF与GBDT对比：\n（1）RF中树的棵树是并行生成的；GBDT中树是顺序生成的；两者中过多的树都会过拟合，但是GBDT更容易过拟合；\n（2）RF中每棵树分裂的特征比较随机；GBDT中前面的树优先分裂对大部分样本区分的特征，后面的树分裂对小部分样本区分特征；\n（3）RF中主要参数是树的棵数；GBDT中主要参数是树的深度，一般为1；\n\n# 三、参考\n- 李航，统计学习方法\n- [AndDS, GBDT](http://aandds.com/blog/ensemble-gbdt.html)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/GBDT模型.md","raw":"---\ntitle: GBDT模型\nmathjax: true\ntop: true\ndate: 2017-12-13 21:20:50\ncategories: \n- 机器学习\ntags:\n- 提升树\n- 梯度提升树\n- GBDT\n---\n　　**提升(Boosting)方法**实际采用加法模型（即基函数的线性组合）与前向分布算法。\n　　**提升树(boosting tree)**：以**决策树为基函数**的**提升方法**称为提升树。对分类问题，决策树是二叉分类树，对回归问题，决策树是二叉回归树。 \n　　本文先记录回归问题的提升树算法，后记录回归问题的梯度提升树(gradient boosting decision tree,GBDT)算法。\n<!-- more --> \n# 一、提升树\n## 1. 回归问题的提升树算法\n### 1.1 基本分类器：回归树 (同[CART回归树](http://zhanglimin.com/2017/12/07/CART%E6%A8%A1%E5%9E%8B/))\n　　已知一个训练数据集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$X$为输入空间，$y_i\\in Y \\in R$，$Y$为输出空间。如果将输入空间$X$划分为$J$个互不相交的区域$R_1,R_2,...,R_j$，并且在每个区域上确定输出的常量$c_j$，那么树可表示为\n$$T\\left(x;\\varTheta\\right)=\\sum_{j=1}^Jc_jI(x\\in R_j)$$\n　　其中，参数$\\varTheta=\\{(R_1,c_1),(R_2,c_2),...,(R_J,c_J)\\}$表示树的区域划分和各区域上的常数。$J$是回归树的复杂度即叶结点个数。\n### 1.2 提升树模型\n　　提升树模型可以表示为决策树的加法模型：\n$$f_M(x)=\\sum_{m=1}^{M}T(x;\\theta_m)$$\n　　其中，$T(x;\\Theta_m)$表示决策树；$\\Theta_m$为决策树的参数；$M$为树的个数。\n### 1.3 代价函数：平方误差损失函数\n$$L(y,f(x))=(y-f(x))^2$$\n### 1.4 学习算法：前向分步算法\n回归问题提升树使用以下前向分布算法：\n$$\n\\begin{eqnarray*}\nf_0(x)&=&0\\\\\nf_m(x)&=&f_{m-1}(x)+T(x;\\Theta_m), \\quad m=1,2,...,M\\\\\nf_M(x)&=&\\sum_{m=1}^{M}T(x;\\theta_m)\n\\end{eqnarray*}\n$$\n在前向分步算法的第$m$步，给定当前模型$f_{m-1}(x)$，需求解\n$$\\hat{\\Theta}_m=arg\\min_{\\Theta_m}\\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+T(x_i;\\Theta_m))$$\n得到$\\hat{\\Theta}_m$，即第$m$颗树的参数。\n当采用平方误差损失函数时，\n$$L(y,f(x))=(y-f(x))^2$$\n其损失变为\n$$L(y,f_{m-1}(x)+T(x;\\Theta_m))\\\\\n=[(y-f_{m-1}(x)-T(x;\\Theta_m))]^2\\\\\n=[r-T(x;\\Theta_m)]^2$$\n这里\n$$r=y-f_{m-1}(x)$$\n是当前模型拟合数据的残差。所以，**对回归问题的提升树算法来说，只需要简单地拟合当前模型的残差**。\n### 1.5 回归问题的提升树算法\n输入：训练数据集$T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$, $x_i \\in X \\in R^n$，$y_i\\in Y \\in R$\n输出：提升树$f_M(x)$\n（1）初始化$f_0(x)=0$\n（2）对$m=1,2,...,M$\n（a）计算残差\n$$r_{mi}=y_i−f_{m−1}(x_i),\\ i=1,2,...,N$$\n（b）拟合残差`$r_{mi}$`学习一个回归树，得到 `$T(x;\\Theta_m)$`\n（c）更新`$f_m(x)=f_{m−1}(x)+T(x;\\Theta_m)$`\n（3）得到回归问题提升树\n$$f_M(x)=\\sum_{m=1}^MT(x;\\Theta_m)$$\n\n### 1.6 例题\n训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的最小二叉回归树。\n\n|$x_i$| 1|\t2\t|3\t|4\t|5\t|6\t|7\t|8\t|9\t|10|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$y_i$|\t5.56|\t5.70|\t5.91|\t6.40|\t6.80|\t7.05|\t8.90|\t8.70|\t9.00|\t9.05|\n\n首先来看这个优化问题\n$$\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n求解训练数据的切分点$s$:\n$$R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace$$\n容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：\n$$c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i$$\n这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。\n求训练数据的切分点，根据所给数据，考虑如下切分点：\n$$1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5$$\n对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$\n例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,\n$$m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72$$\n现将$s$及$m(s)$的计算结果列表如下：\n\n|$s$| \t1.5|\t2.5|\t3.5|\t4.5|\t5.5|\t6.5|\t7.5|\t8.5|\t9.5|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|$m(s)$|\t15.72|\t12.07|\t8.36|\t5.78|\t3.91|\t1.93|\t8.01|\t11.73|\t15.74|\n\n由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：\n$$T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}$$\n$$f_1(x) = T_1(x)$$\n用`$f_1(x)$`拟合训练数据的残差见下表，表中`$r_{2i} = y_i - f_1(x_i),i=1,2,\\ldots , 10$`\n\n|$x_i$| \t1|\t2|\t3|\t4|\t5|\t6|\t7|\t8|\t9|\t10|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|$y_i$|\t-0.68|\t-0.54|\t-0.33|\t0.16|\t0.56|\t0.81|\t-0.01|\t-0.21|\t0.09|\t0.14|\n\n用$f_1(x)$拟合训练数据的平方误差：\n$$L(y,f_1(x)) = \\sum_{i=1}^{10}(y_i-f_1(x_i))^2 = 1.93$$\n第2步求$T_2(x)$.方法与求$T_1(x)$一样，只是拟合的数据是上表的残差，可以得到：\n$$T_2(x) =\n\\begin{cases}\n-0.52, & x\\lt 3.5 \\\\\n0.22, & x \\ge 3.5 \\\\\n\\end{cases}$$\n$$f_2(x) = f_1(x) + T_2(x)=\n\\begin{cases}\n5.72, & x\\lt 3.5 \\\\\n6.46, & 3.5\\le x \\lt 6.5 \\\\\n9.13, & x\\ge 6.5 \\\\\n\\end{cases}$$\n用$f_2(x)$拟合训练数据的平方误差是：\n$$L(y,f_2(x)) = \\sum_{i=1}^{10}(y_i-f_2(x_i))^2 = 0.79$$\n继续求得\n$$T_3(x) =\n\\begin{cases}\n0.15, & x\\lt 6.5 \\\\\n-0.22, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.47 ,$$\n$$T_4(x) =\n\\begin{cases}\n-0.16, & x\\lt 4.5 \\\\\n0.11, & x \\ge 4.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.30 ,$$\n$$T_5(x) =\n\\begin{cases}\n0.07, & x\\lt 6.5 \\\\\n-0.11, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.23 ,$$\n$$T_6(x) =\n\\begin{cases}\n-0.15, & x\\lt 2.5 \\\\\n0.04, & x \\ge 2.5 \\\\\n\\end{cases}$$\n$$f_6(x) = f_5(x)+T_6(x) =T_1(x)+ \\ldots + T_5(x) + T_6(x)=\n\\begin{cases}\n5.63, & x\\lt 2.5 \\\\\n5.82, & 2.5 \\le x\\lt 3.5 \\\\\n6.56, & 3.5 \\le x\\lt 4.5 \\\\\n6.83, & 4.5 \\le x\\lt 6.5 \\\\\n8.95, & x\\ge 6.5 \\\\\n\\end{cases}$$\n用$f_6(x)$拟合训练数据的平方损失误差是\n$$L(y,f_6(x)) = \\sum_{i=1}^{10}(y_i-f_6(x_i))^2 = 0.17$$\n假设此时已经满足误差要求，那么$f(x) = f_6(x)$即为所求的回归树。\n\n## 2.分类问题的提升树算法\n　　对于二分类问题，提升树算法只需将[AdaBoost算法](http://zhanglimin.com/2017/12/13/Adaboost%E7%AE%97%E6%B3%95/)中的基本分类器限制为二类分类树即可(如[CART分类树](http://zhanglimin.com/2017/12/07/CART%E7%AE%97%E6%B3%95/))。\n　　故略。\n\n# 二、梯度提升树决策模型\n　　提升树利用加法模型与前向分布算法实现学习的优化过程。**当损失函数是平方损失函数时，每一步优化是很简单的，只需简单地拟合当前模型的残差**；**但对于一般损失函数而言，往往每一步优化并不那么容易**，针对这一问题，梯度提升算法(gradient boosting)被提出。\n## 2.1 核心思想\n　　**用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值**，拟合一个回归树： \n$$-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}$$\n## 2.2 梯度提升算法\n**输入**：训练数据集 $T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$y_i\\in Y \\in R$，损失函数$L(y,f(x))$\n**输出**：回归树$\\hat{f}(x)$\n**步骤1**：初始化\n$$f_0\\left(x\\right)=arg\\min_c\\sum_{i=1}^N{L\\left(y_i,c\\right)}$$\n**说明**：算法第一步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树。\n**步骤2**：对 $m=1,2,...,M$\n（a）对 $i=1,2,...,N$，计算\n$$r_{mi}=-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}$$\n**说明**：计算损失函数的负梯度在当前模型的值，将它作为残差的估计。**对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值**。\n（b）对`$r_{mi}$`拟合一个回归树，得到第$m$颗树的叶结点区域`$R_{mj}$`，`$j=1,2,...,J$`\n**说明**：估计回归树叶结点区域，以拟合残差的近似值。\n（c）对`$j=1,2,...,J$`，计算\n$$c_{mj}=arg\\min_c\\sum_{x_i\\in R_{mj}}{L\\left(y_i,f_{m-1}\\left(x_i\\right)+c\\right)}$$\n**说明**：利用线性搜索估计叶结点区域的值，使损失函数极小化。\n（d）更新\n$$f_m\\left(x\\right)=f_{m-1}\\left(x\\right)+\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}$$\n**说明**：更新回归树。\n**步骤3**：得到回归树\n$$\\hat{f}\\left(x\\right)=f_M\\left(x\\right)=\\sum_{m=1}^M{\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}}$$\n**说明**：得到输出的最终模型 $\\hat{f}(x)$\n\n## 2.3 GBDT的特点（待补）\nGBDT中的树是回归树，不是分类树；\n优点：GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。\nRF与GBDT对比：\n（1）RF中树的棵树是并行生成的；GBDT中树是顺序生成的；两者中过多的树都会过拟合，但是GBDT更容易过拟合；\n（2）RF中每棵树分裂的特征比较随机；GBDT中前面的树优先分裂对大部分样本区分的特征，后面的树分裂对小部分样本区分特征；\n（3）RF中主要参数是树的棵数；GBDT中主要参数是树的深度，一般为1；\n\n# 三、参考\n- 李航，统计学习方法\n- [AndDS, GBDT](http://aandds.com/blog/ensemble-gbdt.html)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"GBDT模型","published":1,"updated":"2018-02-23T13:29:53.825Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w02002kqslpj74z6p1u","content":"<p>　　<strong>提升(Boosting)方法</strong>实际采用加法模型（即基函数的线性组合）与前向分布算法。<br>　　<strong>提升树(boosting tree)</strong>：以<strong>决策树为基函数</strong>的<strong>提升方法</strong>称为提升树。对分类问题，决策树是二叉分类树，对回归问题，决策树是二叉回归树。<br>　　本文先记录回归问题的提升树算法，后记录回归问题的梯度提升树(gradient boosting decision tree,GBDT)算法。<br><a id=\"more\"></a> </p>\n<h1 id=\"一、提升树\"><a href=\"#一、提升树\" class=\"headerlink\" title=\"一、提升树\"></a>一、提升树</h1><h2 id=\"1-回归问题的提升树算法\"><a href=\"#1-回归问题的提升树算法\" class=\"headerlink\" title=\"1. 回归问题的提升树算法\"></a>1. 回归问题的提升树算法</h2><h3 id=\"1-1-基本分类器：回归树-同CART回归树\"><a href=\"#1-1-基本分类器：回归树-同CART回归树\" class=\"headerlink\" title=\"1.1 基本分类器：回归树 (同CART回归树)\"></a>1.1 基本分类器：回归树 (同<a href=\"http://zhanglimin.com/2017/12/07/CART%E6%A8%A1%E5%9E%8B/\" target=\"_blank\" rel=\"noopener\">CART回归树</a>)</h3><p>　　已知一个训练数据集$T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$X$为输入空间，$y_i\\in Y \\in R$，$Y$为输出空间。如果将输入空间$X$划分为$J$个互不相交的区域$R_1,R_2,…,R_j$，并且在每个区域上确定输出的常量$c_j$，那么树可表示为</p>\n<script type=\"math/tex; mode=display\">T\\left(x;\\varTheta\\right)=\\sum_{j=1}^Jc_jI(x\\in R_j)</script><p>　　其中，参数$\\varTheta=\\{(R_1,c_1),(R_2,c_2),…,(R_J,c_J)\\}$表示树的区域划分和各区域上的常数。$J$是回归树的复杂度即叶结点个数。</p>\n<h3 id=\"1-2-提升树模型\"><a href=\"#1-2-提升树模型\" class=\"headerlink\" title=\"1.2 提升树模型\"></a>1.2 提升树模型</h3><p>　　提升树模型可以表示为决策树的加法模型：</p>\n<script type=\"math/tex; mode=display\">f_M(x)=\\sum_{m=1}^{M}T(x;\\theta_m)</script><p>　　其中，$T(x;\\Theta_m)$表示决策树；$\\Theta_m$为决策树的参数；$M$为树的个数。</p>\n<h3 id=\"1-3-代价函数：平方误差损失函数\"><a href=\"#1-3-代价函数：平方误差损失函数\" class=\"headerlink\" title=\"1.3 代价函数：平方误差损失函数\"></a>1.3 代价函数：平方误差损失函数</h3><script type=\"math/tex; mode=display\">L(y,f(x))=(y-f(x))^2</script><h3 id=\"1-4-学习算法：前向分步算法\"><a href=\"#1-4-学习算法：前向分步算法\" class=\"headerlink\" title=\"1.4 学习算法：前向分步算法\"></a>1.4 学习算法：前向分步算法</h3><p>回归问题提升树使用以下前向分布算法：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nf_0(x)&=&0\\\\\nf_m(x)&=&f_{m-1}(x)+T(x;\\Theta_m), \\quad m=1,2,...,M\\\\\nf_M(x)&=&\\sum_{m=1}^{M}T(x;\\theta_m)\n\\end{eqnarray*}</script><p>在前向分步算法的第$m$步，给定当前模型$f_{m-1}(x)$，需求解</p>\n<script type=\"math/tex; mode=display\">\\hat{\\Theta}_m=arg\\min_{\\Theta_m}\\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+T(x_i;\\Theta_m))</script><p>得到$\\hat{\\Theta}_m$，即第$m$颗树的参数。<br>当采用平方误差损失函数时，</p>\n<script type=\"math/tex; mode=display\">L(y,f(x))=(y-f(x))^2</script><p>其损失变为</p>\n<script type=\"math/tex; mode=display\">L(y,f_{m-1}(x)+T(x;\\Theta_m))\\\\\n=[(y-f_{m-1}(x)-T(x;\\Theta_m))]^2\\\\\n=[r-T(x;\\Theta_m)]^2</script><p>这里</p>\n<script type=\"math/tex; mode=display\">r=y-f_{m-1}(x)</script><p>是当前模型拟合数据的残差。所以，<strong>对回归问题的提升树算法来说，只需要简单地拟合当前模型的残差</strong>。</p>\n<h3 id=\"1-5-回归问题的提升树算法\"><a href=\"#1-5-回归问题的提升树算法\" class=\"headerlink\" title=\"1.5 回归问题的提升树算法\"></a>1.5 回归问题的提升树算法</h3><p>输入：训练数据集$T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$, $x_i \\in X \\in R^n$，$y_i\\in Y \\in R$<br>输出：提升树$f_M(x)$<br>（1）初始化$f_0(x)=0$<br>（2）对$m=1,2,…,M$<br>（a）计算残差</p>\n<script type=\"math/tex; mode=display\">r_{mi}=y_i−f_{m−1}(x_i),\\ i=1,2,...,N</script><p>（b）拟合残差<script type=\"math/tex\">r_{mi}</script>学习一个回归树，得到 <script type=\"math/tex\">T(x;\\Theta_m)</script><br>（c）更新<script type=\"math/tex\">f_m(x)=f_{m−1}(x)+T(x;\\Theta_m)</script><br>（3）得到回归问题提升树</p>\n<script type=\"math/tex; mode=display\">f_M(x)=\\sum_{m=1}^MT(x;\\Theta_m)</script><h3 id=\"1-6-例题\"><a href=\"#1-6-例题\" class=\"headerlink\" title=\"1.6 例题\"></a>1.6 例题</h3><p>训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的最小二叉回归树。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th style=\"text-align:center\">10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">5.56</td>\n<td style=\"text-align:center\">5.70</td>\n<td style=\"text-align:center\">5.91</td>\n<td style=\"text-align:center\">6.40</td>\n<td style=\"text-align:center\">6.80</td>\n<td style=\"text-align:center\">7.05</td>\n<td style=\"text-align:center\">8.90</td>\n<td style=\"text-align:center\">8.70</td>\n<td style=\"text-align:center\">9.00</td>\n<td style=\"text-align:center\">9.05</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>首先来看这个优化问题</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>求解训练数据的切分点$s$:</p>\n<script type=\"math/tex; mode=display\">R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace</script><p>容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：</p>\n<script type=\"math/tex; mode=display\">c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i</script><p>这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。<br>求训练数据的切分点，根据所给数据，考虑如下切分点：</p>\n<script type=\"math/tex; mode=display\">1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5</script><p>对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72</script><p>现将$s$及$m(s)$的计算结果列表如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$s$</th>\n<th style=\"text-align:center\">1.5</th>\n<th style=\"text-align:center\">2.5</th>\n<th style=\"text-align:center\">3.5</th>\n<th style=\"text-align:center\">4.5</th>\n<th style=\"text-align:center\">5.5</th>\n<th style=\"text-align:center\">6.5</th>\n<th style=\"text-align:center\">7.5</th>\n<th>8.5</th>\n<th>9.5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$m(s)$</td>\n<td style=\"text-align:center\">15.72</td>\n<td style=\"text-align:center\">12.07</td>\n<td style=\"text-align:center\">8.36</td>\n<td style=\"text-align:center\">5.78</td>\n<td style=\"text-align:center\">3.91</td>\n<td style=\"text-align:center\">1.93</td>\n<td style=\"text-align:center\">8.01</td>\n<td>11.73</td>\n<td>15.74</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：</p>\n<script type=\"math/tex; mode=display\">T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_1(x) = T_1(x)</script><p>用<script type=\"math/tex\">f_1(x)</script>拟合训练数据的残差见下表，表中<script type=\"math/tex\">r_{2i} = y_i - f_1(x_i),i=1,2,\\ldots , 10</script></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th>10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">-0.68</td>\n<td style=\"text-align:center\">-0.54</td>\n<td style=\"text-align:center\">-0.33</td>\n<td style=\"text-align:center\">0.16</td>\n<td style=\"text-align:center\">0.56</td>\n<td style=\"text-align:center\">0.81</td>\n<td style=\"text-align:center\">-0.01</td>\n<td style=\"text-align:center\">-0.21</td>\n<td style=\"text-align:center\">0.09</td>\n<td>0.14</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>用$f_1(x)$拟合训练数据的平方误差：</p>\n<script type=\"math/tex; mode=display\">L(y,f_1(x)) = \\sum_{i=1}^{10}(y_i-f_1(x_i))^2 = 1.93</script><p>第2步求$T_2(x)$.方法与求$T_1(x)$一样，只是拟合的数据是上表的残差，可以得到：</p>\n<script type=\"math/tex; mode=display\">T_2(x) =\n\\begin{cases}\n-0.52, & x\\lt 3.5 \\\\\n0.22, & x \\ge 3.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_2(x) = f_1(x) + T_2(x)=\n\\begin{cases}\n5.72, & x\\lt 3.5 \\\\\n6.46, & 3.5\\le x \\lt 6.5 \\\\\n9.13, & x\\ge 6.5 \\\\\n\\end{cases}</script><p>用$f_2(x)$拟合训练数据的平方误差是：</p>\n<script type=\"math/tex; mode=display\">L(y,f_2(x)) = \\sum_{i=1}^{10}(y_i-f_2(x_i))^2 = 0.79</script><p>继续求得</p>\n<script type=\"math/tex; mode=display\">T_3(x) =\n\\begin{cases}\n0.15, & x\\lt 6.5 \\\\\n-0.22, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.47 ,</script><script type=\"math/tex; mode=display\">T_4(x) =\n\\begin{cases}\n-0.16, & x\\lt 4.5 \\\\\n0.11, & x \\ge 4.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.30 ,</script><script type=\"math/tex; mode=display\">T_5(x) =\n\\begin{cases}\n0.07, & x\\lt 6.5 \\\\\n-0.11, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.23 ,</script><script type=\"math/tex; mode=display\">T_6(x) =\n\\begin{cases}\n-0.15, & x\\lt 2.5 \\\\\n0.04, & x \\ge 2.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_6(x) = f_5(x)+T_6(x) =T_1(x)+ \\ldots + T_5(x) + T_6(x)=\n\\begin{cases}\n5.63, & x\\lt 2.5 \\\\\n5.82, & 2.5 \\le x\\lt 3.5 \\\\\n6.56, & 3.5 \\le x\\lt 4.5 \\\\\n6.83, & 4.5 \\le x\\lt 6.5 \\\\\n8.95, & x\\ge 6.5 \\\\\n\\end{cases}</script><p>用$f_6(x)$拟合训练数据的平方损失误差是</p>\n<script type=\"math/tex; mode=display\">L(y,f_6(x)) = \\sum_{i=1}^{10}(y_i-f_6(x_i))^2 = 0.17</script><p>假设此时已经满足误差要求，那么$f(x) = f_6(x)$即为所求的回归树。</p>\n<h2 id=\"2-分类问题的提升树算法\"><a href=\"#2-分类问题的提升树算法\" class=\"headerlink\" title=\"2.分类问题的提升树算法\"></a>2.分类问题的提升树算法</h2><p>　　对于二分类问题，提升树算法只需将<a href=\"http://zhanglimin.com/2017/12/13/Adaboost%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">AdaBoost算法</a>中的基本分类器限制为二类分类树即可(如<a href=\"http://zhanglimin.com/2017/12/07/CART%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">CART分类树</a>)。<br>　　故略。</p>\n<h1 id=\"二、梯度提升树决策模型\"><a href=\"#二、梯度提升树决策模型\" class=\"headerlink\" title=\"二、梯度提升树决策模型\"></a>二、梯度提升树决策模型</h1><p>　　提升树利用加法模型与前向分布算法实现学习的优化过程。<strong>当损失函数是平方损失函数时，每一步优化是很简单的，只需简单地拟合当前模型的残差</strong>；<strong>但对于一般损失函数而言，往往每一步优化并不那么容易</strong>，针对这一问题，梯度提升算法(gradient boosting)被提出。</p>\n<h2 id=\"2-1-核心思想\"><a href=\"#2-1-核心思想\" class=\"headerlink\" title=\"2.1 核心思想\"></a>2.1 核心思想</h2><p>　　<strong>用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值</strong>，拟合一个回归树： </p>\n<script type=\"math/tex; mode=display\">-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}</script><h2 id=\"2-2-梯度提升算法\"><a href=\"#2-2-梯度提升算法\" class=\"headerlink\" title=\"2.2 梯度提升算法\"></a>2.2 梯度提升算法</h2><p><strong>输入</strong>：训练数据集 $T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$y_i\\in Y \\in R$，损失函数$L(y,f(x))$<br><strong>输出</strong>：回归树$\\hat{f}(x)$<br><strong>步骤1</strong>：初始化</p>\n<script type=\"math/tex; mode=display\">f_0\\left(x\\right)=arg\\min_c\\sum_{i=1}^N{L\\left(y_i,c\\right)}</script><p><strong>说明</strong>：算法第一步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树。<br><strong>步骤2</strong>：对 $m=1,2,…,M$<br>（a）对 $i=1,2,…,N$，计算</p>\n<script type=\"math/tex; mode=display\">r_{mi}=-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}</script><p><strong>说明</strong>：计算损失函数的负梯度在当前模型的值，将它作为残差的估计。<strong>对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值</strong>。<br>（b）对<script type=\"math/tex\">r_{mi}</script>拟合一个回归树，得到第$m$颗树的叶结点区域<script type=\"math/tex\">R_{mj}</script>，<script type=\"math/tex\">j=1,2,...,J</script><br><strong>说明</strong>：估计回归树叶结点区域，以拟合残差的近似值。<br>（c）对<script type=\"math/tex\">j=1,2,...,J</script>，计算</p>\n<script type=\"math/tex; mode=display\">c_{mj}=arg\\min_c\\sum_{x_i\\in R_{mj}}{L\\left(y_i,f_{m-1}\\left(x_i\\right)+c\\right)}</script><p><strong>说明</strong>：利用线性搜索估计叶结点区域的值，使损失函数极小化。<br>（d）更新</p>\n<script type=\"math/tex; mode=display\">f_m\\left(x\\right)=f_{m-1}\\left(x\\right)+\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}</script><p><strong>说明</strong>：更新回归树。<br><strong>步骤3</strong>：得到回归树</p>\n<script type=\"math/tex; mode=display\">\\hat{f}\\left(x\\right)=f_M\\left(x\\right)=\\sum_{m=1}^M{\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}}</script><p><strong>说明</strong>：得到输出的最终模型 $\\hat{f}(x)$</p>\n<h2 id=\"2-3-GBDT的特点（待补）\"><a href=\"#2-3-GBDT的特点（待补）\" class=\"headerlink\" title=\"2.3 GBDT的特点（待补）\"></a>2.3 GBDT的特点（待补）</h2><p>GBDT中的树是回归树，不是分类树；<br>优点：GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。<br>RF与GBDT对比：<br>（1）RF中树的棵树是并行生成的；GBDT中树是顺序生成的；两者中过多的树都会过拟合，但是GBDT更容易过拟合；<br>（2）RF中每棵树分裂的特征比较随机；GBDT中前面的树优先分裂对大部分样本区分的特征，后面的树分裂对小部分样本区分特征；<br>（3）RF中主要参数是树的棵数；GBDT中主要参数是树的深度，一般为1；</p>\n<h1 id=\"三、参考\"><a href=\"#三、参考\" class=\"headerlink\" title=\"三、参考\"></a>三、参考</h1><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"http://aandds.com/blog/ensemble-gbdt.html\" target=\"_blank\" rel=\"noopener\">AndDS, GBDT</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　<strong>提升(Boosting)方法</strong>实际采用加法模型（即基函数的线性组合）与前向分布算法。<br>　　<strong>提升树(boosting tree)</strong>：以<strong>决策树为基函数</strong>的<strong>提升方法</strong>称为提升树。对分类问题，决策树是二叉分类树，对回归问题，决策树是二叉回归树。<br>　　本文先记录回归问题的提升树算法，后记录回归问题的梯度提升树(gradient boosting decision tree,GBDT)算法。<br>","more":"</p>\n<h1 id=\"一、提升树\"><a href=\"#一、提升树\" class=\"headerlink\" title=\"一、提升树\"></a>一、提升树</h1><h2 id=\"1-回归问题的提升树算法\"><a href=\"#1-回归问题的提升树算法\" class=\"headerlink\" title=\"1. 回归问题的提升树算法\"></a>1. 回归问题的提升树算法</h2><h3 id=\"1-1-基本分类器：回归树-同CART回归树\"><a href=\"#1-1-基本分类器：回归树-同CART回归树\" class=\"headerlink\" title=\"1.1 基本分类器：回归树 (同CART回归树)\"></a>1.1 基本分类器：回归树 (同<a href=\"http://zhanglimin.com/2017/12/07/CART%E6%A8%A1%E5%9E%8B/\" target=\"_blank\" rel=\"noopener\">CART回归树</a>)</h3><p>　　已知一个训练数据集$T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$X$为输入空间，$y_i\\in Y \\in R$，$Y$为输出空间。如果将输入空间$X$划分为$J$个互不相交的区域$R_1,R_2,…,R_j$，并且在每个区域上确定输出的常量$c_j$，那么树可表示为</p>\n<script type=\"math/tex; mode=display\">T\\left(x;\\varTheta\\right)=\\sum_{j=1}^Jc_jI(x\\in R_j)</script><p>　　其中，参数$\\varTheta=\\{(R_1,c_1),(R_2,c_2),…,(R_J,c_J)\\}$表示树的区域划分和各区域上的常数。$J$是回归树的复杂度即叶结点个数。</p>\n<h3 id=\"1-2-提升树模型\"><a href=\"#1-2-提升树模型\" class=\"headerlink\" title=\"1.2 提升树模型\"></a>1.2 提升树模型</h3><p>　　提升树模型可以表示为决策树的加法模型：</p>\n<script type=\"math/tex; mode=display\">f_M(x)=\\sum_{m=1}^{M}T(x;\\theta_m)</script><p>　　其中，$T(x;\\Theta_m)$表示决策树；$\\Theta_m$为决策树的参数；$M$为树的个数。</p>\n<h3 id=\"1-3-代价函数：平方误差损失函数\"><a href=\"#1-3-代价函数：平方误差损失函数\" class=\"headerlink\" title=\"1.3 代价函数：平方误差损失函数\"></a>1.3 代价函数：平方误差损失函数</h3><script type=\"math/tex; mode=display\">L(y,f(x))=(y-f(x))^2</script><h3 id=\"1-4-学习算法：前向分步算法\"><a href=\"#1-4-学习算法：前向分步算法\" class=\"headerlink\" title=\"1.4 学习算法：前向分步算法\"></a>1.4 学习算法：前向分步算法</h3><p>回归问题提升树使用以下前向分布算法：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nf_0(x)&=&0\\\\\nf_m(x)&=&f_{m-1}(x)+T(x;\\Theta_m), \\quad m=1,2,...,M\\\\\nf_M(x)&=&\\sum_{m=1}^{M}T(x;\\theta_m)\n\\end{eqnarray*}</script><p>在前向分步算法的第$m$步，给定当前模型$f_{m-1}(x)$，需求解</p>\n<script type=\"math/tex; mode=display\">\\hat{\\Theta}_m=arg\\min_{\\Theta_m}\\sum_{i=1}^NL(y_i,f_{m-1}(x_i)+T(x_i;\\Theta_m))</script><p>得到$\\hat{\\Theta}_m$，即第$m$颗树的参数。<br>当采用平方误差损失函数时，</p>\n<script type=\"math/tex; mode=display\">L(y,f(x))=(y-f(x))^2</script><p>其损失变为</p>\n<script type=\"math/tex; mode=display\">L(y,f_{m-1}(x)+T(x;\\Theta_m))\\\\\n=[(y-f_{m-1}(x)-T(x;\\Theta_m))]^2\\\\\n=[r-T(x;\\Theta_m)]^2</script><p>这里</p>\n<script type=\"math/tex; mode=display\">r=y-f_{m-1}(x)</script><p>是当前模型拟合数据的残差。所以，<strong>对回归问题的提升树算法来说，只需要简单地拟合当前模型的残差</strong>。</p>\n<h3 id=\"1-5-回归问题的提升树算法\"><a href=\"#1-5-回归问题的提升树算法\" class=\"headerlink\" title=\"1.5 回归问题的提升树算法\"></a>1.5 回归问题的提升树算法</h3><p>输入：训练数据集$T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$, $x_i \\in X \\in R^n$，$y_i\\in Y \\in R$<br>输出：提升树$f_M(x)$<br>（1）初始化$f_0(x)=0$<br>（2）对$m=1,2,…,M$<br>（a）计算残差</p>\n<script type=\"math/tex; mode=display\">r_{mi}=y_i−f_{m−1}(x_i),\\ i=1,2,...,N</script><p>（b）拟合残差<script type=\"math/tex\">r_{mi}</script>学习一个回归树，得到 <script type=\"math/tex\">T(x;\\Theta_m)</script><br>（c）更新<script type=\"math/tex\">f_m(x)=f_{m−1}(x)+T(x;\\Theta_m)</script><br>（3）得到回归问题提升树</p>\n<script type=\"math/tex; mode=display\">f_M(x)=\\sum_{m=1}^MT(x;\\Theta_m)</script><h3 id=\"1-6-例题\"><a href=\"#1-6-例题\" class=\"headerlink\" title=\"1.6 例题\"></a>1.6 例题</h3><p>训练数据见下表，$x$的取值范围为区间$[0.5,10.5]$,$y$的取值范围为区间$[5.0,10.0]$,学习这个回归问题的最小二叉回归树。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th style=\"text-align:center\">10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">5.56</td>\n<td style=\"text-align:center\">5.70</td>\n<td style=\"text-align:center\">5.91</td>\n<td style=\"text-align:center\">6.40</td>\n<td style=\"text-align:center\">6.80</td>\n<td style=\"text-align:center\">7.05</td>\n<td style=\"text-align:center\">8.90</td>\n<td style=\"text-align:center\">8.70</td>\n<td style=\"text-align:center\">9.00</td>\n<td style=\"text-align:center\">9.05</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>首先来看这个优化问题</p>\n<script type=\"math/tex; mode=display\">\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>求解训练数据的切分点$s$:</p>\n<script type=\"math/tex; mode=display\">R_1=\\lbrace x\\mid x\\le s\\rbrace , \\quad R_2=\\lbrace x\\mid x\\gt s\\rbrace</script><p>容易求得在$R_1$,$R_2$内部使得平方损失误差达到最小值的$c_1$,$c_2$为：</p>\n<script type=\"math/tex; mode=display\">c_1={1\\over N_1}\\sum_{x_i \\in R_1}y_i , \\quad c_2={1\\over N_2}\\sum_{x_i \\in R_2}y_i</script><p>这里$N_1$,$N_2$是$R_1$,$R_2$的样本点数。<br>求训练数据的切分点，根据所给数据，考虑如下切分点：</p>\n<script type=\"math/tex; mode=display\">1.5 ,2.5 ,3.5 ,4.5 ,5.5 , 6.5 , 7.5 , 8.5 , 9.5</script><p>对各切分点，不难求出相应的$R1$ , $R2$ , $c1$ , $c2$及</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]</script><p>例如，当$s=1.5$时，$R_1 = \\lbrace 1\\rbrace$, $R_2 = \\lbrace 2, 3 , \\ldots , 10\\rbrace$ , $c_1 = 5.56$ , $c_2 = 7.50$ ,</p>\n<script type=\"math/tex; mode=display\">m(s)=\\min_{j,s}[\\min_{c_1} \\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2] = 0+15.72 = 15.72</script><p>现将$s$及$m(s)$的计算结果列表如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$s$</th>\n<th style=\"text-align:center\">1.5</th>\n<th style=\"text-align:center\">2.5</th>\n<th style=\"text-align:center\">3.5</th>\n<th style=\"text-align:center\">4.5</th>\n<th style=\"text-align:center\">5.5</th>\n<th style=\"text-align:center\">6.5</th>\n<th style=\"text-align:center\">7.5</th>\n<th>8.5</th>\n<th>9.5</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$m(s)$</td>\n<td style=\"text-align:center\">15.72</td>\n<td style=\"text-align:center\">12.07</td>\n<td style=\"text-align:center\">8.36</td>\n<td style=\"text-align:center\">5.78</td>\n<td style=\"text-align:center\">3.91</td>\n<td style=\"text-align:center\">1.93</td>\n<td style=\"text-align:center\">8.01</td>\n<td>11.73</td>\n<td>15.74</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可知，当$s=6.5$的时候达到最小值，此时$R_1 = \\lbrace 1 ,2 , \\ldots , 6\\rbrace$, $R_2 ={7 ,8 ,9 , 10}$ , $c_1=6.24$, $c_2=8.9$, 所以回归树$T_1(x)$为：</p>\n<script type=\"math/tex; mode=display\">T_1(x) =\n\\begin{cases}\n6.24, & x\\lt 6.5 \\\\\n8.91, & x \\ge 6.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_1(x) = T_1(x)</script><p>用<script type=\"math/tex\">f_1(x)</script>拟合训练数据的残差见下表，表中<script type=\"math/tex\">r_{2i} = y_i - f_1(x_i),i=1,2,\\ldots , 10</script></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">$x_i$</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n<th style=\"text-align:center\">8</th>\n<th style=\"text-align:center\">9</th>\n<th>10</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">$y_i$</td>\n<td style=\"text-align:center\">-0.68</td>\n<td style=\"text-align:center\">-0.54</td>\n<td style=\"text-align:center\">-0.33</td>\n<td style=\"text-align:center\">0.16</td>\n<td style=\"text-align:center\">0.56</td>\n<td style=\"text-align:center\">0.81</td>\n<td style=\"text-align:center\">-0.01</td>\n<td style=\"text-align:center\">-0.21</td>\n<td style=\"text-align:center\">0.09</td>\n<td>0.14</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>用$f_1(x)$拟合训练数据的平方误差：</p>\n<script type=\"math/tex; mode=display\">L(y,f_1(x)) = \\sum_{i=1}^{10}(y_i-f_1(x_i))^2 = 1.93</script><p>第2步求$T_2(x)$.方法与求$T_1(x)$一样，只是拟合的数据是上表的残差，可以得到：</p>\n<script type=\"math/tex; mode=display\">T_2(x) =\n\\begin{cases}\n-0.52, & x\\lt 3.5 \\\\\n0.22, & x \\ge 3.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_2(x) = f_1(x) + T_2(x)=\n\\begin{cases}\n5.72, & x\\lt 3.5 \\\\\n6.46, & 3.5\\le x \\lt 6.5 \\\\\n9.13, & x\\ge 6.5 \\\\\n\\end{cases}</script><p>用$f_2(x)$拟合训练数据的平方误差是：</p>\n<script type=\"math/tex; mode=display\">L(y,f_2(x)) = \\sum_{i=1}^{10}(y_i-f_2(x_i))^2 = 0.79</script><p>继续求得</p>\n<script type=\"math/tex; mode=display\">T_3(x) =\n\\begin{cases}\n0.15, & x\\lt 6.5 \\\\\n-0.22, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.47 ,</script><script type=\"math/tex; mode=display\">T_4(x) =\n\\begin{cases}\n-0.16, & x\\lt 4.5 \\\\\n0.11, & x \\ge 4.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.30 ,</script><script type=\"math/tex; mode=display\">T_5(x) =\n\\begin{cases}\n0.07, & x\\lt 6.5 \\\\\n-0.11, & x \\ge 6.5 \\\\\n\\end{cases}\n\\quad L(y,f_3(x)) = 0.23 ,</script><script type=\"math/tex; mode=display\">T_6(x) =\n\\begin{cases}\n-0.15, & x\\lt 2.5 \\\\\n0.04, & x \\ge 2.5 \\\\\n\\end{cases}</script><script type=\"math/tex; mode=display\">f_6(x) = f_5(x)+T_6(x) =T_1(x)+ \\ldots + T_5(x) + T_6(x)=\n\\begin{cases}\n5.63, & x\\lt 2.5 \\\\\n5.82, & 2.5 \\le x\\lt 3.5 \\\\\n6.56, & 3.5 \\le x\\lt 4.5 \\\\\n6.83, & 4.5 \\le x\\lt 6.5 \\\\\n8.95, & x\\ge 6.5 \\\\\n\\end{cases}</script><p>用$f_6(x)$拟合训练数据的平方损失误差是</p>\n<script type=\"math/tex; mode=display\">L(y,f_6(x)) = \\sum_{i=1}^{10}(y_i-f_6(x_i))^2 = 0.17</script><p>假设此时已经满足误差要求，那么$f(x) = f_6(x)$即为所求的回归树。</p>\n<h2 id=\"2-分类问题的提升树算法\"><a href=\"#2-分类问题的提升树算法\" class=\"headerlink\" title=\"2.分类问题的提升树算法\"></a>2.分类问题的提升树算法</h2><p>　　对于二分类问题，提升树算法只需将<a href=\"http://zhanglimin.com/2017/12/13/Adaboost%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">AdaBoost算法</a>中的基本分类器限制为二类分类树即可(如<a href=\"http://zhanglimin.com/2017/12/07/CART%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">CART分类树</a>)。<br>　　故略。</p>\n<h1 id=\"二、梯度提升树决策模型\"><a href=\"#二、梯度提升树决策模型\" class=\"headerlink\" title=\"二、梯度提升树决策模型\"></a>二、梯度提升树决策模型</h1><p>　　提升树利用加法模型与前向分布算法实现学习的优化过程。<strong>当损失函数是平方损失函数时，每一步优化是很简单的，只需简单地拟合当前模型的残差</strong>；<strong>但对于一般损失函数而言，往往每一步优化并不那么容易</strong>，针对这一问题，梯度提升算法(gradient boosting)被提出。</p>\n<h2 id=\"2-1-核心思想\"><a href=\"#2-1-核心思想\" class=\"headerlink\" title=\"2.1 核心思想\"></a>2.1 核心思想</h2><p>　　<strong>用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值</strong>，拟合一个回归树： </p>\n<script type=\"math/tex; mode=display\">-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}</script><h2 id=\"2-2-梯度提升算法\"><a href=\"#2-2-梯度提升算法\" class=\"headerlink\" title=\"2.2 梯度提升算法\"></a>2.2 梯度提升算法</h2><p><strong>输入</strong>：训练数据集 $T=\\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\\}$,$x_i \\in X \\in R^n$，$y_i\\in Y \\in R$，损失函数$L(y,f(x))$<br><strong>输出</strong>：回归树$\\hat{f}(x)$<br><strong>步骤1</strong>：初始化</p>\n<script type=\"math/tex; mode=display\">f_0\\left(x\\right)=arg\\min_c\\sum_{i=1}^N{L\\left(y_i,c\\right)}</script><p><strong>说明</strong>：算法第一步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树。<br><strong>步骤2</strong>：对 $m=1,2,…,M$<br>（a）对 $i=1,2,…,N$，计算</p>\n<script type=\"math/tex; mode=display\">r_{mi}=-\\left[\\frac{\\partial L\\left(y,f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)}\\right]_{f\\left(x\\right)=f_{m-1}\\left(x\\right)}</script><p><strong>说明</strong>：计算损失函数的负梯度在当前模型的值，将它作为残差的估计。<strong>对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值</strong>。<br>（b）对<script type=\"math/tex\">r_{mi}</script>拟合一个回归树，得到第$m$颗树的叶结点区域<script type=\"math/tex\">R_{mj}</script>，<script type=\"math/tex\">j=1,2,...,J</script><br><strong>说明</strong>：估计回归树叶结点区域，以拟合残差的近似值。<br>（c）对<script type=\"math/tex\">j=1,2,...,J</script>，计算</p>\n<script type=\"math/tex; mode=display\">c_{mj}=arg\\min_c\\sum_{x_i\\in R_{mj}}{L\\left(y_i,f_{m-1}\\left(x_i\\right)+c\\right)}</script><p><strong>说明</strong>：利用线性搜索估计叶结点区域的值，使损失函数极小化。<br>（d）更新</p>\n<script type=\"math/tex; mode=display\">f_m\\left(x\\right)=f_{m-1}\\left(x\\right)+\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}</script><p><strong>说明</strong>：更新回归树。<br><strong>步骤3</strong>：得到回归树</p>\n<script type=\"math/tex; mode=display\">\\hat{f}\\left(x\\right)=f_M\\left(x\\right)=\\sum_{m=1}^M{\\sum_{j=1}^J{c_{mj}I\\left(x\\in R_{mj}\\right)}}</script><p><strong>说明</strong>：得到输出的最终模型 $\\hat{f}(x)$</p>\n<h2 id=\"2-3-GBDT的特点（待补）\"><a href=\"#2-3-GBDT的特点（待补）\" class=\"headerlink\" title=\"2.3 GBDT的特点（待补）\"></a>2.3 GBDT的特点（待补）</h2><p>GBDT中的树是回归树，不是分类树；<br>优点：GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。<br>RF与GBDT对比：<br>（1）RF中树的棵树是并行生成的；GBDT中树是顺序生成的；两者中过多的树都会过拟合，但是GBDT更容易过拟合；<br>（2）RF中每棵树分裂的特征比较随机；GBDT中前面的树优先分裂对大部分样本区分的特征，后面的树分裂对小部分样本区分特征；<br>（3）RF中主要参数是树的棵数；GBDT中主要参数是树的深度，一般为1；</p>\n<h1 id=\"三、参考\"><a href=\"#三、参考\" class=\"headerlink\" title=\"三、参考\"></a>三、参考</h1><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"http://aandds.com/blog/ensemble-gbdt.html\" target=\"_blank\" rel=\"noopener\">AndDS, GBDT</a></li>\n</ul>"},{"title":"ID3/C4.5算法","mathjax":true,"date":"2017-12-06T13:30:50.000Z","_content":"　　决策树(decision tree)是机器学习中一种基本的分类与回归方法。\n　　决策树模型的3种经典学习算法：ID3，C4.5，CART。ID3与C4.5主要适用于分类问题；CART既适用于分类也适用于回归预测问题。\n　　本文主要记录ID3与C4.5算法，两者的区别主要在于前者用的是信息增益来选择特征，后者用的是信息增益比来选择特征以及增加对连续值特征的处理和缺失值特征的处理。\n\n<!-- more --> \n\n## 一、简介\n（1）决策树定义：决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)组成。内部节点表示一个特征或属性，叶结点表示一个类或者回归预测值。\n（2）决策树决策过程：从根结点开始，对样本的某一特征进行测试，根据测试结果，将样本分配到其子结点；这时，每一个子结点对应着该特征值的一个取值。如此递归对样本进行测试并分配，直至达到叶结点；\n（3）决策树模型的学习包含3个步骤：特征选择，决策树的生成（局部最优化过程），决策树的剪枝（全局最优化过程）。\n## 二、特征选择\n### 2.1 熵的定义\n　　熵表示随机变量不确定性的度量。设$X$是一个取有限值的离散随机变量，其概率分布为：`$P(X=x_i)=p_i,\\ i=1,2,...,n$`，则随机变量`$X$`的熵定义为：$$H(X) = -\\sum_{i=1}^{n}p_ilog_2p_i$$\n　　由定义可知，熵只依赖于$X$的分布，而与$X$的值无关，所以熵也可以记为$H(p)$。\n熵越大，随机变量的不确定性越大。当随机变量只取两个值时，例如1，0时，熵$H(p)$随概率$p$变化的曲线如图（分布为伯努利分布时熵与概率的关系）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ID3%E4%B8%8EC4.5/Binary_entropy_plot.svg.png\" width=\"30%\" height=\"30%\">　　当$p=0$或$p=1$时$H(p)=0$，随机变量完全没有不确定性。当$p=0.5$时，$H(p)=1$，熵取值最大，随机变量不确定性最大。\n### 2.2 条件熵的定义\n　　设有随机变量$(X,Y)$，其联合概率分布为\n$$P(X=x_i,Y=y_j)=p_{ij},i=1,2,...,n;j=1,2,...,m$$\n　　条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望\n$$H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)$$\n　　这里，$p_i=P(X=x_i),i=1,2,...,n.$\n　　当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的**熵**与**条件熵**分别成为**经验熵**和**经验条件熵**。\n### 2.3 信息增益的定义\n（1）符号定义\n- $D$：训练数据集；\n- $C_k$：第$k$个类的数据集； \n- $D_i$：根据特征$A$的第$i$个取值划分出来的数据集;\n- $D_{ik}$：根据特征$A$的第$i$个取值划分出来的数据集与第$k$个类的数据集的交集；\n- 数据集总共有$K$个类，特征$A$有$n$个取值，符号$|\\cdot |$表示数据集容量。\n\n（2）数据集$D$的经验熵$H(D)$：\n$$\\begin{eqnarray*}\nH(D)&=&-\\sum_{k=1}^{K}p_klog_2p_k\\\\\n    &=&-\\sum_{k=1}^{K}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}\n\\end{eqnarray*}\n$$\n（3）特征$A$给定条件下$D$的经验条件熵$H(D|A)$(尝试用特征$A$划分会有$n$个分支，相当求于求特征$A$的Expected Entropy，也可写做$EH(A)$)：\n$$\\begin{eqnarray*}\nH(D|A)&=&\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)\\\\\n&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^{K}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}\n\\end{eqnarray*}\n$$\n（4）计算特征$A$对样本集$D$的信息增益$g(D,A)$：\n$$g(D,A)=H(D)-H(D|A)$$\n　　给定训练数据集$D$和特征$A$，经验熵$H(D)$表示对数据集$D$进行分类的不确定性。而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性。那么它们的差，即信息增益$g(D,A)$，就**表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度**。\n　　显然，对于数据集$D$而言，信息增益依赖于特征，不同的特征往往具有不同的信息增益。**信息增益大的特征具有更强的分类能力**。\n　　**ID3采用信息增益来选择最优划分属性**。信息增益准则对可取值数目较多的特征有所偏好，为减少这种偏好可能带来的不利影响，**C4.5决策树算法不直接采用信息增益，而是使用“信息增益比”来选择最优划分属性**。\n### 2.4 信息增益比\n　　特征$A$对训练数据集$D$的信息增益比`$Gain\\_ratio(D,A)$`定义为：其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的分裂信息`$split\\_info(A)$`之比，即\n$$Gain\\_ratio(D,A)=\\frac{Gain(D,A)}{split\\_info(A)}$$\n　　分裂信息定义如下：\n$$\n\\begin{eqnarray*}\nsplit\\_info(A)&=&-\\sum_{i=1}^np_ilog_2p_i\n\\\\&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}\n\\end{eqnarray*}\n$$\n　　其中，$n$是特征$A$的取值个数。`$split\\_info(A)$`称为特征$A$的“固有值”(intrinsic value)。属性$A$的可能取值数目越多（即$n$越大），则`$split\\_info(A)$`的值通常会越大。\n　　**信息增益比准则对可能取值数目较少的特征有所偏好**，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：**先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的**。\n## 三、决策树的生成\n　　输入：训练数据集$D$，特征集$A$，信息增益阈值$\\epsilon$\n　　输出：决策树$T$\n　　(1) 从根结点开始，数据集$D$全部分配在根结点；\n　　(2) 若$D$中所有样本都属于同一类$C_K$，则将$C_k$作为该结点的类标记，并返回$T$；\n　　(3) 若$A=\\varnothing$，则将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；\n　　(4) 否则，计算特征集$A$中各特征对$D$的信息增益，选择信息增益最大的特征$Ag$；\n　　(5) 如果特征$A_g$的信息增益小于阈值$\\epsilon$，那么将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；\n　　(6) 否则，对特征$Ag$的每一可能值$a_i$，依照$A_g=a_i$将$D$分割为若干个非空子集$D_i$，并将$D_i$中样本数最大的类作为类标记构建子结点，由结点跟子结点组成树$T$，返回$T$；\n　　(7) 对于第 $i$ 个子结点，以$D_i$为训练集，以$A-\\{Ag\\}$为特征集，递归地调用步骤(2)~(5)，得到子树$T_i$，返回$T_i$.\n## 四、剪枝处理\n　　剪枝是决策树学习算法对于“过拟合”的主要手段。决策树的剪枝策略有“预剪枝”和“后剪枝”。\n### 4.1 预剪枝\n　　预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶节点。\n　　预剪枝使得决策树的很多分支没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销，和测试时间开销；但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策带来了欠拟合的风险。\n### 4.2 后剪枝\n　　后剪枝是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。\n　　后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。\n　　注：对于如何判断决策树泛化性能能否提升，可采用留出法，即预留一部分数据用作“验证集”以进行性能评估。\n## 五、连续值和缺失值处理\n### 5.1 连续值处理\n　　现实学习任务中经常会遇到连续属性，对于连续属性，采用连续属性离散化技术。C4.5决策树算法中采用最简单的策略——二分法对连续属性进行处理。将这一特征下的所有取值从小到大排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点。\n### 5.2**缺失值处理（待补）**\n　　C4.5采用了下述解决方案：\n　　(1)对于如何在属性值缺失的情况下进行划分属性选择\n　　(2)对于给定属性划分，若样本在该属性上的值缺失，如何对样本进行划分\n## 六、常见问题\n### 6.1 C4.5比起ID3的改进：\n　　(1)在ID3中用信息增益选择特征时，会偏向于选择取值多的特征（不一定是最好的特征）；而采用信息增益比，可以削弱这种影响；\n　　注：需要注意的是，信息增益比准则对可能取值数目较少的特征有所偏好，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。\n　　(2)增加对连续值特征的处理步骤，将值排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点；\n　　(3)**增加缺失值的处理步骤,（待补）**\n### 6.2 决策树的优点\n　　(1)计算简单，可解释性强；\n　　(2)适合处理有缺失属性值的样本：空缺值相当于分裂时加多一个分支；\n　　(3)能够处理不相关的特征.\n### 6.3 决策树的缺点\n　　(1)容易过拟合；\n　　(2)不适合大样本数据集：每次分裂都需要遍历整个样本.\n## 七、参考\n- 李航，统计学习方法\n- 周志华，机器学习\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n\n\n\n\n","source":"_posts/ID3和C4.5算法.md","raw":"---\ntitle: ID3/C4.5算法\nmathjax: true\ndate: 2017-12-6 21:30:50\ncategories: \n- 机器学习\ntags:\n- 决策树\n- ID3\n- C4.5\n- 熵\n- 条件熵\n- 信息增益\n- 信息增益比\n- 预剪枝\n- 后剪枝\n- 连续值\n- 缺失值\n---\n　　决策树(decision tree)是机器学习中一种基本的分类与回归方法。\n　　决策树模型的3种经典学习算法：ID3，C4.5，CART。ID3与C4.5主要适用于分类问题；CART既适用于分类也适用于回归预测问题。\n　　本文主要记录ID3与C4.5算法，两者的区别主要在于前者用的是信息增益来选择特征，后者用的是信息增益比来选择特征以及增加对连续值特征的处理和缺失值特征的处理。\n\n<!-- more --> \n\n## 一、简介\n（1）决策树定义：决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)组成。内部节点表示一个特征或属性，叶结点表示一个类或者回归预测值。\n（2）决策树决策过程：从根结点开始，对样本的某一特征进行测试，根据测试结果，将样本分配到其子结点；这时，每一个子结点对应着该特征值的一个取值。如此递归对样本进行测试并分配，直至达到叶结点；\n（3）决策树模型的学习包含3个步骤：特征选择，决策树的生成（局部最优化过程），决策树的剪枝（全局最优化过程）。\n## 二、特征选择\n### 2.1 熵的定义\n　　熵表示随机变量不确定性的度量。设$X$是一个取有限值的离散随机变量，其概率分布为：`$P(X=x_i)=p_i,\\ i=1,2,...,n$`，则随机变量`$X$`的熵定义为：$$H(X) = -\\sum_{i=1}^{n}p_ilog_2p_i$$\n　　由定义可知，熵只依赖于$X$的分布，而与$X$的值无关，所以熵也可以记为$H(p)$。\n熵越大，随机变量的不确定性越大。当随机变量只取两个值时，例如1，0时，熵$H(p)$随概率$p$变化的曲线如图（分布为伯努利分布时熵与概率的关系）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ID3%E4%B8%8EC4.5/Binary_entropy_plot.svg.png\" width=\"30%\" height=\"30%\">　　当$p=0$或$p=1$时$H(p)=0$，随机变量完全没有不确定性。当$p=0.5$时，$H(p)=1$，熵取值最大，随机变量不确定性最大。\n### 2.2 条件熵的定义\n　　设有随机变量$(X,Y)$，其联合概率分布为\n$$P(X=x_i,Y=y_j)=p_{ij},i=1,2,...,n;j=1,2,...,m$$\n　　条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望\n$$H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)$$\n　　这里，$p_i=P(X=x_i),i=1,2,...,n.$\n　　当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的**熵**与**条件熵**分别成为**经验熵**和**经验条件熵**。\n### 2.3 信息增益的定义\n（1）符号定义\n- $D$：训练数据集；\n- $C_k$：第$k$个类的数据集； \n- $D_i$：根据特征$A$的第$i$个取值划分出来的数据集;\n- $D_{ik}$：根据特征$A$的第$i$个取值划分出来的数据集与第$k$个类的数据集的交集；\n- 数据集总共有$K$个类，特征$A$有$n$个取值，符号$|\\cdot |$表示数据集容量。\n\n（2）数据集$D$的经验熵$H(D)$：\n$$\\begin{eqnarray*}\nH(D)&=&-\\sum_{k=1}^{K}p_klog_2p_k\\\\\n    &=&-\\sum_{k=1}^{K}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}\n\\end{eqnarray*}\n$$\n（3）特征$A$给定条件下$D$的经验条件熵$H(D|A)$(尝试用特征$A$划分会有$n$个分支，相当求于求特征$A$的Expected Entropy，也可写做$EH(A)$)：\n$$\\begin{eqnarray*}\nH(D|A)&=&\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)\\\\\n&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^{K}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}\n\\end{eqnarray*}\n$$\n（4）计算特征$A$对样本集$D$的信息增益$g(D,A)$：\n$$g(D,A)=H(D)-H(D|A)$$\n　　给定训练数据集$D$和特征$A$，经验熵$H(D)$表示对数据集$D$进行分类的不确定性。而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性。那么它们的差，即信息增益$g(D,A)$，就**表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度**。\n　　显然，对于数据集$D$而言，信息增益依赖于特征，不同的特征往往具有不同的信息增益。**信息增益大的特征具有更强的分类能力**。\n　　**ID3采用信息增益来选择最优划分属性**。信息增益准则对可取值数目较多的特征有所偏好，为减少这种偏好可能带来的不利影响，**C4.5决策树算法不直接采用信息增益，而是使用“信息增益比”来选择最优划分属性**。\n### 2.4 信息增益比\n　　特征$A$对训练数据集$D$的信息增益比`$Gain\\_ratio(D,A)$`定义为：其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的分裂信息`$split\\_info(A)$`之比，即\n$$Gain\\_ratio(D,A)=\\frac{Gain(D,A)}{split\\_info(A)}$$\n　　分裂信息定义如下：\n$$\n\\begin{eqnarray*}\nsplit\\_info(A)&=&-\\sum_{i=1}^np_ilog_2p_i\n\\\\&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}\n\\end{eqnarray*}\n$$\n　　其中，$n$是特征$A$的取值个数。`$split\\_info(A)$`称为特征$A$的“固有值”(intrinsic value)。属性$A$的可能取值数目越多（即$n$越大），则`$split\\_info(A)$`的值通常会越大。\n　　**信息增益比准则对可能取值数目较少的特征有所偏好**，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：**先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的**。\n## 三、决策树的生成\n　　输入：训练数据集$D$，特征集$A$，信息增益阈值$\\epsilon$\n　　输出：决策树$T$\n　　(1) 从根结点开始，数据集$D$全部分配在根结点；\n　　(2) 若$D$中所有样本都属于同一类$C_K$，则将$C_k$作为该结点的类标记，并返回$T$；\n　　(3) 若$A=\\varnothing$，则将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；\n　　(4) 否则，计算特征集$A$中各特征对$D$的信息增益，选择信息增益最大的特征$Ag$；\n　　(5) 如果特征$A_g$的信息增益小于阈值$\\epsilon$，那么将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；\n　　(6) 否则，对特征$Ag$的每一可能值$a_i$，依照$A_g=a_i$将$D$分割为若干个非空子集$D_i$，并将$D_i$中样本数最大的类作为类标记构建子结点，由结点跟子结点组成树$T$，返回$T$；\n　　(7) 对于第 $i$ 个子结点，以$D_i$为训练集，以$A-\\{Ag\\}$为特征集，递归地调用步骤(2)~(5)，得到子树$T_i$，返回$T_i$.\n## 四、剪枝处理\n　　剪枝是决策树学习算法对于“过拟合”的主要手段。决策树的剪枝策略有“预剪枝”和“后剪枝”。\n### 4.1 预剪枝\n　　预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶节点。\n　　预剪枝使得决策树的很多分支没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销，和测试时间开销；但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策带来了欠拟合的风险。\n### 4.2 后剪枝\n　　后剪枝是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。\n　　后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。\n　　注：对于如何判断决策树泛化性能能否提升，可采用留出法，即预留一部分数据用作“验证集”以进行性能评估。\n## 五、连续值和缺失值处理\n### 5.1 连续值处理\n　　现实学习任务中经常会遇到连续属性，对于连续属性，采用连续属性离散化技术。C4.5决策树算法中采用最简单的策略——二分法对连续属性进行处理。将这一特征下的所有取值从小到大排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点。\n### 5.2**缺失值处理（待补）**\n　　C4.5采用了下述解决方案：\n　　(1)对于如何在属性值缺失的情况下进行划分属性选择\n　　(2)对于给定属性划分，若样本在该属性上的值缺失，如何对样本进行划分\n## 六、常见问题\n### 6.1 C4.5比起ID3的改进：\n　　(1)在ID3中用信息增益选择特征时，会偏向于选择取值多的特征（不一定是最好的特征）；而采用信息增益比，可以削弱这种影响；\n　　注：需要注意的是，信息增益比准则对可能取值数目较少的特征有所偏好，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。\n　　(2)增加对连续值特征的处理步骤，将值排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点；\n　　(3)**增加缺失值的处理步骤,（待补）**\n### 6.2 决策树的优点\n　　(1)计算简单，可解释性强；\n　　(2)适合处理有缺失属性值的样本：空缺值相当于分裂时加多一个分支；\n　　(3)能够处理不相关的特征.\n### 6.3 决策树的缺点\n　　(1)容易过拟合；\n　　(2)不适合大样本数据集：每次分裂都需要遍历整个样本.\n## 七、参考\n- 李航，统计学习方法\n- 周志华，机器学习\n- [Nando de Freitas, CPS540](https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6)\n- [林轩田，机器学习技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n\n\n\n\n","slug":"ID3和C4.5算法","published":1,"updated":"2018-02-03T09:13:24.985Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w04002mqslpao12uiv6","content":"<p>　　决策树(decision tree)是机器学习中一种基本的分类与回归方法。<br>　　决策树模型的3种经典学习算法：ID3，C4.5，CART。ID3与C4.5主要适用于分类问题；CART既适用于分类也适用于回归预测问题。<br>　　本文主要记录ID3与C4.5算法，两者的区别主要在于前者用的是信息增益来选择特征，后者用的是信息增益比来选择特征以及增加对连续值特征的处理和缺失值特征的处理。</p>\n<a id=\"more\"></a> \n<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>（1）决策树定义：决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)组成。内部节点表示一个特征或属性，叶结点表示一个类或者回归预测值。<br>（2）决策树决策过程：从根结点开始，对样本的某一特征进行测试，根据测试结果，将样本分配到其子结点；这时，每一个子结点对应着该特征值的一个取值。如此递归对样本进行测试并分配，直至达到叶结点；<br>（3）决策树模型的学习包含3个步骤：特征选择，决策树的生成（局部最优化过程），决策树的剪枝（全局最优化过程）。</p>\n<h2 id=\"二、特征选择\"><a href=\"#二、特征选择\" class=\"headerlink\" title=\"二、特征选择\"></a>二、特征选择</h2><h3 id=\"2-1-熵的定义\"><a href=\"#2-1-熵的定义\" class=\"headerlink\" title=\"2.1 熵的定义\"></a>2.1 熵的定义</h3><p>　　熵表示随机变量不确定性的度量。设$X$是一个取有限值的离散随机变量，其概率分布为：<script type=\"math/tex\">P(X=x_i)=p_i,\\ i=1,2,...,n</script>，则随机变量<script type=\"math/tex\">X</script>的熵定义为：<script type=\"math/tex\">H(X) = -\\sum_{i=1}^{n}p_ilog_2p_i</script><br>　　由定义可知，熵只依赖于$X$的分布，而与$X$的值无关，所以熵也可以记为$H(p)$。<br>熵越大，随机变量的不确定性越大。当随机变量只取两个值时，例如1，0时，熵$H(p)$随概率$p$变化的曲线如图（分布为伯努利分布时熵与概率的关系）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ID3%E4%B8%8EC4.5/Binary_entropy_plot.svg.png\" width=\"30%\" height=\"30%\">　　当$p=0$或$p=1$时$H(p)=0$，随机变量完全没有不确定性。当$p=0.5$时，$H(p)=1$，熵取值最大，随机变量不确定性最大。</p>\n<h3 id=\"2-2-条件熵的定义\"><a href=\"#2-2-条件熵的定义\" class=\"headerlink\" title=\"2.2 条件熵的定义\"></a>2.2 条件熵的定义</h3><p>　　设有随机变量$(X,Y)$，其联合概率分布为</p>\n<script type=\"math/tex; mode=display\">P(X=x_i,Y=y_j)=p_{ij},i=1,2,...,n;j=1,2,...,m</script><p>　　条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望</p>\n<script type=\"math/tex; mode=display\">H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)</script><p>　　这里，$p_i=P(X=x_i),i=1,2,…,n.$<br>　　当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的<strong>熵</strong>与<strong>条件熵</strong>分别成为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</p>\n<h3 id=\"2-3-信息增益的定义\"><a href=\"#2-3-信息增益的定义\" class=\"headerlink\" title=\"2.3 信息增益的定义\"></a>2.3 信息增益的定义</h3><p>（1）符号定义</p>\n<ul>\n<li>$D$：训练数据集；</li>\n<li>$C_k$：第$k$个类的数据集； </li>\n<li>$D_i$：根据特征$A$的第$i$个取值划分出来的数据集;</li>\n<li>$D_{ik}$：根据特征$A$的第$i$个取值划分出来的数据集与第$k$个类的数据集的交集；</li>\n<li>数据集总共有$K$个类，特征$A$有$n$个取值，符号$|\\cdot |$表示数据集容量。</li>\n</ul>\n<p>（2）数据集$D$的经验熵$H(D)$：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nH(D)&=&-\\sum_{k=1}^{K}p_klog_2p_k\\\\\n    &=&-\\sum_{k=1}^{K}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}\n\\end{eqnarray*}</script><p>（3）特征$A$给定条件下$D$的经验条件熵$H(D|A)$(尝试用特征$A$划分会有$n$个分支，相当求于求特征$A$的Expected Entropy，也可写做$EH(A)$)：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nH(D|A)&=&\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)\\\\\n&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^{K}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}\n\\end{eqnarray*}</script><p>（4）计算特征$A$对样本集$D$的信息增益$g(D,A)$：</p>\n<script type=\"math/tex; mode=display\">g(D,A)=H(D)-H(D|A)</script><p>　　给定训练数据集$D$和特征$A$，经验熵$H(D)$表示对数据集$D$进行分类的不确定性。而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性。那么它们的差，即信息增益$g(D,A)$，就<strong>表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度</strong>。<br>　　显然，对于数据集$D$而言，信息增益依赖于特征，不同的特征往往具有不同的信息增益。<strong>信息增益大的特征具有更强的分类能力</strong>。<br>　　<strong>ID3采用信息增益来选择最优划分属性</strong>。信息增益准则对可取值数目较多的特征有所偏好，为减少这种偏好可能带来的不利影响，<strong>C4.5决策树算法不直接采用信息增益，而是使用“信息增益比”来选择最优划分属性</strong>。</p>\n<h3 id=\"2-4-信息增益比\"><a href=\"#2-4-信息增益比\" class=\"headerlink\" title=\"2.4 信息增益比\"></a>2.4 信息增益比</h3><p>　　特征$A$对训练数据集$D$的信息增益比<script type=\"math/tex\">Gain\\_ratio(D,A)</script>定义为：其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的分裂信息<script type=\"math/tex\">split\\_info(A)</script>之比，即</p>\n<script type=\"math/tex; mode=display\">Gain\\_ratio(D,A)=\\frac{Gain(D,A)}{split\\_info(A)}</script><p>　　分裂信息定义如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nsplit\\_info(A)&=&-\\sum_{i=1}^np_ilog_2p_i\n\\\\&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}\n\\end{eqnarray*}</script><p>　　其中，$n$是特征$A$的取值个数。<script type=\"math/tex\">split\\_info(A)</script>称为特征$A$的“固有值”(intrinsic value)。属性$A$的可能取值数目越多（即$n$越大），则<script type=\"math/tex\">split\\_info(A)</script>的值通常会越大。<br>　　<strong>信息增益比准则对可能取值数目较少的特征有所偏好</strong>，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：<strong>先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的</strong>。</p>\n<h2 id=\"三、决策树的生成\"><a href=\"#三、决策树的生成\" class=\"headerlink\" title=\"三、决策树的生成\"></a>三、决策树的生成</h2><p>　　输入：训练数据集$D$，特征集$A$，信息增益阈值$\\epsilon$<br>　　输出：决策树$T$<br>　　(1) 从根结点开始，数据集$D$全部分配在根结点；<br>　　(2) 若$D$中所有样本都属于同一类$C_K$，则将$C_k$作为该结点的类标记，并返回$T$；<br>　　(3) 若$A=\\varnothing$，则将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；<br>　　(4) 否则，计算特征集$A$中各特征对$D$的信息增益，选择信息增益最大的特征$Ag$；<br>　　(5) 如果特征$A_g$的信息增益小于阈值$\\epsilon$，那么将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；<br>　　(6) 否则，对特征$Ag$的每一可能值$a_i$，依照$A_g=a_i$将$D$分割为若干个非空子集$D_i$，并将$D_i$中样本数最大的类作为类标记构建子结点，由结点跟子结点组成树$T$，返回$T$；<br>　　(7) 对于第 $i$ 个子结点，以$D_i$为训练集，以$A-\\{Ag\\}$为特征集，递归地调用步骤(2)~(5)，得到子树$T_i$，返回$T_i$.</p>\n<h2 id=\"四、剪枝处理\"><a href=\"#四、剪枝处理\" class=\"headerlink\" title=\"四、剪枝处理\"></a>四、剪枝处理</h2><p>　　剪枝是决策树学习算法对于“过拟合”的主要手段。决策树的剪枝策略有“预剪枝”和“后剪枝”。</p>\n<h3 id=\"4-1-预剪枝\"><a href=\"#4-1-预剪枝\" class=\"headerlink\" title=\"4.1 预剪枝\"></a>4.1 预剪枝</h3><p>　　预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶节点。<br>　　预剪枝使得决策树的很多分支没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销，和测试时间开销；但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策带来了欠拟合的风险。</p>\n<h3 id=\"4-2-后剪枝\"><a href=\"#4-2-后剪枝\" class=\"headerlink\" title=\"4.2 后剪枝\"></a>4.2 后剪枝</h3><p>　　后剪枝是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。<br>　　后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。<br>　　注：对于如何判断决策树泛化性能能否提升，可采用留出法，即预留一部分数据用作“验证集”以进行性能评估。</p>\n<h2 id=\"五、连续值和缺失值处理\"><a href=\"#五、连续值和缺失值处理\" class=\"headerlink\" title=\"五、连续值和缺失值处理\"></a>五、连续值和缺失值处理</h2><h3 id=\"5-1-连续值处理\"><a href=\"#5-1-连续值处理\" class=\"headerlink\" title=\"5.1 连续值处理\"></a>5.1 连续值处理</h3><p>　　现实学习任务中经常会遇到连续属性，对于连续属性，采用连续属性离散化技术。C4.5决策树算法中采用最简单的策略——二分法对连续属性进行处理。将这一特征下的所有取值从小到大排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点。</p>\n<h3 id=\"5-2缺失值处理（待补）\"><a href=\"#5-2缺失值处理（待补）\" class=\"headerlink\" title=\"5.2缺失值处理（待补）\"></a>5.2<strong>缺失值处理（待补）</strong></h3><p>　　C4.5采用了下述解决方案：<br>　　(1)对于如何在属性值缺失的情况下进行划分属性选择<br>　　(2)对于给定属性划分，若样本在该属性上的值缺失，如何对样本进行划分</p>\n<h2 id=\"六、常见问题\"><a href=\"#六、常见问题\" class=\"headerlink\" title=\"六、常见问题\"></a>六、常见问题</h2><h3 id=\"6-1-C4-5比起ID3的改进：\"><a href=\"#6-1-C4-5比起ID3的改进：\" class=\"headerlink\" title=\"6.1 C4.5比起ID3的改进：\"></a>6.1 C4.5比起ID3的改进：</h3><p>　　(1)在ID3中用信息增益选择特征时，会偏向于选择取值多的特征（不一定是最好的特征）；而采用信息增益比，可以削弱这种影响；<br>　　注：需要注意的是，信息增益比准则对可能取值数目较少的特征有所偏好，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。<br>　　(2)增加对连续值特征的处理步骤，将值排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点；<br>　　(3)<strong>增加缺失值的处理步骤,（待补）</strong></p>\n<h3 id=\"6-2-决策树的优点\"><a href=\"#6-2-决策树的优点\" class=\"headerlink\" title=\"6.2 决策树的优点\"></a>6.2 决策树的优点</h3><p>　　(1)计算简单，可解释性强；<br>　　(2)适合处理有缺失属性值的样本：空缺值相当于分裂时加多一个分支；<br>　　(3)能够处理不相关的特征.</p>\n<h3 id=\"6-3-决策树的缺点\"><a href=\"#6-3-决策树的缺点\" class=\"headerlink\" title=\"6.3 决策树的缺点\"></a>6.3 决策树的缺点</h3><p>　　(1)容易过拟合；<br>　　(2)不适合大样本数据集：每次分裂都需要遍历整个样本.</p>\n<h2 id=\"七、参考\"><a href=\"#七、参考\" class=\"headerlink\" title=\"七、参考\"></a>七、参考</h2><ul>\n<li>李航，统计学习方法</li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　决策树(decision tree)是机器学习中一种基本的分类与回归方法。<br>　　决策树模型的3种经典学习算法：ID3，C4.5，CART。ID3与C4.5主要适用于分类问题；CART既适用于分类也适用于回归预测问题。<br>　　本文主要记录ID3与C4.5算法，两者的区别主要在于前者用的是信息增益来选择特征，后者用的是信息增益比来选择特征以及增加对连续值特征的处理和缺失值特征的处理。</p>","more":"<h2 id=\"一、简介\"><a href=\"#一、简介\" class=\"headerlink\" title=\"一、简介\"></a>一、简介</h2><p>（1）决策树定义：决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)组成。内部节点表示一个特征或属性，叶结点表示一个类或者回归预测值。<br>（2）决策树决策过程：从根结点开始，对样本的某一特征进行测试，根据测试结果，将样本分配到其子结点；这时，每一个子结点对应着该特征值的一个取值。如此递归对样本进行测试并分配，直至达到叶结点；<br>（3）决策树模型的学习包含3个步骤：特征选择，决策树的生成（局部最优化过程），决策树的剪枝（全局最优化过程）。</p>\n<h2 id=\"二、特征选择\"><a href=\"#二、特征选择\" class=\"headerlink\" title=\"二、特征选择\"></a>二、特征选择</h2><h3 id=\"2-1-熵的定义\"><a href=\"#2-1-熵的定义\" class=\"headerlink\" title=\"2.1 熵的定义\"></a>2.1 熵的定义</h3><p>　　熵表示随机变量不确定性的度量。设$X$是一个取有限值的离散随机变量，其概率分布为：<script type=\"math/tex\">P(X=x_i)=p_i,\\ i=1,2,...,n</script>，则随机变量<script type=\"math/tex\">X</script>的熵定义为：<script type=\"math/tex\">H(X) = -\\sum_{i=1}^{n}p_ilog_2p_i</script><br>　　由定义可知，熵只依赖于$X$的分布，而与$X$的值无关，所以熵也可以记为$H(p)$。<br>熵越大，随机变量的不确定性越大。当随机变量只取两个值时，例如1，0时，熵$H(p)$随概率$p$变化的曲线如图（分布为伯努利分布时熵与概率的关系）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ID3%E4%B8%8EC4.5/Binary_entropy_plot.svg.png\" width=\"30%\" height=\"30%\">　　当$p=0$或$p=1$时$H(p)=0$，随机变量完全没有不确定性。当$p=0.5$时，$H(p)=1$，熵取值最大，随机变量不确定性最大。</p>\n<h3 id=\"2-2-条件熵的定义\"><a href=\"#2-2-条件熵的定义\" class=\"headerlink\" title=\"2.2 条件熵的定义\"></a>2.2 条件熵的定义</h3><p>　　设有随机变量$(X,Y)$，其联合概率分布为</p>\n<script type=\"math/tex; mode=display\">P(X=x_i,Y=y_j)=p_{ij},i=1,2,...,n;j=1,2,...,m</script><p>　　条件熵$H(Y|X)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$，定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望</p>\n<script type=\"math/tex; mode=display\">H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)</script><p>　　这里，$p_i=P(X=x_i),i=1,2,…,n.$<br>　　当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的<strong>熵</strong>与<strong>条件熵</strong>分别成为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</p>\n<h3 id=\"2-3-信息增益的定义\"><a href=\"#2-3-信息增益的定义\" class=\"headerlink\" title=\"2.3 信息增益的定义\"></a>2.3 信息增益的定义</h3><p>（1）符号定义</p>\n<ul>\n<li>$D$：训练数据集；</li>\n<li>$C_k$：第$k$个类的数据集； </li>\n<li>$D_i$：根据特征$A$的第$i$个取值划分出来的数据集;</li>\n<li>$D_{ik}$：根据特征$A$的第$i$个取值划分出来的数据集与第$k$个类的数据集的交集；</li>\n<li>数据集总共有$K$个类，特征$A$有$n$个取值，符号$|\\cdot |$表示数据集容量。</li>\n</ul>\n<p>（2）数据集$D$的经验熵$H(D)$：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nH(D)&=&-\\sum_{k=1}^{K}p_klog_2p_k\\\\\n    &=&-\\sum_{k=1}^{K}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}\n\\end{eqnarray*}</script><p>（3）特征$A$给定条件下$D$的经验条件熵$H(D|A)$(尝试用特征$A$划分会有$n$个分支，相当求于求特征$A$的Expected Entropy，也可写做$EH(A)$)：</p>\n<script type=\"math/tex; mode=display\">\\begin{eqnarray*}\nH(D|A)&=&\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)\\\\\n&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^{K}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}\n\\end{eqnarray*}</script><p>（4）计算特征$A$对样本集$D$的信息增益$g(D,A)$：</p>\n<script type=\"math/tex; mode=display\">g(D,A)=H(D)-H(D|A)</script><p>　　给定训练数据集$D$和特征$A$，经验熵$H(D)$表示对数据集$D$进行分类的不确定性。而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性。那么它们的差，即信息增益$g(D,A)$，就<strong>表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度</strong>。<br>　　显然，对于数据集$D$而言，信息增益依赖于特征，不同的特征往往具有不同的信息增益。<strong>信息增益大的特征具有更强的分类能力</strong>。<br>　　<strong>ID3采用信息增益来选择最优划分属性</strong>。信息增益准则对可取值数目较多的特征有所偏好，为减少这种偏好可能带来的不利影响，<strong>C4.5决策树算法不直接采用信息增益，而是使用“信息增益比”来选择最优划分属性</strong>。</p>\n<h3 id=\"2-4-信息增益比\"><a href=\"#2-4-信息增益比\" class=\"headerlink\" title=\"2.4 信息增益比\"></a>2.4 信息增益比</h3><p>　　特征$A$对训练数据集$D$的信息增益比<script type=\"math/tex\">Gain\\_ratio(D,A)</script>定义为：其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的分裂信息<script type=\"math/tex\">split\\_info(A)</script>之比，即</p>\n<script type=\"math/tex; mode=display\">Gain\\_ratio(D,A)=\\frac{Gain(D,A)}{split\\_info(A)}</script><p>　　分裂信息定义如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{eqnarray*}\nsplit\\_info(A)&=&-\\sum_{i=1}^np_ilog_2p_i\n\\\\&=&-\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}\n\\end{eqnarray*}</script><p>　　其中，$n$是特征$A$的取值个数。<script type=\"math/tex\">split\\_info(A)</script>称为特征$A$的“固有值”(intrinsic value)。属性$A$的可能取值数目越多（即$n$越大），则<script type=\"math/tex\">split\\_info(A)</script>的值通常会越大。<br>　　<strong>信息增益比准则对可能取值数目较少的特征有所偏好</strong>，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：<strong>先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的</strong>。</p>\n<h2 id=\"三、决策树的生成\"><a href=\"#三、决策树的生成\" class=\"headerlink\" title=\"三、决策树的生成\"></a>三、决策树的生成</h2><p>　　输入：训练数据集$D$，特征集$A$，信息增益阈值$\\epsilon$<br>　　输出：决策树$T$<br>　　(1) 从根结点开始，数据集$D$全部分配在根结点；<br>　　(2) 若$D$中所有样本都属于同一类$C_K$，则将$C_k$作为该结点的类标记，并返回$T$；<br>　　(3) 若$A=\\varnothing$，则将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；<br>　　(4) 否则，计算特征集$A$中各特征对$D$的信息增益，选择信息增益最大的特征$Ag$；<br>　　(5) 如果特征$A_g$的信息增益小于阈值$\\epsilon$，那么将$D$中样本数最大的类$C_k$作为该结点的类标记，并返回$T$；<br>　　(6) 否则，对特征$Ag$的每一可能值$a_i$，依照$A_g=a_i$将$D$分割为若干个非空子集$D_i$，并将$D_i$中样本数最大的类作为类标记构建子结点，由结点跟子结点组成树$T$，返回$T$；<br>　　(7) 对于第 $i$ 个子结点，以$D_i$为训练集，以$A-\\{Ag\\}$为特征集，递归地调用步骤(2)~(5)，得到子树$T_i$，返回$T_i$.</p>\n<h2 id=\"四、剪枝处理\"><a href=\"#四、剪枝处理\" class=\"headerlink\" title=\"四、剪枝处理\"></a>四、剪枝处理</h2><p>　　剪枝是决策树学习算法对于“过拟合”的主要手段。决策树的剪枝策略有“预剪枝”和“后剪枝”。</p>\n<h3 id=\"4-1-预剪枝\"><a href=\"#4-1-预剪枝\" class=\"headerlink\" title=\"4.1 预剪枝\"></a>4.1 预剪枝</h3><p>　　预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶节点。<br>　　预剪枝使得决策树的很多分支没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销，和测试时间开销；但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策带来了欠拟合的风险。</p>\n<h3 id=\"4-2-后剪枝\"><a href=\"#4-2-后剪枝\" class=\"headerlink\" title=\"4.2 后剪枝\"></a>4.2 后剪枝</h3><p>　　后剪枝是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。<br>　　后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。<br>　　注：对于如何判断决策树泛化性能能否提升，可采用留出法，即预留一部分数据用作“验证集”以进行性能评估。</p>\n<h2 id=\"五、连续值和缺失值处理\"><a href=\"#五、连续值和缺失值处理\" class=\"headerlink\" title=\"五、连续值和缺失值处理\"></a>五、连续值和缺失值处理</h2><h3 id=\"5-1-连续值处理\"><a href=\"#5-1-连续值处理\" class=\"headerlink\" title=\"5.1 连续值处理\"></a>5.1 连续值处理</h3><p>　　现实学习任务中经常会遇到连续属性，对于连续属性，采用连续属性离散化技术。C4.5决策树算法中采用最简单的策略——二分法对连续属性进行处理。将这一特征下的所有取值从小到大排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点。</p>\n<h3 id=\"5-2缺失值处理（待补）\"><a href=\"#5-2缺失值处理（待补）\" class=\"headerlink\" title=\"5.2缺失值处理（待补）\"></a>5.2<strong>缺失值处理（待补）</strong></h3><p>　　C4.5采用了下述解决方案：<br>　　(1)对于如何在属性值缺失的情况下进行划分属性选择<br>　　(2)对于给定属性划分，若样本在该属性上的值缺失，如何对样本进行划分</p>\n<h2 id=\"六、常见问题\"><a href=\"#六、常见问题\" class=\"headerlink\" title=\"六、常见问题\"></a>六、常见问题</h2><h3 id=\"6-1-C4-5比起ID3的改进：\"><a href=\"#6-1-C4-5比起ID3的改进：\" class=\"headerlink\" title=\"6.1 C4.5比起ID3的改进：\"></a>6.1 C4.5比起ID3的改进：</h3><p>　　(1)在ID3中用信息增益选择特征时，会偏向于选择取值多的特征（不一定是最好的特征）；而采用信息增益比，可以削弱这种影响；<br>　　注：需要注意的是，信息增益比准则对可能取值数目较少的特征有所偏好，因此C4.5算法并不是直接选择增益率最大的候选划分特征，而是使用了一个启发式：先从候选划分特征中找出信息增益高于平均水平的特征，再从中选择增益率最高的。<br>　　(2)增加对连续值特征的处理步骤，将值排序，然后依次选择相邻两个数的中值进行二元划分，计算信息增益比，从而选出最佳划分点；<br>　　(3)<strong>增加缺失值的处理步骤,（待补）</strong></p>\n<h3 id=\"6-2-决策树的优点\"><a href=\"#6-2-决策树的优点\" class=\"headerlink\" title=\"6.2 决策树的优点\"></a>6.2 决策树的优点</h3><p>　　(1)计算简单，可解释性强；<br>　　(2)适合处理有缺失属性值的样本：空缺值相当于分裂时加多一个分支；<br>　　(3)能够处理不相关的特征.</p>\n<h3 id=\"6-3-决策树的缺点\"><a href=\"#6-3-决策树的缺点\" class=\"headerlink\" title=\"6.3 决策树的缺点\"></a>6.3 决策树的缺点</h3><p>　　(1)容易过拟合；<br>　　(2)不适合大样本数据集：每次分裂都需要遍历整个样本.</p>\n<h2 id=\"七、参考\"><a href=\"#七、参考\" class=\"headerlink\" title=\"七、参考\"></a>七、参考</h2><ul>\n<li>李航，统计学习方法</li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\" target=\"_blank\" rel=\"noopener\">Nando de Freitas, CPS540</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n</ul>"},{"title":"ShuffleNetV1","mathjax":true,"date":"2018-12-30T14:22:50.000Z","_content":"\n# 摘要\n\n- 提出CNN结构ShuffleNet，专门针对计算力非常有限的移动设备(10-150MFLOPs)而设计。\n- ShuffleNet利用两种新的操作：逐点分组卷积(pointwise group convolution)和通道重排(channel shuffle)，在保持准确率的同时，显著地减少了计算代价。\n- 在给定的计算复杂度开销下，ShuffleNet允许更多的特征图通道数，这一点可以帮助编码更多的信息，这对于小型网络的表现是尤其关键的。\n- 在ImageNet分类任务中，在计算开销为40MFLOPs时，ShuffleNet的top-1错误率，比MobileNetV1要低7.8%。\n- 在基于ARM的移动设备上，ShuffleNet相比于AlexNet得到了大约13倍的实际加速，同时保持了类似的精度。\n\n<!-- more -->\n\n# 创新点\n\n## 逐点分组卷积(pointwise group convolution)\n\n背景：\n\n- 现代卷积神经网络的绝大多数计算量集中在卷积操作上，因此高效的卷积层设计是减少网络复杂度的关键。\n- 其中，稀疏连接(sparse connection)是提高卷积运算效率的有效途径，当前不少优秀的卷积模型均沿用了这一思路：\n - 谷歌的”Xception“网络引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积（depthwise convolution）和逐点卷积（pointwise convolution）两部进行，有效地减少了计算量和参数量；\n - 而 Facebook 的“ResNeXt”网络[2]则首先使用逐点卷积减少输入特征的通道数，再利用计算量较小的分组卷积（group convolution）结构取代原有的卷积运算，同样可以减少整体的计算复杂度。\n\n具体改进：\n\n- ShuffleNet 网络结构同样沿袭了稀疏连接的设计理念。\n- 作者通过分析Xception和ResNeXt模型，发现这两种结构通过卷积核拆分虽然计算复杂度均较原始卷积运算有所下降，然而拆分所产生的逐点卷积计算量却相当可观，成为了新的瓶颈。\n- 即分析Xception和ResNeXt，它们在$1 \\times1$卷积上的代价过大。因此提出逐点分组卷积来减少$1 \\times1$卷积的复杂度:\n - 例如：在ResNeXt中，只有$3 \\times3$卷积配备了分组卷积。因此，在ResNeXt的残差单元中，逐点卷积占据了93.4%的multiplication-adds。\n - 在小型网络中，昂贵的逐点卷积会限制通道的数目，以应对复杂度限制。但这也显著地伤害了准确率。\n - 为了解决这个问题，一个直截了当的解决方案便是施加通道稀疏连接，如对$1 \\times1$卷积进行分组卷积。\n - 分组卷积通过保证在对应的输入通道分组上进行卷积，因此显著地减少了计算代价。\n\n## 通道重排(channel shuffle)\n\n<img src=\"/images/ShuffleNetV1/1.png\"  width = \"400\" height = \"100\"/>\n\n原因：\n\n- 在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换（如图 1(a) 所示）。这将可能影响到模型的表示能力和识别精度。\n- 因此，在使用分组逐点卷积的同时，需要引入组间信息交换的机制；也就是说，对于第二层卷积而言，每个卷积核需要同时接收各组的特征作为输入，如图 1(b) 所示。\n- 作者指出，通过引入“通道重排”（channel shuffle，见图 1(c) ）可以很方便地实现这一机制；并且由于通道重排操作是可导的，因此可以嵌在网络结构中实现端到端的学习。\n\n## ShuffleNet单元(ShuffleNet Unit)\n<img src=\"/images/ShuffleNetV1/2.png\"  width = \"700\" height = \"100\"/>\n\n基于分组逐点卷积和通道重排操作，作者提出了全新的ShuffleNet结构单元，如Fig2所示。该结构继承了“残差网络”（ResNet）的设计思想，在此基础上做出了一系列改进来提升模型的效率：\n\n- 首先，如Fig2(a)所示，使用逐通道卷积替换原有的 3x3 卷积，降低卷积操作抽取空间特征的复杂度；\n- 然后，如Fig2(b)所示，将原先结构中前后两个 1x1 逐点卷积分组化，并在两层之间添加通道重排操作，进一步降低卷积运算的跨通道计算量。最终的结构单元如图 2(b) 所示。\n - 第二个逐点分组卷积的目的是恢复通道的维度，来与捷径相匹配。\n - 为了简洁，没有在第二个逐点分组卷积层之后施加通道重排，因为这样的网络结构已经可以得到有力的结果。\n-  BN和非线性激活函数的使用同ResNet和ResNeXt类似；但在depthwise卷积之后，不适用ReLU。这一点由Xception建议。\n- 如Fig2(c)所示，为ShuffleNet专门用于特征图的降采样的单元，做了两点修改：\n - 在捷径中增加$3\\times 3$的步长为2的平均池化操作\n - 用通道串联(channel concatenation)替代逐像素加(element-wise addition)，使得通过较少的额外的计算代价，来简单地实现通道维度的扩大\n- 由于伴有通道重排的逐点分组卷积，ShuffleNet单元中的所有组件均能够有效地进行计算。给定一个计算开销，ShuffleNet能够得到更宽的特征图，这一点对于小型网络至关重要，因为小型网络通常没有足够数量的通道数目来处理信息。\n\n## ShuffleNet结构\n<img src=\"/images/ShuffleNetV1/3.png\"  width = \"800\" height = \"100\"/>\n\n如Table1所示，为ShuffleNet总体结构：\n\n- 借助ShuffleNet结构单元，作者构建了完整的ShuffeNet网络模型：\n - 它主要由16个ShuffleNet结构单元堆叠而成，分属网络的三个阶段；\n - 每经过一个阶段特征图的空间尺寸减半，而通道数翻倍；\n - 即在每一个阶段中的第一个building block中施加步长为2；在每一阶段中的其他超参数保持一致；下一个阶段的输出通道数double；\n - 整个模型的总计算量约为 140 MFLOPs。通过简单地将各层通道数进行放缩，可以得到其他任意复杂度的模型。\n- 对于每一个ShuffleNet单元，与ResNet相似，设置bottleneck的通道数为输出通道数的$1/4$。\n- 在ShuffleNet中，分组数目$g$控制着逐点卷积的连接稀疏性。Table1中探究了不同的分组数目，文中通过调整输出通道数来保证了总体的计算代价大体不变(~140MFLOPs)：\n - 可以发现，当卷积运算的分组数越多，模型的计算量就越低；\n - 这就意味着当总计算量一定时，较大的分组数可以允许较多的通道数，作者认为这将有利于网络编码更多的信息，提升模型的识别能力。\n- 为了定制模型到想要的复杂度，简单地在通道数目上施加一个缩放因子$s$即可。Table1中的模型称为\"ShuffleNet 1x\"，\"ShuffleNet sx\"意为缩放\"ShuffleNet 1x\"中的通道数目$s$倍，因此，总体地复杂度大约是\"ShuffleNet 1x\"的$s^2$倍。\n - 疑问：为什么是$s^2$倍？\n\n# 训练策略\n\n大多数的训练设置和超参数选择和ResNeXt一致，有两点例外：\n\n- 将权重衰减设置为$4e^{-5}$而不是$1e^{-4}$；用线性衰减学习率策略(从0.5减少到0)\n- 在预处理时，用更少的尺寸增强(scale augmentation)\n- 在MobileNet中，也有上述两点相似的修改，因为小网络通常更易欠拟合而不是过拟合。\n\n# 消融实验\n<img src=\"/images/ShuffleNetV1/4.png\"  width = \"600\" height = \"100\"/>\n\n 如Table2所示，为逐点分组卷积的组数对分类错误率的影响：\n\n- 从结果可以看出，带有分组卷积($g>1$)的模型，总是比对应的不带有分组卷积($g=1$)的模型要好。\n- 更小的网络从分组卷积中受益更多：\n - 如ShuffleNet1x($g=8$)比ShuffleNet1x($g=1$)的错误率低1.2%;\n - ShuffleNet0.5x($g=4$)比ShuffleNet0.5x($g=1$)的错误率低3.5%;\n - ShuffleNet0.25x($g=8$)比ShuffleNet0.25x($g=1$)的错误率低4.4%。\n- 注意，在给定的复杂度限制下，分组卷积允许了更多的特征图通道数，因此本文假设：更宽的特征图帮助编码更多信息，可以获得更好的表现。\n\n<img src=\"/images/ShuffleNetV1/5.png\"  width = \"600\" height = \"100\"/>\n\n  如Table3所示，为通道重排的消融实验结果：\n  \n  - 通道重排的目的是使得组间信息能够互相交流。在实验中，有通道重排的网络始终优于没有通道重排的网络，错误率降低 0.9%~4.0%。\n  - 尤其，当分组数目较大(如$g=8$)时，通道重排对于模型的提升更大，如对于ShuffleNet1x($g=8$)，通道重排对于模型的提升达5.2%；这也说明了跨组之间的信息交换的重要性。\n\n# 模型比较\n<img src=\"/images/ShuffleNetV1/6.png\"  width = \"600\" height = \"100\"/>\n\n如Table5所示，为在不同复杂度下，ShuffleNet和MobileNet的对比结果：\n\n- 结果表明，在所有复杂度下，ShuffleNet都优于MobileNet：\n - 尽管ShuffleNet专为小型网络设计(<150MFLOPs)，在增大到 MobileNet 的 500~600 MFLOPs 量级，仍优于MobileNet，如在500MFLOPs的计算代价上，ShuffleNet比MobileNet1x高3.1%。\n - 在40MFLOPs的计算代价上，ShuffleNet比MobileNet错误率低 6.7%。\n \n<img src=\"/images/ShuffleNetV1/7.png\"  width = \"600\" height = \"100\"/>\n\n如Table6所示，为ShuffleNet与不同模型的计算复杂度对比。\n\n<img src=\"/images/ShuffleNetV1/8.png\"  width = \"700\" height = \"100\"/>\n \n 如Table8所示，为在基于ARM平台的移动设备上，ShuffleNet与不同模型的真实推理速度评估结果：\n\n- 对于ShuffleNet，尽管更大的分组卷积(如$g=4$或如$g=8$)通常有更好的表现，但文中发现在实际应用中地效率较低；因此，文中经验性地选择$g=3$来作为精度和实际推理速度之间的合适的权衡值。\n- 在实际应用中，由于内存访问和其他开销，文中发现：每4倍的理论复杂度减少通常会导致约2.6倍的实际加速。\n- 相比于AlexNet，ShuffleNet0.5x在得到相似准确率的同时，得到约13倍的实际加速(理论加速为18倍)。\n\n# 参考文献\n\n- [论文：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2017](https://arxiv.org/pdf/1707.01083.pdf)\n- [博客(旷视官方)：为移动AI而生——旷视(Face++)最新成果ShuffleNet全面解读](https://www.sohu.com/a/156321743_418390)\n\n\n\n\n\n","source":"_posts/ShuffleNetV1.md","raw":"---\ntitle: ShuffleNetV1\nmathjax: true\ndate: 2018-12-30 22:22:50\ncategories: \n- 轻量型CNN\ntags:\n---\n\n# 摘要\n\n- 提出CNN结构ShuffleNet，专门针对计算力非常有限的移动设备(10-150MFLOPs)而设计。\n- ShuffleNet利用两种新的操作：逐点分组卷积(pointwise group convolution)和通道重排(channel shuffle)，在保持准确率的同时，显著地减少了计算代价。\n- 在给定的计算复杂度开销下，ShuffleNet允许更多的特征图通道数，这一点可以帮助编码更多的信息，这对于小型网络的表现是尤其关键的。\n- 在ImageNet分类任务中，在计算开销为40MFLOPs时，ShuffleNet的top-1错误率，比MobileNetV1要低7.8%。\n- 在基于ARM的移动设备上，ShuffleNet相比于AlexNet得到了大约13倍的实际加速，同时保持了类似的精度。\n\n<!-- more -->\n\n# 创新点\n\n## 逐点分组卷积(pointwise group convolution)\n\n背景：\n\n- 现代卷积神经网络的绝大多数计算量集中在卷积操作上，因此高效的卷积层设计是减少网络复杂度的关键。\n- 其中，稀疏连接(sparse connection)是提高卷积运算效率的有效途径，当前不少优秀的卷积模型均沿用了这一思路：\n - 谷歌的”Xception“网络引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积（depthwise convolution）和逐点卷积（pointwise convolution）两部进行，有效地减少了计算量和参数量；\n - 而 Facebook 的“ResNeXt”网络[2]则首先使用逐点卷积减少输入特征的通道数，再利用计算量较小的分组卷积（group convolution）结构取代原有的卷积运算，同样可以减少整体的计算复杂度。\n\n具体改进：\n\n- ShuffleNet 网络结构同样沿袭了稀疏连接的设计理念。\n- 作者通过分析Xception和ResNeXt模型，发现这两种结构通过卷积核拆分虽然计算复杂度均较原始卷积运算有所下降，然而拆分所产生的逐点卷积计算量却相当可观，成为了新的瓶颈。\n- 即分析Xception和ResNeXt，它们在$1 \\times1$卷积上的代价过大。因此提出逐点分组卷积来减少$1 \\times1$卷积的复杂度:\n - 例如：在ResNeXt中，只有$3 \\times3$卷积配备了分组卷积。因此，在ResNeXt的残差单元中，逐点卷积占据了93.4%的multiplication-adds。\n - 在小型网络中，昂贵的逐点卷积会限制通道的数目，以应对复杂度限制。但这也显著地伤害了准确率。\n - 为了解决这个问题，一个直截了当的解决方案便是施加通道稀疏连接，如对$1 \\times1$卷积进行分组卷积。\n - 分组卷积通过保证在对应的输入通道分组上进行卷积，因此显著地减少了计算代价。\n\n## 通道重排(channel shuffle)\n\n<img src=\"/images/ShuffleNetV1/1.png\"  width = \"400\" height = \"100\"/>\n\n原因：\n\n- 在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换（如图 1(a) 所示）。这将可能影响到模型的表示能力和识别精度。\n- 因此，在使用分组逐点卷积的同时，需要引入组间信息交换的机制；也就是说，对于第二层卷积而言，每个卷积核需要同时接收各组的特征作为输入，如图 1(b) 所示。\n- 作者指出，通过引入“通道重排”（channel shuffle，见图 1(c) ）可以很方便地实现这一机制；并且由于通道重排操作是可导的，因此可以嵌在网络结构中实现端到端的学习。\n\n## ShuffleNet单元(ShuffleNet Unit)\n<img src=\"/images/ShuffleNetV1/2.png\"  width = \"700\" height = \"100\"/>\n\n基于分组逐点卷积和通道重排操作，作者提出了全新的ShuffleNet结构单元，如Fig2所示。该结构继承了“残差网络”（ResNet）的设计思想，在此基础上做出了一系列改进来提升模型的效率：\n\n- 首先，如Fig2(a)所示，使用逐通道卷积替换原有的 3x3 卷积，降低卷积操作抽取空间特征的复杂度；\n- 然后，如Fig2(b)所示，将原先结构中前后两个 1x1 逐点卷积分组化，并在两层之间添加通道重排操作，进一步降低卷积运算的跨通道计算量。最终的结构单元如图 2(b) 所示。\n - 第二个逐点分组卷积的目的是恢复通道的维度，来与捷径相匹配。\n - 为了简洁，没有在第二个逐点分组卷积层之后施加通道重排，因为这样的网络结构已经可以得到有力的结果。\n-  BN和非线性激活函数的使用同ResNet和ResNeXt类似；但在depthwise卷积之后，不适用ReLU。这一点由Xception建议。\n- 如Fig2(c)所示，为ShuffleNet专门用于特征图的降采样的单元，做了两点修改：\n - 在捷径中增加$3\\times 3$的步长为2的平均池化操作\n - 用通道串联(channel concatenation)替代逐像素加(element-wise addition)，使得通过较少的额外的计算代价，来简单地实现通道维度的扩大\n- 由于伴有通道重排的逐点分组卷积，ShuffleNet单元中的所有组件均能够有效地进行计算。给定一个计算开销，ShuffleNet能够得到更宽的特征图，这一点对于小型网络至关重要，因为小型网络通常没有足够数量的通道数目来处理信息。\n\n## ShuffleNet结构\n<img src=\"/images/ShuffleNetV1/3.png\"  width = \"800\" height = \"100\"/>\n\n如Table1所示，为ShuffleNet总体结构：\n\n- 借助ShuffleNet结构单元，作者构建了完整的ShuffeNet网络模型：\n - 它主要由16个ShuffleNet结构单元堆叠而成，分属网络的三个阶段；\n - 每经过一个阶段特征图的空间尺寸减半，而通道数翻倍；\n - 即在每一个阶段中的第一个building block中施加步长为2；在每一阶段中的其他超参数保持一致；下一个阶段的输出通道数double；\n - 整个模型的总计算量约为 140 MFLOPs。通过简单地将各层通道数进行放缩，可以得到其他任意复杂度的模型。\n- 对于每一个ShuffleNet单元，与ResNet相似，设置bottleneck的通道数为输出通道数的$1/4$。\n- 在ShuffleNet中，分组数目$g$控制着逐点卷积的连接稀疏性。Table1中探究了不同的分组数目，文中通过调整输出通道数来保证了总体的计算代价大体不变(~140MFLOPs)：\n - 可以发现，当卷积运算的分组数越多，模型的计算量就越低；\n - 这就意味着当总计算量一定时，较大的分组数可以允许较多的通道数，作者认为这将有利于网络编码更多的信息，提升模型的识别能力。\n- 为了定制模型到想要的复杂度，简单地在通道数目上施加一个缩放因子$s$即可。Table1中的模型称为\"ShuffleNet 1x\"，\"ShuffleNet sx\"意为缩放\"ShuffleNet 1x\"中的通道数目$s$倍，因此，总体地复杂度大约是\"ShuffleNet 1x\"的$s^2$倍。\n - 疑问：为什么是$s^2$倍？\n\n# 训练策略\n\n大多数的训练设置和超参数选择和ResNeXt一致，有两点例外：\n\n- 将权重衰减设置为$4e^{-5}$而不是$1e^{-4}$；用线性衰减学习率策略(从0.5减少到0)\n- 在预处理时，用更少的尺寸增强(scale augmentation)\n- 在MobileNet中，也有上述两点相似的修改，因为小网络通常更易欠拟合而不是过拟合。\n\n# 消融实验\n<img src=\"/images/ShuffleNetV1/4.png\"  width = \"600\" height = \"100\"/>\n\n 如Table2所示，为逐点分组卷积的组数对分类错误率的影响：\n\n- 从结果可以看出，带有分组卷积($g>1$)的模型，总是比对应的不带有分组卷积($g=1$)的模型要好。\n- 更小的网络从分组卷积中受益更多：\n - 如ShuffleNet1x($g=8$)比ShuffleNet1x($g=1$)的错误率低1.2%;\n - ShuffleNet0.5x($g=4$)比ShuffleNet0.5x($g=1$)的错误率低3.5%;\n - ShuffleNet0.25x($g=8$)比ShuffleNet0.25x($g=1$)的错误率低4.4%。\n- 注意，在给定的复杂度限制下，分组卷积允许了更多的特征图通道数，因此本文假设：更宽的特征图帮助编码更多信息，可以获得更好的表现。\n\n<img src=\"/images/ShuffleNetV1/5.png\"  width = \"600\" height = \"100\"/>\n\n  如Table3所示，为通道重排的消融实验结果：\n  \n  - 通道重排的目的是使得组间信息能够互相交流。在实验中，有通道重排的网络始终优于没有通道重排的网络，错误率降低 0.9%~4.0%。\n  - 尤其，当分组数目较大(如$g=8$)时，通道重排对于模型的提升更大，如对于ShuffleNet1x($g=8$)，通道重排对于模型的提升达5.2%；这也说明了跨组之间的信息交换的重要性。\n\n# 模型比较\n<img src=\"/images/ShuffleNetV1/6.png\"  width = \"600\" height = \"100\"/>\n\n如Table5所示，为在不同复杂度下，ShuffleNet和MobileNet的对比结果：\n\n- 结果表明，在所有复杂度下，ShuffleNet都优于MobileNet：\n - 尽管ShuffleNet专为小型网络设计(<150MFLOPs)，在增大到 MobileNet 的 500~600 MFLOPs 量级，仍优于MobileNet，如在500MFLOPs的计算代价上，ShuffleNet比MobileNet1x高3.1%。\n - 在40MFLOPs的计算代价上，ShuffleNet比MobileNet错误率低 6.7%。\n \n<img src=\"/images/ShuffleNetV1/7.png\"  width = \"600\" height = \"100\"/>\n\n如Table6所示，为ShuffleNet与不同模型的计算复杂度对比。\n\n<img src=\"/images/ShuffleNetV1/8.png\"  width = \"700\" height = \"100\"/>\n \n 如Table8所示，为在基于ARM平台的移动设备上，ShuffleNet与不同模型的真实推理速度评估结果：\n\n- 对于ShuffleNet，尽管更大的分组卷积(如$g=4$或如$g=8$)通常有更好的表现，但文中发现在实际应用中地效率较低；因此，文中经验性地选择$g=3$来作为精度和实际推理速度之间的合适的权衡值。\n- 在实际应用中，由于内存访问和其他开销，文中发现：每4倍的理论复杂度减少通常会导致约2.6倍的实际加速。\n- 相比于AlexNet，ShuffleNet0.5x在得到相似准确率的同时，得到约13倍的实际加速(理论加速为18倍)。\n\n# 参考文献\n\n- [论文：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2017](https://arxiv.org/pdf/1707.01083.pdf)\n- [博客(旷视官方)：为移动AI而生——旷视(Face++)最新成果ShuffleNet全面解读](https://www.sohu.com/a/156321743_418390)\n\n\n\n\n\n","slug":"ShuffleNetV1","published":1,"updated":"2019-01-02T04:09:07.539Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w06002nqslpsw79ezxc","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出CNN结构ShuffleNet，专门针对计算力非常有限的移动设备(10-150MFLOPs)而设计。</li>\n<li>ShuffleNet利用两种新的操作：逐点分组卷积(pointwise group convolution)和通道重排(channel shuffle)，在保持准确率的同时，显著地减少了计算代价。</li>\n<li>在给定的计算复杂度开销下，ShuffleNet允许更多的特征图通道数，这一点可以帮助编码更多的信息，这对于小型网络的表现是尤其关键的。</li>\n<li>在ImageNet分类任务中，在计算开销为40MFLOPs时，ShuffleNet的top-1错误率，比MobileNetV1要低7.8%。</li>\n<li>在基于ARM的移动设备上，ShuffleNet相比于AlexNet得到了大约13倍的实际加速，同时保持了类似的精度。</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"逐点分组卷积-pointwise-group-convolution\"><a href=\"#逐点分组卷积-pointwise-group-convolution\" class=\"headerlink\" title=\"逐点分组卷积(pointwise group convolution)\"></a>逐点分组卷积(pointwise group convolution)</h2><p>背景：</p>\n<ul>\n<li>现代卷积神经网络的绝大多数计算量集中在卷积操作上，因此高效的卷积层设计是减少网络复杂度的关键。</li>\n<li>其中，稀疏连接(sparse connection)是提高卷积运算效率的有效途径，当前不少优秀的卷积模型均沿用了这一思路：<ul>\n<li>谷歌的”Xception“网络引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积（depthwise convolution）和逐点卷积（pointwise convolution）两部进行，有效地减少了计算量和参数量；</li>\n<li>而 Facebook 的“ResNeXt”网络[2]则首先使用逐点卷积减少输入特征的通道数，再利用计算量较小的分组卷积（group convolution）结构取代原有的卷积运算，同样可以减少整体的计算复杂度。</li>\n</ul>\n</li>\n</ul>\n<p>具体改进：</p>\n<ul>\n<li>ShuffleNet 网络结构同样沿袭了稀疏连接的设计理念。</li>\n<li>作者通过分析Xception和ResNeXt模型，发现这两种结构通过卷积核拆分虽然计算复杂度均较原始卷积运算有所下降，然而拆分所产生的逐点卷积计算量却相当可观，成为了新的瓶颈。</li>\n<li>即分析Xception和ResNeXt，它们在$1 \\times1$卷积上的代价过大。因此提出逐点分组卷积来减少$1 \\times1$卷积的复杂度:<ul>\n<li>例如：在ResNeXt中，只有$3 \\times3$卷积配备了分组卷积。因此，在ResNeXt的残差单元中，逐点卷积占据了93.4%的multiplication-adds。</li>\n<li>在小型网络中，昂贵的逐点卷积会限制通道的数目，以应对复杂度限制。但这也显著地伤害了准确率。</li>\n<li>为了解决这个问题，一个直截了当的解决方案便是施加通道稀疏连接，如对$1 \\times1$卷积进行分组卷积。</li>\n<li>分组卷积通过保证在对应的输入通道分组上进行卷积，因此显著地减少了计算代价。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"通道重排-channel-shuffle\"><a href=\"#通道重排-channel-shuffle\" class=\"headerlink\" title=\"通道重排(channel shuffle)\"></a>通道重排(channel shuffle)</h2><p><img src=\"/images/ShuffleNetV1/1.png\" width=\"400\" height=\"100\"></p>\n<p>原因：</p>\n<ul>\n<li>在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换（如图 1(a) 所示）。这将可能影响到模型的表示能力和识别精度。</li>\n<li>因此，在使用分组逐点卷积的同时，需要引入组间信息交换的机制；也就是说，对于第二层卷积而言，每个卷积核需要同时接收各组的特征作为输入，如图 1(b) 所示。</li>\n<li>作者指出，通过引入“通道重排”（channel shuffle，见图 1(c) ）可以很方便地实现这一机制；并且由于通道重排操作是可导的，因此可以嵌在网络结构中实现端到端的学习。</li>\n</ul>\n<h2 id=\"ShuffleNet单元-ShuffleNet-Unit\"><a href=\"#ShuffleNet单元-ShuffleNet-Unit\" class=\"headerlink\" title=\"ShuffleNet单元(ShuffleNet Unit)\"></a>ShuffleNet单元(ShuffleNet Unit)</h2><p><img src=\"/images/ShuffleNetV1/2.png\" width=\"700\" height=\"100\"></p>\n<p>基于分组逐点卷积和通道重排操作，作者提出了全新的ShuffleNet结构单元，如Fig2所示。该结构继承了“残差网络”（ResNet）的设计思想，在此基础上做出了一系列改进来提升模型的效率：</p>\n<ul>\n<li>首先，如Fig2(a)所示，使用逐通道卷积替换原有的 3x3 卷积，降低卷积操作抽取空间特征的复杂度；</li>\n<li>然后，如Fig2(b)所示，将原先结构中前后两个 1x1 逐点卷积分组化，并在两层之间添加通道重排操作，进一步降低卷积运算的跨通道计算量。最终的结构单元如图 2(b) 所示。<ul>\n<li>第二个逐点分组卷积的目的是恢复通道的维度，来与捷径相匹配。</li>\n<li>为了简洁，没有在第二个逐点分组卷积层之后施加通道重排，因为这样的网络结构已经可以得到有力的结果。</li>\n</ul>\n</li>\n<li>BN和非线性激活函数的使用同ResNet和ResNeXt类似；但在depthwise卷积之后，不适用ReLU。这一点由Xception建议。</li>\n<li>如Fig2(c)所示，为ShuffleNet专门用于特征图的降采样的单元，做了两点修改：<ul>\n<li>在捷径中增加$3\\times 3$的步长为2的平均池化操作</li>\n<li>用通道串联(channel concatenation)替代逐像素加(element-wise addition)，使得通过较少的额外的计算代价，来简单地实现通道维度的扩大</li>\n</ul>\n</li>\n<li>由于伴有通道重排的逐点分组卷积，ShuffleNet单元中的所有组件均能够有效地进行计算。给定一个计算开销，ShuffleNet能够得到更宽的特征图，这一点对于小型网络至关重要，因为小型网络通常没有足够数量的通道数目来处理信息。</li>\n</ul>\n<h2 id=\"ShuffleNet结构\"><a href=\"#ShuffleNet结构\" class=\"headerlink\" title=\"ShuffleNet结构\"></a>ShuffleNet结构</h2><p><img src=\"/images/ShuffleNetV1/3.png\" width=\"800\" height=\"100\"></p>\n<p>如Table1所示，为ShuffleNet总体结构：</p>\n<ul>\n<li>借助ShuffleNet结构单元，作者构建了完整的ShuffeNet网络模型：<ul>\n<li>它主要由16个ShuffleNet结构单元堆叠而成，分属网络的三个阶段；</li>\n<li>每经过一个阶段特征图的空间尺寸减半，而通道数翻倍；</li>\n<li>即在每一个阶段中的第一个building block中施加步长为2；在每一阶段中的其他超参数保持一致；下一个阶段的输出通道数double；</li>\n<li>整个模型的总计算量约为 140 MFLOPs。通过简单地将各层通道数进行放缩，可以得到其他任意复杂度的模型。</li>\n</ul>\n</li>\n<li>对于每一个ShuffleNet单元，与ResNet相似，设置bottleneck的通道数为输出通道数的$1/4$。</li>\n<li>在ShuffleNet中，分组数目$g$控制着逐点卷积的连接稀疏性。Table1中探究了不同的分组数目，文中通过调整输出通道数来保证了总体的计算代价大体不变(~140MFLOPs)：<ul>\n<li>可以发现，当卷积运算的分组数越多，模型的计算量就越低；</li>\n<li>这就意味着当总计算量一定时，较大的分组数可以允许较多的通道数，作者认为这将有利于网络编码更多的信息，提升模型的识别能力。</li>\n</ul>\n</li>\n<li>为了定制模型到想要的复杂度，简单地在通道数目上施加一个缩放因子$s$即可。Table1中的模型称为”ShuffleNet 1x”，”ShuffleNet sx”意为缩放”ShuffleNet 1x”中的通道数目$s$倍，因此，总体地复杂度大约是”ShuffleNet 1x”的$s^2$倍。<ul>\n<li>疑问：为什么是$s^2$倍？</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>大多数的训练设置和超参数选择和ResNeXt一致，有两点例外：</p>\n<ul>\n<li>将权重衰减设置为$4e^{-5}$而不是$1e^{-4}$；用线性衰减学习率策略(从0.5减少到0)</li>\n<li>在预处理时，用更少的尺寸增强(scale augmentation)</li>\n<li>在MobileNet中，也有上述两点相似的修改，因为小网络通常更易欠拟合而不是过拟合。</li>\n</ul>\n<h1 id=\"消融实验\"><a href=\"#消融实验\" class=\"headerlink\" title=\"消融实验\"></a>消融实验</h1><p><img src=\"/images/ShuffleNetV1/4.png\" width=\"600\" height=\"100\"></p>\n<p> 如Table2所示，为逐点分组卷积的组数对分类错误率的影响：</p>\n<ul>\n<li>从结果可以看出，带有分组卷积($g&gt;1$)的模型，总是比对应的不带有分组卷积($g=1$)的模型要好。</li>\n<li>更小的网络从分组卷积中受益更多：<ul>\n<li>如ShuffleNet1x($g=8$)比ShuffleNet1x($g=1$)的错误率低1.2%;</li>\n<li>ShuffleNet0.5x($g=4$)比ShuffleNet0.5x($g=1$)的错误率低3.5%;</li>\n<li>ShuffleNet0.25x($g=8$)比ShuffleNet0.25x($g=1$)的错误率低4.4%。</li>\n</ul>\n</li>\n<li>注意，在给定的复杂度限制下，分组卷积允许了更多的特征图通道数，因此本文假设：更宽的特征图帮助编码更多信息，可以获得更好的表现。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV1/5.png\" width=\"600\" height=\"100\"></p>\n<p>  如Table3所示，为通道重排的消融实验结果：</p>\n<ul>\n<li>通道重排的目的是使得组间信息能够互相交流。在实验中，有通道重排的网络始终优于没有通道重排的网络，错误率降低 0.9%~4.0%。</li>\n<li>尤其，当分组数目较大(如$g=8$)时，通道重排对于模型的提升更大，如对于ShuffleNet1x($g=8$)，通道重排对于模型的提升达5.2%；这也说明了跨组之间的信息交换的重要性。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/ShuffleNetV1/6.png\" width=\"600\" height=\"100\"></p>\n<p>如Table5所示，为在不同复杂度下，ShuffleNet和MobileNet的对比结果：</p>\n<ul>\n<li>结果表明，在所有复杂度下，ShuffleNet都优于MobileNet：<ul>\n<li>尽管ShuffleNet专为小型网络设计(&lt;150MFLOPs)，在增大到 MobileNet 的 500~600 MFLOPs 量级，仍优于MobileNet，如在500MFLOPs的计算代价上，ShuffleNet比MobileNet1x高3.1%。</li>\n<li>在40MFLOPs的计算代价上，ShuffleNet比MobileNet错误率低 6.7%。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV1/7.png\" width=\"600\" height=\"100\"></p>\n<p>如Table6所示，为ShuffleNet与不同模型的计算复杂度对比。</p>\n<p><img src=\"/images/ShuffleNetV1/8.png\" width=\"700\" height=\"100\"></p>\n<p> 如Table8所示，为在基于ARM平台的移动设备上，ShuffleNet与不同模型的真实推理速度评估结果：</p>\n<ul>\n<li>对于ShuffleNet，尽管更大的分组卷积(如$g=4$或如$g=8$)通常有更好的表现，但文中发现在实际应用中地效率较低；因此，文中经验性地选择$g=3$来作为精度和实际推理速度之间的合适的权衡值。</li>\n<li>在实际应用中，由于内存访问和其他开销，文中发现：每4倍的理论复杂度减少通常会导致约2.6倍的实际加速。</li>\n<li>相比于AlexNet，ShuffleNet0.5x在得到相似准确率的同时，得到约13倍的实际加速(理论加速为18倍)。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1707.01083.pdf\" target=\"_blank\" rel=\"noopener\">论文：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2017</a></li>\n<li><a href=\"https://www.sohu.com/a/156321743_418390\" target=\"_blank\" rel=\"noopener\">博客(旷视官方)：为移动AI而生——旷视(Face++)最新成果ShuffleNet全面解读</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>提出CNN结构ShuffleNet，专门针对计算力非常有限的移动设备(10-150MFLOPs)而设计。</li>\n<li>ShuffleNet利用两种新的操作：逐点分组卷积(pointwise group convolution)和通道重排(channel shuffle)，在保持准确率的同时，显著地减少了计算代价。</li>\n<li>在给定的计算复杂度开销下，ShuffleNet允许更多的特征图通道数，这一点可以帮助编码更多的信息，这对于小型网络的表现是尤其关键的。</li>\n<li>在ImageNet分类任务中，在计算开销为40MFLOPs时，ShuffleNet的top-1错误率，比MobileNetV1要低7.8%。</li>\n<li>在基于ARM的移动设备上，ShuffleNet相比于AlexNet得到了大约13倍的实际加速，同时保持了类似的精度。</li>\n</ul>","more":"<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"逐点分组卷积-pointwise-group-convolution\"><a href=\"#逐点分组卷积-pointwise-group-convolution\" class=\"headerlink\" title=\"逐点分组卷积(pointwise group convolution)\"></a>逐点分组卷积(pointwise group convolution)</h2><p>背景：</p>\n<ul>\n<li>现代卷积神经网络的绝大多数计算量集中在卷积操作上，因此高效的卷积层设计是减少网络复杂度的关键。</li>\n<li>其中，稀疏连接(sparse connection)是提高卷积运算效率的有效途径，当前不少优秀的卷积模型均沿用了这一思路：<ul>\n<li>谷歌的”Xception“网络引入了”深度可分离卷积”的概念，将普通的卷积运算拆分成逐通道卷积（depthwise convolution）和逐点卷积（pointwise convolution）两部进行，有效地减少了计算量和参数量；</li>\n<li>而 Facebook 的“ResNeXt”网络[2]则首先使用逐点卷积减少输入特征的通道数，再利用计算量较小的分组卷积（group convolution）结构取代原有的卷积运算，同样可以减少整体的计算复杂度。</li>\n</ul>\n</li>\n</ul>\n<p>具体改进：</p>\n<ul>\n<li>ShuffleNet 网络结构同样沿袭了稀疏连接的设计理念。</li>\n<li>作者通过分析Xception和ResNeXt模型，发现这两种结构通过卷积核拆分虽然计算复杂度均较原始卷积运算有所下降，然而拆分所产生的逐点卷积计算量却相当可观，成为了新的瓶颈。</li>\n<li>即分析Xception和ResNeXt，它们在$1 \\times1$卷积上的代价过大。因此提出逐点分组卷积来减少$1 \\times1$卷积的复杂度:<ul>\n<li>例如：在ResNeXt中，只有$3 \\times3$卷积配备了分组卷积。因此，在ResNeXt的残差单元中，逐点卷积占据了93.4%的multiplication-adds。</li>\n<li>在小型网络中，昂贵的逐点卷积会限制通道的数目，以应对复杂度限制。但这也显著地伤害了准确率。</li>\n<li>为了解决这个问题，一个直截了当的解决方案便是施加通道稀疏连接，如对$1 \\times1$卷积进行分组卷积。</li>\n<li>分组卷积通过保证在对应的输入通道分组上进行卷积，因此显著地减少了计算代价。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"通道重排-channel-shuffle\"><a href=\"#通道重排-channel-shuffle\" class=\"headerlink\" title=\"通道重排(channel shuffle)\"></a>通道重排(channel shuffle)</h2><p><img src=\"/images/ShuffleNetV1/1.png\" width=\"400\" height=\"100\"></p>\n<p>原因：</p>\n<ul>\n<li>在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换（如图 1(a) 所示）。这将可能影响到模型的表示能力和识别精度。</li>\n<li>因此，在使用分组逐点卷积的同时，需要引入组间信息交换的机制；也就是说，对于第二层卷积而言，每个卷积核需要同时接收各组的特征作为输入，如图 1(b) 所示。</li>\n<li>作者指出，通过引入“通道重排”（channel shuffle，见图 1(c) ）可以很方便地实现这一机制；并且由于通道重排操作是可导的，因此可以嵌在网络结构中实现端到端的学习。</li>\n</ul>\n<h2 id=\"ShuffleNet单元-ShuffleNet-Unit\"><a href=\"#ShuffleNet单元-ShuffleNet-Unit\" class=\"headerlink\" title=\"ShuffleNet单元(ShuffleNet Unit)\"></a>ShuffleNet单元(ShuffleNet Unit)</h2><p><img src=\"/images/ShuffleNetV1/2.png\" width=\"700\" height=\"100\"></p>\n<p>基于分组逐点卷积和通道重排操作，作者提出了全新的ShuffleNet结构单元，如Fig2所示。该结构继承了“残差网络”（ResNet）的设计思想，在此基础上做出了一系列改进来提升模型的效率：</p>\n<ul>\n<li>首先，如Fig2(a)所示，使用逐通道卷积替换原有的 3x3 卷积，降低卷积操作抽取空间特征的复杂度；</li>\n<li>然后，如Fig2(b)所示，将原先结构中前后两个 1x1 逐点卷积分组化，并在两层之间添加通道重排操作，进一步降低卷积运算的跨通道计算量。最终的结构单元如图 2(b) 所示。<ul>\n<li>第二个逐点分组卷积的目的是恢复通道的维度，来与捷径相匹配。</li>\n<li>为了简洁，没有在第二个逐点分组卷积层之后施加通道重排，因为这样的网络结构已经可以得到有力的结果。</li>\n</ul>\n</li>\n<li>BN和非线性激活函数的使用同ResNet和ResNeXt类似；但在depthwise卷积之后，不适用ReLU。这一点由Xception建议。</li>\n<li>如Fig2(c)所示，为ShuffleNet专门用于特征图的降采样的单元，做了两点修改：<ul>\n<li>在捷径中增加$3\\times 3$的步长为2的平均池化操作</li>\n<li>用通道串联(channel concatenation)替代逐像素加(element-wise addition)，使得通过较少的额外的计算代价，来简单地实现通道维度的扩大</li>\n</ul>\n</li>\n<li>由于伴有通道重排的逐点分组卷积，ShuffleNet单元中的所有组件均能够有效地进行计算。给定一个计算开销，ShuffleNet能够得到更宽的特征图，这一点对于小型网络至关重要，因为小型网络通常没有足够数量的通道数目来处理信息。</li>\n</ul>\n<h2 id=\"ShuffleNet结构\"><a href=\"#ShuffleNet结构\" class=\"headerlink\" title=\"ShuffleNet结构\"></a>ShuffleNet结构</h2><p><img src=\"/images/ShuffleNetV1/3.png\" width=\"800\" height=\"100\"></p>\n<p>如Table1所示，为ShuffleNet总体结构：</p>\n<ul>\n<li>借助ShuffleNet结构单元，作者构建了完整的ShuffeNet网络模型：<ul>\n<li>它主要由16个ShuffleNet结构单元堆叠而成，分属网络的三个阶段；</li>\n<li>每经过一个阶段特征图的空间尺寸减半，而通道数翻倍；</li>\n<li>即在每一个阶段中的第一个building block中施加步长为2；在每一阶段中的其他超参数保持一致；下一个阶段的输出通道数double；</li>\n<li>整个模型的总计算量约为 140 MFLOPs。通过简单地将各层通道数进行放缩，可以得到其他任意复杂度的模型。</li>\n</ul>\n</li>\n<li>对于每一个ShuffleNet单元，与ResNet相似，设置bottleneck的通道数为输出通道数的$1/4$。</li>\n<li>在ShuffleNet中，分组数目$g$控制着逐点卷积的连接稀疏性。Table1中探究了不同的分组数目，文中通过调整输出通道数来保证了总体的计算代价大体不变(~140MFLOPs)：<ul>\n<li>可以发现，当卷积运算的分组数越多，模型的计算量就越低；</li>\n<li>这就意味着当总计算量一定时，较大的分组数可以允许较多的通道数，作者认为这将有利于网络编码更多的信息，提升模型的识别能力。</li>\n</ul>\n</li>\n<li>为了定制模型到想要的复杂度，简单地在通道数目上施加一个缩放因子$s$即可。Table1中的模型称为”ShuffleNet 1x”，”ShuffleNet sx”意为缩放”ShuffleNet 1x”中的通道数目$s$倍，因此，总体地复杂度大约是”ShuffleNet 1x”的$s^2$倍。<ul>\n<li>疑问：为什么是$s^2$倍？</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"训练策略\"><a href=\"#训练策略\" class=\"headerlink\" title=\"训练策略\"></a>训练策略</h1><p>大多数的训练设置和超参数选择和ResNeXt一致，有两点例外：</p>\n<ul>\n<li>将权重衰减设置为$4e^{-5}$而不是$1e^{-4}$；用线性衰减学习率策略(从0.5减少到0)</li>\n<li>在预处理时，用更少的尺寸增强(scale augmentation)</li>\n<li>在MobileNet中，也有上述两点相似的修改，因为小网络通常更易欠拟合而不是过拟合。</li>\n</ul>\n<h1 id=\"消融实验\"><a href=\"#消融实验\" class=\"headerlink\" title=\"消融实验\"></a>消融实验</h1><p><img src=\"/images/ShuffleNetV1/4.png\" width=\"600\" height=\"100\"></p>\n<p> 如Table2所示，为逐点分组卷积的组数对分类错误率的影响：</p>\n<ul>\n<li>从结果可以看出，带有分组卷积($g&gt;1$)的模型，总是比对应的不带有分组卷积($g=1$)的模型要好。</li>\n<li>更小的网络从分组卷积中受益更多：<ul>\n<li>如ShuffleNet1x($g=8$)比ShuffleNet1x($g=1$)的错误率低1.2%;</li>\n<li>ShuffleNet0.5x($g=4$)比ShuffleNet0.5x($g=1$)的错误率低3.5%;</li>\n<li>ShuffleNet0.25x($g=8$)比ShuffleNet0.25x($g=1$)的错误率低4.4%。</li>\n</ul>\n</li>\n<li>注意，在给定的复杂度限制下，分组卷积允许了更多的特征图通道数，因此本文假设：更宽的特征图帮助编码更多信息，可以获得更好的表现。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV1/5.png\" width=\"600\" height=\"100\"></p>\n<p>  如Table3所示，为通道重排的消融实验结果：</p>\n<ul>\n<li>通道重排的目的是使得组间信息能够互相交流。在实验中，有通道重排的网络始终优于没有通道重排的网络，错误率降低 0.9%~4.0%。</li>\n<li>尤其，当分组数目较大(如$g=8$)时，通道重排对于模型的提升更大，如对于ShuffleNet1x($g=8$)，通道重排对于模型的提升达5.2%；这也说明了跨组之间的信息交换的重要性。</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/ShuffleNetV1/6.png\" width=\"600\" height=\"100\"></p>\n<p>如Table5所示，为在不同复杂度下，ShuffleNet和MobileNet的对比结果：</p>\n<ul>\n<li>结果表明，在所有复杂度下，ShuffleNet都优于MobileNet：<ul>\n<li>尽管ShuffleNet专为小型网络设计(&lt;150MFLOPs)，在增大到 MobileNet 的 500~600 MFLOPs 量级，仍优于MobileNet，如在500MFLOPs的计算代价上，ShuffleNet比MobileNet1x高3.1%。</li>\n<li>在40MFLOPs的计算代价上，ShuffleNet比MobileNet错误率低 6.7%。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV1/7.png\" width=\"600\" height=\"100\"></p>\n<p>如Table6所示，为ShuffleNet与不同模型的计算复杂度对比。</p>\n<p><img src=\"/images/ShuffleNetV1/8.png\" width=\"700\" height=\"100\"></p>\n<p> 如Table8所示，为在基于ARM平台的移动设备上，ShuffleNet与不同模型的真实推理速度评估结果：</p>\n<ul>\n<li>对于ShuffleNet，尽管更大的分组卷积(如$g=4$或如$g=8$)通常有更好的表现，但文中发现在实际应用中地效率较低；因此，文中经验性地选择$g=3$来作为精度和实际推理速度之间的合适的权衡值。</li>\n<li>在实际应用中，由于内存访问和其他开销，文中发现：每4倍的理论复杂度减少通常会导致约2.6倍的实际加速。</li>\n<li>相比于AlexNet，ShuffleNet0.5x在得到相似准确率的同时，得到约13倍的实际加速(理论加速为18倍)。</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1707.01083.pdf\" target=\"_blank\" rel=\"noopener\">论文：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2017</a></li>\n<li><a href=\"https://www.sohu.com/a/156321743_418390\" target=\"_blank\" rel=\"noopener\">博客(旷视官方)：为移动AI而生——旷视(Face++)最新成果ShuffleNet全面解读</a></li>\n</ul>"},{"title":"ShuffleNetV2","mathjax":true,"date":"2018-12-30T14:25:50.000Z","_content":" \n# 摘要\n\n- 目前，神经网络架构的设计主要由计算复杂度的间接指标(即FLOPs)来指导；\n- 但是，直接指标(如速度或延迟)还依赖于其他因素，如内存访问成本(MAC, memory access cost)和平台特点(platform characterics)；\n- 因此，本文指出过去在网络架构设计上仅注重间接指标 FLOPs 的不足，并提出两个基本原则(principles)和四个实用准则(practical guidelines)来指导网络架构设计；\n- 提出针对移动端深度学习的第二代卷积神经网络ShuffleNetV2，在综合实验评估中，ShuffleNetV2在速度和精度的权衡方面达到当前最优水平。\n- 注：FLOPs，即the number of float-point operations，定义为the number of multiply-adds.\n<!-- more -->\n\n# 创新点\n\n## 间接指标(FLOPs)与直接指标(速度/延迟)\n\n对于FLOPs：\n\n- 当前，FLOPs，即浮点运算数，是度量计算复杂度的常用指标。\n- 然而，FLOPs是一种间接指标。它只是本文真正关心的直接指标(如速度或延迟)的一种近似形式，通常无法与直接指标划等号。\n- 实验表明：FLOPs近似的网络也会有不同的速度。\n- 所以，将FLOPs作为衡量计算复杂度的唯一标准是不够的，这样会导致次优设计。\n\n间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因可以归结为两点：\n- 首先，对速度有较大影响的几个重要因素对FLOPs不产生太大作用:\n - 第一个因素是内存访问成本(MAC, memory access cost)。在某些操作(如组卷积)中，MAC占运行时间的很大一部分。对于像GPU这样具备强大计算能力的设备而言，这就是瓶颈。在网络架构设计过程中，MAC不能被简单忽视。\n - 第二个因素是并行度(degree of parallelism)。当FLOPs相同时，高并行度的模型可能比低并行度的模型快得多。\n- 其次，取决于平台特点(platform characterics)，FLOPs相同的运算可能有着不同的运行时间\n - 例如，早期研究广泛使用张量分解(tensor decomposition)来加速矩阵相乘。但是，近期研究发现尽管张量分解减少了75%的FLOPs，但在GPU上甚至更慢。本文研究人员对此进行了调查，发现原因在于最新的CUDNN库专为3×3卷积优化。因此，不能简单地认为3×3卷积的速度比1×1卷积慢9倍。\n\n## 两个基本原则(two principles)\n基于上述间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因，本文提出了高效网络架构设计应该考虑的两个基本原则：\n\n- 第一，应该用直接指标(速度/延迟)替换间接指标(FLOPs)；\n- 第二，这些指标应该在目标平台(target platform)上进行评估。\n\n## ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析\n<img src=\"/images/ShuffleNetV2/1.png\"  width = \"600\" height = \"100\"/>\n\n如Fig2所示，为ShuffleNetV1和MobileNetV2在ARM和GPU上的运行时间分析：\n\n- 总体的运行时间可以分解为五个部分：卷积、数据I/O、数据重排(data shuffle)、元素级运算(张量加法、ReLU等)及其他；\n- 文中注意到FLOPs仅和卷积部分相关，尽管这一部分需要消耗大部分的时间，但其它过程也需要消耗相当数量的时间；\n- 因此，FLOPs不是真实运行时间的足够准确地估计。\n\n## 四个实用准则(practical guidelines)\n基于上述网络运行时间性能的分析，提出设计高效网络架构需要遵循的四个实用准则(practical guidelines)。\n### G1. 相同的通道宽度可最小化内存访问成本(MAC）\n\n- 现代网络大多会采用depthwise separable convolutions，pointwise convolution($1\\times1$卷积)占据了其中大部分复杂度。\n- $1\\times1$卷积的FLOPs为：$B=h w c_1 c_2$\n - 其中，$h$和$w$为特征图的空间尺寸，$c_1$为输入通道数，$c_2$为输出通道数\n- 为了简化计算，假设计算设备的缓存足够大，能够储存完整的特征图和参数。那么，MAC或内存访问操作的数量是：$MAC = hw(c_1+c_2)+c_1c_2$\n - 其中，第一项为输入/输出特征图的内存访问，第二项为卷积核权重参数的内存访问\n- 依据均值不等式(mean value inequality)，即$\\sqrt{c_1 c_2} \\leq \\frac{c_1+c_2}{2}$，可得：$MAC \\geq 2\\sqrt{hwB}+\\frac{B}{hw}$\n- **因此，在给定FLOPs时，即可得到MAC的下界(lower bound)。并且，当输入的通道数和输出的通道数相等时，达到MAC的下界。**\n- 注意，该结论只是理论性的。因为在实际中，许多设备的缓存并不足够大，并且现代计算库通常采用复杂的模块策略来充分利用其缓存机制。\n\n\n<img src=\"/images/ShuffleNetV2/2.png\"  width = \"600\" height = \"100\"/>\n\n如Table1所示，为G1的验证试验：\n\n- 该实验固定总体的FLOPs，变化比率$c_1：c_2$，来比较运行速度；\n- 可以发现：当$c_1:c_2$接近$1:1$时，MAC开始变小，网络评估速度更快；\n- 因此，G1得到实际验证。\n\n### G2. 过度的组卷积会增加MAC\n \n- 分组卷积通过改变所有通道之间的密集卷积(dense convolution)，成为只和组内通道进行的稀疏卷积(sparse convolution)，来减少计算复杂度(FLOPs)；\n- 一方面，在固定的FLOPs下，它允许了更多的通道数；并且，它增加了网络的容量(capacity)，也因此得到更高的准确率；\n- 另一方面，然而，增加的通道数量导致了更多的MAC。\n\n- 正式的讲，对于$1\\times1$分组卷积，MAC和FLOPs的关系为：$MAC = hw(c_1+c_2)+\\frac{c_1c_2}{g} = hwc_1 + \\frac{Bg}{c_1}+ \\frac{B}{hw} $\n - 其中，$g$为分组的组数；B为$1\\times1$分组卷积的FLOPs，$B = \\frac{hwc_1c_2}{g}$\n - 容易看出，在给定固定的输入尺寸$c_1 \\times h \\times w$以及计算代价$B$时，MAC随着$g$的增长而增加。\n\n<img src=\"/images/ShuffleNetV2/3.png\"  width = \"600\" height = \"100\"/>\n\n如Table2所示，为G2的验证试验：\n\n- 该实验固定总体的FLOPs，采用不同的组数，来比较运行速度；\n- 明显地，采用大的分组数，显著地降低了运行速度。\n - 例如：在GPU上，当采用分组数为8时，比分组数为1(标准密集卷积)时，慢2两倍；在ARM上，慢30%。\n - 这主要是由于MAC的增加。\n- 因此，我们建议：\n - 对于分组数，基于目标平台和任务，来谨慎地选择；\n - 简单地因为大的分组数可以允许更大的通道数(获得更高的准确率)，而选择大的分组数，是不明智的。\n\n### G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)\n\n- 例如GoogLeNet的多路径结构会降低并行度\n- 尽管这种分散的结构(fragmented structure)已经展示出对准确率有益，但是它可能降低效率，因为它对像GPU这种带有强大并行计算能力(parallel\ncomputing powers)的设备很不友好。\n - 疑问：为啥不友好？\n- 这种分散的结构也引起了诸如卷积核加载(kernel launching)和同步化(synchronization)等开销。\n\n<img src=\"/images/ShuffleNetV2/4.png\"  width = \"600\" height = \"100\"/>\n\n如Table3所示，为G3的验证试验：\n\n- 可以发现：\n - 在GPU上，分散化显著地减少了运行速度；\n - 在ARM上，速度的减少相对较小。\n\n### G4. 元素级运算(element-wise operations)不可忽视(non-negligible)\n\n- 如Fig2所示，对于轻量化的模型ShuffleNetV1和MobileNetV2，元素级运算占据了相当大的时间，尤其是在GPU上。\n- 在这里，元素级运算包括：ReLU, AddTensor, AddBias等。它们有较小的FLOPs，但是有相对较大的MAC。\n- 特殊地，我们将depthwise convolution考虑为元素级运算，因为它也有较高的MAC/FLOPs比率。\n\n<img src=\"/images/ShuffleNetV2/5.png\"  width = \"600\" height = \"100\"/>\n\n如Table4所示，为G4的验证试验：\n- 该实验以ResNet中的“bottleneck”单元为实验对象，探究在ReLU和捷径连接在分别被去除后，运行时间的变化；\n- 可以发现：在ReLU和捷径连接被移除之后，在GPU和ARM上，均取得了20%的加速。\n\n### 结论和建议\n\n基于上述四点指导准则和实证研究，对于高效网络结构的设计，我们给出以下结论：\n\n- 1.应该使用平衡的卷积(\"balanced\" convolutions)，即相等的通道宽度\n- 2.意识到使用分组卷积的代价\n- 3.减少分散程度(the degree of fragmentation)\n- 4.减少元素级运算\n- 并且，这些期望特性(desirable properties)取决于平台特性(如内存操作和代码优化)，超越了理论的FLOPs。它们都应该在实际的网络设计中被考虑到。\n\n## 近期轻量型网络分析\n\n- 近期，轻量级神经网络架构上的研究进展主要基于间接指标FLOPs，并且没有考虑上述四个准则\n- 例如，ShuffleNetV1严重依赖组卷积(违反G2)和瓶颈形态的构造块(违反G1)\n- MobileNetV2使用倒置的瓶颈结构，违反了G1。它在「厚」特征图上(\"thick\" feature maps)使用了depthwise convolution和ReLU，违反了G4\n- 自动生成结构(the auto-generated structures)的高度碎片化，违反了G3\n\n## ShuffleNetV1回顾与分析\n\n<img src=\"/images/ShuffleNetV2/6.png\"  width = \"600\" height = \"100\"/>\n\n- ShuﬄeNetV1是一种先进的网络架构，广泛应用于手机等低配设备。它启发了本文工作，因此首先对其进行回顾与分析。\n- 根据ShuﬄeNetV1，轻量级网络的主要挑战是在给定计算预算(FLOPs)时，只能获得有限数量的特征通道。\n- 为了在不显著增加FLOPs情况下增加通道数量，ShuﬄeNetV1采用了两种技术：逐点分组卷积(pointwise group convolutions)和类瓶颈(bottleneck-like)结构；\n- 然后引入通道重排(channel shuﬄe)操作，令不同组的通道之间能够进行信息交流，提高精度。\n- 其构建模块如Fig3中的(a)(b)所示。\n\n- 如第二部分所述，逐点分组卷积和瓶颈结构都增加了MAC(G2和G1)。这个成本不可忽视，特别是对于轻量级模型。\n- 另外，使用太多分组也违背了G3。\n - 疑问：应该是违背了G2吧\n- 捷径连接（shortcut connection）中的元素级「加法」操作也不可取 (G4)。\n- 因此，为了实现较高的模型容量和效率，关键问题是如何保持大量且同样宽的通道，既没有密集卷积也没有太多的分组。\n\n## 通道分割(channel split)\n\n为此，本文引入一个简单的操作——通道分割(channel split)。\n\n- 如Fig3(c)所示:\n - 在每个单元的开始，$c$特征通道的输入被分为两支，分别带有$c−c'$ 和$c'$个通道。\n - 按照G3，一个分支仍然保持不变。\n - 另一个分支由三个卷积组成，为满足 G1，令输入和输出通道相同。\n - 与ShuffleNetV1不同的是，两个$1\\times 1$卷积不再是分组卷积。这样做的部分原因是为了遵循G2，部分原因是因为通道分割操作已经产生了两个组。\n - 卷积之后，把两个分支拼接起来，从而通道数量保持不变(G1)。然后进行与ShuffleNetV1相同的通道重排(channel shuﬄe)操作来保证两个分支间能进行信息交流。\n - 通道重排(Channel Shuﬄe)之后，下一个单元开始运算。\n - 注意，ShuﬄeNetV1中的「加法」操作不再存在。像ReLU 和epth- wise convolutions这样的操作只存在一个分支中。\n - 另外，三个连续的操作拼接(concat)、通道重排(channel shuﬄe)和通道分割(channel shuﬄe)合并成一个元素级操作。根据G4，这些变化是有利的。\n - 疑问：三个连续操作时如何合并成一个的？？\n\n- 如Fig3(d)所示，对于空间下采样，该单元经过稍微修改:\n - 通道分割运算被移除。因此，输出通道数量翻了一倍。\n\n## ShuffleNetV2 \n\n<img src=\"/images/ShuffleNetV2/7.png\"  width = \"600\" height = \"100\"/>\n\n- 基于本文提出的构造模块Fig3(c)(d)而构成的网络，被称之为ShuﬄeNetV2。\n- 基于上述对构造模块Fig3(c)(d)分析，本文得出结论：由于遵循四个准则的遵循，该架构设计异常高效。\n- 上述基础构建模块被重复堆叠以构建整个网络。为了简洁，本文令$c' = c/2$。\n- 如Table5所示，为ShufﬂeNetV2的整体结构：\n - 整个网络结构类似于ShufﬂeNetV1，二者之间只有一个区别：前者在全局平均池化层之前添加了一个额外的$1\\times 1$卷积层来混合特征，ShuﬄeNetV1中没有该层。\n - 与ShuﬄeNetV1类似，每个构建块中的通道数量可以扩展以生成不同复杂度的网络，标记为`0.5×`、`1×`等。\n\n# 模型比较\n<img src=\"/images/ShuffleNetV2/8.png\"  width = \"600\" height = \"100\"/>\n\n- 如Table8所示，为各网络在四个级别的计算复杂度(40/140/300/500+ MFLOPs)级别上的FLOPs、Top-1错误率以及在GPU/ARM上的速度对比。\n - 可以发现：在同等的FLOPs下，ShuffleNetV2的各项表现均为最佳。\n\n# 参考文献\n- [论文：ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/pdf/1807.11164.pdf)\n- [博客(旷视官方)：ECCV 2018 | 旷视科技提出新型轻量架构ShuffleNet V2：从理论复杂度到实用设计准则](http://www.sohu.com/a/244491616_418390)\n\n\n\n\n\n","source":"_posts/ShuffleNetV2.md","raw":"---\ntitle: ShuffleNetV2\nmathjax: true\ndate: 2018-12-30 22:25:50\ncategories: \n- 轻量型CNN\ntags:\n---\n \n# 摘要\n\n- 目前，神经网络架构的设计主要由计算复杂度的间接指标(即FLOPs)来指导；\n- 但是，直接指标(如速度或延迟)还依赖于其他因素，如内存访问成本(MAC, memory access cost)和平台特点(platform characterics)；\n- 因此，本文指出过去在网络架构设计上仅注重间接指标 FLOPs 的不足，并提出两个基本原则(principles)和四个实用准则(practical guidelines)来指导网络架构设计；\n- 提出针对移动端深度学习的第二代卷积神经网络ShuffleNetV2，在综合实验评估中，ShuffleNetV2在速度和精度的权衡方面达到当前最优水平。\n- 注：FLOPs，即the number of float-point operations，定义为the number of multiply-adds.\n<!-- more -->\n\n# 创新点\n\n## 间接指标(FLOPs)与直接指标(速度/延迟)\n\n对于FLOPs：\n\n- 当前，FLOPs，即浮点运算数，是度量计算复杂度的常用指标。\n- 然而，FLOPs是一种间接指标。它只是本文真正关心的直接指标(如速度或延迟)的一种近似形式，通常无法与直接指标划等号。\n- 实验表明：FLOPs近似的网络也会有不同的速度。\n- 所以，将FLOPs作为衡量计算复杂度的唯一标准是不够的，这样会导致次优设计。\n\n间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因可以归结为两点：\n- 首先，对速度有较大影响的几个重要因素对FLOPs不产生太大作用:\n - 第一个因素是内存访问成本(MAC, memory access cost)。在某些操作(如组卷积)中，MAC占运行时间的很大一部分。对于像GPU这样具备强大计算能力的设备而言，这就是瓶颈。在网络架构设计过程中，MAC不能被简单忽视。\n - 第二个因素是并行度(degree of parallelism)。当FLOPs相同时，高并行度的模型可能比低并行度的模型快得多。\n- 其次，取决于平台特点(platform characterics)，FLOPs相同的运算可能有着不同的运行时间\n - 例如，早期研究广泛使用张量分解(tensor decomposition)来加速矩阵相乘。但是，近期研究发现尽管张量分解减少了75%的FLOPs，但在GPU上甚至更慢。本文研究人员对此进行了调查，发现原因在于最新的CUDNN库专为3×3卷积优化。因此，不能简单地认为3×3卷积的速度比1×1卷积慢9倍。\n\n## 两个基本原则(two principles)\n基于上述间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因，本文提出了高效网络架构设计应该考虑的两个基本原则：\n\n- 第一，应该用直接指标(速度/延迟)替换间接指标(FLOPs)；\n- 第二，这些指标应该在目标平台(target platform)上进行评估。\n\n## ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析\n<img src=\"/images/ShuffleNetV2/1.png\"  width = \"600\" height = \"100\"/>\n\n如Fig2所示，为ShuffleNetV1和MobileNetV2在ARM和GPU上的运行时间分析：\n\n- 总体的运行时间可以分解为五个部分：卷积、数据I/O、数据重排(data shuffle)、元素级运算(张量加法、ReLU等)及其他；\n- 文中注意到FLOPs仅和卷积部分相关，尽管这一部分需要消耗大部分的时间，但其它过程也需要消耗相当数量的时间；\n- 因此，FLOPs不是真实运行时间的足够准确地估计。\n\n## 四个实用准则(practical guidelines)\n基于上述网络运行时间性能的分析，提出设计高效网络架构需要遵循的四个实用准则(practical guidelines)。\n### G1. 相同的通道宽度可最小化内存访问成本(MAC）\n\n- 现代网络大多会采用depthwise separable convolutions，pointwise convolution($1\\times1$卷积)占据了其中大部分复杂度。\n- $1\\times1$卷积的FLOPs为：$B=h w c_1 c_2$\n - 其中，$h$和$w$为特征图的空间尺寸，$c_1$为输入通道数，$c_2$为输出通道数\n- 为了简化计算，假设计算设备的缓存足够大，能够储存完整的特征图和参数。那么，MAC或内存访问操作的数量是：$MAC = hw(c_1+c_2)+c_1c_2$\n - 其中，第一项为输入/输出特征图的内存访问，第二项为卷积核权重参数的内存访问\n- 依据均值不等式(mean value inequality)，即$\\sqrt{c_1 c_2} \\leq \\frac{c_1+c_2}{2}$，可得：$MAC \\geq 2\\sqrt{hwB}+\\frac{B}{hw}$\n- **因此，在给定FLOPs时，即可得到MAC的下界(lower bound)。并且，当输入的通道数和输出的通道数相等时，达到MAC的下界。**\n- 注意，该结论只是理论性的。因为在实际中，许多设备的缓存并不足够大，并且现代计算库通常采用复杂的模块策略来充分利用其缓存机制。\n\n\n<img src=\"/images/ShuffleNetV2/2.png\"  width = \"600\" height = \"100\"/>\n\n如Table1所示，为G1的验证试验：\n\n- 该实验固定总体的FLOPs，变化比率$c_1：c_2$，来比较运行速度；\n- 可以发现：当$c_1:c_2$接近$1:1$时，MAC开始变小，网络评估速度更快；\n- 因此，G1得到实际验证。\n\n### G2. 过度的组卷积会增加MAC\n \n- 分组卷积通过改变所有通道之间的密集卷积(dense convolution)，成为只和组内通道进行的稀疏卷积(sparse convolution)，来减少计算复杂度(FLOPs)；\n- 一方面，在固定的FLOPs下，它允许了更多的通道数；并且，它增加了网络的容量(capacity)，也因此得到更高的准确率；\n- 另一方面，然而，增加的通道数量导致了更多的MAC。\n\n- 正式的讲，对于$1\\times1$分组卷积，MAC和FLOPs的关系为：$MAC = hw(c_1+c_2)+\\frac{c_1c_2}{g} = hwc_1 + \\frac{Bg}{c_1}+ \\frac{B}{hw} $\n - 其中，$g$为分组的组数；B为$1\\times1$分组卷积的FLOPs，$B = \\frac{hwc_1c_2}{g}$\n - 容易看出，在给定固定的输入尺寸$c_1 \\times h \\times w$以及计算代价$B$时，MAC随着$g$的增长而增加。\n\n<img src=\"/images/ShuffleNetV2/3.png\"  width = \"600\" height = \"100\"/>\n\n如Table2所示，为G2的验证试验：\n\n- 该实验固定总体的FLOPs，采用不同的组数，来比较运行速度；\n- 明显地，采用大的分组数，显著地降低了运行速度。\n - 例如：在GPU上，当采用分组数为8时，比分组数为1(标准密集卷积)时，慢2两倍；在ARM上，慢30%。\n - 这主要是由于MAC的增加。\n- 因此，我们建议：\n - 对于分组数，基于目标平台和任务，来谨慎地选择；\n - 简单地因为大的分组数可以允许更大的通道数(获得更高的准确率)，而选择大的分组数，是不明智的。\n\n### G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)\n\n- 例如GoogLeNet的多路径结构会降低并行度\n- 尽管这种分散的结构(fragmented structure)已经展示出对准确率有益，但是它可能降低效率，因为它对像GPU这种带有强大并行计算能力(parallel\ncomputing powers)的设备很不友好。\n - 疑问：为啥不友好？\n- 这种分散的结构也引起了诸如卷积核加载(kernel launching)和同步化(synchronization)等开销。\n\n<img src=\"/images/ShuffleNetV2/4.png\"  width = \"600\" height = \"100\"/>\n\n如Table3所示，为G3的验证试验：\n\n- 可以发现：\n - 在GPU上，分散化显著地减少了运行速度；\n - 在ARM上，速度的减少相对较小。\n\n### G4. 元素级运算(element-wise operations)不可忽视(non-negligible)\n\n- 如Fig2所示，对于轻量化的模型ShuffleNetV1和MobileNetV2，元素级运算占据了相当大的时间，尤其是在GPU上。\n- 在这里，元素级运算包括：ReLU, AddTensor, AddBias等。它们有较小的FLOPs，但是有相对较大的MAC。\n- 特殊地，我们将depthwise convolution考虑为元素级运算，因为它也有较高的MAC/FLOPs比率。\n\n<img src=\"/images/ShuffleNetV2/5.png\"  width = \"600\" height = \"100\"/>\n\n如Table4所示，为G4的验证试验：\n- 该实验以ResNet中的“bottleneck”单元为实验对象，探究在ReLU和捷径连接在分别被去除后，运行时间的变化；\n- 可以发现：在ReLU和捷径连接被移除之后，在GPU和ARM上，均取得了20%的加速。\n\n### 结论和建议\n\n基于上述四点指导准则和实证研究，对于高效网络结构的设计，我们给出以下结论：\n\n- 1.应该使用平衡的卷积(\"balanced\" convolutions)，即相等的通道宽度\n- 2.意识到使用分组卷积的代价\n- 3.减少分散程度(the degree of fragmentation)\n- 4.减少元素级运算\n- 并且，这些期望特性(desirable properties)取决于平台特性(如内存操作和代码优化)，超越了理论的FLOPs。它们都应该在实际的网络设计中被考虑到。\n\n## 近期轻量型网络分析\n\n- 近期，轻量级神经网络架构上的研究进展主要基于间接指标FLOPs，并且没有考虑上述四个准则\n- 例如，ShuffleNetV1严重依赖组卷积(违反G2)和瓶颈形态的构造块(违反G1)\n- MobileNetV2使用倒置的瓶颈结构，违反了G1。它在「厚」特征图上(\"thick\" feature maps)使用了depthwise convolution和ReLU，违反了G4\n- 自动生成结构(the auto-generated structures)的高度碎片化，违反了G3\n\n## ShuffleNetV1回顾与分析\n\n<img src=\"/images/ShuffleNetV2/6.png\"  width = \"600\" height = \"100\"/>\n\n- ShuﬄeNetV1是一种先进的网络架构，广泛应用于手机等低配设备。它启发了本文工作，因此首先对其进行回顾与分析。\n- 根据ShuﬄeNetV1，轻量级网络的主要挑战是在给定计算预算(FLOPs)时，只能获得有限数量的特征通道。\n- 为了在不显著增加FLOPs情况下增加通道数量，ShuﬄeNetV1采用了两种技术：逐点分组卷积(pointwise group convolutions)和类瓶颈(bottleneck-like)结构；\n- 然后引入通道重排(channel shuﬄe)操作，令不同组的通道之间能够进行信息交流，提高精度。\n- 其构建模块如Fig3中的(a)(b)所示。\n\n- 如第二部分所述，逐点分组卷积和瓶颈结构都增加了MAC(G2和G1)。这个成本不可忽视，特别是对于轻量级模型。\n- 另外，使用太多分组也违背了G3。\n - 疑问：应该是违背了G2吧\n- 捷径连接（shortcut connection）中的元素级「加法」操作也不可取 (G4)。\n- 因此，为了实现较高的模型容量和效率，关键问题是如何保持大量且同样宽的通道，既没有密集卷积也没有太多的分组。\n\n## 通道分割(channel split)\n\n为此，本文引入一个简单的操作——通道分割(channel split)。\n\n- 如Fig3(c)所示:\n - 在每个单元的开始，$c$特征通道的输入被分为两支，分别带有$c−c'$ 和$c'$个通道。\n - 按照G3，一个分支仍然保持不变。\n - 另一个分支由三个卷积组成，为满足 G1，令输入和输出通道相同。\n - 与ShuffleNetV1不同的是，两个$1\\times 1$卷积不再是分组卷积。这样做的部分原因是为了遵循G2，部分原因是因为通道分割操作已经产生了两个组。\n - 卷积之后，把两个分支拼接起来，从而通道数量保持不变(G1)。然后进行与ShuffleNetV1相同的通道重排(channel shuﬄe)操作来保证两个分支间能进行信息交流。\n - 通道重排(Channel Shuﬄe)之后，下一个单元开始运算。\n - 注意，ShuﬄeNetV1中的「加法」操作不再存在。像ReLU 和epth- wise convolutions这样的操作只存在一个分支中。\n - 另外，三个连续的操作拼接(concat)、通道重排(channel shuﬄe)和通道分割(channel shuﬄe)合并成一个元素级操作。根据G4，这些变化是有利的。\n - 疑问：三个连续操作时如何合并成一个的？？\n\n- 如Fig3(d)所示，对于空间下采样，该单元经过稍微修改:\n - 通道分割运算被移除。因此，输出通道数量翻了一倍。\n\n## ShuffleNetV2 \n\n<img src=\"/images/ShuffleNetV2/7.png\"  width = \"600\" height = \"100\"/>\n\n- 基于本文提出的构造模块Fig3(c)(d)而构成的网络，被称之为ShuﬄeNetV2。\n- 基于上述对构造模块Fig3(c)(d)分析，本文得出结论：由于遵循四个准则的遵循，该架构设计异常高效。\n- 上述基础构建模块被重复堆叠以构建整个网络。为了简洁，本文令$c' = c/2$。\n- 如Table5所示，为ShufﬂeNetV2的整体结构：\n - 整个网络结构类似于ShufﬂeNetV1，二者之间只有一个区别：前者在全局平均池化层之前添加了一个额外的$1\\times 1$卷积层来混合特征，ShuﬄeNetV1中没有该层。\n - 与ShuﬄeNetV1类似，每个构建块中的通道数量可以扩展以生成不同复杂度的网络，标记为`0.5×`、`1×`等。\n\n# 模型比较\n<img src=\"/images/ShuffleNetV2/8.png\"  width = \"600\" height = \"100\"/>\n\n- 如Table8所示，为各网络在四个级别的计算复杂度(40/140/300/500+ MFLOPs)级别上的FLOPs、Top-1错误率以及在GPU/ARM上的速度对比。\n - 可以发现：在同等的FLOPs下，ShuffleNetV2的各项表现均为最佳。\n\n# 参考文献\n- [论文：ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/pdf/1807.11164.pdf)\n- [博客(旷视官方)：ECCV 2018 | 旷视科技提出新型轻量架构ShuffleNet V2：从理论复杂度到实用设计准则](http://www.sohu.com/a/244491616_418390)\n\n\n\n\n\n","slug":"ShuffleNetV2","published":1,"updated":"2019-01-04T10:44:40.482Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w08002pqslpwdf6k6p5","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>目前，神经网络架构的设计主要由计算复杂度的间接指标(即FLOPs)来指导；</li>\n<li>但是，直接指标(如速度或延迟)还依赖于其他因素，如内存访问成本(MAC, memory access cost)和平台特点(platform characterics)；</li>\n<li>因此，本文指出过去在网络架构设计上仅注重间接指标 FLOPs 的不足，并提出两个基本原则(principles)和四个实用准则(practical guidelines)来指导网络架构设计；</li>\n<li>提出针对移动端深度学习的第二代卷积神经网络ShuffleNetV2，在综合实验评估中，ShuffleNetV2在速度和精度的权衡方面达到当前最优水平。</li>\n<li>注：FLOPs，即the number of float-point operations，定义为the number of multiply-adds.<a id=\"more\"></a>\n</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"间接指标-FLOPs-与直接指标-速度-延迟\"><a href=\"#间接指标-FLOPs-与直接指标-速度-延迟\" class=\"headerlink\" title=\"间接指标(FLOPs)与直接指标(速度/延迟)\"></a>间接指标(FLOPs)与直接指标(速度/延迟)</h2><p>对于FLOPs：</p>\n<ul>\n<li>当前，FLOPs，即浮点运算数，是度量计算复杂度的常用指标。</li>\n<li>然而，FLOPs是一种间接指标。它只是本文真正关心的直接指标(如速度或延迟)的一种近似形式，通常无法与直接指标划等号。</li>\n<li>实验表明：FLOPs近似的网络也会有不同的速度。</li>\n<li>所以，将FLOPs作为衡量计算复杂度的唯一标准是不够的，这样会导致次优设计。</li>\n</ul>\n<p>间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因可以归结为两点：</p>\n<ul>\n<li>首先，对速度有较大影响的几个重要因素对FLOPs不产生太大作用:<ul>\n<li>第一个因素是内存访问成本(MAC, memory access cost)。在某些操作(如组卷积)中，MAC占运行时间的很大一部分。对于像GPU这样具备强大计算能力的设备而言，这就是瓶颈。在网络架构设计过程中，MAC不能被简单忽视。</li>\n<li>第二个因素是并行度(degree of parallelism)。当FLOPs相同时，高并行度的模型可能比低并行度的模型快得多。</li>\n</ul>\n</li>\n<li>其次，取决于平台特点(platform characterics)，FLOPs相同的运算可能有着不同的运行时间<ul>\n<li>例如，早期研究广泛使用张量分解(tensor decomposition)来加速矩阵相乘。但是，近期研究发现尽管张量分解减少了75%的FLOPs，但在GPU上甚至更慢。本文研究人员对此进行了调查，发现原因在于最新的CUDNN库专为3×3卷积优化。因此，不能简单地认为3×3卷积的速度比1×1卷积慢9倍。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"两个基本原则-two-principles\"><a href=\"#两个基本原则-two-principles\" class=\"headerlink\" title=\"两个基本原则(two principles)\"></a>两个基本原则(two principles)</h2><p>基于上述间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因，本文提出了高效网络架构设计应该考虑的两个基本原则：</p>\n<ul>\n<li>第一，应该用直接指标(速度/延迟)替换间接指标(FLOPs)；</li>\n<li>第二，这些指标应该在目标平台(target platform)上进行评估。</li>\n</ul>\n<h2 id=\"ShuffleNetV1和MobileNetV2的运行时间性能-runtime-performance-分析\"><a href=\"#ShuffleNetV1和MobileNetV2的运行时间性能-runtime-performance-分析\" class=\"headerlink\" title=\"ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析\"></a>ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析</h2><p><img src=\"/images/ShuffleNetV2/1.png\" width=\"600\" height=\"100\"></p>\n<p>如Fig2所示，为ShuffleNetV1和MobileNetV2在ARM和GPU上的运行时间分析：</p>\n<ul>\n<li>总体的运行时间可以分解为五个部分：卷积、数据I/O、数据重排(data shuffle)、元素级运算(张量加法、ReLU等)及其他；</li>\n<li>文中注意到FLOPs仅和卷积部分相关，尽管这一部分需要消耗大部分的时间，但其它过程也需要消耗相当数量的时间；</li>\n<li>因此，FLOPs不是真实运行时间的足够准确地估计。</li>\n</ul>\n<h2 id=\"四个实用准则-practical-guidelines\"><a href=\"#四个实用准则-practical-guidelines\" class=\"headerlink\" title=\"四个实用准则(practical guidelines)\"></a>四个实用准则(practical guidelines)</h2><p>基于上述网络运行时间性能的分析，提出设计高效网络架构需要遵循的四个实用准则(practical guidelines)。</p>\n<h3 id=\"G1-相同的通道宽度可最小化内存访问成本-MAC）\"><a href=\"#G1-相同的通道宽度可最小化内存访问成本-MAC）\" class=\"headerlink\" title=\"G1. 相同的通道宽度可最小化内存访问成本(MAC）\"></a>G1. 相同的通道宽度可最小化内存访问成本(MAC）</h3><ul>\n<li>现代网络大多会采用depthwise separable convolutions，pointwise convolution($1\\times1$卷积)占据了其中大部分复杂度。</li>\n<li>$1\\times1$卷积的FLOPs为：$B=h w c_1 c_2$<ul>\n<li>其中，$h$和$w$为特征图的空间尺寸，$c_1$为输入通道数，$c_2$为输出通道数</li>\n</ul>\n</li>\n<li>为了简化计算，假设计算设备的缓存足够大，能够储存完整的特征图和参数。那么，MAC或内存访问操作的数量是：$MAC = hw(c_1+c_2)+c_1c_2$<ul>\n<li>其中，第一项为输入/输出特征图的内存访问，第二项为卷积核权重参数的内存访问</li>\n</ul>\n</li>\n<li>依据均值不等式(mean value inequality)，即$\\sqrt{c_1 c_2} \\leq \\frac{c_1+c_2}{2}$，可得：$MAC \\geq 2\\sqrt{hwB}+\\frac{B}{hw}$</li>\n<li><strong>因此，在给定FLOPs时，即可得到MAC的下界(lower bound)。并且，当输入的通道数和输出的通道数相等时，达到MAC的下界。</strong></li>\n<li>注意，该结论只是理论性的。因为在实际中，许多设备的缓存并不足够大，并且现代计算库通常采用复杂的模块策略来充分利用其缓存机制。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/2.png\" width=\"600\" height=\"100\"></p>\n<p>如Table1所示，为G1的验证试验：</p>\n<ul>\n<li>该实验固定总体的FLOPs，变化比率$c_1：c_2$，来比较运行速度；</li>\n<li>可以发现：当$c_1:c_2$接近$1:1$时，MAC开始变小，网络评估速度更快；</li>\n<li>因此，G1得到实际验证。</li>\n</ul>\n<h3 id=\"G2-过度的组卷积会增加MAC\"><a href=\"#G2-过度的组卷积会增加MAC\" class=\"headerlink\" title=\"G2. 过度的组卷积会增加MAC\"></a>G2. 过度的组卷积会增加MAC</h3><ul>\n<li>分组卷积通过改变所有通道之间的密集卷积(dense convolution)，成为只和组内通道进行的稀疏卷积(sparse convolution)，来减少计算复杂度(FLOPs)；</li>\n<li>一方面，在固定的FLOPs下，它允许了更多的通道数；并且，它增加了网络的容量(capacity)，也因此得到更高的准确率；</li>\n<li><p>另一方面，然而，增加的通道数量导致了更多的MAC。</p>\n</li>\n<li><p>正式的讲，对于$1\\times1$分组卷积，MAC和FLOPs的关系为：$MAC = hw(c_1+c_2)+\\frac{c_1c_2}{g} = hwc_1 + \\frac{Bg}{c_1}+ \\frac{B}{hw} $</p>\n<ul>\n<li>其中，$g$为分组的组数；B为$1\\times1$分组卷积的FLOPs，$B = \\frac{hwc_1c_2}{g}$</li>\n<li>容易看出，在给定固定的输入尺寸$c_1 \\times h \\times w$以及计算代价$B$时，MAC随着$g$的增长而增加。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/3.png\" width=\"600\" height=\"100\"></p>\n<p>如Table2所示，为G2的验证试验：</p>\n<ul>\n<li>该实验固定总体的FLOPs，采用不同的组数，来比较运行速度；</li>\n<li>明显地，采用大的分组数，显著地降低了运行速度。<ul>\n<li>例如：在GPU上，当采用分组数为8时，比分组数为1(标准密集卷积)时，慢2两倍；在ARM上，慢30%。</li>\n<li>这主要是由于MAC的增加。</li>\n</ul>\n</li>\n<li>因此，我们建议：<ul>\n<li>对于分组数，基于目标平台和任务，来谨慎地选择；</li>\n<li>简单地因为大的分组数可以允许更大的通道数(获得更高的准确率)，而选择大的分组数，是不明智的。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"G3-网络碎片化-network-fragmentation-会降低并行度-degree-of-parallelism\"><a href=\"#G3-网络碎片化-network-fragmentation-会降低并行度-degree-of-parallelism\" class=\"headerlink\" title=\"G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)\"></a>G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)</h3><ul>\n<li>例如GoogLeNet的多路径结构会降低并行度</li>\n<li>尽管这种分散的结构(fragmented structure)已经展示出对准确率有益，但是它可能降低效率，因为它对像GPU这种带有强大并行计算能力(parallel<br>computing powers)的设备很不友好。<ul>\n<li>疑问：为啥不友好？</li>\n</ul>\n</li>\n<li>这种分散的结构也引起了诸如卷积核加载(kernel launching)和同步化(synchronization)等开销。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/4.png\" width=\"600\" height=\"100\"></p>\n<p>如Table3所示，为G3的验证试验：</p>\n<ul>\n<li>可以发现：<ul>\n<li>在GPU上，分散化显著地减少了运行速度；</li>\n<li>在ARM上，速度的减少相对较小。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"G4-元素级运算-element-wise-operations-不可忽视-non-negligible\"><a href=\"#G4-元素级运算-element-wise-operations-不可忽视-non-negligible\" class=\"headerlink\" title=\"G4. 元素级运算(element-wise operations)不可忽视(non-negligible)\"></a>G4. 元素级运算(element-wise operations)不可忽视(non-negligible)</h3><ul>\n<li>如Fig2所示，对于轻量化的模型ShuffleNetV1和MobileNetV2，元素级运算占据了相当大的时间，尤其是在GPU上。</li>\n<li>在这里，元素级运算包括：ReLU, AddTensor, AddBias等。它们有较小的FLOPs，但是有相对较大的MAC。</li>\n<li>特殊地，我们将depthwise convolution考虑为元素级运算，因为它也有较高的MAC/FLOPs比率。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/5.png\" width=\"600\" height=\"100\"></p>\n<p>如Table4所示，为G4的验证试验：</p>\n<ul>\n<li>该实验以ResNet中的“bottleneck”单元为实验对象，探究在ReLU和捷径连接在分别被去除后，运行时间的变化；</li>\n<li>可以发现：在ReLU和捷径连接被移除之后，在GPU和ARM上，均取得了20%的加速。</li>\n</ul>\n<h3 id=\"结论和建议\"><a href=\"#结论和建议\" class=\"headerlink\" title=\"结论和建议\"></a>结论和建议</h3><p>基于上述四点指导准则和实证研究，对于高效网络结构的设计，我们给出以下结论：</p>\n<ul>\n<li>1.应该使用平衡的卷积(“balanced” convolutions)，即相等的通道宽度</li>\n<li>2.意识到使用分组卷积的代价</li>\n<li>3.减少分散程度(the degree of fragmentation)</li>\n<li>4.减少元素级运算</li>\n<li>并且，这些期望特性(desirable properties)取决于平台特性(如内存操作和代码优化)，超越了理论的FLOPs。它们都应该在实际的网络设计中被考虑到。</li>\n</ul>\n<h2 id=\"近期轻量型网络分析\"><a href=\"#近期轻量型网络分析\" class=\"headerlink\" title=\"近期轻量型网络分析\"></a>近期轻量型网络分析</h2><ul>\n<li>近期，轻量级神经网络架构上的研究进展主要基于间接指标FLOPs，并且没有考虑上述四个准则</li>\n<li>例如，ShuffleNetV1严重依赖组卷积(违反G2)和瓶颈形态的构造块(违反G1)</li>\n<li>MobileNetV2使用倒置的瓶颈结构，违反了G1。它在「厚」特征图上(“thick” feature maps)使用了depthwise convolution和ReLU，违反了G4</li>\n<li>自动生成结构(the auto-generated structures)的高度碎片化，违反了G3</li>\n</ul>\n<h2 id=\"ShuffleNetV1回顾与分析\"><a href=\"#ShuffleNetV1回顾与分析\" class=\"headerlink\" title=\"ShuffleNetV1回顾与分析\"></a>ShuffleNetV1回顾与分析</h2><p><img src=\"/images/ShuffleNetV2/6.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>ShuﬄeNetV1是一种先进的网络架构，广泛应用于手机等低配设备。它启发了本文工作，因此首先对其进行回顾与分析。</li>\n<li>根据ShuﬄeNetV1，轻量级网络的主要挑战是在给定计算预算(FLOPs)时，只能获得有限数量的特征通道。</li>\n<li>为了在不显著增加FLOPs情况下增加通道数量，ShuﬄeNetV1采用了两种技术：逐点分组卷积(pointwise group convolutions)和类瓶颈(bottleneck-like)结构；</li>\n<li>然后引入通道重排(channel shuﬄe)操作，令不同组的通道之间能够进行信息交流，提高精度。</li>\n<li><p>其构建模块如Fig3中的(a)(b)所示。</p>\n</li>\n<li><p>如第二部分所述，逐点分组卷积和瓶颈结构都增加了MAC(G2和G1)。这个成本不可忽视，特别是对于轻量级模型。</p>\n</li>\n<li>另外，使用太多分组也违背了G3。<ul>\n<li>疑问：应该是违背了G2吧</li>\n</ul>\n</li>\n<li>捷径连接（shortcut connection）中的元素级「加法」操作也不可取 (G4)。</li>\n<li>因此，为了实现较高的模型容量和效率，关键问题是如何保持大量且同样宽的通道，既没有密集卷积也没有太多的分组。</li>\n</ul>\n<h2 id=\"通道分割-channel-split\"><a href=\"#通道分割-channel-split\" class=\"headerlink\" title=\"通道分割(channel split)\"></a>通道分割(channel split)</h2><p>为此，本文引入一个简单的操作——通道分割(channel split)。</p>\n<ul>\n<li><p>如Fig3(c)所示:</p>\n<ul>\n<li>在每个单元的开始，$c$特征通道的输入被分为两支，分别带有$c−c’$ 和$c’$个通道。</li>\n<li>按照G3，一个分支仍然保持不变。</li>\n<li>另一个分支由三个卷积组成，为满足 G1，令输入和输出通道相同。</li>\n<li>与ShuffleNetV1不同的是，两个$1\\times 1$卷积不再是分组卷积。这样做的部分原因是为了遵循G2，部分原因是因为通道分割操作已经产生了两个组。</li>\n<li>卷积之后，把两个分支拼接起来，从而通道数量保持不变(G1)。然后进行与ShuffleNetV1相同的通道重排(channel shuﬄe)操作来保证两个分支间能进行信息交流。</li>\n<li>通道重排(Channel Shuﬄe)之后，下一个单元开始运算。</li>\n<li>注意，ShuﬄeNetV1中的「加法」操作不再存在。像ReLU 和epth- wise convolutions这样的操作只存在一个分支中。</li>\n<li>另外，三个连续的操作拼接(concat)、通道重排(channel shuﬄe)和通道分割(channel shuﬄe)合并成一个元素级操作。根据G4，这些变化是有利的。</li>\n<li>疑问：三个连续操作时如何合并成一个的？？</li>\n</ul>\n</li>\n<li><p>如Fig3(d)所示，对于空间下采样，该单元经过稍微修改:</p>\n<ul>\n<li>通道分割运算被移除。因此，输出通道数量翻了一倍。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ShuffleNetV2\"><a href=\"#ShuffleNetV2\" class=\"headerlink\" title=\"ShuffleNetV2\"></a>ShuffleNetV2</h2><p><img src=\"/images/ShuffleNetV2/7.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>基于本文提出的构造模块Fig3(c)(d)而构成的网络，被称之为ShuﬄeNetV2。</li>\n<li>基于上述对构造模块Fig3(c)(d)分析，本文得出结论：由于遵循四个准则的遵循，该架构设计异常高效。</li>\n<li>上述基础构建模块被重复堆叠以构建整个网络。为了简洁，本文令$c’ = c/2$。</li>\n<li>如Table5所示，为ShufﬂeNetV2的整体结构：<ul>\n<li>整个网络结构类似于ShufﬂeNetV1，二者之间只有一个区别：前者在全局平均池化层之前添加了一个额外的$1\\times 1$卷积层来混合特征，ShuﬄeNetV1中没有该层。</li>\n<li>与ShuﬄeNetV1类似，每个构建块中的通道数量可以扩展以生成不同复杂度的网络，标记为<code>0.5×</code>、<code>1×</code>等。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/ShuffleNetV2/8.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>如Table8所示，为各网络在四个级别的计算复杂度(40/140/300/500+ MFLOPs)级别上的FLOPs、Top-1错误率以及在GPU/ARM上的速度对比。<ul>\n<li>可以发现：在同等的FLOPs下，ShuffleNetV2的各项表现均为最佳。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1807.11164.pdf\" target=\"_blank\" rel=\"noopener\">论文：ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a></li>\n<li><a href=\"http://www.sohu.com/a/244491616_418390\" target=\"_blank\" rel=\"noopener\">博客(旷视官方)：ECCV 2018 | 旷视科技提出新型轻量架构ShuffleNet V2：从理论复杂度到实用设计准则</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><ul>\n<li>目前，神经网络架构的设计主要由计算复杂度的间接指标(即FLOPs)来指导；</li>\n<li>但是，直接指标(如速度或延迟)还依赖于其他因素，如内存访问成本(MAC, memory access cost)和平台特点(platform characterics)；</li>\n<li>因此，本文指出过去在网络架构设计上仅注重间接指标 FLOPs 的不足，并提出两个基本原则(principles)和四个实用准则(practical guidelines)来指导网络架构设计；</li>\n<li>提出针对移动端深度学习的第二代卷积神经网络ShuffleNetV2，在综合实验评估中，ShuffleNetV2在速度和精度的权衡方面达到当前最优水平。</li>\n<li>注：FLOPs，即the number of float-point operations，定义为the number of multiply-adds.","more":"</li>\n</ul>\n<h1 id=\"创新点\"><a href=\"#创新点\" class=\"headerlink\" title=\"创新点\"></a>创新点</h1><h2 id=\"间接指标-FLOPs-与直接指标-速度-延迟\"><a href=\"#间接指标-FLOPs-与直接指标-速度-延迟\" class=\"headerlink\" title=\"间接指标(FLOPs)与直接指标(速度/延迟)\"></a>间接指标(FLOPs)与直接指标(速度/延迟)</h2><p>对于FLOPs：</p>\n<ul>\n<li>当前，FLOPs，即浮点运算数，是度量计算复杂度的常用指标。</li>\n<li>然而，FLOPs是一种间接指标。它只是本文真正关心的直接指标(如速度或延迟)的一种近似形式，通常无法与直接指标划等号。</li>\n<li>实验表明：FLOPs近似的网络也会有不同的速度。</li>\n<li>所以，将FLOPs作为衡量计算复杂度的唯一标准是不够的，这样会导致次优设计。</li>\n</ul>\n<p>间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因可以归结为两点：</p>\n<ul>\n<li>首先，对速度有较大影响的几个重要因素对FLOPs不产生太大作用:<ul>\n<li>第一个因素是内存访问成本(MAC, memory access cost)。在某些操作(如组卷积)中，MAC占运行时间的很大一部分。对于像GPU这样具备强大计算能力的设备而言，这就是瓶颈。在网络架构设计过程中，MAC不能被简单忽视。</li>\n<li>第二个因素是并行度(degree of parallelism)。当FLOPs相同时，高并行度的模型可能比低并行度的模型快得多。</li>\n</ul>\n</li>\n<li>其次，取决于平台特点(platform characterics)，FLOPs相同的运算可能有着不同的运行时间<ul>\n<li>例如，早期研究广泛使用张量分解(tensor decomposition)来加速矩阵相乘。但是，近期研究发现尽管张量分解减少了75%的FLOPs，但在GPU上甚至更慢。本文研究人员对此进行了调查，发现原因在于最新的CUDNN库专为3×3卷积优化。因此，不能简单地认为3×3卷积的速度比1×1卷积慢9倍。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"两个基本原则-two-principles\"><a href=\"#两个基本原则-two-principles\" class=\"headerlink\" title=\"两个基本原则(two principles)\"></a>两个基本原则(two principles)</h2><p>基于上述间接指标(FLOPs)与直接指标(速度/延迟)之间存在差异的原因，本文提出了高效网络架构设计应该考虑的两个基本原则：</p>\n<ul>\n<li>第一，应该用直接指标(速度/延迟)替换间接指标(FLOPs)；</li>\n<li>第二，这些指标应该在目标平台(target platform)上进行评估。</li>\n</ul>\n<h2 id=\"ShuffleNetV1和MobileNetV2的运行时间性能-runtime-performance-分析\"><a href=\"#ShuffleNetV1和MobileNetV2的运行时间性能-runtime-performance-分析\" class=\"headerlink\" title=\"ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析\"></a>ShuffleNetV1和MobileNetV2的运行时间性能(runtime performance)分析</h2><p><img src=\"/images/ShuffleNetV2/1.png\" width=\"600\" height=\"100\"></p>\n<p>如Fig2所示，为ShuffleNetV1和MobileNetV2在ARM和GPU上的运行时间分析：</p>\n<ul>\n<li>总体的运行时间可以分解为五个部分：卷积、数据I/O、数据重排(data shuffle)、元素级运算(张量加法、ReLU等)及其他；</li>\n<li>文中注意到FLOPs仅和卷积部分相关，尽管这一部分需要消耗大部分的时间，但其它过程也需要消耗相当数量的时间；</li>\n<li>因此，FLOPs不是真实运行时间的足够准确地估计。</li>\n</ul>\n<h2 id=\"四个实用准则-practical-guidelines\"><a href=\"#四个实用准则-practical-guidelines\" class=\"headerlink\" title=\"四个实用准则(practical guidelines)\"></a>四个实用准则(practical guidelines)</h2><p>基于上述网络运行时间性能的分析，提出设计高效网络架构需要遵循的四个实用准则(practical guidelines)。</p>\n<h3 id=\"G1-相同的通道宽度可最小化内存访问成本-MAC）\"><a href=\"#G1-相同的通道宽度可最小化内存访问成本-MAC）\" class=\"headerlink\" title=\"G1. 相同的通道宽度可最小化内存访问成本(MAC）\"></a>G1. 相同的通道宽度可最小化内存访问成本(MAC）</h3><ul>\n<li>现代网络大多会采用depthwise separable convolutions，pointwise convolution($1\\times1$卷积)占据了其中大部分复杂度。</li>\n<li>$1\\times1$卷积的FLOPs为：$B=h w c_1 c_2$<ul>\n<li>其中，$h$和$w$为特征图的空间尺寸，$c_1$为输入通道数，$c_2$为输出通道数</li>\n</ul>\n</li>\n<li>为了简化计算，假设计算设备的缓存足够大，能够储存完整的特征图和参数。那么，MAC或内存访问操作的数量是：$MAC = hw(c_1+c_2)+c_1c_2$<ul>\n<li>其中，第一项为输入/输出特征图的内存访问，第二项为卷积核权重参数的内存访问</li>\n</ul>\n</li>\n<li>依据均值不等式(mean value inequality)，即$\\sqrt{c_1 c_2} \\leq \\frac{c_1+c_2}{2}$，可得：$MAC \\geq 2\\sqrt{hwB}+\\frac{B}{hw}$</li>\n<li><strong>因此，在给定FLOPs时，即可得到MAC的下界(lower bound)。并且，当输入的通道数和输出的通道数相等时，达到MAC的下界。</strong></li>\n<li>注意，该结论只是理论性的。因为在实际中，许多设备的缓存并不足够大，并且现代计算库通常采用复杂的模块策略来充分利用其缓存机制。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/2.png\" width=\"600\" height=\"100\"></p>\n<p>如Table1所示，为G1的验证试验：</p>\n<ul>\n<li>该实验固定总体的FLOPs，变化比率$c_1：c_2$，来比较运行速度；</li>\n<li>可以发现：当$c_1:c_2$接近$1:1$时，MAC开始变小，网络评估速度更快；</li>\n<li>因此，G1得到实际验证。</li>\n</ul>\n<h3 id=\"G2-过度的组卷积会增加MAC\"><a href=\"#G2-过度的组卷积会增加MAC\" class=\"headerlink\" title=\"G2. 过度的组卷积会增加MAC\"></a>G2. 过度的组卷积会增加MAC</h3><ul>\n<li>分组卷积通过改变所有通道之间的密集卷积(dense convolution)，成为只和组内通道进行的稀疏卷积(sparse convolution)，来减少计算复杂度(FLOPs)；</li>\n<li>一方面，在固定的FLOPs下，它允许了更多的通道数；并且，它增加了网络的容量(capacity)，也因此得到更高的准确率；</li>\n<li><p>另一方面，然而，增加的通道数量导致了更多的MAC。</p>\n</li>\n<li><p>正式的讲，对于$1\\times1$分组卷积，MAC和FLOPs的关系为：$MAC = hw(c_1+c_2)+\\frac{c_1c_2}{g} = hwc_1 + \\frac{Bg}{c_1}+ \\frac{B}{hw} $</p>\n<ul>\n<li>其中，$g$为分组的组数；B为$1\\times1$分组卷积的FLOPs，$B = \\frac{hwc_1c_2}{g}$</li>\n<li>容易看出，在给定固定的输入尺寸$c_1 \\times h \\times w$以及计算代价$B$时，MAC随着$g$的增长而增加。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/3.png\" width=\"600\" height=\"100\"></p>\n<p>如Table2所示，为G2的验证试验：</p>\n<ul>\n<li>该实验固定总体的FLOPs，采用不同的组数，来比较运行速度；</li>\n<li>明显地，采用大的分组数，显著地降低了运行速度。<ul>\n<li>例如：在GPU上，当采用分组数为8时，比分组数为1(标准密集卷积)时，慢2两倍；在ARM上，慢30%。</li>\n<li>这主要是由于MAC的增加。</li>\n</ul>\n</li>\n<li>因此，我们建议：<ul>\n<li>对于分组数，基于目标平台和任务，来谨慎地选择；</li>\n<li>简单地因为大的分组数可以允许更大的通道数(获得更高的准确率)，而选择大的分组数，是不明智的。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"G3-网络碎片化-network-fragmentation-会降低并行度-degree-of-parallelism\"><a href=\"#G3-网络碎片化-network-fragmentation-会降低并行度-degree-of-parallelism\" class=\"headerlink\" title=\"G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)\"></a>G3. 网络碎片化(network fragmentation)会降低并行度(degree of parallelism)</h3><ul>\n<li>例如GoogLeNet的多路径结构会降低并行度</li>\n<li>尽管这种分散的结构(fragmented structure)已经展示出对准确率有益，但是它可能降低效率，因为它对像GPU这种带有强大并行计算能力(parallel<br>computing powers)的设备很不友好。<ul>\n<li>疑问：为啥不友好？</li>\n</ul>\n</li>\n<li>这种分散的结构也引起了诸如卷积核加载(kernel launching)和同步化(synchronization)等开销。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/4.png\" width=\"600\" height=\"100\"></p>\n<p>如Table3所示，为G3的验证试验：</p>\n<ul>\n<li>可以发现：<ul>\n<li>在GPU上，分散化显著地减少了运行速度；</li>\n<li>在ARM上，速度的减少相对较小。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"G4-元素级运算-element-wise-operations-不可忽视-non-negligible\"><a href=\"#G4-元素级运算-element-wise-operations-不可忽视-non-negligible\" class=\"headerlink\" title=\"G4. 元素级运算(element-wise operations)不可忽视(non-negligible)\"></a>G4. 元素级运算(element-wise operations)不可忽视(non-negligible)</h3><ul>\n<li>如Fig2所示，对于轻量化的模型ShuffleNetV1和MobileNetV2，元素级运算占据了相当大的时间，尤其是在GPU上。</li>\n<li>在这里，元素级运算包括：ReLU, AddTensor, AddBias等。它们有较小的FLOPs，但是有相对较大的MAC。</li>\n<li>特殊地，我们将depthwise convolution考虑为元素级运算，因为它也有较高的MAC/FLOPs比率。</li>\n</ul>\n<p><img src=\"/images/ShuffleNetV2/5.png\" width=\"600\" height=\"100\"></p>\n<p>如Table4所示，为G4的验证试验：</p>\n<ul>\n<li>该实验以ResNet中的“bottleneck”单元为实验对象，探究在ReLU和捷径连接在分别被去除后，运行时间的变化；</li>\n<li>可以发现：在ReLU和捷径连接被移除之后，在GPU和ARM上，均取得了20%的加速。</li>\n</ul>\n<h3 id=\"结论和建议\"><a href=\"#结论和建议\" class=\"headerlink\" title=\"结论和建议\"></a>结论和建议</h3><p>基于上述四点指导准则和实证研究，对于高效网络结构的设计，我们给出以下结论：</p>\n<ul>\n<li>1.应该使用平衡的卷积(“balanced” convolutions)，即相等的通道宽度</li>\n<li>2.意识到使用分组卷积的代价</li>\n<li>3.减少分散程度(the degree of fragmentation)</li>\n<li>4.减少元素级运算</li>\n<li>并且，这些期望特性(desirable properties)取决于平台特性(如内存操作和代码优化)，超越了理论的FLOPs。它们都应该在实际的网络设计中被考虑到。</li>\n</ul>\n<h2 id=\"近期轻量型网络分析\"><a href=\"#近期轻量型网络分析\" class=\"headerlink\" title=\"近期轻量型网络分析\"></a>近期轻量型网络分析</h2><ul>\n<li>近期，轻量级神经网络架构上的研究进展主要基于间接指标FLOPs，并且没有考虑上述四个准则</li>\n<li>例如，ShuffleNetV1严重依赖组卷积(违反G2)和瓶颈形态的构造块(违反G1)</li>\n<li>MobileNetV2使用倒置的瓶颈结构，违反了G1。它在「厚」特征图上(“thick” feature maps)使用了depthwise convolution和ReLU，违反了G4</li>\n<li>自动生成结构(the auto-generated structures)的高度碎片化，违反了G3</li>\n</ul>\n<h2 id=\"ShuffleNetV1回顾与分析\"><a href=\"#ShuffleNetV1回顾与分析\" class=\"headerlink\" title=\"ShuffleNetV1回顾与分析\"></a>ShuffleNetV1回顾与分析</h2><p><img src=\"/images/ShuffleNetV2/6.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>ShuﬄeNetV1是一种先进的网络架构，广泛应用于手机等低配设备。它启发了本文工作，因此首先对其进行回顾与分析。</li>\n<li>根据ShuﬄeNetV1，轻量级网络的主要挑战是在给定计算预算(FLOPs)时，只能获得有限数量的特征通道。</li>\n<li>为了在不显著增加FLOPs情况下增加通道数量，ShuﬄeNetV1采用了两种技术：逐点分组卷积(pointwise group convolutions)和类瓶颈(bottleneck-like)结构；</li>\n<li>然后引入通道重排(channel shuﬄe)操作，令不同组的通道之间能够进行信息交流，提高精度。</li>\n<li><p>其构建模块如Fig3中的(a)(b)所示。</p>\n</li>\n<li><p>如第二部分所述，逐点分组卷积和瓶颈结构都增加了MAC(G2和G1)。这个成本不可忽视，特别是对于轻量级模型。</p>\n</li>\n<li>另外，使用太多分组也违背了G3。<ul>\n<li>疑问：应该是违背了G2吧</li>\n</ul>\n</li>\n<li>捷径连接（shortcut connection）中的元素级「加法」操作也不可取 (G4)。</li>\n<li>因此，为了实现较高的模型容量和效率，关键问题是如何保持大量且同样宽的通道，既没有密集卷积也没有太多的分组。</li>\n</ul>\n<h2 id=\"通道分割-channel-split\"><a href=\"#通道分割-channel-split\" class=\"headerlink\" title=\"通道分割(channel split)\"></a>通道分割(channel split)</h2><p>为此，本文引入一个简单的操作——通道分割(channel split)。</p>\n<ul>\n<li><p>如Fig3(c)所示:</p>\n<ul>\n<li>在每个单元的开始，$c$特征通道的输入被分为两支，分别带有$c−c’$ 和$c’$个通道。</li>\n<li>按照G3，一个分支仍然保持不变。</li>\n<li>另一个分支由三个卷积组成，为满足 G1，令输入和输出通道相同。</li>\n<li>与ShuffleNetV1不同的是，两个$1\\times 1$卷积不再是分组卷积。这样做的部分原因是为了遵循G2，部分原因是因为通道分割操作已经产生了两个组。</li>\n<li>卷积之后，把两个分支拼接起来，从而通道数量保持不变(G1)。然后进行与ShuffleNetV1相同的通道重排(channel shuﬄe)操作来保证两个分支间能进行信息交流。</li>\n<li>通道重排(Channel Shuﬄe)之后，下一个单元开始运算。</li>\n<li>注意，ShuﬄeNetV1中的「加法」操作不再存在。像ReLU 和epth- wise convolutions这样的操作只存在一个分支中。</li>\n<li>另外，三个连续的操作拼接(concat)、通道重排(channel shuﬄe)和通道分割(channel shuﬄe)合并成一个元素级操作。根据G4，这些变化是有利的。</li>\n<li>疑问：三个连续操作时如何合并成一个的？？</li>\n</ul>\n</li>\n<li><p>如Fig3(d)所示，对于空间下采样，该单元经过稍微修改:</p>\n<ul>\n<li>通道分割运算被移除。因此，输出通道数量翻了一倍。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ShuffleNetV2\"><a href=\"#ShuffleNetV2\" class=\"headerlink\" title=\"ShuffleNetV2\"></a>ShuffleNetV2</h2><p><img src=\"/images/ShuffleNetV2/7.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>基于本文提出的构造模块Fig3(c)(d)而构成的网络，被称之为ShuﬄeNetV2。</li>\n<li>基于上述对构造模块Fig3(c)(d)分析，本文得出结论：由于遵循四个准则的遵循，该架构设计异常高效。</li>\n<li>上述基础构建模块被重复堆叠以构建整个网络。为了简洁，本文令$c’ = c/2$。</li>\n<li>如Table5所示，为ShufﬂeNetV2的整体结构：<ul>\n<li>整个网络结构类似于ShufﬂeNetV1，二者之间只有一个区别：前者在全局平均池化层之前添加了一个额外的$1\\times 1$卷积层来混合特征，ShuﬄeNetV1中没有该层。</li>\n<li>与ShuﬄeNetV1类似，每个构建块中的通道数量可以扩展以生成不同复杂度的网络，标记为<code>0.5×</code>、<code>1×</code>等。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"模型比较\"><a href=\"#模型比较\" class=\"headerlink\" title=\"模型比较\"></a>模型比较</h1><p><img src=\"/images/ShuffleNetV2/8.png\" width=\"600\" height=\"100\"></p>\n<ul>\n<li>如Table8所示，为各网络在四个级别的计算复杂度(40/140/300/500+ MFLOPs)级别上的FLOPs、Top-1错误率以及在GPU/ARM上的速度对比。<ul>\n<li>可以发现：在同等的FLOPs下，ShuffleNetV2的各项表现均为最佳。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li><a href=\"https://arxiv.org/pdf/1807.11164.pdf\" target=\"_blank\" rel=\"noopener\">论文：ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a></li>\n<li><a href=\"http://www.sohu.com/a/244491616_418390\" target=\"_blank\" rel=\"noopener\">博客(旷视官方)：ECCV 2018 | 旷视科技提出新型轻量架构ShuffleNet V2：从理论复杂度到实用设计准则</a></li>\n</ul>"},{"title":"线性表","date":"2017-11-21T14:40:50.000Z","_content":"## 一、线性表的概念\n线性表：零个或者多个具有相同类型的数据元素组成的有限序列。  \n线性表的抽象数据类型：\n```C++\nADT 线性表(List)\nData\n    线性表的数据对象集合为{a1,a2,...,an}，每个元素的类型均为DataType\nOperation\n    ListInit(*L):          初始化操作，建立一个空的线性表L。\n    ListEmpty(L):          若线性表为空，返回true，否则返回false。\n    ListInsert(*L,i,e):    在L的第i个位置插入新元素e。\n    ListDelete(*L,i,*e):   删除L中的第i个元素，并用e返回其值。\n    ListLength(L):         返回L中的元素个数\n    GetElem(L, i, *e):     将线性表L中的第i个位置元素值返回给e。\n    ListClear(*L):         将线性表清空。\nendADT\n```\n\n## 二、顺序存储结构——顺序表\n顺序存储结构:用一段地址连续的存储单元依次存储线性表的数据元素。  \n### 2.1 顺序表的实现  \n实现：C语言的一维数组可以实现线性表的顺序存储结构。\n（1）线性表的下标从1开始，数组的下标从0开始；\n（2）在任意时刻，线性表的长度应该小于等于数组的长度。\n示例：\n<img src=\"http://7xjzhz.com1.z0.glb.clouddn.com/3-4-3.jpg\" width=\"90%\" height=\"50%\">\n<!-- more --> \n### 2.2 常见操作\n（1）查找：依照数组下标进行读/写，时间复杂度O(1)；\n（2）插入：插入位置之后的元素依次往后移动一个位置，时间复杂度为O(n)；\n（3）删除：删除位置之后的元素依次往前移动一个位置，时间复杂度为O(n)。\n## 三、链式存储结构——单链表\n线性表的链式存储结构的是用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。\n### 3.1 单链表的实现\n（1）链表的每个结点包含一个数据域跟一个指针域，指针域存放后继结点的存储位置；\n（2）头指针：链表中第一个结点的存储位置；\n（3）头结点：单链表的第一个结点前的附设结点，数据域存储链表相关信息，比如长度，指针域存储指向下一个结点的指针。\n注：头指针是必须的，头结点不是必须的。\n单链表结点:\n```C\n/* 线性表的单链表存储结构*/\ntypedef struct Node\n{\n    ElemType data;\n    struct Node* next;\n}Node;\n```\n单链表示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"80%\" height=\"30%\">\n\n### 3.2 常见操作\n（1）查找：从头指针开始，指针后移直至第i个结点为止，时间复杂度为O(n)；\n（2）插入：遍历查找第i个结点，修改指针域，插入结点，时间复杂度为O(n)（不算查找时间为O(1)）；\n（3）删除：遍历查找第i个结点，修改指针域，删除结点，时间复杂度为O(n)（不算查找时间为O(1)）。\n注：对于单个结点的插入或者删除，单链表比起顺序表并没有优势，但是插入或删除数据越频繁的操作，单链表的效率优势就越明显。\n### 3.3 插入操作\n（1）思路：\na.在首位置(n=1)插入结点：新建待插入结点，待插入结点指向头指针head所指向的内容；头指针head指向待插入结点。\nb.在n(n>1)位置插入结点：新建待插入结点，将头指针移动到n-1结点位置，待插入结点指向n结点，n-1结点指向待插入结点。\n（2）代码：\n```C++\nNode* InsertNth(Node* head, ElementType x, int n)\n{   \n    //新建结点\n    Node* temp1=new Node();\n    temp1->data=x;\n    temp1->next=NULL;\n    //在首位置(n=1)插入一个结点\n    if(n==1)\n    {\n        temp1->next=head;  //head为NULL也行\n        head=temp1;\n        return head;\n    }\n    //在n(n>1)位置插入结点\n    Node* temp2=head;\n    for(int i=0; i<n-2; i++)\n    {   \n        if(temp2==NULL) return NULL; //位置n有误\n        temp2=temp2->next;\n    } //temp2指向第(n-1)个结点\n    temp1->next=temp2->next;\n    temp2->next=temp1;\n    return head;\n}\n```\n（3）[示例](https://www.youtube.com/watch?v=IbvsNF22Ud0&index=7&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\na.在首位置(n=1)插入一个结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_1.jpg\" width=\"100%\" height=\"50%\">\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_2.jpg\" width=\"100%\" height=\"50%\">\nb.在n(n>1)位置插入结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E4%BB%BB%E6%84%8F%E4%BD%8D%E7%BD%AE%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\n### 3.4 删除操作\n（1）思路：调整链表+释放空间\na.删除首位置(n=1)结点：头指针指向第2个结点，释放第一个结点空间。\nb.删除n(n>1)位置结点：将头指针移动到n-1结点位置，n-1结点指向n+1结点。释放n结点空间。\n（2）代码：\n```C++\nNode* DeleteNth(Node* head, int n)\n{\n    if(head==NULL || n<=0) \n        return NULL;\n    Node* temp1=head;\n    //删除首位置(n=1)结点\n    if(n==1)\n    {\n        head=temp1->next;\n        delete temp1;\n        return head;\n    }\n    //删除n(n>1)位置结点\n    for(int i=0; i<n-2; i++)\n    {\n        if(temp1==NULL) return NULL; //位置n有误\n        temp1=temp1->next;\n    } //temp1指向第(n-1)个结点\n    Node *temp2=temp1->next; \n    temp1->next=temp2->next;\n    delete temp2;\n    return head;\n}\n```\n（3）[示例](https://www.youtube.com/watch?v=Y0n86K43GO4&index=8&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\na.删除第(n=1)个结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\nb.删除第(n>1)个结点:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%ACn%E5%A4%A7%E4%BA%8E1%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\n\n### 3.5 测试代码\n```C++\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    struct Node* next;\n};\nNode* InsertNth(Node* head, int x, int n)\n{\n    Node* temp1 = new Node();\n    temp1->data = x;\n    temp1->next = NULL;\n    if (n == 1)\n    {\n        temp1->next = head;  //head为NULL也行\n        head = temp1; \n        return head;\n    }\n    Node* temp2 = head;\n    for (int i = 0; i < n-2;i++)\n    {\n        if (temp2 == NULL) return NULL;\n        temp2 = temp2->next;\n    }\n    temp1->next = temp2->next;\n    temp2->next = temp1;\n    return head;\n}\nNode* DeleteNth(Node* head, int n)\n{\n    if (head == NULL || n <= 0)\n        return NULL;\n    Node* temp1 = head;\n    if (n == 1)\n    {\n        head =temp1->next;\n        delete temp1;\n        return head;\n    }\n    for (int i = 0; i < n - 2; i++)\n    {\n        if (temp1 == NULL) return NULL;\n        temp1 = temp1->next;\n    }\n    Node* temp2 = temp1->next;\n    temp1->next = temp2->next;\n    delete temp2;\n    return head;\n}\nvoid Print(Node* head) \n{\n    Node* temp = head;\n    while (temp != NULL)\n    {\n        cout << temp->data << \",\";\n        temp = temp->next;\n    }\t\n    cout << endl;\n}\n\nint main()\n{\n    Node* head = NULL;\n    //插入操作\n    head=InsertNth(head, 6, 1);//6\n    Print(head);\n    head=InsertNth(head, 7, 2);//6,7\n    Print(head);\n    head=InsertNth(head, 8, 3);//6,7,8\n    Print(head);\n    head=InsertNth(head, 9, 4);//6,7,8,9\n    Print(head);\n    head=InsertNth(head, 5, 1);//5,6,7,8,9\n    Print(head);\n    head=InsertNth(head, 0, 2);//5,0,6,7,8,9\n    Print(head);\n    //删除操作\n    head=DeleteNth(head, 1);//0,6,7,8,9\n    Print(head);\n    head=DeleteNth(head, 5);//0,6,7,8\n    Print(head);\n    head=DeleteNth(head, 2);//0,7,8\n    Print(head);\n    return 0;\n}\n```\n\n### 3.6 顺序存储结构与单链表对比\n|存储类别 |顺序存储结构 |单链表 | \n|:--:|:--:|:--:|:--:|\n|存储分配方式 |用一段连续的存储单元依次存储线性表的数据元素 | 采用链式存储结构，用一组任意的存储单元存放线性表的元素|\n|时间性能|查找O(1)、插入和删除O(n)|查找、插入和删除O(n）|\n|空间性能|需要预分配存储空间，分大了浪费，小了容易发生上溢|不需要分配存储空间，只要有就可以分配，元素个数不受限制|\n\n通过对比：\n\n - 若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。若需要频繁插入和删除时，宜采用单链表结构（单链表在找出某位置的指针后，插入和删除时间仅为O(1)）。\n - 当线性表中的元素个数变化较大或者根本不知道有多大时，最好用单链表结构，这样可以不需要考虑存储空间的大小问题。而如果事先知道线性表的大致长度，用顺序存储结构效率会高很多。\n\n## 四、双向链表\n### 4.1 双向链表的实现\n双向链表：在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。\n双向链表的结点：\n```C\n/* 双向链表的结点 */\ntypedef struct Node\n{\n    ElemType data;\n    struct Node* prev;    /* 直接前驱指针 */\n    struct Node* next;     /* 直接后继指针 */\n}Node;\n```\n[示例](https://www.youtube.com/watch?v=JdQeNxWCguQ&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&index=12)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8F%8C%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"90%\" height=\"50%\">\n### 4.2 实现（待）\n```C++\n/* Doubly Linked List implementation */\n#include<stdio.h>\n#include<stdlib.h>\nstruct Node  {\n    int data;\n    struct Node* next;\n    struct Node* prev;\n};\nstruct Node* head; // global variable - pointer to head node.\n//Creates a new Node and returns pointer to it. \nstruct Node* GetNewNode(int x) {\n    struct Node* newNode\n        = (struct Node*)malloc(sizeof(struct Node));\n    newNode->data = x;\n    newNode->prev = NULL;\n    newNode->next = NULL;\n    return newNode;\n}\n//Inserts a Node at head of doubly linked list\nvoid InsertAtHead(int x) {\n    struct Node* newNode = GetNewNode(x);\n    if(head == NULL) {\n        head = newNode;\n        return;\n    }\n    head->prev = newNode;\n    newNode->next = head; \n    head = newNode;\n}\n//Inserts a Node at tail of Doubly linked list\nvoid InsertAtTail(int x) {\n    struct Node* temp = head;\n    struct Node* newNode = GetNewNode(x);\n    if(head == NULL) {\n        head = newNode;\n        return;\n    }\n    while(temp->next != NULL) temp = temp->next; // Go To last Node\n    temp->next = newNode;\n    newNode->prev = temp;\n}\n//Prints all the elements in linked list in forward traversal order\nvoid Print() {\n    struct Node* temp = head;\n    printf(\"Forward: \");\n    while(temp != NULL) {\n        printf(\"%d \",temp->data);\n        temp = temp->next;\n    }\n    printf(\"\\n\");\n}\n//Prints all elements in linked list in reverse traversal order. \nvoid ReversePrint() {\n    struct Node* temp = head;\n    if(temp == NULL) return; // empty list, exit\n    // Going to last Node\n    while(temp->next != NULL) {\n        temp = temp->next;\n    }\n    // Traversing backward using prev pointer\n    printf(\"Reverse: \");\n    while(temp != NULL) {\n        printf(\"%d \",temp->data);\n        temp = temp->prev;\n    }\n    printf(\"\\n\");\n}\nint main() {\n    /*Driver code to test the implementation*/\n    Node* head = NULL; // empty list. set head as NULL. \n    // Calling an Insert and printing list both in forward as well as reverse direction. \n    InsertAtTail(2); Print(); ReversePrint();\n    InsertAtTail(4); Print(); ReversePrint();\n    InsertAtHead(6); Print(); ReversePrint();\n    InsertAtTail(8); Print(); ReversePrint();\n}\n```\n## 五、循环链表\n循环链表：将单链表中终端结点的指针端由空指针改成指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表。\n## 六、参考\n1.[数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n2.[Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n3.[程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n\n\n\n\n","source":"_posts/线性表.md","raw":"---\ntitle: 线性表\ndate: 2017-11-21 22:40:50\ncategories: \n- 数据结构与算法\ntags:\n- 线性表\n- 顺序存储结构\n- 数组\n- 链式存储结构\n- 链表\n- 单链表\n- 双向链表\n- 循环链表\n---\n## 一、线性表的概念\n线性表：零个或者多个具有相同类型的数据元素组成的有限序列。  \n线性表的抽象数据类型：\n```C++\nADT 线性表(List)\nData\n    线性表的数据对象集合为{a1,a2,...,an}，每个元素的类型均为DataType\nOperation\n    ListInit(*L):          初始化操作，建立一个空的线性表L。\n    ListEmpty(L):          若线性表为空，返回true，否则返回false。\n    ListInsert(*L,i,e):    在L的第i个位置插入新元素e。\n    ListDelete(*L,i,*e):   删除L中的第i个元素，并用e返回其值。\n    ListLength(L):         返回L中的元素个数\n    GetElem(L, i, *e):     将线性表L中的第i个位置元素值返回给e。\n    ListClear(*L):         将线性表清空。\nendADT\n```\n\n## 二、顺序存储结构——顺序表\n顺序存储结构:用一段地址连续的存储单元依次存储线性表的数据元素。  \n### 2.1 顺序表的实现  \n实现：C语言的一维数组可以实现线性表的顺序存储结构。\n（1）线性表的下标从1开始，数组的下标从0开始；\n（2）在任意时刻，线性表的长度应该小于等于数组的长度。\n示例：\n<img src=\"http://7xjzhz.com1.z0.glb.clouddn.com/3-4-3.jpg\" width=\"90%\" height=\"50%\">\n<!-- more --> \n### 2.2 常见操作\n（1）查找：依照数组下标进行读/写，时间复杂度O(1)；\n（2）插入：插入位置之后的元素依次往后移动一个位置，时间复杂度为O(n)；\n（3）删除：删除位置之后的元素依次往前移动一个位置，时间复杂度为O(n)。\n## 三、链式存储结构——单链表\n线性表的链式存储结构的是用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。\n### 3.1 单链表的实现\n（1）链表的每个结点包含一个数据域跟一个指针域，指针域存放后继结点的存储位置；\n（2）头指针：链表中第一个结点的存储位置；\n（3）头结点：单链表的第一个结点前的附设结点，数据域存储链表相关信息，比如长度，指针域存储指向下一个结点的指针。\n注：头指针是必须的，头结点不是必须的。\n单链表结点:\n```C\n/* 线性表的单链表存储结构*/\ntypedef struct Node\n{\n    ElemType data;\n    struct Node* next;\n}Node;\n```\n单链表示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"80%\" height=\"30%\">\n\n### 3.2 常见操作\n（1）查找：从头指针开始，指针后移直至第i个结点为止，时间复杂度为O(n)；\n（2）插入：遍历查找第i个结点，修改指针域，插入结点，时间复杂度为O(n)（不算查找时间为O(1)）；\n（3）删除：遍历查找第i个结点，修改指针域，删除结点，时间复杂度为O(n)（不算查找时间为O(1)）。\n注：对于单个结点的插入或者删除，单链表比起顺序表并没有优势，但是插入或删除数据越频繁的操作，单链表的效率优势就越明显。\n### 3.3 插入操作\n（1）思路：\na.在首位置(n=1)插入结点：新建待插入结点，待插入结点指向头指针head所指向的内容；头指针head指向待插入结点。\nb.在n(n>1)位置插入结点：新建待插入结点，将头指针移动到n-1结点位置，待插入结点指向n结点，n-1结点指向待插入结点。\n（2）代码：\n```C++\nNode* InsertNth(Node* head, ElementType x, int n)\n{   \n    //新建结点\n    Node* temp1=new Node();\n    temp1->data=x;\n    temp1->next=NULL;\n    //在首位置(n=1)插入一个结点\n    if(n==1)\n    {\n        temp1->next=head;  //head为NULL也行\n        head=temp1;\n        return head;\n    }\n    //在n(n>1)位置插入结点\n    Node* temp2=head;\n    for(int i=0; i<n-2; i++)\n    {   \n        if(temp2==NULL) return NULL; //位置n有误\n        temp2=temp2->next;\n    } //temp2指向第(n-1)个结点\n    temp1->next=temp2->next;\n    temp2->next=temp1;\n    return head;\n}\n```\n（3）[示例](https://www.youtube.com/watch?v=IbvsNF22Ud0&index=7&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\na.在首位置(n=1)插入一个结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_1.jpg\" width=\"100%\" height=\"50%\">\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_2.jpg\" width=\"100%\" height=\"50%\">\nb.在n(n>1)位置插入结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E4%BB%BB%E6%84%8F%E4%BD%8D%E7%BD%AE%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\n### 3.4 删除操作\n（1）思路：调整链表+释放空间\na.删除首位置(n=1)结点：头指针指向第2个结点，释放第一个结点空间。\nb.删除n(n>1)位置结点：将头指针移动到n-1结点位置，n-1结点指向n+1结点。释放n结点空间。\n（2）代码：\n```C++\nNode* DeleteNth(Node* head, int n)\n{\n    if(head==NULL || n<=0) \n        return NULL;\n    Node* temp1=head;\n    //删除首位置(n=1)结点\n    if(n==1)\n    {\n        head=temp1->next;\n        delete temp1;\n        return head;\n    }\n    //删除n(n>1)位置结点\n    for(int i=0; i<n-2; i++)\n    {\n        if(temp1==NULL) return NULL; //位置n有误\n        temp1=temp1->next;\n    } //temp1指向第(n-1)个结点\n    Node *temp2=temp1->next; \n    temp1->next=temp2->next;\n    delete temp2;\n    return head;\n}\n```\n（3）[示例](https://www.youtube.com/watch?v=Y0n86K43GO4&index=8&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\na.删除第(n=1)个结点：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\nb.删除第(n>1)个结点:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%ACn%E5%A4%A7%E4%BA%8E1%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\">\n\n### 3.5 测试代码\n```C++\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    struct Node* next;\n};\nNode* InsertNth(Node* head, int x, int n)\n{\n    Node* temp1 = new Node();\n    temp1->data = x;\n    temp1->next = NULL;\n    if (n == 1)\n    {\n        temp1->next = head;  //head为NULL也行\n        head = temp1; \n        return head;\n    }\n    Node* temp2 = head;\n    for (int i = 0; i < n-2;i++)\n    {\n        if (temp2 == NULL) return NULL;\n        temp2 = temp2->next;\n    }\n    temp1->next = temp2->next;\n    temp2->next = temp1;\n    return head;\n}\nNode* DeleteNth(Node* head, int n)\n{\n    if (head == NULL || n <= 0)\n        return NULL;\n    Node* temp1 = head;\n    if (n == 1)\n    {\n        head =temp1->next;\n        delete temp1;\n        return head;\n    }\n    for (int i = 0; i < n - 2; i++)\n    {\n        if (temp1 == NULL) return NULL;\n        temp1 = temp1->next;\n    }\n    Node* temp2 = temp1->next;\n    temp1->next = temp2->next;\n    delete temp2;\n    return head;\n}\nvoid Print(Node* head) \n{\n    Node* temp = head;\n    while (temp != NULL)\n    {\n        cout << temp->data << \",\";\n        temp = temp->next;\n    }\t\n    cout << endl;\n}\n\nint main()\n{\n    Node* head = NULL;\n    //插入操作\n    head=InsertNth(head, 6, 1);//6\n    Print(head);\n    head=InsertNth(head, 7, 2);//6,7\n    Print(head);\n    head=InsertNth(head, 8, 3);//6,7,8\n    Print(head);\n    head=InsertNth(head, 9, 4);//6,7,8,9\n    Print(head);\n    head=InsertNth(head, 5, 1);//5,6,7,8,9\n    Print(head);\n    head=InsertNth(head, 0, 2);//5,0,6,7,8,9\n    Print(head);\n    //删除操作\n    head=DeleteNth(head, 1);//0,6,7,8,9\n    Print(head);\n    head=DeleteNth(head, 5);//0,6,7,8\n    Print(head);\n    head=DeleteNth(head, 2);//0,7,8\n    Print(head);\n    return 0;\n}\n```\n\n### 3.6 顺序存储结构与单链表对比\n|存储类别 |顺序存储结构 |单链表 | \n|:--:|:--:|:--:|:--:|\n|存储分配方式 |用一段连续的存储单元依次存储线性表的数据元素 | 采用链式存储结构，用一组任意的存储单元存放线性表的元素|\n|时间性能|查找O(1)、插入和删除O(n)|查找、插入和删除O(n）|\n|空间性能|需要预分配存储空间，分大了浪费，小了容易发生上溢|不需要分配存储空间，只要有就可以分配，元素个数不受限制|\n\n通过对比：\n\n - 若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。若需要频繁插入和删除时，宜采用单链表结构（单链表在找出某位置的指针后，插入和删除时间仅为O(1)）。\n - 当线性表中的元素个数变化较大或者根本不知道有多大时，最好用单链表结构，这样可以不需要考虑存储空间的大小问题。而如果事先知道线性表的大致长度，用顺序存储结构效率会高很多。\n\n## 四、双向链表\n### 4.1 双向链表的实现\n双向链表：在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。\n双向链表的结点：\n```C\n/* 双向链表的结点 */\ntypedef struct Node\n{\n    ElemType data;\n    struct Node* prev;    /* 直接前驱指针 */\n    struct Node* next;     /* 直接后继指针 */\n}Node;\n```\n[示例](https://www.youtube.com/watch?v=JdQeNxWCguQ&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&index=12)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8F%8C%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"90%\" height=\"50%\">\n### 4.2 实现（待）\n```C++\n/* Doubly Linked List implementation */\n#include<stdio.h>\n#include<stdlib.h>\nstruct Node  {\n    int data;\n    struct Node* next;\n    struct Node* prev;\n};\nstruct Node* head; // global variable - pointer to head node.\n//Creates a new Node and returns pointer to it. \nstruct Node* GetNewNode(int x) {\n    struct Node* newNode\n        = (struct Node*)malloc(sizeof(struct Node));\n    newNode->data = x;\n    newNode->prev = NULL;\n    newNode->next = NULL;\n    return newNode;\n}\n//Inserts a Node at head of doubly linked list\nvoid InsertAtHead(int x) {\n    struct Node* newNode = GetNewNode(x);\n    if(head == NULL) {\n        head = newNode;\n        return;\n    }\n    head->prev = newNode;\n    newNode->next = head; \n    head = newNode;\n}\n//Inserts a Node at tail of Doubly linked list\nvoid InsertAtTail(int x) {\n    struct Node* temp = head;\n    struct Node* newNode = GetNewNode(x);\n    if(head == NULL) {\n        head = newNode;\n        return;\n    }\n    while(temp->next != NULL) temp = temp->next; // Go To last Node\n    temp->next = newNode;\n    newNode->prev = temp;\n}\n//Prints all the elements in linked list in forward traversal order\nvoid Print() {\n    struct Node* temp = head;\n    printf(\"Forward: \");\n    while(temp != NULL) {\n        printf(\"%d \",temp->data);\n        temp = temp->next;\n    }\n    printf(\"\\n\");\n}\n//Prints all elements in linked list in reverse traversal order. \nvoid ReversePrint() {\n    struct Node* temp = head;\n    if(temp == NULL) return; // empty list, exit\n    // Going to last Node\n    while(temp->next != NULL) {\n        temp = temp->next;\n    }\n    // Traversing backward using prev pointer\n    printf(\"Reverse: \");\n    while(temp != NULL) {\n        printf(\"%d \",temp->data);\n        temp = temp->prev;\n    }\n    printf(\"\\n\");\n}\nint main() {\n    /*Driver code to test the implementation*/\n    Node* head = NULL; // empty list. set head as NULL. \n    // Calling an Insert and printing list both in forward as well as reverse direction. \n    InsertAtTail(2); Print(); ReversePrint();\n    InsertAtTail(4); Print(); ReversePrint();\n    InsertAtHead(6); Print(); ReversePrint();\n    InsertAtTail(8); Print(); ReversePrint();\n}\n```\n## 五、循环链表\n循环链表：将单链表中终端结点的指针端由空指针改成指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表。\n## 六、参考\n1.[数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n2.[Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n3.[程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n\n\n\n\n","slug":"线性表","published":1,"updated":"2018-01-27T12:05:51.390Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w09002sqslpq7ezyudu","content":"<h2 id=\"一、线性表的概念\"><a href=\"#一、线性表的概念\" class=\"headerlink\" title=\"一、线性表的概念\"></a>一、线性表的概念</h2><p>线性表：零个或者多个具有相同类型的数据元素组成的有限序列。<br>线性表的抽象数据类型：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 线性表(List)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    线性表的数据对象集合为&#123;a1,a2,...,an&#125;，每个元素的类型均为DataType</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    ListInit(*L):          初始化操作，建立一个空的线性表L。</span><br><span class=\"line\">    ListEmpty(L):          若线性表为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    ListInsert(*L,i,e):    在L的第i个位置插入新元素e。</span><br><span class=\"line\">    ListDelete(*L,i,*e):   删除L中的第i个元素，并用e返回其值。</span><br><span class=\"line\">    ListLength(L):         返回L中的元素个数</span><br><span class=\"line\">    GetElem(L, i, *e):     将线性表L中的第i个位置元素值返回给e。</span><br><span class=\"line\">    ListClear(*L):         将线性表清空。</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"二、顺序存储结构——顺序表\"><a href=\"#二、顺序存储结构——顺序表\" class=\"headerlink\" title=\"二、顺序存储结构——顺序表\"></a>二、顺序存储结构——顺序表</h2><p>顺序存储结构:用一段地址连续的存储单元依次存储线性表的数据元素。  </p>\n<h3 id=\"2-1-顺序表的实现\"><a href=\"#2-1-顺序表的实现\" class=\"headerlink\" title=\"2.1 顺序表的实现\"></a>2.1 顺序表的实现</h3><p>实现：C语言的一维数组可以实现线性表的顺序存储结构。<br>（1）线性表的下标从1开始，数组的下标从0开始；<br>（2）在任意时刻，线性表的长度应该小于等于数组的长度。<br>示例：<br><img src=\"http://7xjzhz.com1.z0.glb.clouddn.com/3-4-3.jpg\" width=\"90%\" height=\"50%\"><br><a id=\"more\"></a> </p>\n<h3 id=\"2-2-常见操作\"><a href=\"#2-2-常见操作\" class=\"headerlink\" title=\"2.2 常见操作\"></a>2.2 常见操作</h3><p>（1）查找：依照数组下标进行读/写，时间复杂度O(1)；<br>（2）插入：插入位置之后的元素依次往后移动一个位置，时间复杂度为O(n)；<br>（3）删除：删除位置之后的元素依次往前移动一个位置，时间复杂度为O(n)。</p>\n<h2 id=\"三、链式存储结构——单链表\"><a href=\"#三、链式存储结构——单链表\" class=\"headerlink\" title=\"三、链式存储结构——单链表\"></a>三、链式存储结构——单链表</h2><p>线性表的链式存储结构的是用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。</p>\n<h3 id=\"3-1-单链表的实现\"><a href=\"#3-1-单链表的实现\" class=\"headerlink\" title=\"3.1 单链表的实现\"></a>3.1 单链表的实现</h3><p>（1）链表的每个结点包含一个数据域跟一个指针域，指针域存放后继结点的存储位置；<br>（2）头指针：链表中第一个结点的存储位置；<br>（3）头结点：单链表的第一个结点前的附设结点，数据域存储链表相关信息，比如长度，指针域存储指向下一个结点的指针。<br>注：头指针是必须的，头结点不是必须的。<br>单链表结点:<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 线性表的单链表存储结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;Node;</span><br></pre></td></tr></table></figure></p>\n<p>单链表示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"80%\" height=\"30%\"></p>\n<h3 id=\"3-2-常见操作\"><a href=\"#3-2-常见操作\" class=\"headerlink\" title=\"3.2 常见操作\"></a>3.2 常见操作</h3><p>（1）查找：从头指针开始，指针后移直至第i个结点为止，时间复杂度为O(n)；<br>（2）插入：遍历查找第i个结点，修改指针域，插入结点，时间复杂度为O(n)（不算查找时间为O(1)）；<br>（3）删除：遍历查找第i个结点，修改指针域，删除结点，时间复杂度为O(n)（不算查找时间为O(1)）。<br>注：对于单个结点的插入或者删除，单链表比起顺序表并没有优势，但是插入或删除数据越频繁的操作，单链表的效率优势就越明显。</p>\n<h3 id=\"3-3-插入操作\"><a href=\"#3-3-插入操作\" class=\"headerlink\" title=\"3.3 插入操作\"></a>3.3 插入操作</h3><p>（1）思路：<br>a.在首位置(n=1)插入结点：新建待插入结点，待插入结点指向头指针head所指向的内容；头指针head指向待插入结点。<br>b.在n(n&gt;1)位置插入结点：新建待插入结点，将头指针移动到n-1结点位置，待插入结点指向n结点，n-1结点指向待插入结点。<br>（2）代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">InsertNth</span><span class=\"params\">(Node* head, ElementType x, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;   </span><br><span class=\"line\">    <span class=\"comment\">//新建结点</span></span><br><span class=\"line\">    Node* temp1=<span class=\"keyword\">new</span> Node();</span><br><span class=\"line\">    temp1-&gt;data=x;</span><br><span class=\"line\">    temp1-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//在首位置(n=1)插入一个结点</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(n==<span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        temp1-&gt;next=head;  <span class=\"comment\">//head为NULL也行</span></span><br><span class=\"line\">        head=temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//在n(n&gt;1)位置插入结点</span></span><br><span class=\"line\">    Node* temp2=head;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-2</span>; i++)</span><br><span class=\"line\">    &#123;   </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(temp2==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>; <span class=\"comment\">//位置n有误</span></span><br><span class=\"line\">        temp2=temp2-&gt;next;</span><br><span class=\"line\">    &#125; <span class=\"comment\">//temp2指向第(n-1)个结点</span></span><br><span class=\"line\">    temp1-&gt;next=temp2-&gt;next;</span><br><span class=\"line\">    temp2-&gt;next=temp1;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）<a href=\"https://www.youtube.com/watch?v=IbvsNF22Ud0&amp;index=7&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>a.在首位置(n=1)插入一个结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_1.jpg\" width=\"100%\" height=\"50%\"><br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_2.jpg\" width=\"100%\" height=\"50%\"><br>b.在n(n&gt;1)位置插入结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E4%BB%BB%E6%84%8F%E4%BD%8D%E7%BD%AE%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"></p>\n<h3 id=\"3-4-删除操作\"><a href=\"#3-4-删除操作\" class=\"headerlink\" title=\"3.4 删除操作\"></a>3.4 删除操作</h3><p>（1）思路：调整链表+释放空间<br>a.删除首位置(n=1)结点：头指针指向第2个结点，释放第一个结点空间。<br>b.删除n(n&gt;1)位置结点：将头指针移动到n-1结点位置，n-1结点指向n+1结点。释放n结点空间。<br>（2）代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">DeleteNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head==<span class=\"literal\">NULL</span> || n&lt;=<span class=\"number\">0</span>) </span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node* temp1=head;</span><br><span class=\"line\">    <span class=\"comment\">//删除首位置(n=1)结点</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(n==<span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        head=temp1-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//删除n(n&gt;1)位置结点</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-2</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(temp1==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>; <span class=\"comment\">//位置n有误</span></span><br><span class=\"line\">        temp1=temp1-&gt;next;</span><br><span class=\"line\">    &#125; <span class=\"comment\">//temp1指向第(n-1)个结点</span></span><br><span class=\"line\">    Node *temp2=temp1-&gt;next; </span><br><span class=\"line\">    temp1-&gt;next=temp2-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> temp2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）<a href=\"https://www.youtube.com/watch?v=Y0n86K43GO4&amp;index=8&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>a.删除第(n=1)个结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"><br>b.删除第(n&gt;1)个结点:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%ACn%E5%A4%A7%E4%BA%8E1%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"></p>\n<h3 id=\"3-5-测试代码\"><a href=\"#3-5-测试代码\" class=\"headerlink\" title=\"3.5 测试代码\"></a>3.5 测试代码</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">InsertNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> x, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* temp1 = <span class=\"keyword\">new</span> Node();</span><br><span class=\"line\">    temp1-&gt;data = x;</span><br><span class=\"line\">    temp1-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n == <span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        temp1-&gt;next = head;  <span class=\"comment\">//head为NULL也行</span></span><br><span class=\"line\">        head = temp1; </span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Node* temp2 = head;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n<span class=\"number\">-2</span>;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp2 == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        temp2 = temp2-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    temp1-&gt;next = temp2-&gt;next;</span><br><span class=\"line\">    temp2-&gt;next = temp1;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">DeleteNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head == <span class=\"literal\">NULL</span> || n &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node* temp1 = head;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n == <span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        head =temp1-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">2</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp1 == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        temp1 = temp1-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Node* temp2 = temp1-&gt;next;</span><br><span class=\"line\">    temp1-&gt;next = temp2-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> temp2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Print</span><span class=\"params\">(Node* head)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* temp = head;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (temp != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; temp-&gt;data &lt;&lt; <span class=\"string\">\",\"</span>;</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;\t</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//插入操作</span></span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">6</span>, <span class=\"number\">1</span>);<span class=\"comment\">//6</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">7</span>, <span class=\"number\">2</span>);<span class=\"comment\">//6,7</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">8</span>, <span class=\"number\">3</span>);<span class=\"comment\">//6,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">9</span>, <span class=\"number\">4</span>);<span class=\"comment\">//6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">5</span>, <span class=\"number\">1</span>);<span class=\"comment\">//5,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">0</span>, <span class=\"number\">2</span>);<span class=\"comment\">//5,0,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    <span class=\"comment\">//删除操作</span></span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">1</span>);<span class=\"comment\">//0,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">5</span>);<span class=\"comment\">//0,6,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">2</span>);<span class=\"comment\">//0,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-6-顺序存储结构与单链表对比\"><a href=\"#3-6-顺序存储结构与单链表对比\" class=\"headerlink\" title=\"3.6 顺序存储结构与单链表对比\"></a>3.6 顺序存储结构与单链表对比</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">存储类别</th>\n<th style=\"text-align:center\">顺序存储结构</th>\n<th style=\"text-align:center\">单链表</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">存储分配方式</td>\n<td style=\"text-align:center\">用一段连续的存储单元依次存储线性表的数据元素</td>\n<td style=\"text-align:center\">采用链式存储结构，用一组任意的存储单元存放线性表的元素</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">时间性能</td>\n<td style=\"text-align:center\">查找O(1)、插入和删除O(n)</td>\n<td style=\"text-align:center\">查找、插入和删除O(n）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">空间性能</td>\n<td style=\"text-align:center\">需要预分配存储空间，分大了浪费，小了容易发生上溢</td>\n<td style=\"text-align:center\">不需要分配存储空间，只要有就可以分配，元素个数不受限制</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过对比：</p>\n<ul>\n<li>若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。若需要频繁插入和删除时，宜采用单链表结构（单链表在找出某位置的指针后，插入和删除时间仅为O(1)）。</li>\n<li>当线性表中的元素个数变化较大或者根本不知道有多大时，最好用单链表结构，这样可以不需要考虑存储空间的大小问题。而如果事先知道线性表的大致长度，用顺序存储结构效率会高很多。</li>\n</ul>\n<h2 id=\"四、双向链表\"><a href=\"#四、双向链表\" class=\"headerlink\" title=\"四、双向链表\"></a>四、双向链表</h2><h3 id=\"4-1-双向链表的实现\"><a href=\"#4-1-双向链表的实现\" class=\"headerlink\" title=\"4.1 双向链表的实现\"></a>4.1 双向链表的实现</h3><p>双向链表：在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。<br>双向链表的结点：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 双向链表的结点 */</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">prev</span>;</span>    <span class=\"comment\">/* 直接前驱指针 */</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span>     <span class=\"comment\">/* 直接后继指针 */</span></span><br><span class=\"line\">&#125;Node;</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://www.youtube.com/watch?v=JdQeNxWCguQ&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;index=12\" target=\"_blank\" rel=\"noopener\">示例</a>：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8F%8C%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"90%\" height=\"50%\"></p>\n<h3 id=\"4-2-实现（待）\"><a href=\"#4-2-实现（待）\" class=\"headerlink\" title=\"4.2 实现（待）\"></a>4.2 实现（待）</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* Doubly Linked List implementation */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>  &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">prev</span>;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">head</span>;</span> <span class=\"comment\">// global variable - pointer to head node.</span></span><br><span class=\"line\"><span class=\"comment\">//Creates a new Node and returns pointer to it. </span></span><br><span class=\"line\"><span class=\"function\">struct Node* <span class=\"title\">GetNewNode</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span></span></span><br><span class=\"line\"><span class=\"class\">        = (<span class=\"title\">struct</span> <span class=\"title\">Node</span>*)<span class=\"title\">malloc</span>(<span class=\"title\">sizeof</span>(<span class=\"title\">struct</span> <span class=\"title\">Node</span>));</span></span><br><span class=\"line\">    newNode-&gt;data = x;</span><br><span class=\"line\">    newNode-&gt;prev = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    newNode-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> newNode;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Inserts a Node at head of doubly linked list</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InsertAtHead</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span> = <span class=\"title\">GetNewNode</span>(<span class=\"title\">x</span>);</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head = newNode;</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    head-&gt;prev = newNode;</span><br><span class=\"line\">    newNode-&gt;next = head; </span><br><span class=\"line\">    head = newNode;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Inserts a Node at tail of Doubly linked list</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InsertAtTail</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span> = <span class=\"title\">GetNewNode</span>(<span class=\"title\">x</span>);</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head = newNode;</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp-&gt;next != <span class=\"literal\">NULL</span>) temp = temp-&gt;next; <span class=\"comment\">// Go To last Node</span></span><br><span class=\"line\">    temp-&gt;next = newNode;</span><br><span class=\"line\">    newNode-&gt;prev = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Prints all the elements in linked list in forward traversal order</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Print</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Forward: \"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>,temp-&gt;data);</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Prints all elements in linked list in reverse traversal order. </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReversePrint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(temp == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span>; <span class=\"comment\">// empty list, exit</span></span><br><span class=\"line\">    <span class=\"comment\">// Going to last Node</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp-&gt;next != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Traversing backward using prev pointer</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Reverse: \"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>,temp-&gt;data);</span><br><span class=\"line\">        temp = temp-&gt;prev;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*Driver code to test the implementation*/</span></span><br><span class=\"line\">    Node* head = <span class=\"literal\">NULL</span>; <span class=\"comment\">// empty list. set head as NULL. </span></span><br><span class=\"line\">    <span class=\"comment\">// Calling an Insert and printing list both in forward as well as reverse direction. </span></span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">2</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">4</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtHead(<span class=\"number\">6</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">8</span>); Print(); ReversePrint();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"五、循环链表\"><a href=\"#五、循环链表\" class=\"headerlink\" title=\"五、循环链表\"></a>五、循环链表</h2><p>循环链表：将单链表中终端结点的指针端由空指针改成指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表。</p>\n<h2 id=\"六、参考\"><a href=\"#六、参考\" class=\"headerlink\" title=\"六、参考\"></a>六、参考</h2><p>1.<a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a><br>2.<a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a><br>3.<a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"一、线性表的概念\"><a href=\"#一、线性表的概念\" class=\"headerlink\" title=\"一、线性表的概念\"></a>一、线性表的概念</h2><p>线性表：零个或者多个具有相同类型的数据元素组成的有限序列。<br>线性表的抽象数据类型：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 线性表(List)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    线性表的数据对象集合为&#123;a1,a2,...,an&#125;，每个元素的类型均为DataType</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    ListInit(*L):          初始化操作，建立一个空的线性表L。</span><br><span class=\"line\">    ListEmpty(L):          若线性表为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    ListInsert(*L,i,e):    在L的第i个位置插入新元素e。</span><br><span class=\"line\">    ListDelete(*L,i,*e):   删除L中的第i个元素，并用e返回其值。</span><br><span class=\"line\">    ListLength(L):         返回L中的元素个数</span><br><span class=\"line\">    GetElem(L, i, *e):     将线性表L中的第i个位置元素值返回给e。</span><br><span class=\"line\">    ListClear(*L):         将线性表清空。</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"二、顺序存储结构——顺序表\"><a href=\"#二、顺序存储结构——顺序表\" class=\"headerlink\" title=\"二、顺序存储结构——顺序表\"></a>二、顺序存储结构——顺序表</h2><p>顺序存储结构:用一段地址连续的存储单元依次存储线性表的数据元素。  </p>\n<h3 id=\"2-1-顺序表的实现\"><a href=\"#2-1-顺序表的实现\" class=\"headerlink\" title=\"2.1 顺序表的实现\"></a>2.1 顺序表的实现</h3><p>实现：C语言的一维数组可以实现线性表的顺序存储结构。<br>（1）线性表的下标从1开始，数组的下标从0开始；<br>（2）在任意时刻，线性表的长度应该小于等于数组的长度。<br>示例：<br><img src=\"http://7xjzhz.com1.z0.glb.clouddn.com/3-4-3.jpg\" width=\"90%\" height=\"50%\"><br>","more":"</p>\n<h3 id=\"2-2-常见操作\"><a href=\"#2-2-常见操作\" class=\"headerlink\" title=\"2.2 常见操作\"></a>2.2 常见操作</h3><p>（1）查找：依照数组下标进行读/写，时间复杂度O(1)；<br>（2）插入：插入位置之后的元素依次往后移动一个位置，时间复杂度为O(n)；<br>（3）删除：删除位置之后的元素依次往前移动一个位置，时间复杂度为O(n)。</p>\n<h2 id=\"三、链式存储结构——单链表\"><a href=\"#三、链式存储结构——单链表\" class=\"headerlink\" title=\"三、链式存储结构——单链表\"></a>三、链式存储结构——单链表</h2><p>线性表的链式存储结构的是用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。</p>\n<h3 id=\"3-1-单链表的实现\"><a href=\"#3-1-单链表的实现\" class=\"headerlink\" title=\"3.1 单链表的实现\"></a>3.1 单链表的实现</h3><p>（1）链表的每个结点包含一个数据域跟一个指针域，指针域存放后继结点的存储位置；<br>（2）头指针：链表中第一个结点的存储位置；<br>（3）头结点：单链表的第一个结点前的附设结点，数据域存储链表相关信息，比如长度，指针域存储指向下一个结点的指针。<br>注：头指针是必须的，头结点不是必须的。<br>单链表结点:<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 线性表的单链表存储结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;Node;</span><br></pre></td></tr></table></figure></p>\n<p>单链表示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8D%95%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"80%\" height=\"30%\"></p>\n<h3 id=\"3-2-常见操作\"><a href=\"#3-2-常见操作\" class=\"headerlink\" title=\"3.2 常见操作\"></a>3.2 常见操作</h3><p>（1）查找：从头指针开始，指针后移直至第i个结点为止，时间复杂度为O(n)；<br>（2）插入：遍历查找第i个结点，修改指针域，插入结点，时间复杂度为O(n)（不算查找时间为O(1)）；<br>（3）删除：遍历查找第i个结点，修改指针域，删除结点，时间复杂度为O(n)（不算查找时间为O(1)）。<br>注：对于单个结点的插入或者删除，单链表比起顺序表并没有优势，但是插入或删除数据越频繁的操作，单链表的效率优势就越明显。</p>\n<h3 id=\"3-3-插入操作\"><a href=\"#3-3-插入操作\" class=\"headerlink\" title=\"3.3 插入操作\"></a>3.3 插入操作</h3><p>（1）思路：<br>a.在首位置(n=1)插入结点：新建待插入结点，待插入结点指向头指针head所指向的内容；头指针head指向待插入结点。<br>b.在n(n&gt;1)位置插入结点：新建待插入结点，将头指针移动到n-1结点位置，待插入结点指向n结点，n-1结点指向待插入结点。<br>（2）代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">InsertNth</span><span class=\"params\">(Node* head, ElementType x, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;   </span><br><span class=\"line\">    <span class=\"comment\">//新建结点</span></span><br><span class=\"line\">    Node* temp1=<span class=\"keyword\">new</span> Node();</span><br><span class=\"line\">    temp1-&gt;data=x;</span><br><span class=\"line\">    temp1-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//在首位置(n=1)插入一个结点</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(n==<span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        temp1-&gt;next=head;  <span class=\"comment\">//head为NULL也行</span></span><br><span class=\"line\">        head=temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//在n(n&gt;1)位置插入结点</span></span><br><span class=\"line\">    Node* temp2=head;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-2</span>; i++)</span><br><span class=\"line\">    &#123;   </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(temp2==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>; <span class=\"comment\">//位置n有误</span></span><br><span class=\"line\">        temp2=temp2-&gt;next;</span><br><span class=\"line\">    &#125; <span class=\"comment\">//temp2指向第(n-1)个结点</span></span><br><span class=\"line\">    temp1-&gt;next=temp2-&gt;next;</span><br><span class=\"line\">    temp2-&gt;next=temp1;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）<a href=\"https://www.youtube.com/watch?v=IbvsNF22Ud0&amp;index=7&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>a.在首位置(n=1)插入一个结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_1.jpg\" width=\"100%\" height=\"50%\"><br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E5%A4%B4%E9%83%A8%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9_2.jpg\" width=\"100%\" height=\"50%\"><br>b.在n(n&gt;1)位置插入结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%9C%A8%E9%93%BE%E8%A1%A8%E4%BB%BB%E6%84%8F%E4%BD%8D%E7%BD%AE%E6%8F%92%E5%85%A5%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"></p>\n<h3 id=\"3-4-删除操作\"><a href=\"#3-4-删除操作\" class=\"headerlink\" title=\"3.4 删除操作\"></a>3.4 删除操作</h3><p>（1）思路：调整链表+释放空间<br>a.删除首位置(n=1)结点：头指针指向第2个结点，释放第一个结点空间。<br>b.删除n(n&gt;1)位置结点：将头指针移动到n-1结点位置，n-1结点指向n+1结点。释放n结点空间。<br>（2）代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">DeleteNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head==<span class=\"literal\">NULL</span> || n&lt;=<span class=\"number\">0</span>) </span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node* temp1=head;</span><br><span class=\"line\">    <span class=\"comment\">//删除首位置(n=1)结点</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(n==<span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        head=temp1-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//删除n(n&gt;1)位置结点</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; i&lt;n<span class=\"number\">-2</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(temp1==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>; <span class=\"comment\">//位置n有误</span></span><br><span class=\"line\">        temp1=temp1-&gt;next;</span><br><span class=\"line\">    &#125; <span class=\"comment\">//temp1指向第(n-1)个结点</span></span><br><span class=\"line\">    Node *temp2=temp1-&gt;next; </span><br><span class=\"line\">    temp1-&gt;next=temp2-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> temp2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）<a href=\"https://www.youtube.com/watch?v=Y0n86K43GO4&amp;index=8&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>a.删除第(n=1)个结点：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"><br>b.删除第(n&gt;1)个结点:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%88%A0%E9%99%A4%E7%AC%ACn%E5%A4%A7%E4%BA%8E1%E4%B8%AA%E7%BB%93%E7%82%B9.jpg\" width=\"100%\" height=\"50%\"></p>\n<h3 id=\"3-5-测试代码\"><a href=\"#3-5-测试代码\" class=\"headerlink\" title=\"3.5 测试代码\"></a>3.5 测试代码</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">InsertNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> x, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* temp1 = <span class=\"keyword\">new</span> Node();</span><br><span class=\"line\">    temp1-&gt;data = x;</span><br><span class=\"line\">    temp1-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n == <span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        temp1-&gt;next = head;  <span class=\"comment\">//head为NULL也行</span></span><br><span class=\"line\">        head = temp1; </span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Node* temp2 = head;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n<span class=\"number\">-2</span>;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp2 == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        temp2 = temp2-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    temp1-&gt;next = temp2-&gt;next;</span><br><span class=\"line\">    temp2-&gt;next = temp1;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">DeleteNth</span><span class=\"params\">(Node* head, <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (head == <span class=\"literal\">NULL</span> || n &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    Node* temp1 = head;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n == <span class=\"number\">1</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        head =temp1-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp1;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">2</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp1 == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        temp1 = temp1-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    Node* temp2 = temp1-&gt;next;</span><br><span class=\"line\">    temp1-&gt;next = temp2-&gt;next;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span> temp2;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Print</span><span class=\"params\">(Node* head)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* temp = head;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (temp != <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; temp-&gt;data &lt;&lt; <span class=\"string\">\",\"</span>;</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;\t</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    Node* head = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"comment\">//插入操作</span></span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">6</span>, <span class=\"number\">1</span>);<span class=\"comment\">//6</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">7</span>, <span class=\"number\">2</span>);<span class=\"comment\">//6,7</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">8</span>, <span class=\"number\">3</span>);<span class=\"comment\">//6,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">9</span>, <span class=\"number\">4</span>);<span class=\"comment\">//6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">5</span>, <span class=\"number\">1</span>);<span class=\"comment\">//5,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=InsertNth(head, <span class=\"number\">0</span>, <span class=\"number\">2</span>);<span class=\"comment\">//5,0,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    <span class=\"comment\">//删除操作</span></span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">1</span>);<span class=\"comment\">//0,6,7,8,9</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">5</span>);<span class=\"comment\">//0,6,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    head=DeleteNth(head, <span class=\"number\">2</span>);<span class=\"comment\">//0,7,8</span></span><br><span class=\"line\">    Print(head);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-6-顺序存储结构与单链表对比\"><a href=\"#3-6-顺序存储结构与单链表对比\" class=\"headerlink\" title=\"3.6 顺序存储结构与单链表对比\"></a>3.6 顺序存储结构与单链表对比</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">存储类别</th>\n<th style=\"text-align:center\">顺序存储结构</th>\n<th style=\"text-align:center\">单链表</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">存储分配方式</td>\n<td style=\"text-align:center\">用一段连续的存储单元依次存储线性表的数据元素</td>\n<td style=\"text-align:center\">采用链式存储结构，用一组任意的存储单元存放线性表的元素</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">时间性能</td>\n<td style=\"text-align:center\">查找O(1)、插入和删除O(n)</td>\n<td style=\"text-align:center\">查找、插入和删除O(n）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">空间性能</td>\n<td style=\"text-align:center\">需要预分配存储空间，分大了浪费，小了容易发生上溢</td>\n<td style=\"text-align:center\">不需要分配存储空间，只要有就可以分配，元素个数不受限制</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过对比：</p>\n<ul>\n<li>若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。若需要频繁插入和删除时，宜采用单链表结构（单链表在找出某位置的指针后，插入和删除时间仅为O(1)）。</li>\n<li>当线性表中的元素个数变化较大或者根本不知道有多大时，最好用单链表结构，这样可以不需要考虑存储空间的大小问题。而如果事先知道线性表的大致长度，用顺序存储结构效率会高很多。</li>\n</ul>\n<h2 id=\"四、双向链表\"><a href=\"#四、双向链表\" class=\"headerlink\" title=\"四、双向链表\"></a>四、双向链表</h2><h3 id=\"4-1-双向链表的实现\"><a href=\"#4-1-双向链表的实现\" class=\"headerlink\" title=\"4.1 双向链表的实现\"></a>4.1 双向链表的实现</h3><p>双向链表：在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。<br>双向链表的结点：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 双向链表的结点 */</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">prev</span>;</span>    <span class=\"comment\">/* 直接前驱指针 */</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span>     <span class=\"comment\">/* 直接后继指针 */</span></span><br><span class=\"line\">&#125;Node;</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://www.youtube.com/watch?v=JdQeNxWCguQ&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;index=12\" target=\"_blank\" rel=\"noopener\">示例</a>：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%93%BE%E8%A1%A8/%E5%8F%8C%E9%93%BE%E8%A1%A8%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"90%\" height=\"50%\"></p>\n<h3 id=\"4-2-实现（待）\"><a href=\"#4-2-实现（待）\" class=\"headerlink\" title=\"4.2 实现（待）\"></a>4.2 实现（待）</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* Doubly Linked List implementation */</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>  &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">next</span>;</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">prev</span>;</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">head</span>;</span> <span class=\"comment\">// global variable - pointer to head node.</span></span><br><span class=\"line\"><span class=\"comment\">//Creates a new Node and returns pointer to it. </span></span><br><span class=\"line\"><span class=\"function\">struct Node* <span class=\"title\">GetNewNode</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span></span></span><br><span class=\"line\"><span class=\"class\">        = (<span class=\"title\">struct</span> <span class=\"title\">Node</span>*)<span class=\"title\">malloc</span>(<span class=\"title\">sizeof</span>(<span class=\"title\">struct</span> <span class=\"title\">Node</span>));</span></span><br><span class=\"line\">    newNode-&gt;data = x;</span><br><span class=\"line\">    newNode-&gt;prev = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    newNode-&gt;next = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> newNode;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Inserts a Node at head of doubly linked list</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InsertAtHead</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span> = <span class=\"title\">GetNewNode</span>(<span class=\"title\">x</span>);</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head = newNode;</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    head-&gt;prev = newNode;</span><br><span class=\"line\">    newNode-&gt;next = head; </span><br><span class=\"line\">    head = newNode;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Inserts a Node at tail of Doubly linked list</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InsertAtTail</span><span class=\"params\">(<span class=\"keyword\">int</span> x)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">newNode</span> = <span class=\"title\">GetNewNode</span>(<span class=\"title\">x</span>);</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(head == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        head = newNode;</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp-&gt;next != <span class=\"literal\">NULL</span>) temp = temp-&gt;next; <span class=\"comment\">// Go To last Node</span></span><br><span class=\"line\">    temp-&gt;next = newNode;</span><br><span class=\"line\">    newNode-&gt;prev = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Prints all the elements in linked list in forward traversal order</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Print</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Forward: \"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>,temp-&gt;data);</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//Prints all elements in linked list in reverse traversal order. </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReversePrint</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span>* <span class=\"title\">temp</span> = <span class=\"title\">head</span>;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span>(temp == <span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span>; <span class=\"comment\">// empty list, exit</span></span><br><span class=\"line\">    <span class=\"comment\">// Going to last Node</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp-&gt;next != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        temp = temp-&gt;next;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Traversing backward using prev pointer</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Reverse: \"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(temp != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>,temp-&gt;data);</span><br><span class=\"line\">        temp = temp-&gt;prev;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*Driver code to test the implementation*/</span></span><br><span class=\"line\">    Node* head = <span class=\"literal\">NULL</span>; <span class=\"comment\">// empty list. set head as NULL. </span></span><br><span class=\"line\">    <span class=\"comment\">// Calling an Insert and printing list both in forward as well as reverse direction. </span></span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">2</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">4</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtHead(<span class=\"number\">6</span>); Print(); ReversePrint();</span><br><span class=\"line\">    InsertAtTail(<span class=\"number\">8</span>); Print(); ReversePrint();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"五、循环链表\"><a href=\"#五、循环链表\" class=\"headerlink\" title=\"五、循环链表\"></a>五、循环链表</h2><p>循环链表：将单链表中终端结点的指针端由空指针改成指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表。</p>\n<h2 id=\"六、参考\"><a href=\"#六、参考\" class=\"headerlink\" title=\"六、参考\"></a>六、参考</h2><p>1.<a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a><br>2.<a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a><br>3.<a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></p>"},{"title":"逻辑回归模型","date":"2017-12-04T08:35:50.000Z","mathjax":true,"top":true,"_content":"逻辑回归(logistic regression)属于监督学习中的分类(classification)模型，模型输出为离散值。\n\n## 1.模型\n### 1.1 sigmoid函数\n在介绍逻辑回归模型之前，先引入sigmoid函数，其数学形式是：\n$$g(x) = \\frac{1}{1 + e ^ {-x}}$$\n对应的函数曲线如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/sigmoid.png\" width=\"30%\" height=\"30%\">\nsigmoid函数是一个S形的曲线，它的取值在[0, 1]之间，在远离0的地方函数的值会很快接近0/1（这个性质使我们能够以概率的方式来解释）。\n<!-- more --> \n### 1.2 决策函数\n**假设函数**：\n$$h_\\theta(x)= P(y=1|x;\\theta)=g(\\theta^T x) = \\frac{1}{1 + e ^ {-\\theta^T x}}$$\n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,...,\\theta_n]^T\\in R^{n+1}$\n\n<!-- more --> \n**假设函数解释**：$h_\\theta(x)=P(y=1|x;\\theta)$，即**$h_\\theta(x)$意为在给定输入为$x$，参数为$\\theta$的条件下，$y=1$的概率**。此外，$P(y=0|x;\\theta)=1-P(y=1|x;\\theta)$。\n**相应的决策函数为**：\n$$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5$$\n一般选0.5作为为阈值，实际应用时特定的情况可以选择不同阈值，例如对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。\n\n### 1.3 代价函数\n对于训练集：$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}$，其中$y^{(i)}\\in \\{ 0,1 \\} $\n（1）最大似然估计\n模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：\n$$L(\\theta) = P(D|\\theta) = \\prod_{i=1}^m P(y^{(i)}|x^{(i)};\\theta) = \\prod_{i=1}^m g(\\theta^T x^{(i)}) ^ {y^{(i)}} (1-g(\\theta^T x^{(i)}))^{1-y{(i)}}$$\n取对数可以得到对数似然度：\n$$l(\\theta) = logL(\\theta)=\\sum_{i=1}^m {y^{(i)}\\log{g(\\theta^T x^{(i)})} + (1-y^{(i)})\\log{(1-g(\\theta^T x^{(i)}))}}$$\n（2）代价函数\n另一方面，在机器学习领域，更经常遇到的是损失函数的概念，其衡量的是模型预测错误的程度。常用的损失函数有0-1损失，log损失，hinge损失等。其中log损失在单个数据点上的定义为：\n$$-y\\log{h_\\theta(x)}-(1-y)\\log{(1-h_\\theta(x))}$$\n如果取整个数据集上的平均log损失，我们可以得到：\n$$J(\\theta) = -\\frac{1}{m} l(\\theta)=-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}$$\n即在逻辑回归模型中，我们最大化似然函数和最小化log损失函数实际上是等价的。\n### 1.4 参数求解\n对于该优化问题，常用的凸优化的方法都可以用于求解该问题，例如梯度下降，共轭梯度下降，BFGS，LBFGS等，这里以梯度下降的为例说明。\n逻辑回归的代价函数是凸函数，梯度下降总是收敛到全局最小值。\n梯度下降(Gradient Descent)又叫作最速梯度下降，是一种迭代求解的方法，通过在每一步选取使目标函数变化最快的一个方向调整参数的值来逼近最优值。\n基本步骤如下：\n\n- 选择下降方向（负梯度方向，$\\nabla {J(\\theta)}$)\n- 选择步长$\\alpha$，更新参数 $\\theta^i = \\theta^{i-1} - \\alpha^i \\nabla {J(\\theta^{i-1})}$\n- 重复以上两步直到满足终止条件\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/gradient_descent.png\" width=\"30%\" height=\"30%\">\n其中代价的梯度计算方法为：\n$$\\frac{\\partial{}}{\\partial{\\theta_j}}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m (y^{(i)}-h_\\theta (x^{(i)}) )x^{(i)}_j $$\n计算过程：\n先看如何对sigmoid函数求导：\n\n$$\n\\begin{align*}\n\\sigma(x)'&=&\\left(\\frac{1}{1+e^{-x}}\\right)'=\\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}\\\\\n&=&\\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\\frac{e^{-x}}{(1+e^{-x})^2}\\\\&=&\\left(\\frac{1}{1+e^{-x}}\\right)\\left(\\frac{e^{-x}}{1+e^{-x}}\\right)=\\sigma(x)\\left(\\frac{+1-1 + e^{-x}}{1+e^{-x}}\\right)\\\\&=&\\sigma(x)\\left(\\frac{1 + e^{-x}}{1+e^{-x}} - \\frac{1}{1+e^{-x}}\\right)=\\sigma(x)(1 - \\sigma(x))\n\\end{align*}\n$$\n\n利用上面的结果，借助复合函数求导公式等，可得：\n$$\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_j} J(\\theta) &= \\frac{\\partial}{\\partial \\theta_j} \\frac{-1}{m}\\sum_{i=1}^m \\left [ y^{(i)} log (h_\\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\\theta(x^{(i)})) \\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} \\frac{\\partial}{\\partial \\theta_j} log (h_\\theta(x^{(i)}))   + (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} log (1 - h_\\theta(x^{(i)}))\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - h_\\theta(x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - \\sigma(\\theta^T x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   + \\frac{- (1-y^{(i)}) \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   - \\frac{(1-y^{(i)}) h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\\theta(x^{(i)}) x^{(i)}_j\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) - (1-y^{(i)}) h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} - y^{(i)} h_\\theta(x^{(i)}) - h_\\theta(x^{(i)}) + y^{(i)} h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [ y^{(i)} - h_\\theta(x^{(i)}) \\right ] x^{(i)}_j  \\newline&= \\frac{1}{m}\\sum_{i=1}^m \\left [ h_\\theta(x^{(i)}) - y^{(i)} \\right ] x^{(i)}_j\n\\end{align*} \n$$\n\n### 1.5 决策边界\n进行求解参数后，可得模型的输出结果。决策函数为$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5$，可从sigmoid函数看出，当$\\theta^T x > 0$时，$y=1$，否则 $y=0$。$\\theta^T x = 0$ 是模型隐含的分类平面（在高维空间中，我们说是超平面），即决策边界。所以说逻辑回归本质上是一个线性模型，但是，这不意味着只有线性可分的数据能通过LR求解，实际上，我们可以通过特征变换的方式把低维空间转换到高维空间，而在低维空间不可分的数据，到高维空间中线性可分的几率会高一些。下面两个图的对比说明了线性分类曲线和非线性分类曲线（通过特征映射）。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%AB%98%E7%BB%B4%E5%BA%A6%E6%95%B0%E6%8D%AE.jpg\" width=\"70%\" height=\"70%\">\n左图是一个线性可分的数据集，右图在原始空间中线性不可分，但是在特征转换$[x_1, x_2] => [x_1, x_2, x_1^2, x_2^2, x_1x_2]$ 后的空间是线性可分的，对应的原始空间中分类边界为一条类椭圆曲线。\n### 1.6 正则化\n当模型的参数过多时，很容易遇到过拟合的问题。这时就需要有一种方法来控制模型的复杂度，典型的做法在优化目标中加入正则项，通过惩罚过大的参数来防止过拟合：\n$$J(\\theta) = -\\frac{1}{m}\\sum {y\\log{g(\\theta^T x)} + (1-y)\\log{(1-g(\\theta^T x))}} + \\lambda \\Vert \\theta \\Vert_p$$\n一般情况下，取$p=1$或$p=2$，分别对应L1，L2正则化，两者的区别可以从下图中看出来，L1正则化（左图）倾向于使参数变为0，因此能产生稀疏解。\nL2正则化：\n$$J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||^2_2$$\nL1正则化：\n$$J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||_1$$\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.jpg\" width=\"70%\" height=\"70%\">\n实际应用时，由于数据的维度可能非常高，L1正则化因为能产生稀疏解，使用的更为广泛一些。\n\n## 2.多分类\n如果$y$不是在[0,1]中取值，而是在$K$个类别中取值，这时问题就变为一个多分类问题。有两种方式可以出处理该类问题：一种是我们对每个类别训练一个二元分类器（One-vs-all），当$K$个类别不是互斥的时候，比如用户会购买哪种品类，这种方法是合适的。如果$K$个类别是互斥的，即 $y=i$ 的时候意味着 $y$ 不能取其他的值，比如用户的年龄段，这种情况下 Softmax 回归更合适一些。\n（1）One-vs-all\n\n- 对每一类别$i$训练一个逻辑回归分类器$h_\\theta^{(i)}(x)$，来预测$y=i$的可能性。\n- 对于一个新的输入，要做出预测，选择$h_\\theta^{(i)}(x)$最大的那个，即$\\max\\limits_ih_\\theta^{(i)}(x)$\n\n（2）[Softmax回归](http://zhanglimin.com/2017/12/04/Softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/)\nSoftmax回归是直接对逻辑回归在多分类的推广，相应的模型也可以叫做多元逻辑回归（Multinomial Logistic Regression）。\n模型通过 softmax 函数来对概率建模，具体形式如下：\n$$P(y=i|x, \\theta) = \\frac{e^{\\theta_i^T x}}{\\sum_j^K{e^{\\theta_j^T x}}}$$\n而决策函数为：$y^* = \\textrm{argmax}_i P(y=i|x,\\theta)$\n对应的损失函数为：\n$$J(\\theta) = -\\frac{1}{m} \\sum_i^m \\sum_j^K {1[y_i=j] \\log{\\frac{e^{\\theta_i^T x}}{\\sum {e^{\\theta_k^T x}}}}}$$\n类似的，也可以通过梯度下降或其他高阶方法来求解该问题，这里不再赘述。\n\n注：\n\n- 疑问1：到底什么是交叉熵\n- 疑问2：逻辑回归的损失函数和softmax的损失函数有什么联系，如何推导出这个联系？\n\n## 3.参考资料\n- [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- [林轩田，机器学习基石](https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf)\n- 周志华，机器学习\n- [美团技术点评团队，Logistic Regression 模型简介](https://tech.meituan.com/intro_to_logistic_regression.html)\n- [UFLDL Tutorial, Softmax回归](http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92)\n\n","source":"_posts/逻辑回归模型.md","raw":"---\ntitle: 逻辑回归模型\ndate: 2017-12-4 16:35:50\nmathjax: true\ntop: true\ncategories: \n- 机器学习\ntags:\n- 逻辑回归\n- Logistic Regression\n- sigmoid函数\n- 似然估计\n- 梯度下降\n- 决策边界\n- 正则化\n---\n逻辑回归(logistic regression)属于监督学习中的分类(classification)模型，模型输出为离散值。\n\n## 1.模型\n### 1.1 sigmoid函数\n在介绍逻辑回归模型之前，先引入sigmoid函数，其数学形式是：\n$$g(x) = \\frac{1}{1 + e ^ {-x}}$$\n对应的函数曲线如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/sigmoid.png\" width=\"30%\" height=\"30%\">\nsigmoid函数是一个S形的曲线，它的取值在[0, 1]之间，在远离0的地方函数的值会很快接近0/1（这个性质使我们能够以概率的方式来解释）。\n<!-- more --> \n### 1.2 决策函数\n**假设函数**：\n$$h_\\theta(x)= P(y=1|x;\\theta)=g(\\theta^T x) = \\frac{1}{1 + e ^ {-\\theta^T x}}$$\n其中，$x=[x_0,x_1,...,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,...,\\theta_n]^T\\in R^{n+1}$\n\n<!-- more --> \n**假设函数解释**：$h_\\theta(x)=P(y=1|x;\\theta)$，即**$h_\\theta(x)$意为在给定输入为$x$，参数为$\\theta$的条件下，$y=1$的概率**。此外，$P(y=0|x;\\theta)=1-P(y=1|x;\\theta)$。\n**相应的决策函数为**：\n$$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5$$\n一般选0.5作为为阈值，实际应用时特定的情况可以选择不同阈值，例如对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。\n\n### 1.3 代价函数\n对于训练集：$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}$，其中$y^{(i)}\\in \\{ 0,1 \\} $\n（1）最大似然估计\n模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：\n$$L(\\theta) = P(D|\\theta) = \\prod_{i=1}^m P(y^{(i)}|x^{(i)};\\theta) = \\prod_{i=1}^m g(\\theta^T x^{(i)}) ^ {y^{(i)}} (1-g(\\theta^T x^{(i)}))^{1-y{(i)}}$$\n取对数可以得到对数似然度：\n$$l(\\theta) = logL(\\theta)=\\sum_{i=1}^m {y^{(i)}\\log{g(\\theta^T x^{(i)})} + (1-y^{(i)})\\log{(1-g(\\theta^T x^{(i)}))}}$$\n（2）代价函数\n另一方面，在机器学习领域，更经常遇到的是损失函数的概念，其衡量的是模型预测错误的程度。常用的损失函数有0-1损失，log损失，hinge损失等。其中log损失在单个数据点上的定义为：\n$$-y\\log{h_\\theta(x)}-(1-y)\\log{(1-h_\\theta(x))}$$\n如果取整个数据集上的平均log损失，我们可以得到：\n$$J(\\theta) = -\\frac{1}{m} l(\\theta)=-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}$$\n即在逻辑回归模型中，我们最大化似然函数和最小化log损失函数实际上是等价的。\n### 1.4 参数求解\n对于该优化问题，常用的凸优化的方法都可以用于求解该问题，例如梯度下降，共轭梯度下降，BFGS，LBFGS等，这里以梯度下降的为例说明。\n逻辑回归的代价函数是凸函数，梯度下降总是收敛到全局最小值。\n梯度下降(Gradient Descent)又叫作最速梯度下降，是一种迭代求解的方法，通过在每一步选取使目标函数变化最快的一个方向调整参数的值来逼近最优值。\n基本步骤如下：\n\n- 选择下降方向（负梯度方向，$\\nabla {J(\\theta)}$)\n- 选择步长$\\alpha$，更新参数 $\\theta^i = \\theta^{i-1} - \\alpha^i \\nabla {J(\\theta^{i-1})}$\n- 重复以上两步直到满足终止条件\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/gradient_descent.png\" width=\"30%\" height=\"30%\">\n其中代价的梯度计算方法为：\n$$\\frac{\\partial{}}{\\partial{\\theta_j}}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m (y^{(i)}-h_\\theta (x^{(i)}) )x^{(i)}_j $$\n计算过程：\n先看如何对sigmoid函数求导：\n\n$$\n\\begin{align*}\n\\sigma(x)'&=&\\left(\\frac{1}{1+e^{-x}}\\right)'=\\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}\\\\\n&=&\\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\\frac{e^{-x}}{(1+e^{-x})^2}\\\\&=&\\left(\\frac{1}{1+e^{-x}}\\right)\\left(\\frac{e^{-x}}{1+e^{-x}}\\right)=\\sigma(x)\\left(\\frac{+1-1 + e^{-x}}{1+e^{-x}}\\right)\\\\&=&\\sigma(x)\\left(\\frac{1 + e^{-x}}{1+e^{-x}} - \\frac{1}{1+e^{-x}}\\right)=\\sigma(x)(1 - \\sigma(x))\n\\end{align*}\n$$\n\n利用上面的结果，借助复合函数求导公式等，可得：\n$$\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_j} J(\\theta) &= \\frac{\\partial}{\\partial \\theta_j} \\frac{-1}{m}\\sum_{i=1}^m \\left [ y^{(i)} log (h_\\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\\theta(x^{(i)})) \\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} \\frac{\\partial}{\\partial \\theta_j} log (h_\\theta(x^{(i)}))   + (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} log (1 - h_\\theta(x^{(i)}))\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - h_\\theta(x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - \\sigma(\\theta^T x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   + \\frac{- (1-y^{(i)}) \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   - \\frac{(1-y^{(i)}) h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\\theta(x^{(i)}) x^{(i)}_j\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) - (1-y^{(i)}) h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} - y^{(i)} h_\\theta(x^{(i)}) - h_\\theta(x^{(i)}) + y^{(i)} h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [ y^{(i)} - h_\\theta(x^{(i)}) \\right ] x^{(i)}_j  \\newline&= \\frac{1}{m}\\sum_{i=1}^m \\left [ h_\\theta(x^{(i)}) - y^{(i)} \\right ] x^{(i)}_j\n\\end{align*} \n$$\n\n### 1.5 决策边界\n进行求解参数后，可得模型的输出结果。决策函数为$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5$，可从sigmoid函数看出，当$\\theta^T x > 0$时，$y=1$，否则 $y=0$。$\\theta^T x = 0$ 是模型隐含的分类平面（在高维空间中，我们说是超平面），即决策边界。所以说逻辑回归本质上是一个线性模型，但是，这不意味着只有线性可分的数据能通过LR求解，实际上，我们可以通过特征变换的方式把低维空间转换到高维空间，而在低维空间不可分的数据，到高维空间中线性可分的几率会高一些。下面两个图的对比说明了线性分类曲线和非线性分类曲线（通过特征映射）。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%AB%98%E7%BB%B4%E5%BA%A6%E6%95%B0%E6%8D%AE.jpg\" width=\"70%\" height=\"70%\">\n左图是一个线性可分的数据集，右图在原始空间中线性不可分，但是在特征转换$[x_1, x_2] => [x_1, x_2, x_1^2, x_2^2, x_1x_2]$ 后的空间是线性可分的，对应的原始空间中分类边界为一条类椭圆曲线。\n### 1.6 正则化\n当模型的参数过多时，很容易遇到过拟合的问题。这时就需要有一种方法来控制模型的复杂度，典型的做法在优化目标中加入正则项，通过惩罚过大的参数来防止过拟合：\n$$J(\\theta) = -\\frac{1}{m}\\sum {y\\log{g(\\theta^T x)} + (1-y)\\log{(1-g(\\theta^T x))}} + \\lambda \\Vert \\theta \\Vert_p$$\n一般情况下，取$p=1$或$p=2$，分别对应L1，L2正则化，两者的区别可以从下图中看出来，L1正则化（左图）倾向于使参数变为0，因此能产生稀疏解。\nL2正则化：\n$$J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||^2_2$$\nL1正则化：\n$$J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||_1$$\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.jpg\" width=\"70%\" height=\"70%\">\n实际应用时，由于数据的维度可能非常高，L1正则化因为能产生稀疏解，使用的更为广泛一些。\n\n## 2.多分类\n如果$y$不是在[0,1]中取值，而是在$K$个类别中取值，这时问题就变为一个多分类问题。有两种方式可以出处理该类问题：一种是我们对每个类别训练一个二元分类器（One-vs-all），当$K$个类别不是互斥的时候，比如用户会购买哪种品类，这种方法是合适的。如果$K$个类别是互斥的，即 $y=i$ 的时候意味着 $y$ 不能取其他的值，比如用户的年龄段，这种情况下 Softmax 回归更合适一些。\n（1）One-vs-all\n\n- 对每一类别$i$训练一个逻辑回归分类器$h_\\theta^{(i)}(x)$，来预测$y=i$的可能性。\n- 对于一个新的输入，要做出预测，选择$h_\\theta^{(i)}(x)$最大的那个，即$\\max\\limits_ih_\\theta^{(i)}(x)$\n\n（2）[Softmax回归](http://zhanglimin.com/2017/12/04/Softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/)\nSoftmax回归是直接对逻辑回归在多分类的推广，相应的模型也可以叫做多元逻辑回归（Multinomial Logistic Regression）。\n模型通过 softmax 函数来对概率建模，具体形式如下：\n$$P(y=i|x, \\theta) = \\frac{e^{\\theta_i^T x}}{\\sum_j^K{e^{\\theta_j^T x}}}$$\n而决策函数为：$y^* = \\textrm{argmax}_i P(y=i|x,\\theta)$\n对应的损失函数为：\n$$J(\\theta) = -\\frac{1}{m} \\sum_i^m \\sum_j^K {1[y_i=j] \\log{\\frac{e^{\\theta_i^T x}}{\\sum {e^{\\theta_k^T x}}}}}$$\n类似的，也可以通过梯度下降或其他高阶方法来求解该问题，这里不再赘述。\n\n注：\n\n- 疑问1：到底什么是交叉熵\n- 疑问2：逻辑回归的损失函数和softmax的损失函数有什么联系，如何推导出这个联系？\n\n## 3.参考资料\n- [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- [林轩田，机器学习基石](https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf)\n- 周志华，机器学习\n- [美团技术点评团队，Logistic Regression 模型简介](https://tech.meituan.com/intro_to_logistic_regression.html)\n- [UFLDL Tutorial, Softmax回归](http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92)\n\n","slug":"逻辑回归模型","published":1,"updated":"2018-11-19T10:02:17.172Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w0a002uqslpuxvgdp7p","content":"<p>逻辑回归(logistic regression)属于监督学习中的分类(classification)模型，模型输出为离散值。</p>\n<h2 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h2><h3 id=\"1-1-sigmoid函数\"><a href=\"#1-1-sigmoid函数\" class=\"headerlink\" title=\"1.1 sigmoid函数\"></a>1.1 sigmoid函数</h3><p>在介绍逻辑回归模型之前，先引入sigmoid函数，其数学形式是：</p>\n<script type=\"math/tex; mode=display\">g(x) = \\frac{1}{1 + e ^ {-x}}</script><p>对应的函数曲线如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/sigmoid.png\" width=\"30%\" height=\"30%\"><br>sigmoid函数是一个S形的曲线，它的取值在[0, 1]之间，在远离0的地方函数的值会很快接近0/1（这个性质使我们能够以概率的方式来解释）。<br><a id=\"more\"></a> </p>\n<h3 id=\"1-2-决策函数\"><a href=\"#1-2-决策函数\" class=\"headerlink\" title=\"1.2 决策函数\"></a>1.2 决策函数</h3><p><strong>假设函数</strong>：</p>\n<script type=\"math/tex; mode=display\">h_\\theta(x)= P(y=1|x;\\theta)=g(\\theta^T x) = \\frac{1}{1 + e ^ {-\\theta^T x}}</script><p>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,…,\\theta_n]^T\\in R^{n+1}$</p>\n<!-- more --> \n<p><strong>假设函数解释</strong>：$h_\\theta(x)=P(y=1|x;\\theta)$，即<strong>$h_\\theta(x)$意为在给定输入为$x$，参数为$\\theta$的条件下，$y=1$的概率</strong>。此外，$P(y=0|x;\\theta)=1-P(y=1|x;\\theta)$。<br><strong>相应的决策函数为</strong>：</p>\n<script type=\"math/tex; mode=display\">y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5</script><p>一般选0.5作为为阈值，实际应用时特定的情况可以选择不同阈值，例如对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。</p>\n<h3 id=\"1-3-代价函数\"><a href=\"#1-3-代价函数\" class=\"headerlink\" title=\"1.3 代价函数\"></a>1.3 代价函数</h3><p>对于训练集：$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})\\}$，其中$y^{(i)}\\in \\{ 0,1 \\} $<br>（1）最大似然估计<br>模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：</p>\n<script type=\"math/tex; mode=display\">L(\\theta) = P(D|\\theta) = \\prod_{i=1}^m P(y^{(i)}|x^{(i)};\\theta) = \\prod_{i=1}^m g(\\theta^T x^{(i)}) ^ {y^{(i)}} (1-g(\\theta^T x^{(i)}))^{1-y{(i)}}</script><p>取对数可以得到对数似然度：</p>\n<script type=\"math/tex; mode=display\">l(\\theta) = logL(\\theta)=\\sum_{i=1}^m {y^{(i)}\\log{g(\\theta^T x^{(i)})} + (1-y^{(i)})\\log{(1-g(\\theta^T x^{(i)}))}}</script><p>（2）代价函数<br>另一方面，在机器学习领域，更经常遇到的是损失函数的概念，其衡量的是模型预测错误的程度。常用的损失函数有0-1损失，log损失，hinge损失等。其中log损失在单个数据点上的定义为：</p>\n<script type=\"math/tex; mode=display\">-y\\log{h_\\theta(x)}-(1-y)\\log{(1-h_\\theta(x))}</script><p>如果取整个数据集上的平均log损失，我们可以得到：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m} l(\\theta)=-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}</script><p>即在逻辑回归模型中，我们最大化似然函数和最小化log损失函数实际上是等价的。</p>\n<h3 id=\"1-4-参数求解\"><a href=\"#1-4-参数求解\" class=\"headerlink\" title=\"1.4 参数求解\"></a>1.4 参数求解</h3><p>对于该优化问题，常用的凸优化的方法都可以用于求解该问题，例如梯度下降，共轭梯度下降，BFGS，LBFGS等，这里以梯度下降的为例说明。<br>逻辑回归的代价函数是凸函数，梯度下降总是收敛到全局最小值。<br>梯度下降(Gradient Descent)又叫作最速梯度下降，是一种迭代求解的方法，通过在每一步选取使目标函数变化最快的一个方向调整参数的值来逼近最优值。<br>基本步骤如下：</p>\n<ul>\n<li>选择下降方向（负梯度方向，$\\nabla {J(\\theta)}$)</li>\n<li>选择步长$\\alpha$，更新参数 $\\theta^i = \\theta^{i-1} - \\alpha^i \\nabla {J(\\theta^{i-1})}$</li>\n<li>重复以上两步直到满足终止条件</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/gradient_descent.png\" width=\"30%\" height=\"30%\"><br>其中代价的梯度计算方法为：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial{}}{\\partial{\\theta_j}}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m (y^{(i)}-h_\\theta (x^{(i)}) )x^{(i)}_j</script><p>计算过程：<br>先看如何对sigmoid函数求导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\sigma(x)'&=&\\left(\\frac{1}{1+e^{-x}}\\right)'=\\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}\\\\\n&=&\\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\\frac{e^{-x}}{(1+e^{-x})^2}\\\\&=&\\left(\\frac{1}{1+e^{-x}}\\right)\\left(\\frac{e^{-x}}{1+e^{-x}}\\right)=\\sigma(x)\\left(\\frac{+1-1 + e^{-x}}{1+e^{-x}}\\right)\\\\&=&\\sigma(x)\\left(\\frac{1 + e^{-x}}{1+e^{-x}} - \\frac{1}{1+e^{-x}}\\right)=\\sigma(x)(1 - \\sigma(x))\n\\end{align*}</script><p>利用上面的结果，借助复合函数求导公式等，可得：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_j} J(\\theta) &= \\frac{\\partial}{\\partial \\theta_j} \\frac{-1}{m}\\sum_{i=1}^m \\left [ y^{(i)} log (h_\\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\\theta(x^{(i)})) \\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} \\frac{\\partial}{\\partial \\theta_j} log (h_\\theta(x^{(i)}))   + (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} log (1 - h_\\theta(x^{(i)}))\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - h_\\theta(x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - \\sigma(\\theta^T x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   + \\frac{- (1-y^{(i)}) \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   - \\frac{(1-y^{(i)}) h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\\theta(x^{(i)}) x^{(i)}_j\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) - (1-y^{(i)}) h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} - y^{(i)} h_\\theta(x^{(i)}) - h_\\theta(x^{(i)}) + y^{(i)} h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [ y^{(i)} - h_\\theta(x^{(i)}) \\right ] x^{(i)}_j  \\newline&= \\frac{1}{m}\\sum_{i=1}^m \\left [ h_\\theta(x^{(i)}) - y^{(i)} \\right ] x^{(i)}_j\n\\end{align*}</script><h3 id=\"1-5-决策边界\"><a href=\"#1-5-决策边界\" class=\"headerlink\" title=\"1.5 决策边界\"></a>1.5 决策边界</h3><p>进行求解参数后，可得模型的输出结果。决策函数为$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) &gt; 0.5$，可从sigmoid函数看出，当$\\theta^T x &gt; 0$时，$y=1$，否则 $y=0$。$\\theta^T x = 0$ 是模型隐含的分类平面（在高维空间中，我们说是超平面），即决策边界。所以说逻辑回归本质上是一个线性模型，但是，这不意味着只有线性可分的数据能通过LR求解，实际上，我们可以通过特征变换的方式把低维空间转换到高维空间，而在低维空间不可分的数据，到高维空间中线性可分的几率会高一些。下面两个图的对比说明了线性分类曲线和非线性分类曲线（通过特征映射）。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%AB%98%E7%BB%B4%E5%BA%A6%E6%95%B0%E6%8D%AE.jpg\" width=\"70%\" height=\"70%\"><br>左图是一个线性可分的数据集，右图在原始空间中线性不可分，但是在特征转换$[x_1, x_2] =&gt; [x_1, x_2, x_1^2, x_2^2, x_1x_2]$ 后的空间是线性可分的，对应的原始空间中分类边界为一条类椭圆曲线。</p>\n<h3 id=\"1-6-正则化\"><a href=\"#1-6-正则化\" class=\"headerlink\" title=\"1.6 正则化\"></a>1.6 正则化</h3><p>当模型的参数过多时，很容易遇到过拟合的问题。这时就需要有一种方法来控制模型的复杂度，典型的做法在优化目标中加入正则项，通过惩罚过大的参数来防止过拟合：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m}\\sum {y\\log{g(\\theta^T x)} + (1-y)\\log{(1-g(\\theta^T x))}} + \\lambda \\Vert \\theta \\Vert_p</script><p>一般情况下，取$p=1$或$p=2$，分别对应L1，L2正则化，两者的区别可以从下图中看出来，L1正则化（左图）倾向于使参数变为0，因此能产生稀疏解。<br>L2正则化：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||^2_2</script><p>L1正则化：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||_1</script><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.jpg\" width=\"70%\" height=\"70%\"><br>实际应用时，由于数据的维度可能非常高，L1正则化因为能产生稀疏解，使用的更为广泛一些。</p>\n<h2 id=\"2-多分类\"><a href=\"#2-多分类\" class=\"headerlink\" title=\"2.多分类\"></a>2.多分类</h2><p>如果$y$不是在[0,1]中取值，而是在$K$个类别中取值，这时问题就变为一个多分类问题。有两种方式可以出处理该类问题：一种是我们对每个类别训练一个二元分类器（One-vs-all），当$K$个类别不是互斥的时候，比如用户会购买哪种品类，这种方法是合适的。如果$K$个类别是互斥的，即 $y=i$ 的时候意味着 $y$ 不能取其他的值，比如用户的年龄段，这种情况下 Softmax 回归更合适一些。<br>（1）One-vs-all</p>\n<ul>\n<li>对每一类别$i$训练一个逻辑回归分类器$h_\\theta^{(i)}(x)$，来预测$y=i$的可能性。</li>\n<li>对于一个新的输入，要做出预测，选择$h_\\theta^{(i)}(x)$最大的那个，即$\\max\\limits_ih_\\theta^{(i)}(x)$</li>\n</ul>\n<p>（2）<a href=\"http://zhanglimin.com/2017/12/04/Softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/\" target=\"_blank\" rel=\"noopener\">Softmax回归</a><br>Softmax回归是直接对逻辑回归在多分类的推广，相应的模型也可以叫做多元逻辑回归（Multinomial Logistic Regression）。<br>模型通过 softmax 函数来对概率建模，具体形式如下：</p>\n<script type=\"math/tex; mode=display\">P(y=i|x, \\theta) = \\frac{e^{\\theta_i^T x}}{\\sum_j^K{e^{\\theta_j^T x}}}</script><p>而决策函数为：$y^* = \\textrm{argmax}_i P(y=i|x,\\theta)$<br>对应的损失函数为：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m} \\sum_i^m \\sum_j^K {1[y_i=j] \\log{\\frac{e^{\\theta_i^T x}}{\\sum {e^{\\theta_k^T x}}}}}</script><p>类似的，也可以通过梯度下降或其他高阶方法来求解该问题，这里不再赘述。</p>\n<p>注：</p>\n<ul>\n<li>疑问1：到底什么是交叉熵</li>\n<li>疑问2：逻辑回归的损失函数和softmax的损失函数有什么联系，如何推导出这个联系？</li>\n</ul>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\">Andrew Ng, Machine Learning</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习基石</a></li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://tech.meituan.com/intro_to_logistic_regression.html\" target=\"_blank\" rel=\"noopener\">美团技术点评团队，Logistic Regression 模型简介</a></li>\n<li><a href=\"http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92\" target=\"_blank\" rel=\"noopener\">UFLDL Tutorial, Softmax回归</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>逻辑回归(logistic regression)属于监督学习中的分类(classification)模型，模型输出为离散值。</p>\n<h2 id=\"1-模型\"><a href=\"#1-模型\" class=\"headerlink\" title=\"1.模型\"></a>1.模型</h2><h3 id=\"1-1-sigmoid函数\"><a href=\"#1-1-sigmoid函数\" class=\"headerlink\" title=\"1.1 sigmoid函数\"></a>1.1 sigmoid函数</h3><p>在介绍逻辑回归模型之前，先引入sigmoid函数，其数学形式是：</p>\n<script type=\"math/tex; mode=display\">g(x) = \\frac{1}{1 + e ^ {-x}}</script><p>对应的函数曲线如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/sigmoid.png\" width=\"30%\" height=\"30%\"><br>sigmoid函数是一个S形的曲线，它的取值在[0, 1]之间，在远离0的地方函数的值会很快接近0/1（这个性质使我们能够以概率的方式来解释）。<br>","more":"</p>\n<h3 id=\"1-2-决策函数\"><a href=\"#1-2-决策函数\" class=\"headerlink\" title=\"1.2 决策函数\"></a>1.2 决策函数</h3><p><strong>假设函数</strong>：</p>\n<script type=\"math/tex; mode=display\">h_\\theta(x)= P(y=1|x;\\theta)=g(\\theta^T x) = \\frac{1}{1 + e ^ {-\\theta^T x}}</script><p>其中，$x=[x_0,x_1,…,x_n]^T\\in R^{n+1}$, $x_0^{(i)}=1$(对应偏置项); $\\theta = [\\theta_0,\\theta_1,…,\\theta_n]^T\\in R^{n+1}$</p>\n<!-- more --> \n<p><strong>假设函数解释</strong>：$h_\\theta(x)=P(y=1|x;\\theta)$，即<strong>$h_\\theta(x)$意为在给定输入为$x$，参数为$\\theta$的条件下，$y=1$的概率</strong>。此外，$P(y=0|x;\\theta)=1-P(y=1|x;\\theta)$。<br><strong>相应的决策函数为</strong>：</p>\n<script type=\"math/tex; mode=display\">y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) > 0.5</script><p>一般选0.5作为为阈值，实际应用时特定的情况可以选择不同阈值，例如对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。</p>\n<h3 id=\"1-3-代价函数\"><a href=\"#1-3-代价函数\" class=\"headerlink\" title=\"1.3 代价函数\"></a>1.3 代价函数</h3><p>对于训练集：$\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})\\}$，其中$y^{(i)}\\in \\{ 0,1 \\} $<br>（1）最大似然估计<br>模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，数据的似然度（概率）越大。在逻辑回归模型中，似然度可表示为：</p>\n<script type=\"math/tex; mode=display\">L(\\theta) = P(D|\\theta) = \\prod_{i=1}^m P(y^{(i)}|x^{(i)};\\theta) = \\prod_{i=1}^m g(\\theta^T x^{(i)}) ^ {y^{(i)}} (1-g(\\theta^T x^{(i)}))^{1-y{(i)}}</script><p>取对数可以得到对数似然度：</p>\n<script type=\"math/tex; mode=display\">l(\\theta) = logL(\\theta)=\\sum_{i=1}^m {y^{(i)}\\log{g(\\theta^T x^{(i)})} + (1-y^{(i)})\\log{(1-g(\\theta^T x^{(i)}))}}</script><p>（2）代价函数<br>另一方面，在机器学习领域，更经常遇到的是损失函数的概念，其衡量的是模型预测错误的程度。常用的损失函数有0-1损失，log损失，hinge损失等。其中log损失在单个数据点上的定义为：</p>\n<script type=\"math/tex; mode=display\">-y\\log{h_\\theta(x)}-(1-y)\\log{(1-h_\\theta(x))}</script><p>如果取整个数据集上的平均log损失，我们可以得到：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m} l(\\theta)=-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}</script><p>即在逻辑回归模型中，我们最大化似然函数和最小化log损失函数实际上是等价的。</p>\n<h3 id=\"1-4-参数求解\"><a href=\"#1-4-参数求解\" class=\"headerlink\" title=\"1.4 参数求解\"></a>1.4 参数求解</h3><p>对于该优化问题，常用的凸优化的方法都可以用于求解该问题，例如梯度下降，共轭梯度下降，BFGS，LBFGS等，这里以梯度下降的为例说明。<br>逻辑回归的代价函数是凸函数，梯度下降总是收敛到全局最小值。<br>梯度下降(Gradient Descent)又叫作最速梯度下降，是一种迭代求解的方法，通过在每一步选取使目标函数变化最快的一个方向调整参数的值来逼近最优值。<br>基本步骤如下：</p>\n<ul>\n<li>选择下降方向（负梯度方向，$\\nabla {J(\\theta)}$)</li>\n<li>选择步长$\\alpha$，更新参数 $\\theta^i = \\theta^{i-1} - \\alpha^i \\nabla {J(\\theta^{i-1})}$</li>\n<li>重复以上两步直到满足终止条件</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/gradient_descent.png\" width=\"30%\" height=\"30%\"><br>其中代价的梯度计算方法为：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial{}}{\\partial{\\theta_j}}J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m (y^{(i)}-h_\\theta (x^{(i)}) )x^{(i)}_j</script><p>计算过程：<br>先看如何对sigmoid函数求导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\sigma(x)'&=&\\left(\\frac{1}{1+e^{-x}}\\right)'=\\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}\\\\\n&=&\\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\\frac{e^{-x}}{(1+e^{-x})^2}\\\\&=&\\left(\\frac{1}{1+e^{-x}}\\right)\\left(\\frac{e^{-x}}{1+e^{-x}}\\right)=\\sigma(x)\\left(\\frac{+1-1 + e^{-x}}{1+e^{-x}}\\right)\\\\&=&\\sigma(x)\\left(\\frac{1 + e^{-x}}{1+e^{-x}} - \\frac{1}{1+e^{-x}}\\right)=\\sigma(x)(1 - \\sigma(x))\n\\end{align*}</script><p>利用上面的结果，借助复合函数求导公式等，可得：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_j} J(\\theta) &= \\frac{\\partial}{\\partial \\theta_j} \\frac{-1}{m}\\sum_{i=1}^m \\left [ y^{(i)} log (h_\\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\\theta(x^{(i)})) \\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} \\frac{\\partial}{\\partial \\theta_j} log (h_\\theta(x^{(i)}))   + (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} log (1 - h_\\theta(x^{(i)}))\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - h_\\theta(x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\sigma(\\theta^T x^{(i)})}{h_\\theta(x^{(i)})}   + \\frac{(1-y^{(i)})\\frac{\\partial}{\\partial \\theta_j} (1 - \\sigma(\\theta^T x^{(i)}))}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   + \\frac{- (1-y^{(i)}) \\sigma(\\theta^T x^{(i)}) (1 - \\sigma(\\theta^T x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     \\frac{y^{(i)} h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{h_\\theta(x^{(i)})}   - \\frac{(1-y^{(i)}) h_\\theta(x^{(i)}) (1 - h_\\theta(x^{(i)})) \\frac{\\partial}{\\partial \\theta_j} \\theta^T x^{(i)}}{1 - h_\\theta(x^{(i)})}\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\\theta(x^{(i)}) x^{(i)}_j\\right ] \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} (1 - h_\\theta(x^{(i)})) - (1-y^{(i)}) h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [     y^{(i)} - y^{(i)} h_\\theta(x^{(i)}) - h_\\theta(x^{(i)}) + y^{(i)} h_\\theta(x^{(i)}) \\right ] x^{(i)}_j \\newline&= - \\frac{1}{m}\\sum_{i=1}^m \\left [ y^{(i)} - h_\\theta(x^{(i)}) \\right ] x^{(i)}_j  \\newline&= \\frac{1}{m}\\sum_{i=1}^m \\left [ h_\\theta(x^{(i)}) - y^{(i)} \\right ] x^{(i)}_j\n\\end{align*}</script><h3 id=\"1-5-决策边界\"><a href=\"#1-5-决策边界\" class=\"headerlink\" title=\"1.5 决策边界\"></a>1.5 决策边界</h3><p>进行求解参数后，可得模型的输出结果。决策函数为$y^* = 1, \\, \\textrm{if} \\, \\ h_\\theta(x) &gt; 0.5$，可从sigmoid函数看出，当$\\theta^T x &gt; 0$时，$y=1$，否则 $y=0$。$\\theta^T x = 0$ 是模型隐含的分类平面（在高维空间中，我们说是超平面），即决策边界。所以说逻辑回归本质上是一个线性模型，但是，这不意味着只有线性可分的数据能通过LR求解，实际上，我们可以通过特征变换的方式把低维空间转换到高维空间，而在低维空间不可分的数据，到高维空间中线性可分的几率会高一些。下面两个图的对比说明了线性分类曲线和非线性分类曲线（通过特征映射）。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E9%AB%98%E7%BB%B4%E5%BA%A6%E6%95%B0%E6%8D%AE.jpg\" width=\"70%\" height=\"70%\"><br>左图是一个线性可分的数据集，右图在原始空间中线性不可分，但是在特征转换$[x_1, x_2] =&gt; [x_1, x_2, x_1^2, x_2^2, x_1x_2]$ 后的空间是线性可分的，对应的原始空间中分类边界为一条类椭圆曲线。</p>\n<h3 id=\"1-6-正则化\"><a href=\"#1-6-正则化\" class=\"headerlink\" title=\"1.6 正则化\"></a>1.6 正则化</h3><p>当模型的参数过多时，很容易遇到过拟合的问题。这时就需要有一种方法来控制模型的复杂度，典型的做法在优化目标中加入正则项，通过惩罚过大的参数来防止过拟合：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m}\\sum {y\\log{g(\\theta^T x)} + (1-y)\\log{(1-g(\\theta^T x))}} + \\lambda \\Vert \\theta \\Vert_p</script><p>一般情况下，取$p=1$或$p=2$，分别对应L1，L2正则化，两者的区别可以从下图中看出来，L1正则化（左图）倾向于使参数变为0，因此能产生稀疏解。<br>L2正则化：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||^2_2</script><p>L1正则化：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) =-\\frac{1}{m} \\sum_{i=1}^m {y^{(i)}\\log{h_\\theta(x^{(i)})} + (1-y^{(i)})\\log{(1-h_\\theta(x^{(i)}))}}+\\lambda||\\theta||_1</script><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/%E6%AD%A3%E5%88%99%E5%8C%96.jpg\" width=\"70%\" height=\"70%\"><br>实际应用时，由于数据的维度可能非常高，L1正则化因为能产生稀疏解，使用的更为广泛一些。</p>\n<h2 id=\"2-多分类\"><a href=\"#2-多分类\" class=\"headerlink\" title=\"2.多分类\"></a>2.多分类</h2><p>如果$y$不是在[0,1]中取值，而是在$K$个类别中取值，这时问题就变为一个多分类问题。有两种方式可以出处理该类问题：一种是我们对每个类别训练一个二元分类器（One-vs-all），当$K$个类别不是互斥的时候，比如用户会购买哪种品类，这种方法是合适的。如果$K$个类别是互斥的，即 $y=i$ 的时候意味着 $y$ 不能取其他的值，比如用户的年龄段，这种情况下 Softmax 回归更合适一些。<br>（1）One-vs-all</p>\n<ul>\n<li>对每一类别$i$训练一个逻辑回归分类器$h_\\theta^{(i)}(x)$，来预测$y=i$的可能性。</li>\n<li>对于一个新的输入，要做出预测，选择$h_\\theta^{(i)}(x)$最大的那个，即$\\max\\limits_ih_\\theta^{(i)}(x)$</li>\n</ul>\n<p>（2）<a href=\"http://zhanglimin.com/2017/12/04/Softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/\" target=\"_blank\" rel=\"noopener\">Softmax回归</a><br>Softmax回归是直接对逻辑回归在多分类的推广，相应的模型也可以叫做多元逻辑回归（Multinomial Logistic Regression）。<br>模型通过 softmax 函数来对概率建模，具体形式如下：</p>\n<script type=\"math/tex; mode=display\">P(y=i|x, \\theta) = \\frac{e^{\\theta_i^T x}}{\\sum_j^K{e^{\\theta_j^T x}}}</script><p>而决策函数为：$y^* = \\textrm{argmax}_i P(y=i|x,\\theta)$<br>对应的损失函数为：</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = -\\frac{1}{m} \\sum_i^m \\sum_j^K {1[y_i=j] \\log{\\frac{e^{\\theta_i^T x}}{\\sum {e^{\\theta_k^T x}}}}}</script><p>类似的，也可以通过梯度下降或其他高阶方法来求解该问题，这里不再赘述。</p>\n<p>注：</p>\n<ul>\n<li>疑问1：到底什么是交叉熵</li>\n<li>疑问2：逻辑回归的损失函数和softmax的损失函数有什么联系，如何推导出这个联系？</li>\n</ul>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><ul>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\">Andrew Ng, Machine Learning</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PLXVfgk9fNX2I7tB6oIINGBmW50rrmFTqf\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习基石</a></li>\n<li>周志华，机器学习</li>\n<li><a href=\"https://tech.meituan.com/intro_to_logistic_regression.html\" target=\"_blank\" rel=\"noopener\">美团技术点评团队，Logistic Regression 模型简介</a></li>\n<li><a href=\"http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92\" target=\"_blank\" rel=\"noopener\">UFLDL Tutorial, Softmax回归</a></li>\n</ul>"},{"title":"C/C++中const关键字总结","date":"2017-11-28T08:32:00.000Z","_content":"常类型是指使用类型修饰符`const`说明的类型，常类型的变量或对象的值是不能被更新的。不管出现在任何上下文都是为这个目的而服务的。    \n## 0. 声明方式\n\n - 常变量：`const 类型说明符 变量名`\n 例：`const int a=10;` 等价 `int const a=10;`\n - 常数组：`const 类型说明符 数组名[大小]`。\n 例：`const int arr[3]={1,2,3};` 等价 `int const arr[3]={1,2,3};`\n - 常引用：`const 类型说明符& 引用名`\n 例：`const int& a=x;`等价`int const &a=x;`\n - 指针常量：`const 类型说明符* 指针名`\n 例：`const int* a = &b`等价`int const *a = &b` \n - 常量指针：`类型说明符* const 指针名`\n 例：`int* const a = &b`      \n - 常对象：`const 类名 对象名`\n 例：`const test t;`等价于`test const t;`\n - 常成员函数：类体中：`类型说明符 函数名(形参) const` 类体外：`类型说明符 类名::函数名(形参) const`\n 例：类体中：`int GetCount(void) const;` 类体外：`int Stack::GetCount(void) const;`\n\n注：在常变量、常数组、常引用、常对象中，`const`与`类型说明符`或`类名`（其实类名是一种自定义的类型说明符） 的位置可以互换。\n<!-- more --> \n## 1.const对象\n\n（1）`const`修饰符把对象转变成常量对象，该对象的值不能再被修改，否则致编译错误：\n```C\nconst int bufferSize = 512;\nbufferSize = 0; //Error!\n```\n（2）因为常量对象在定义后就不能被修改，所以定义时必须初始化：\n \n```C\nconst i, j=0; //Error，i未初始化\n```\n \n（3）`const`对象默认为文件的局部变量。\n　　在全局作用域里定义`非const`变量时，它在整个程序中都可以访问，我们可以把一个`非const`变量定义在一个文件中（假设已经做了合适的声明），就可以在另外的文件中使用这个变量：\n\n```C++\n//file_1.cc\nint counter; //definition\n```\n```C++\n//file_2.cc\nextern int counter; //use counter from file_1.h\n++counter; //increments counter defined in file_1.h\n```\n　　在全局作用域声明的`const`变量是定义该对象的文件的局部变量。此变量只存在于那个文件中，不能被其他文件访问。通过指定`const`变量为`extern`，就可以在整个程序中访问`const`对象。\n```C++\n//file_1.cc\nextern const int bugSize = 500;\n```\n```C++\n//file_2.cc\nextern const int bugSize; //use bufSize from file_1.h\nfor(int index=0;index != bufSize;++index){}\n```\n　　综上，`非const`变量默认为`extern`。要使`const`变量能够在其他文件中访问，必须在文件中显式地指定它为`extern`。\n\n-----\n （待，放在类中，单独总结一下类）3.const 修饰类的数据成员\n 对于类中的const成员变量必须通过初始化列表进行初始化，如下所示：\n ![](http://images.cnitblog.com/blog/460416/201310/06213502-292090335e124b14a9a0b5ae9d49f3e0.png)\nconst数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类声明中初始化const数据成员，因为类的对象未被创建时，编译器不知道const 数据成员的值是什么。\n```C++\nclass A{\n const int size = 100;    //错误\n int array[size];         //错误，未知的size\n};\n```\nconst数据成员的初始化只能在类的构造函数的初始化表中进行。\n要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现.如:\n```C++\nclass A{\nenum {size1=100, size2 = 200 };\nint array1[size1];\nint array2[size2];\n};\n```\n枚举常量不会占用对象的存储空间，他们在编译时被全部求值。但是枚举常量的隐含数据类型是整数，其最大值有限，且不能表示浮点数。\n\n---\n\n## 2.const对象的动态数组\n\n如果我们在`自由存储区`中创建的数组存储了内置类型的`const对象`，则必须为这个数组提供初始化。\n\n因为数组元素都是`const对象`，无法赋值。实现这个要求的唯一方法是对数组做值初始化：\n```C++\n//error\nconst int* pci_bad = new const int[100];\n//ok\nconst int* pci_ok = new const int[100]();\n```\nC++允许定义`类类型`的`const数组`，但该`类类型`必须提供`默认构造函数`：\n```C++\nconst string* pcs = new string[100];\n```\n这里便会调用`string类`的`默认构造函数`初始化数组元素。\n\n## 3.const引用\n\n（1）`const引用`是指向`const对象`的引用,将普通的引用绑定到`const对象`是不合法的：\n\n```C++\nconst int iVal = 1024;\nconst int& refVal = iVal;  //两者均为const对象\nint& refVal2=iVal;         //错误！不能使用非const引用指向const对象\n```\n`refVal2`是普通的`非const引用`，因此可以用来修改`refVal2`指向的对象的值,为防止这样的修改，需要规定将普通的引用绑定到`const对象`是不合法的。\n\n（2）`const引用`可以初始化为`不同类型的对象`或者初始化为`右值`。\n\n如字面值常量：\n```C++\nint i = 42;\n//仅对const引用合法\nconst int& r2 = r+i;\nconst int& r = 42;\n```\n同样的初始化对于`非const引用`却是不合法的，而且会导致编译时错误。\n观察将引用绑定到不同的类型时所发生的事情，最容易理解上述行为。对于下一段代码：\n```C++\ndouble dval = 3.14;\nconst int& ri = dval;\n```\n编译器会将这些代码转换为：\n```C++\nint temp = dval;\nconst int& ri = temp;\n```\n编译器会创建一个`int`类型的临时变量存储`dval`，然后将`ri`绑定到`temp`上。\n注意：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如`文字常量`，以及`不同类型的对象`，编译器为了实现引用，必须生成一个`临时对象`，引用实际上指向该对象，但用户不能访问它。\n如果`ri`不是`const`，那么可以给`ri`赋一新值。这样做不会修改`dval`的，而是修改了`temp`。期望对`ri`赋值会修改`dval`的程序员会发现`dval`没有被修改。仅允许`const引用`绑定到需要临时使用的值完全避免了这个问题，直接告诉程序员不能修改，因为`const引用`是只读的。\n注意：`非const引用`只能绑定到`与该引用相同类型的对象`。 `const引用`则可以绑定到`不同但相关的类型的对象`或绑定到`右值`。\n\n## 4.const和指针\nconst限定符和指针结合起来常见的情况有以下几种：指针常量（指向const对象的指针）、常量指针（const指针）、指向常量的常指针（指向const对象的const指针）。\n### 4.1 指针常量（指向const对象的指针）\n（1）C++为了保证不允许使用指针改变所指的`const对象`的值的这个特性，强制要求这个指针也必须具备`const`特性：\n```C++\nconst double* cptr;\n```\n这里`cptr`是一个指向`double类型`的`const对象`的指针，`const`先定义了`cptr`指向的对象的类型，而并非`cptr`本身，所以`cptr`本身并不是`const`。所以定义的时候并不需要对它进行初始，如果需要的话，允许给`cptr`重新赋值，让其指向另一个`const对象`。但不能通过`cptr`修改其所指对象的值。\n```C++\n*cptr=42; //error\n```\n\n（2）将一个`const对象`的地址赋给一个普通的`非const`指针会导致编译错误:\n```C++\nconst double pi = 3.14;\ndouble* ptr = &pi;        //error\nconst double* cptr = &pi; //ok\n```\n不能使用`void*`指针保存`const对象`的地址，必须使用`const void*`类型的指针保存`const`对象的地址。\n```C++\nconst int universe = 42;\nconst void* cov = &universe; //ok\nvoid* pv = &universe;        //error\n```\n（3）允许把`非const对象`的地址赋给指向`const对象`的指针，例如：\n```C++\ndouble dval = 3.14;\nconst double* cptr = &dval;\n```\n但是我们不能通过`cptr`指针来修改`dval`的值，即使它指向的是`非const对象`。\n### 4.2 常指针(const指针)\nC++中还提供了`const指针`——本身的值不能被修改。\n```C++\nint errNumb = 0;\nint* const curErr = &errNumb; //curErr是一个const指针\n```\n我们可以从右往左把上述定义语句读作\"指向int型对象的const指针\"。与其他`const对象`一样，`const指针`的值不能被修改，这意味着不能使`curErr`指向其他对象。`const指针`也必须在定义的时候初始化:\n```C++\ncurErr = curErr; //error！即使赋给其相同的值\n```\n 指针本身是`const`的事实并没有说明是否能用该指针修改其所指向的对象的值。指针对象的值能否修改完全取决于该对象的类型。\n### 4.3 指向常量的常指针（指向const对象的const指针）\n 如下可以这样定义：\n```C++\nconst double pi = 3.1415926;\nconst double* const pi_ptr = &pi;\n```\n这样`pi_ptr`首先是一个`const指针`，然后其指向一个`const对象`。\n###**4.4 小结**\n（1）分清以下四种情况：\n```C++\nint b = 500; \nconst int* a = &b  //1. 指针常量（指向常量的指针）\nint const *a = &b  //2. 同1\nint* const a = &b  //3. 常量指针（指针本身为常量，const指针）\nconst int* const a = &b //4.指向常量的常指针\n```\n（2）允许把`非const对象`的地址赋给指向`const对象`的指针,不允许把一个 `const对象`的地址赋给一个`非const对象`的指针。\n\n## 5.const和函数\n### 5.1 类中的const成员函数（常成员函数）\n（1）使用`const`关键字进行说明的成员函数，称为`常成员函数`。在一个类中，任何不会修改数据成员的函数都应该声明为`const类型`。\n对于`const成员函数`：\n（1）只可读取数据成员，不可修改数据成员；\n（2）不可调用其它`非const成员函数`。\n只有`常成员函数`才有资格操作`常量`或`常对象`，没有使用`const`关键字说明的成员函数不能用来操作`常对象`。\n其中，`const`是加在函数说明后面的类型修饰符，它是函数类型的一个组成部分，因此，在函数实现部分也要带`const`关键字。\n下面举一例子说明常成员函数的特征:\n```C++\nclass Stack\n{\nprivate:\n    int m_num;\n    int m_data[100];\npublic:\n    void push(int elem);\n    int pop(void);\n    int GetCount(void) const; //定义为const成员函数\n};\nint Stack::GetCount(void) const\n{\n++m_num;  //编译错误，企图修改数据成员m_num\npop();    //编译错误，企图修改非const成员函数\nreturn m_num;//正确，只能读取同一类中的数据成员的值\n}\n```\n\nconst对象的成员是不能修改的，而通过指针维护的对象确实可以修改的；\nconst对象只能访问const成员函数，而非const对象可以访问任意的成员函数，包括const成员函数。\nconst成员函数不可以修改对象的数据，不管对象是否具有const性质，编译时以是否修改成员数据为依据进行检查；\n\n### 5.2 函数重载\n既然`const`是定义为`const`函数的组成部分，那么就可以通过添加`const`实现函数重载，即：两个成员函数，名字和参数表都一样，但是一个是`const`，一个不是，算重载。\n具体调用哪个函数是根据调用对象是`常量对象`还是`非常量对象`来决定的。`常量对象函数`调用`常量成员`；`非常量对象`调用`非常量成员函数`：\n```C++\nclass R\n{\npublic:\n    R(int r1, int r2)\n    {\n    R1 = r1;\n    R2 = r2;\n    }\n    void print();\n    void print() const;\nprivate:\n    int R1,int R2;\n};\nvoid R::print()\n{\ncout<<R1;\n}\nvoid R::print() const\n{\ncout<<R2;\n}\nvoid main()\n{\nR a(5,4);\na.print();\nconst R b(20,52);\nb.print();\n}\n```\n输出结果为:5,52。\n其中`print`成员函数就实现了重载。`const对象`默认调用`const成员函数`。\n\n### 5.3 const修饰函数参数 \n（1）传递过来的参数在函数内不可以改变(无意义，因为`var`本身就是形参)：\n```C++\nvoid func(const int var);\n```\n（2）参数指针所指内容为常量不可变：\n```C++\nvoid func(const char* var);\n```\n（3）参数指针本身为常量不可变(也无意义，因为`char* var`也是形参)\n```C++\nvoid func(char* const var);\n```\n（4）参数为引用，为了`增加效率`同时`防止修改`。修饰引用参数时：\n```C++\nvoid func(const Class& var); //引用参数在函数内不可以改变\nvoid func(const TYPE& var);  //引用参数在函数内为常量不可变\n```\n  这样的一个`const引用`传递和最普通的函数`按值传递`的效果是一模一样的,他禁止对引用的对象的一切修改。唯一不同的是，`按值传递`会先建立一个类对象的副本, 然后传递过去,而它直接传递地址,所以这种传递比按值传递更有效。另外只有`引用的const传递`可以传递一个`临时对象`,因为`临时对象`都是`const属性`, 且是不可见的,他短时间存在一个局部域中,所以不能使用指针,只有`引用的const传递`能够捕捉到这个家伙.\n  \n### 5.4 const修饰函数返回值\n`const`修饰函数返回值其实用的并不是很多，它的含义和`const`修饰`普通变量`以及指针的含义基本相同。如下所示：\n```C++\n//无意义，因为参数返回本身就是赋值\nconst int func1();\n\n//调用时 const int* pVal = func2(); //必须这样可以理解\n//可把func2()看成一个变量，即指针内容不可变\nconst int* func2();\n\n//调用时 int* const pVal = func2(); //可以 int* pVal = func2()吧，不可理解\n//可把func2()看成一个变量，即指针本身不可变\nint* const func3();\n```\n\n（待）一般情况下，函数的返回值为某个对象时，如果将其声明为`const`时，多用于操作符的重载。\n\n## 6.const限定符和static的区别（待总结完static来看）\nconst定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。\nstatic表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。\n在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25; static关键字只能用于类定义体内部的声明中，定义时不能标示为static\n在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。\nconst数据成员,只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。\nconst数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static const。\nconst成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。\nstatic成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual \n![](http://images.cnitblog.com/blog/460416/201310/06213512-d6ae0722b2ae42f9b60ed2eff799c6be.png)\n其中关于static、const、static cosnt、const static成员的初始化问题：\n\n类里的const成员初始化\n 在一个类里建立一个const时，不能给他初值\n ![](http://images.cnitblog.com/blog/460416/201310/06213513-3befd1d1772d455a8c46f0f095139d72.png)\n 类里的static成员初始化：\n 类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：\n数据类型 类名::静态数据成员名=值\n![](http://images.cnitblog.com/blog/460416/201310/06213513-2d8b85aa88ad47e1b6170dd1d960f5bb.png)\n类里的static cosnt 和 const static成员初始化（这两种写法是一致的！！）\n![](http://images.cnitblog.com/blog/460416/201310/06213514-e6e0265323ec44d88ab3331af53fb3e2.png)\n   最后通过一个完整的例子展示以上结果：\n   ![](http://images.cnitblog.com/blog/460416/201310/06213515-ec5f6c035b9748a1a5849853853867e0.png)\n\n## 7.参考\n1.C++ prime, Stanley\n2.[C/C++中const关键字详解](http://www.cnblogs.com/yc_sunniwell/archive/2010/07/14/1777416.html)\n3.[C++中const关键字的使用方法](http://www.cnblogs.com/jiabei521/p/3335676.html)\n4.[C++ const的用法详解](http://blog.csdn.net/wangkai_123456/article/details/76598917)\n\n\n","source":"_posts/C++中const关键字总结.md","raw":"---\ntitle: C/C++中const关键字总结\ndate: 2017-11-28 16:32:00\ncategories: \n- C/C++\ntags:\n- C\n- C++\n- const\n- const对象\n- const引用\n- 常引用\n- const指针\n- 常量指针\n- 指针常量\n- 常成员函数\n- const成员函数\n- 函数重载\n---\n常类型是指使用类型修饰符`const`说明的类型，常类型的变量或对象的值是不能被更新的。不管出现在任何上下文都是为这个目的而服务的。    \n## 0. 声明方式\n\n - 常变量：`const 类型说明符 变量名`\n 例：`const int a=10;` 等价 `int const a=10;`\n - 常数组：`const 类型说明符 数组名[大小]`。\n 例：`const int arr[3]={1,2,3};` 等价 `int const arr[3]={1,2,3};`\n - 常引用：`const 类型说明符& 引用名`\n 例：`const int& a=x;`等价`int const &a=x;`\n - 指针常量：`const 类型说明符* 指针名`\n 例：`const int* a = &b`等价`int const *a = &b` \n - 常量指针：`类型说明符* const 指针名`\n 例：`int* const a = &b`      \n - 常对象：`const 类名 对象名`\n 例：`const test t;`等价于`test const t;`\n - 常成员函数：类体中：`类型说明符 函数名(形参) const` 类体外：`类型说明符 类名::函数名(形参) const`\n 例：类体中：`int GetCount(void) const;` 类体外：`int Stack::GetCount(void) const;`\n\n注：在常变量、常数组、常引用、常对象中，`const`与`类型说明符`或`类名`（其实类名是一种自定义的类型说明符） 的位置可以互换。\n<!-- more --> \n## 1.const对象\n\n（1）`const`修饰符把对象转变成常量对象，该对象的值不能再被修改，否则致编译错误：\n```C\nconst int bufferSize = 512;\nbufferSize = 0; //Error!\n```\n（2）因为常量对象在定义后就不能被修改，所以定义时必须初始化：\n \n```C\nconst i, j=0; //Error，i未初始化\n```\n \n（3）`const`对象默认为文件的局部变量。\n　　在全局作用域里定义`非const`变量时，它在整个程序中都可以访问，我们可以把一个`非const`变量定义在一个文件中（假设已经做了合适的声明），就可以在另外的文件中使用这个变量：\n\n```C++\n//file_1.cc\nint counter; //definition\n```\n```C++\n//file_2.cc\nextern int counter; //use counter from file_1.h\n++counter; //increments counter defined in file_1.h\n```\n　　在全局作用域声明的`const`变量是定义该对象的文件的局部变量。此变量只存在于那个文件中，不能被其他文件访问。通过指定`const`变量为`extern`，就可以在整个程序中访问`const`对象。\n```C++\n//file_1.cc\nextern const int bugSize = 500;\n```\n```C++\n//file_2.cc\nextern const int bugSize; //use bufSize from file_1.h\nfor(int index=0;index != bufSize;++index){}\n```\n　　综上，`非const`变量默认为`extern`。要使`const`变量能够在其他文件中访问，必须在文件中显式地指定它为`extern`。\n\n-----\n （待，放在类中，单独总结一下类）3.const 修饰类的数据成员\n 对于类中的const成员变量必须通过初始化列表进行初始化，如下所示：\n ![](http://images.cnitblog.com/blog/460416/201310/06213502-292090335e124b14a9a0b5ae9d49f3e0.png)\nconst数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类声明中初始化const数据成员，因为类的对象未被创建时，编译器不知道const 数据成员的值是什么。\n```C++\nclass A{\n const int size = 100;    //错误\n int array[size];         //错误，未知的size\n};\n```\nconst数据成员的初始化只能在类的构造函数的初始化表中进行。\n要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现.如:\n```C++\nclass A{\nenum {size1=100, size2 = 200 };\nint array1[size1];\nint array2[size2];\n};\n```\n枚举常量不会占用对象的存储空间，他们在编译时被全部求值。但是枚举常量的隐含数据类型是整数，其最大值有限，且不能表示浮点数。\n\n---\n\n## 2.const对象的动态数组\n\n如果我们在`自由存储区`中创建的数组存储了内置类型的`const对象`，则必须为这个数组提供初始化。\n\n因为数组元素都是`const对象`，无法赋值。实现这个要求的唯一方法是对数组做值初始化：\n```C++\n//error\nconst int* pci_bad = new const int[100];\n//ok\nconst int* pci_ok = new const int[100]();\n```\nC++允许定义`类类型`的`const数组`，但该`类类型`必须提供`默认构造函数`：\n```C++\nconst string* pcs = new string[100];\n```\n这里便会调用`string类`的`默认构造函数`初始化数组元素。\n\n## 3.const引用\n\n（1）`const引用`是指向`const对象`的引用,将普通的引用绑定到`const对象`是不合法的：\n\n```C++\nconst int iVal = 1024;\nconst int& refVal = iVal;  //两者均为const对象\nint& refVal2=iVal;         //错误！不能使用非const引用指向const对象\n```\n`refVal2`是普通的`非const引用`，因此可以用来修改`refVal2`指向的对象的值,为防止这样的修改，需要规定将普通的引用绑定到`const对象`是不合法的。\n\n（2）`const引用`可以初始化为`不同类型的对象`或者初始化为`右值`。\n\n如字面值常量：\n```C++\nint i = 42;\n//仅对const引用合法\nconst int& r2 = r+i;\nconst int& r = 42;\n```\n同样的初始化对于`非const引用`却是不合法的，而且会导致编译时错误。\n观察将引用绑定到不同的类型时所发生的事情，最容易理解上述行为。对于下一段代码：\n```C++\ndouble dval = 3.14;\nconst int& ri = dval;\n```\n编译器会将这些代码转换为：\n```C++\nint temp = dval;\nconst int& ri = temp;\n```\n编译器会创建一个`int`类型的临时变量存储`dval`，然后将`ri`绑定到`temp`上。\n注意：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如`文字常量`，以及`不同类型的对象`，编译器为了实现引用，必须生成一个`临时对象`，引用实际上指向该对象，但用户不能访问它。\n如果`ri`不是`const`，那么可以给`ri`赋一新值。这样做不会修改`dval`的，而是修改了`temp`。期望对`ri`赋值会修改`dval`的程序员会发现`dval`没有被修改。仅允许`const引用`绑定到需要临时使用的值完全避免了这个问题，直接告诉程序员不能修改，因为`const引用`是只读的。\n注意：`非const引用`只能绑定到`与该引用相同类型的对象`。 `const引用`则可以绑定到`不同但相关的类型的对象`或绑定到`右值`。\n\n## 4.const和指针\nconst限定符和指针结合起来常见的情况有以下几种：指针常量（指向const对象的指针）、常量指针（const指针）、指向常量的常指针（指向const对象的const指针）。\n### 4.1 指针常量（指向const对象的指针）\n（1）C++为了保证不允许使用指针改变所指的`const对象`的值的这个特性，强制要求这个指针也必须具备`const`特性：\n```C++\nconst double* cptr;\n```\n这里`cptr`是一个指向`double类型`的`const对象`的指针，`const`先定义了`cptr`指向的对象的类型，而并非`cptr`本身，所以`cptr`本身并不是`const`。所以定义的时候并不需要对它进行初始，如果需要的话，允许给`cptr`重新赋值，让其指向另一个`const对象`。但不能通过`cptr`修改其所指对象的值。\n```C++\n*cptr=42; //error\n```\n\n（2）将一个`const对象`的地址赋给一个普通的`非const`指针会导致编译错误:\n```C++\nconst double pi = 3.14;\ndouble* ptr = &pi;        //error\nconst double* cptr = &pi; //ok\n```\n不能使用`void*`指针保存`const对象`的地址，必须使用`const void*`类型的指针保存`const`对象的地址。\n```C++\nconst int universe = 42;\nconst void* cov = &universe; //ok\nvoid* pv = &universe;        //error\n```\n（3）允许把`非const对象`的地址赋给指向`const对象`的指针，例如：\n```C++\ndouble dval = 3.14;\nconst double* cptr = &dval;\n```\n但是我们不能通过`cptr`指针来修改`dval`的值，即使它指向的是`非const对象`。\n### 4.2 常指针(const指针)\nC++中还提供了`const指针`——本身的值不能被修改。\n```C++\nint errNumb = 0;\nint* const curErr = &errNumb; //curErr是一个const指针\n```\n我们可以从右往左把上述定义语句读作\"指向int型对象的const指针\"。与其他`const对象`一样，`const指针`的值不能被修改，这意味着不能使`curErr`指向其他对象。`const指针`也必须在定义的时候初始化:\n```C++\ncurErr = curErr; //error！即使赋给其相同的值\n```\n 指针本身是`const`的事实并没有说明是否能用该指针修改其所指向的对象的值。指针对象的值能否修改完全取决于该对象的类型。\n### 4.3 指向常量的常指针（指向const对象的const指针）\n 如下可以这样定义：\n```C++\nconst double pi = 3.1415926;\nconst double* const pi_ptr = &pi;\n```\n这样`pi_ptr`首先是一个`const指针`，然后其指向一个`const对象`。\n###**4.4 小结**\n（1）分清以下四种情况：\n```C++\nint b = 500; \nconst int* a = &b  //1. 指针常量（指向常量的指针）\nint const *a = &b  //2. 同1\nint* const a = &b  //3. 常量指针（指针本身为常量，const指针）\nconst int* const a = &b //4.指向常量的常指针\n```\n（2）允许把`非const对象`的地址赋给指向`const对象`的指针,不允许把一个 `const对象`的地址赋给一个`非const对象`的指针。\n\n## 5.const和函数\n### 5.1 类中的const成员函数（常成员函数）\n（1）使用`const`关键字进行说明的成员函数，称为`常成员函数`。在一个类中，任何不会修改数据成员的函数都应该声明为`const类型`。\n对于`const成员函数`：\n（1）只可读取数据成员，不可修改数据成员；\n（2）不可调用其它`非const成员函数`。\n只有`常成员函数`才有资格操作`常量`或`常对象`，没有使用`const`关键字说明的成员函数不能用来操作`常对象`。\n其中，`const`是加在函数说明后面的类型修饰符，它是函数类型的一个组成部分，因此，在函数实现部分也要带`const`关键字。\n下面举一例子说明常成员函数的特征:\n```C++\nclass Stack\n{\nprivate:\n    int m_num;\n    int m_data[100];\npublic:\n    void push(int elem);\n    int pop(void);\n    int GetCount(void) const; //定义为const成员函数\n};\nint Stack::GetCount(void) const\n{\n++m_num;  //编译错误，企图修改数据成员m_num\npop();    //编译错误，企图修改非const成员函数\nreturn m_num;//正确，只能读取同一类中的数据成员的值\n}\n```\n\nconst对象的成员是不能修改的，而通过指针维护的对象确实可以修改的；\nconst对象只能访问const成员函数，而非const对象可以访问任意的成员函数，包括const成员函数。\nconst成员函数不可以修改对象的数据，不管对象是否具有const性质，编译时以是否修改成员数据为依据进行检查；\n\n### 5.2 函数重载\n既然`const`是定义为`const`函数的组成部分，那么就可以通过添加`const`实现函数重载，即：两个成员函数，名字和参数表都一样，但是一个是`const`，一个不是，算重载。\n具体调用哪个函数是根据调用对象是`常量对象`还是`非常量对象`来决定的。`常量对象函数`调用`常量成员`；`非常量对象`调用`非常量成员函数`：\n```C++\nclass R\n{\npublic:\n    R(int r1, int r2)\n    {\n    R1 = r1;\n    R2 = r2;\n    }\n    void print();\n    void print() const;\nprivate:\n    int R1,int R2;\n};\nvoid R::print()\n{\ncout<<R1;\n}\nvoid R::print() const\n{\ncout<<R2;\n}\nvoid main()\n{\nR a(5,4);\na.print();\nconst R b(20,52);\nb.print();\n}\n```\n输出结果为:5,52。\n其中`print`成员函数就实现了重载。`const对象`默认调用`const成员函数`。\n\n### 5.3 const修饰函数参数 \n（1）传递过来的参数在函数内不可以改变(无意义，因为`var`本身就是形参)：\n```C++\nvoid func(const int var);\n```\n（2）参数指针所指内容为常量不可变：\n```C++\nvoid func(const char* var);\n```\n（3）参数指针本身为常量不可变(也无意义，因为`char* var`也是形参)\n```C++\nvoid func(char* const var);\n```\n（4）参数为引用，为了`增加效率`同时`防止修改`。修饰引用参数时：\n```C++\nvoid func(const Class& var); //引用参数在函数内不可以改变\nvoid func(const TYPE& var);  //引用参数在函数内为常量不可变\n```\n  这样的一个`const引用`传递和最普通的函数`按值传递`的效果是一模一样的,他禁止对引用的对象的一切修改。唯一不同的是，`按值传递`会先建立一个类对象的副本, 然后传递过去,而它直接传递地址,所以这种传递比按值传递更有效。另外只有`引用的const传递`可以传递一个`临时对象`,因为`临时对象`都是`const属性`, 且是不可见的,他短时间存在一个局部域中,所以不能使用指针,只有`引用的const传递`能够捕捉到这个家伙.\n  \n### 5.4 const修饰函数返回值\n`const`修饰函数返回值其实用的并不是很多，它的含义和`const`修饰`普通变量`以及指针的含义基本相同。如下所示：\n```C++\n//无意义，因为参数返回本身就是赋值\nconst int func1();\n\n//调用时 const int* pVal = func2(); //必须这样可以理解\n//可把func2()看成一个变量，即指针内容不可变\nconst int* func2();\n\n//调用时 int* const pVal = func2(); //可以 int* pVal = func2()吧，不可理解\n//可把func2()看成一个变量，即指针本身不可变\nint* const func3();\n```\n\n（待）一般情况下，函数的返回值为某个对象时，如果将其声明为`const`时，多用于操作符的重载。\n\n## 6.const限定符和static的区别（待总结完static来看）\nconst定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。\nstatic表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。\n在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25; static关键字只能用于类定义体内部的声明中，定义时不能标示为static\n在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。\nconst数据成员,只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。\nconst数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static const。\nconst成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。\nstatic成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual \n![](http://images.cnitblog.com/blog/460416/201310/06213512-d6ae0722b2ae42f9b60ed2eff799c6be.png)\n其中关于static、const、static cosnt、const static成员的初始化问题：\n\n类里的const成员初始化\n 在一个类里建立一个const时，不能给他初值\n ![](http://images.cnitblog.com/blog/460416/201310/06213513-3befd1d1772d455a8c46f0f095139d72.png)\n 类里的static成员初始化：\n 类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：\n数据类型 类名::静态数据成员名=值\n![](http://images.cnitblog.com/blog/460416/201310/06213513-2d8b85aa88ad47e1b6170dd1d960f5bb.png)\n类里的static cosnt 和 const static成员初始化（这两种写法是一致的！！）\n![](http://images.cnitblog.com/blog/460416/201310/06213514-e6e0265323ec44d88ab3331af53fb3e2.png)\n   最后通过一个完整的例子展示以上结果：\n   ![](http://images.cnitblog.com/blog/460416/201310/06213515-ec5f6c035b9748a1a5849853853867e0.png)\n\n## 7.参考\n1.C++ prime, Stanley\n2.[C/C++中const关键字详解](http://www.cnblogs.com/yc_sunniwell/archive/2010/07/14/1777416.html)\n3.[C++中const关键字的使用方法](http://www.cnblogs.com/jiabei521/p/3335676.html)\n4.[C++ const的用法详解](http://blog.csdn.net/wangkai_123456/article/details/76598917)\n\n\n","slug":"C++中const关键字总结","published":1,"updated":"2017-11-28T08:49:29.905Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w1e004tqslp3x1xfz5s","content":"<p>常类型是指使用类型修饰符<code>const</code>说明的类型，常类型的变量或对象的值是不能被更新的。不管出现在任何上下文都是为这个目的而服务的。    </p>\n<h2 id=\"0-声明方式\"><a href=\"#0-声明方式\" class=\"headerlink\" title=\"0. 声明方式\"></a>0. 声明方式</h2><ul>\n<li>常变量：<code>const 类型说明符 变量名</code><br>例：<code>const int a=10;</code> 等价 <code>int const a=10;</code></li>\n<li>常数组：<code>const 类型说明符 数组名[大小]</code>。<br>例：<code>const int arr[3]={1,2,3};</code> 等价 <code>int const arr[3]={1,2,3};</code></li>\n<li>常引用：<code>const 类型说明符&amp; 引用名</code><br>例：<code>const int&amp; a=x;</code>等价<code>int const &amp;a=x;</code></li>\n<li>指针常量：<code>const 类型说明符* 指针名</code><br>例：<code>const int* a = &amp;b</code>等价<code>int const *a = &amp;b</code> </li>\n<li>常量指针：<code>类型说明符* const 指针名</code><br>例：<code>int* const a = &amp;b</code>      </li>\n<li>常对象：<code>const 类名 对象名</code><br>例：<code>const test t;</code>等价于<code>test const t;</code></li>\n<li>常成员函数：类体中：<code>类型说明符 函数名(形参) const</code> 类体外：<code>类型说明符 类名::函数名(形参) const</code><br>例：类体中：<code>int GetCount(void) const;</code> 类体外：<code>int Stack::GetCount(void) const;</code></li>\n</ul>\n<p>注：在常变量、常数组、常引用、常对象中，<code>const</code>与<code>类型说明符</code>或<code>类名</code>（其实类名是一种自定义的类型说明符） 的位置可以互换。<br><a id=\"more\"></a> </p>\n<h2 id=\"1-const对象\"><a href=\"#1-const对象\" class=\"headerlink\" title=\"1.const对象\"></a>1.const对象</h2><p>（1）<code>const</code>修饰符把对象转变成常量对象，该对象的值不能再被修改，否则致编译错误：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bufferSize = <span class=\"number\">512</span>;</span><br><span class=\"line\">bufferSize = <span class=\"number\">0</span>; <span class=\"comment\">//Error!</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）因为常量对象在定义后就不能被修改，所以定义时必须初始化：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> i, j=<span class=\"number\">0</span>; <span class=\"comment\">//Error，i未初始化</span></span><br></pre></td></tr></table></figure>\n<p>（3）<code>const</code>对象默认为文件的局部变量。<br>　　在全局作用域里定义<code>非const</code>变量时，它在整个程序中都可以访问，我们可以把一个<code>非const</code>变量定义在一个文件中（假设已经做了合适的声明），就可以在另外的文件中使用这个变量：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_1.cc</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> counter; <span class=\"comment\">//definition</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_2.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">int</span> counter; <span class=\"comment\">//use counter from file_1.h</span></span><br><span class=\"line\">++counter; <span class=\"comment\">//increments counter defined in file_1.h</span></span><br></pre></td></tr></table></figure>\n<p>　　在全局作用域声明的<code>const</code>变量是定义该对象的文件的局部变量。此变量只存在于那个文件中，不能被其他文件访问。通过指定<code>const</code>变量为<code>extern</code>，就可以在整个程序中访问<code>const</code>对象。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_1.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bugSize = <span class=\"number\">500</span>;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_2.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bugSize; <span class=\"comment\">//use bufSize from file_1.h</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> index=<span class=\"number\">0</span>;index != bufSize;++index)&#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>　　综上，<code>非const</code>变量默认为<code>extern</code>。要使<code>const</code>变量能够在其他文件中访问，必须在文件中显式地指定它为<code>extern</code>。</p>\n<hr>\n<p> （待，放在类中，单独总结一下类）3.const 修饰类的数据成员<br> 对于类中的const成员变量必须通过初始化列表进行初始化，如下所示：<br> <img src=\"http://images.cnitblog.com/blog/460416/201310/06213502-292090335e124b14a9a0b5ae9d49f3e0.png\" alt=\"\"><br>const数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类声明中初始化const数据成员，因为类的对象未被创建时，编译器不知道const 数据成员的值是什么。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>&#123;</span></span><br><span class=\"line\"> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> size = <span class=\"number\">100</span>;    <span class=\"comment\">//错误</span></span><br><span class=\"line\"> <span class=\"keyword\">int</span> <span class=\"built_in\">array</span>[size];         <span class=\"comment\">//错误，未知的size</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>const数据成员的初始化只能在类的构造函数的初始化表中进行。<br>要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现.如:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">enum</span> &#123;size1=<span class=\"number\">100</span>, size2 = <span class=\"number\">200</span> &#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> array1[size1];</span><br><span class=\"line\"><span class=\"keyword\">int</span> array2[size2];</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>枚举常量不会占用对象的存储空间，他们在编译时被全部求值。但是枚举常量的隐含数据类型是整数，其最大值有限，且不能表示浮点数。</p>\n<hr>\n<h2 id=\"2-const对象的动态数组\"><a href=\"#2-const对象的动态数组\" class=\"headerlink\" title=\"2.const对象的动态数组\"></a>2.const对象的动态数组</h2><p>如果我们在<code>自由存储区</code>中创建的数组存储了内置类型的<code>const对象</code>，则必须为这个数组提供初始化。</p>\n<p>因为数组元素都是<code>const对象</code>，无法赋值。实现这个要求的唯一方法是对数组做值初始化：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//error</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* pci_bad = <span class=\"keyword\">new</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span>[<span class=\"number\">100</span>];</span><br><span class=\"line\"><span class=\"comment\">//ok</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* pci_ok = <span class=\"keyword\">new</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span>[<span class=\"number\">100</span>]();</span><br></pre></td></tr></table></figure></p>\n<p>C++允许定义<code>类类型</code>的<code>const数组</code>，但该<code>类类型</code>必须提供<code>默认构造函数</code>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"built_in\">string</span>* pcs = <span class=\"keyword\">new</span> <span class=\"built_in\">string</span>[<span class=\"number\">100</span>];</span><br></pre></td></tr></table></figure></p>\n<p>这里便会调用<code>string类</code>的<code>默认构造函数</code>初始化数组元素。</p>\n<h2 id=\"3-const引用\"><a href=\"#3-const引用\" class=\"headerlink\" title=\"3.const引用\"></a>3.const引用</h2><p>（1）<code>const引用</code>是指向<code>const对象</code>的引用,将普通的引用绑定到<code>const对象</code>是不合法的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> iVal = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; refVal = iVal;  <span class=\"comment\">//两者均为const对象</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>&amp; refVal2=iVal;         <span class=\"comment\">//错误！不能使用非const引用指向const对象</span></span><br></pre></td></tr></table></figure>\n<p><code>refVal2</code>是普通的<code>非const引用</code>，因此可以用来修改<code>refVal2</code>指向的对象的值,为防止这样的修改，需要规定将普通的引用绑定到<code>const对象</code>是不合法的。</p>\n<p>（2）<code>const引用</code>可以初始化为<code>不同类型的对象</code>或者初始化为<code>右值</code>。</p>\n<p>如字面值常量：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">42</span>;</span><br><span class=\"line\"><span class=\"comment\">//仅对const引用合法</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; r2 = r+i;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; r = <span class=\"number\">42</span>;</span><br></pre></td></tr></table></figure></p>\n<p>同样的初始化对于<code>非const引用</code>却是不合法的，而且会导致编译时错误。<br>观察将引用绑定到不同的类型时所发生的事情，最容易理解上述行为。对于下一段代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; ri = dval;</span><br></pre></td></tr></table></figure></p>\n<p>编译器会将这些代码转换为：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> temp = dval;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; ri = temp;</span><br></pre></td></tr></table></figure></p>\n<p>编译器会创建一个<code>int</code>类型的临时变量存储<code>dval</code>，然后将<code>ri</code>绑定到<code>temp</code>上。<br>注意：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如<code>文字常量</code>，以及<code>不同类型的对象</code>，编译器为了实现引用，必须生成一个<code>临时对象</code>，引用实际上指向该对象，但用户不能访问它。<br>如果<code>ri</code>不是<code>const</code>，那么可以给<code>ri</code>赋一新值。这样做不会修改<code>dval</code>的，而是修改了<code>temp</code>。期望对<code>ri</code>赋值会修改<code>dval</code>的程序员会发现<code>dval</code>没有被修改。仅允许<code>const引用</code>绑定到需要临时使用的值完全避免了这个问题，直接告诉程序员不能修改，因为<code>const引用</code>是只读的。<br>注意：<code>非const引用</code>只能绑定到<code>与该引用相同类型的对象</code>。 <code>const引用</code>则可以绑定到<code>不同但相关的类型的对象</code>或绑定到<code>右值</code>。</p>\n<h2 id=\"4-const和指针\"><a href=\"#4-const和指针\" class=\"headerlink\" title=\"4.const和指针\"></a>4.const和指针</h2><p>const限定符和指针结合起来常见的情况有以下几种：指针常量（指向const对象的指针）、常量指针（const指针）、指向常量的常指针（指向const对象的const指针）。</p>\n<h3 id=\"4-1-指针常量（指向const对象的指针）\"><a href=\"#4-1-指针常量（指向const对象的指针）\" class=\"headerlink\" title=\"4.1 指针常量（指向const对象的指针）\"></a>4.1 指针常量（指向const对象的指针）</h3><p>（1）C++为了保证不允许使用指针改变所指的<code>const对象</code>的值的这个特性，强制要求这个指针也必须具备<code>const</code>特性：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr;</span><br></pre></td></tr></table></figure></p>\n<p>这里<code>cptr</code>是一个指向<code>double类型</code>的<code>const对象</code>的指针，<code>const</code>先定义了<code>cptr</code>指向的对象的类型，而并非<code>cptr</code>本身，所以<code>cptr</code>本身并不是<code>const</code>。所以定义的时候并不需要对它进行初始，如果需要的话，允许给<code>cptr</code>重新赋值，让其指向另一个<code>const对象</code>。但不能通过<code>cptr</code>修改其所指对象的值。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*cptr=<span class=\"number\">42</span>; <span class=\"comment\">//error</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）将一个<code>const对象</code>的地址赋给一个普通的<code>非const</code>指针会导致编译错误:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span>* ptr = &amp;pi;        <span class=\"comment\">//error</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr = &amp;pi; <span class=\"comment\">//ok</span></span><br></pre></td></tr></table></figure></p>\n<p>不能使用<code>void*</code>指针保存<code>const对象</code>的地址，必须使用<code>const void*</code>类型的指针保存<code>const</code>对象的地址。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> universe = <span class=\"number\">42</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* cov = &amp;universe; <span class=\"comment\">//ok</span></span><br><span class=\"line\"><span class=\"keyword\">void</span>* pv = &amp;universe;        <span class=\"comment\">//error</span></span><br></pre></td></tr></table></figure></p>\n<p>（3）允许把<code>非const对象</code>的地址赋给指向<code>const对象</code>的指针，例如：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr = &amp;dval;</span><br></pre></td></tr></table></figure></p>\n<p>但是我们不能通过<code>cptr</code>指针来修改<code>dval</code>的值，即使它指向的是<code>非const对象</code>。</p>\n<h3 id=\"4-2-常指针-const指针\"><a href=\"#4-2-常指针-const指针\" class=\"headerlink\" title=\"4.2 常指针(const指针)\"></a>4.2 常指针(const指针)</h3><p>C++中还提供了<code>const指针</code>——本身的值不能被修改。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> errNumb = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> curErr = &amp;errNumb; <span class=\"comment\">//curErr是一个const指针</span></span><br></pre></td></tr></table></figure></p>\n<p>我们可以从右往左把上述定义语句读作”指向int型对象的const指针”。与其他<code>const对象</code>一样，<code>const指针</code>的值不能被修改，这意味着不能使<code>curErr</code>指向其他对象。<code>const指针</code>也必须在定义的时候初始化:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curErr = curErr; <span class=\"comment\">//error！即使赋给其相同的值</span></span><br></pre></td></tr></table></figure></p>\n<p> 指针本身是<code>const</code>的事实并没有说明是否能用该指针修改其所指向的对象的值。指针对象的值能否修改完全取决于该对象的类型。</p>\n<h3 id=\"4-3-指向常量的常指针（指向const对象的const指针）\"><a href=\"#4-3-指向常量的常指针（指向const对象的const指针）\" class=\"headerlink\" title=\"4.3 指向常量的常指针（指向const对象的const指针）\"></a>4.3 指向常量的常指针（指向const对象的const指针）</h3><p> 如下可以这样定义：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.1415926</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* <span class=\"keyword\">const</span> pi_ptr = &amp;pi;</span><br></pre></td></tr></table></figure></p>\n<p>这样<code>pi_ptr</code>首先是一个<code>const指针</code>，然后其指向一个<code>const对象</code>。</p>\n<h3 id=\"4-4-小结\"><a href=\"#4-4-小结\" class=\"headerlink\" title=\"4.4 小结\"></a><strong>4.4 小结</strong></h3><p>（1）分清以下四种情况：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> b = <span class=\"number\">500</span>; </span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* a = &amp;b  <span class=\"comment\">//1. 指针常量（指向常量的指针）</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *a = &amp;b  <span class=\"comment\">//2. 同1</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> a = &amp;b  <span class=\"comment\">//3. 常量指针（指针本身为常量，const指针）</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> a = &amp;b <span class=\"comment\">//4.指向常量的常指针</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）允许把<code>非const对象</code>的地址赋给指向<code>const对象</code>的指针,不允许把一个 <code>const对象</code>的地址赋给一个<code>非const对象</code>的指针。</p>\n<h2 id=\"5-const和函数\"><a href=\"#5-const和函数\" class=\"headerlink\" title=\"5.const和函数\"></a>5.const和函数</h2><h3 id=\"5-1-类中的const成员函数（常成员函数）\"><a href=\"#5-1-类中的const成员函数（常成员函数）\" class=\"headerlink\" title=\"5.1 类中的const成员函数（常成员函数）\"></a>5.1 类中的const成员函数（常成员函数）</h3><p>（1）使用<code>const</code>关键字进行说明的成员函数，称为<code>常成员函数</code>。在一个类中，任何不会修改数据成员的函数都应该声明为<code>const类型</code>。<br>对于<code>const成员函数</code>：<br>（1）只可读取数据成员，不可修改数据成员；<br>（2）不可调用其它<code>非const成员函数</code>。<br>只有<code>常成员函数</code>才有资格操作<code>常量</code>或<code>常对象</code>，没有使用<code>const</code>关键字说明的成员函数不能用来操作<code>常对象</code>。<br>其中，<code>const</code>是加在函数说明后面的类型修饰符，它是函数类型的一个组成部分，因此，在函数实现部分也要带<code>const</code>关键字。<br>下面举一例子说明常成员函数的特征:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Stack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> m_num;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> m_data[<span class=\"number\">100</span>];</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> elem)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">pop</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetCount</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> <span class=\"keyword\">const</span></span>; <span class=\"comment\">//定义为const成员函数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> Stack::GetCount(<span class=\"keyword\">void</span>) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">++m_num;  <span class=\"comment\">//编译错误，企图修改数据成员m_num</span></span><br><span class=\"line\">pop();    <span class=\"comment\">//编译错误，企图修改非const成员函数</span></span><br><span class=\"line\"><span class=\"keyword\">return</span> m_num;<span class=\"comment\">//正确，只能读取同一类中的数据成员的值</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>const对象的成员是不能修改的，而通过指针维护的对象确实可以修改的；<br>const对象只能访问const成员函数，而非const对象可以访问任意的成员函数，包括const成员函数。<br>const成员函数不可以修改对象的数据，不管对象是否具有const性质，编译时以是否修改成员数据为依据进行检查；</p>\n<h3 id=\"5-2-函数重载\"><a href=\"#5-2-函数重载\" class=\"headerlink\" title=\"5.2 函数重载\"></a>5.2 函数重载</h3><p>既然<code>const</code>是定义为<code>const</code>函数的组成部分，那么就可以通过添加<code>const</code>实现函数重载，即：两个成员函数，名字和参数表都一样，但是一个是<code>const</code>，一个不是，算重载。<br>具体调用哪个函数是根据调用对象是<code>常量对象</code>还是<code>非常量对象</code>来决定的。<code>常量对象函数</code>调用<code>常量成员</code>；<code>非常量对象</code>调用<code>非常量成员函数</code>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">R</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    R(<span class=\"keyword\">int</span> r1, <span class=\"keyword\">int</span> r2)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    R1 = r1;</span><br><span class=\"line\">    R2 = r2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> R1,<span class=\"keyword\">int</span> R2;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">void</span> R::print()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">cout</span>&lt;&lt;R1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">void</span> R::print() <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">cout</span>&lt;&lt;R2;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"><span class=\"function\">R <span class=\"title\">a</span><span class=\"params\">(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span></span>;</span><br><span class=\"line\">a.print();</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> R <span class=\"title\">b</span><span class=\"params\">(<span class=\"number\">20</span>,<span class=\"number\">52</span>)</span></span>;</span><br><span class=\"line\">b.print();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果为:5,52。<br>其中<code>print</code>成员函数就实现了重载。<code>const对象</code>默认调用<code>const成员函数</code>。</p>\n<h3 id=\"5-3-const修饰函数参数\"><a href=\"#5-3-const修饰函数参数\" class=\"headerlink\" title=\"5.3 const修饰函数参数\"></a>5.3 const修饰函数参数</h3><p>（1）传递过来的参数在函数内不可以改变(无意义，因为<code>var</code>本身就是形参)：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（2）参数指针所指内容为常量不可变：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（3）参数指针本身为常量不可变(也无意义，因为<code>char* var</code>也是形参)<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">char</span>* <span class=\"keyword\">const</span> var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（4）参数为引用，为了<code>增加效率</code>同时<code>防止修改</code>。修饰引用参数时：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> Class&amp; var)</span></span>; <span class=\"comment\">//引用参数在函数内不可以改变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> TYPE&amp; var)</span></span>;  <span class=\"comment\">//引用参数在函数内为常量不可变</span></span><br></pre></td></tr></table></figure></p>\n<p>  这样的一个<code>const引用</code>传递和最普通的函数<code>按值传递</code>的效果是一模一样的,他禁止对引用的对象的一切修改。唯一不同的是，<code>按值传递</code>会先建立一个类对象的副本, 然后传递过去,而它直接传递地址,所以这种传递比按值传递更有效。另外只有<code>引用的const传递</code>可以传递一个<code>临时对象</code>,因为<code>临时对象</code>都是<code>const属性</code>, 且是不可见的,他短时间存在一个局部域中,所以不能使用指针,只有<code>引用的const传递</code>能够捕捉到这个家伙.</p>\n<h3 id=\"5-4-const修饰函数返回值\"><a href=\"#5-4-const修饰函数返回值\" class=\"headerlink\" title=\"5.4 const修饰函数返回值\"></a>5.4 const修饰函数返回值</h3><p><code>const</code>修饰函数返回值其实用的并不是很多，它的含义和<code>const</code>修饰<code>普通变量</code>以及指针的含义基本相同。如下所示：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//无意义，因为参数返回本身就是赋值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> <span class=\"title\">func1</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//调用时 const int* pVal = func2(); //必须这样可以理解</span></span><br><span class=\"line\"><span class=\"comment\">//可把func2()看成一个变量，即指针内容不可变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* <span class=\"title\">func2</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//调用时 int* const pVal = func2(); //可以 int* pVal = func2()吧，不可理解</span></span><br><span class=\"line\"><span class=\"comment\">//可把func2()看成一个变量，即指针本身不可变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> <span class=\"title\">func3</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（待）一般情况下，函数的返回值为某个对象时，如果将其声明为<code>const</code>时，多用于操作符的重载。</p>\n<h2 id=\"6-const限定符和static的区别（待总结完static来看）\"><a href=\"#6-const限定符和static的区别（待总结完static来看）\" class=\"headerlink\" title=\"6.const限定符和static的区别（待总结完static来看）\"></a>6.const限定符和static的区别（待总结完static来看）</h2><p>const定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。<br>static表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。<br>在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25; static关键字只能用于类定义体内部的声明中，定义时不能标示为static<br>在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。<br>const数据成员,只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。<br>const数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static const。<br>const成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。<br>static成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213512-d6ae0722b2ae42f9b60ed2eff799c6be.png\" alt=\"\"><br>其中关于static、const、static cosnt、const static成员的初始化问题：</p>\n<p>类里的const成员初始化<br> 在一个类里建立一个const时，不能给他初值<br> <img src=\"http://images.cnitblog.com/blog/460416/201310/06213513-3befd1d1772d455a8c46f0f095139d72.png\" alt=\"\"><br> 类里的static成员初始化：<br> 类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：<br>数据类型 类名::静态数据成员名=值<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213513-2d8b85aa88ad47e1b6170dd1d960f5bb.png\" alt=\"\"><br>类里的static cosnt 和 const static成员初始化（这两种写法是一致的！！）<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213514-e6e0265323ec44d88ab3331af53fb3e2.png\" alt=\"\"><br>   最后通过一个完整的例子展示以上结果：<br>   <img src=\"http://images.cnitblog.com/blog/460416/201310/06213515-ec5f6c035b9748a1a5849853853867e0.png\" alt=\"\"></p>\n<h2 id=\"7-参考\"><a href=\"#7-参考\" class=\"headerlink\" title=\"7.参考\"></a>7.参考</h2><p>1.C++ prime, Stanley<br>2.<a href=\"http://www.cnblogs.com/yc_sunniwell/archive/2010/07/14/1777416.html\" target=\"_blank\" rel=\"noopener\">C/C++中const关键字详解</a><br>3.<a href=\"http://www.cnblogs.com/jiabei521/p/3335676.html\" target=\"_blank\" rel=\"noopener\">C++中const关键字的使用方法</a><br>4.<a href=\"http://blog.csdn.net/wangkai_123456/article/details/76598917\" target=\"_blank\" rel=\"noopener\">C++ const的用法详解</a></p>\n","site":{"data":{}},"excerpt":"<p>常类型是指使用类型修饰符<code>const</code>说明的类型，常类型的变量或对象的值是不能被更新的。不管出现在任何上下文都是为这个目的而服务的。    </p>\n<h2 id=\"0-声明方式\"><a href=\"#0-声明方式\" class=\"headerlink\" title=\"0. 声明方式\"></a>0. 声明方式</h2><ul>\n<li>常变量：<code>const 类型说明符 变量名</code><br>例：<code>const int a=10;</code> 等价 <code>int const a=10;</code></li>\n<li>常数组：<code>const 类型说明符 数组名[大小]</code>。<br>例：<code>const int arr[3]={1,2,3};</code> 等价 <code>int const arr[3]={1,2,3};</code></li>\n<li>常引用：<code>const 类型说明符&amp; 引用名</code><br>例：<code>const int&amp; a=x;</code>等价<code>int const &amp;a=x;</code></li>\n<li>指针常量：<code>const 类型说明符* 指针名</code><br>例：<code>const int* a = &amp;b</code>等价<code>int const *a = &amp;b</code> </li>\n<li>常量指针：<code>类型说明符* const 指针名</code><br>例：<code>int* const a = &amp;b</code>      </li>\n<li>常对象：<code>const 类名 对象名</code><br>例：<code>const test t;</code>等价于<code>test const t;</code></li>\n<li>常成员函数：类体中：<code>类型说明符 函数名(形参) const</code> 类体外：<code>类型说明符 类名::函数名(形参) const</code><br>例：类体中：<code>int GetCount(void) const;</code> 类体外：<code>int Stack::GetCount(void) const;</code></li>\n</ul>\n<p>注：在常变量、常数组、常引用、常对象中，<code>const</code>与<code>类型说明符</code>或<code>类名</code>（其实类名是一种自定义的类型说明符） 的位置可以互换。<br>","more":"</p>\n<h2 id=\"1-const对象\"><a href=\"#1-const对象\" class=\"headerlink\" title=\"1.const对象\"></a>1.const对象</h2><p>（1）<code>const</code>修饰符把对象转变成常量对象，该对象的值不能再被修改，否则致编译错误：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bufferSize = <span class=\"number\">512</span>;</span><br><span class=\"line\">bufferSize = <span class=\"number\">0</span>; <span class=\"comment\">//Error!</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）因为常量对象在定义后就不能被修改，所以定义时必须初始化：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> i, j=<span class=\"number\">0</span>; <span class=\"comment\">//Error，i未初始化</span></span><br></pre></td></tr></table></figure>\n<p>（3）<code>const</code>对象默认为文件的局部变量。<br>　　在全局作用域里定义<code>非const</code>变量时，它在整个程序中都可以访问，我们可以把一个<code>非const</code>变量定义在一个文件中（假设已经做了合适的声明），就可以在另外的文件中使用这个变量：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_1.cc</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> counter; <span class=\"comment\">//definition</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_2.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">int</span> counter; <span class=\"comment\">//use counter from file_1.h</span></span><br><span class=\"line\">++counter; <span class=\"comment\">//increments counter defined in file_1.h</span></span><br></pre></td></tr></table></figure>\n<p>　　在全局作用域声明的<code>const</code>变量是定义该对象的文件的局部变量。此变量只存在于那个文件中，不能被其他文件访问。通过指定<code>const</code>变量为<code>extern</code>，就可以在整个程序中访问<code>const</code>对象。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_1.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bugSize = <span class=\"number\">500</span>;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//file_2.cc</span></span><br><span class=\"line\"><span class=\"keyword\">extern</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> bugSize; <span class=\"comment\">//use bufSize from file_1.h</span></span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> index=<span class=\"number\">0</span>;index != bufSize;++index)&#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>　　综上，<code>非const</code>变量默认为<code>extern</code>。要使<code>const</code>变量能够在其他文件中访问，必须在文件中显式地指定它为<code>extern</code>。</p>\n<hr>\n<p> （待，放在类中，单独总结一下类）3.const 修饰类的数据成员<br> 对于类中的const成员变量必须通过初始化列表进行初始化，如下所示：<br> <img src=\"http://images.cnitblog.com/blog/460416/201310/06213502-292090335e124b14a9a0b5ae9d49f3e0.png\" alt=\"\"><br>const数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类声明中初始化const数据成员，因为类的对象未被创建时，编译器不知道const 数据成员的值是什么。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>&#123;</span></span><br><span class=\"line\"> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> size = <span class=\"number\">100</span>;    <span class=\"comment\">//错误</span></span><br><span class=\"line\"> <span class=\"keyword\">int</span> <span class=\"built_in\">array</span>[size];         <span class=\"comment\">//错误，未知的size</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>const数据成员的初始化只能在类的构造函数的初始化表中进行。<br>要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现.如:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">A</span>&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">enum</span> &#123;size1=<span class=\"number\">100</span>, size2 = <span class=\"number\">200</span> &#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> array1[size1];</span><br><span class=\"line\"><span class=\"keyword\">int</span> array2[size2];</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>枚举常量不会占用对象的存储空间，他们在编译时被全部求值。但是枚举常量的隐含数据类型是整数，其最大值有限，且不能表示浮点数。</p>\n<hr>\n<h2 id=\"2-const对象的动态数组\"><a href=\"#2-const对象的动态数组\" class=\"headerlink\" title=\"2.const对象的动态数组\"></a>2.const对象的动态数组</h2><p>如果我们在<code>自由存储区</code>中创建的数组存储了内置类型的<code>const对象</code>，则必须为这个数组提供初始化。</p>\n<p>因为数组元素都是<code>const对象</code>，无法赋值。实现这个要求的唯一方法是对数组做值初始化：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//error</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* pci_bad = <span class=\"keyword\">new</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span>[<span class=\"number\">100</span>];</span><br><span class=\"line\"><span class=\"comment\">//ok</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* pci_ok = <span class=\"keyword\">new</span> <span class=\"keyword\">const</span> <span class=\"keyword\">int</span>[<span class=\"number\">100</span>]();</span><br></pre></td></tr></table></figure></p>\n<p>C++允许定义<code>类类型</code>的<code>const数组</code>，但该<code>类类型</code>必须提供<code>默认构造函数</code>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"built_in\">string</span>* pcs = <span class=\"keyword\">new</span> <span class=\"built_in\">string</span>[<span class=\"number\">100</span>];</span><br></pre></td></tr></table></figure></p>\n<p>这里便会调用<code>string类</code>的<code>默认构造函数</code>初始化数组元素。</p>\n<h2 id=\"3-const引用\"><a href=\"#3-const引用\" class=\"headerlink\" title=\"3.const引用\"></a>3.const引用</h2><p>（1）<code>const引用</code>是指向<code>const对象</code>的引用,将普通的引用绑定到<code>const对象</code>是不合法的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> iVal = <span class=\"number\">1024</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; refVal = iVal;  <span class=\"comment\">//两者均为const对象</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>&amp; refVal2=iVal;         <span class=\"comment\">//错误！不能使用非const引用指向const对象</span></span><br></pre></td></tr></table></figure>\n<p><code>refVal2</code>是普通的<code>非const引用</code>，因此可以用来修改<code>refVal2</code>指向的对象的值,为防止这样的修改，需要规定将普通的引用绑定到<code>const对象</code>是不合法的。</p>\n<p>（2）<code>const引用</code>可以初始化为<code>不同类型的对象</code>或者初始化为<code>右值</code>。</p>\n<p>如字面值常量：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> i = <span class=\"number\">42</span>;</span><br><span class=\"line\"><span class=\"comment\">//仅对const引用合法</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; r2 = r+i;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; r = <span class=\"number\">42</span>;</span><br></pre></td></tr></table></figure></p>\n<p>同样的初始化对于<code>非const引用</code>却是不合法的，而且会导致编译时错误。<br>观察将引用绑定到不同的类型时所发生的事情，最容易理解上述行为。对于下一段代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; ri = dval;</span><br></pre></td></tr></table></figure></p>\n<p>编译器会将这些代码转换为：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> temp = dval;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>&amp; ri = temp;</span><br></pre></td></tr></table></figure></p>\n<p>编译器会创建一个<code>int</code>类型的临时变量存储<code>dval</code>，然后将<code>ri</code>绑定到<code>temp</code>上。<br>注意：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如<code>文字常量</code>，以及<code>不同类型的对象</code>，编译器为了实现引用，必须生成一个<code>临时对象</code>，引用实际上指向该对象，但用户不能访问它。<br>如果<code>ri</code>不是<code>const</code>，那么可以给<code>ri</code>赋一新值。这样做不会修改<code>dval</code>的，而是修改了<code>temp</code>。期望对<code>ri</code>赋值会修改<code>dval</code>的程序员会发现<code>dval</code>没有被修改。仅允许<code>const引用</code>绑定到需要临时使用的值完全避免了这个问题，直接告诉程序员不能修改，因为<code>const引用</code>是只读的。<br>注意：<code>非const引用</code>只能绑定到<code>与该引用相同类型的对象</code>。 <code>const引用</code>则可以绑定到<code>不同但相关的类型的对象</code>或绑定到<code>右值</code>。</p>\n<h2 id=\"4-const和指针\"><a href=\"#4-const和指针\" class=\"headerlink\" title=\"4.const和指针\"></a>4.const和指针</h2><p>const限定符和指针结合起来常见的情况有以下几种：指针常量（指向const对象的指针）、常量指针（const指针）、指向常量的常指针（指向const对象的const指针）。</p>\n<h3 id=\"4-1-指针常量（指向const对象的指针）\"><a href=\"#4-1-指针常量（指向const对象的指针）\" class=\"headerlink\" title=\"4.1 指针常量（指向const对象的指针）\"></a>4.1 指针常量（指向const对象的指针）</h3><p>（1）C++为了保证不允许使用指针改变所指的<code>const对象</code>的值的这个特性，强制要求这个指针也必须具备<code>const</code>特性：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr;</span><br></pre></td></tr></table></figure></p>\n<p>这里<code>cptr</code>是一个指向<code>double类型</code>的<code>const对象</code>的指针，<code>const</code>先定义了<code>cptr</code>指向的对象的类型，而并非<code>cptr</code>本身，所以<code>cptr</code>本身并不是<code>const</code>。所以定义的时候并不需要对它进行初始，如果需要的话，允许给<code>cptr</code>重新赋值，让其指向另一个<code>const对象</code>。但不能通过<code>cptr</code>修改其所指对象的值。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*cptr=<span class=\"number\">42</span>; <span class=\"comment\">//error</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）将一个<code>const对象</code>的地址赋给一个普通的<code>非const</code>指针会导致编译错误:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">double</span>* ptr = &amp;pi;        <span class=\"comment\">//error</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr = &amp;pi; <span class=\"comment\">//ok</span></span><br></pre></td></tr></table></figure></p>\n<p>不能使用<code>void*</code>指针保存<code>const对象</code>的地址，必须使用<code>const void*</code>类型的指针保存<code>const</code>对象的地址。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> universe = <span class=\"number\">42</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* cov = &amp;universe; <span class=\"comment\">//ok</span></span><br><span class=\"line\"><span class=\"keyword\">void</span>* pv = &amp;universe;        <span class=\"comment\">//error</span></span><br></pre></td></tr></table></figure></p>\n<p>（3）允许把<code>非const对象</code>的地址赋给指向<code>const对象</code>的指针，例如：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">double</span> dval = <span class=\"number\">3.14</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* cptr = &amp;dval;</span><br></pre></td></tr></table></figure></p>\n<p>但是我们不能通过<code>cptr</code>指针来修改<code>dval</code>的值，即使它指向的是<code>非const对象</code>。</p>\n<h3 id=\"4-2-常指针-const指针\"><a href=\"#4-2-常指针-const指针\" class=\"headerlink\" title=\"4.2 常指针(const指针)\"></a>4.2 常指针(const指针)</h3><p>C++中还提供了<code>const指针</code>——本身的值不能被修改。<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> errNumb = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> curErr = &amp;errNumb; <span class=\"comment\">//curErr是一个const指针</span></span><br></pre></td></tr></table></figure></p>\n<p>我们可以从右往左把上述定义语句读作”指向int型对象的const指针”。与其他<code>const对象</code>一样，<code>const指针</code>的值不能被修改，这意味着不能使<code>curErr</code>指向其他对象。<code>const指针</code>也必须在定义的时候初始化:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curErr = curErr; <span class=\"comment\">//error！即使赋给其相同的值</span></span><br></pre></td></tr></table></figure></p>\n<p> 指针本身是<code>const</code>的事实并没有说明是否能用该指针修改其所指向的对象的值。指针对象的值能否修改完全取决于该对象的类型。</p>\n<h3 id=\"4-3-指向常量的常指针（指向const对象的const指针）\"><a href=\"#4-3-指向常量的常指针（指向const对象的const指针）\" class=\"headerlink\" title=\"4.3 指向常量的常指针（指向const对象的const指针）\"></a>4.3 指向常量的常指针（指向const对象的const指针）</h3><p> 如下可以这样定义：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> pi = <span class=\"number\">3.1415926</span>;</span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span>* <span class=\"keyword\">const</span> pi_ptr = &amp;pi;</span><br></pre></td></tr></table></figure></p>\n<p>这样<code>pi_ptr</code>首先是一个<code>const指针</code>，然后其指向一个<code>const对象</code>。</p>\n<h3 id=\"4-4-小结\"><a href=\"#4-4-小结\" class=\"headerlink\" title=\"4.4 小结\"></a><strong>4.4 小结</strong></h3><p>（1）分清以下四种情况：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> b = <span class=\"number\">500</span>; </span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* a = &amp;b  <span class=\"comment\">//1. 指针常量（指向常量的指针）</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> <span class=\"keyword\">const</span> *a = &amp;b  <span class=\"comment\">//2. 同1</span></span><br><span class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> a = &amp;b  <span class=\"comment\">//3. 常量指针（指针本身为常量，const指针）</span></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> a = &amp;b <span class=\"comment\">//4.指向常量的常指针</span></span><br></pre></td></tr></table></figure></p>\n<p>（2）允许把<code>非const对象</code>的地址赋给指向<code>const对象</code>的指针,不允许把一个 <code>const对象</code>的地址赋给一个<code>非const对象</code>的指针。</p>\n<h2 id=\"5-const和函数\"><a href=\"#5-const和函数\" class=\"headerlink\" title=\"5.const和函数\"></a>5.const和函数</h2><h3 id=\"5-1-类中的const成员函数（常成员函数）\"><a href=\"#5-1-类中的const成员函数（常成员函数）\" class=\"headerlink\" title=\"5.1 类中的const成员函数（常成员函数）\"></a>5.1 类中的const成员函数（常成员函数）</h3><p>（1）使用<code>const</code>关键字进行说明的成员函数，称为<code>常成员函数</code>。在一个类中，任何不会修改数据成员的函数都应该声明为<code>const类型</code>。<br>对于<code>const成员函数</code>：<br>（1）只可读取数据成员，不可修改数据成员；<br>（2）不可调用其它<code>非const成员函数</code>。<br>只有<code>常成员函数</code>才有资格操作<code>常量</code>或<code>常对象</code>，没有使用<code>const</code>关键字说明的成员函数不能用来操作<code>常对象</code>。<br>其中，<code>const</code>是加在函数说明后面的类型修饰符，它是函数类型的一个组成部分，因此，在函数实现部分也要带<code>const</code>关键字。<br>下面举一例子说明常成员函数的特征:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Stack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> m_num;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> m_data[<span class=\"number\">100</span>];</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> elem)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">pop</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetCount</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> <span class=\"keyword\">const</span></span>; <span class=\"comment\">//定义为const成员函数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">int</span> Stack::GetCount(<span class=\"keyword\">void</span>) <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">++m_num;  <span class=\"comment\">//编译错误，企图修改数据成员m_num</span></span><br><span class=\"line\">pop();    <span class=\"comment\">//编译错误，企图修改非const成员函数</span></span><br><span class=\"line\"><span class=\"keyword\">return</span> m_num;<span class=\"comment\">//正确，只能读取同一类中的数据成员的值</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>const对象的成员是不能修改的，而通过指针维护的对象确实可以修改的；<br>const对象只能访问const成员函数，而非const对象可以访问任意的成员函数，包括const成员函数。<br>const成员函数不可以修改对象的数据，不管对象是否具有const性质，编译时以是否修改成员数据为依据进行检查；</p>\n<h3 id=\"5-2-函数重载\"><a href=\"#5-2-函数重载\" class=\"headerlink\" title=\"5.2 函数重载\"></a>5.2 函数重载</h3><p>既然<code>const</code>是定义为<code>const</code>函数的组成部分，那么就可以通过添加<code>const</code>实现函数重载，即：两个成员函数，名字和参数表都一样，但是一个是<code>const</code>，一个不是，算重载。<br>具体调用哪个函数是根据调用对象是<code>常量对象</code>还是<code>非常量对象</code>来决定的。<code>常量对象函数</code>调用<code>常量成员</code>；<code>非常量对象</code>调用<code>非常量成员函数</code>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">R</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    R(<span class=\"keyword\">int</span> r1, <span class=\"keyword\">int</span> r2)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    R1 = r1;</span><br><span class=\"line\">    R2 = r2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> R1,<span class=\"keyword\">int</span> R2;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"keyword\">void</span> R::print()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">cout</span>&lt;&lt;R1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">void</span> R::print() <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">cout</span>&lt;&lt;R2;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"><span class=\"function\">R <span class=\"title\">a</span><span class=\"params\">(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span></span>;</span><br><span class=\"line\">a.print();</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> R <span class=\"title\">b</span><span class=\"params\">(<span class=\"number\">20</span>,<span class=\"number\">52</span>)</span></span>;</span><br><span class=\"line\">b.print();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果为:5,52。<br>其中<code>print</code>成员函数就实现了重载。<code>const对象</code>默认调用<code>const成员函数</code>。</p>\n<h3 id=\"5-3-const修饰函数参数\"><a href=\"#5-3-const修饰函数参数\" class=\"headerlink\" title=\"5.3 const修饰函数参数\"></a>5.3 const修饰函数参数</h3><p>（1）传递过来的参数在函数内不可以改变(无意义，因为<code>var</code>本身就是形参)：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（2）参数指针所指内容为常量不可变：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（3）参数指针本身为常量不可变(也无意义，因为<code>char* var</code>也是形参)<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">char</span>* <span class=\"keyword\">const</span> var)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（4）参数为引用，为了<code>增加效率</code>同时<code>防止修改</code>。修饰引用参数时：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> Class&amp; var)</span></span>; <span class=\"comment\">//引用参数在函数内不可以改变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">func</span><span class=\"params\">(<span class=\"keyword\">const</span> TYPE&amp; var)</span></span>;  <span class=\"comment\">//引用参数在函数内为常量不可变</span></span><br></pre></td></tr></table></figure></p>\n<p>  这样的一个<code>const引用</code>传递和最普通的函数<code>按值传递</code>的效果是一模一样的,他禁止对引用的对象的一切修改。唯一不同的是，<code>按值传递</code>会先建立一个类对象的副本, 然后传递过去,而它直接传递地址,所以这种传递比按值传递更有效。另外只有<code>引用的const传递</code>可以传递一个<code>临时对象</code>,因为<code>临时对象</code>都是<code>const属性</code>, 且是不可见的,他短时间存在一个局部域中,所以不能使用指针,只有<code>引用的const传递</code>能够捕捉到这个家伙.</p>\n<h3 id=\"5-4-const修饰函数返回值\"><a href=\"#5-4-const修饰函数返回值\" class=\"headerlink\" title=\"5.4 const修饰函数返回值\"></a>5.4 const修饰函数返回值</h3><p><code>const</code>修饰函数返回值其实用的并不是很多，它的含义和<code>const</code>修饰<code>普通变量</code>以及指针的含义基本相同。如下所示：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//无意义，因为参数返回本身就是赋值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> <span class=\"title\">func1</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//调用时 const int* pVal = func2(); //必须这样可以理解</span></span><br><span class=\"line\"><span class=\"comment\">//可把func2()看成一个变量，即指针内容不可变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* <span class=\"title\">func2</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//调用时 int* const pVal = func2(); //可以 int* pVal = func2()吧，不可理解</span></span><br><span class=\"line\"><span class=\"comment\">//可把func2()看成一个变量，即指针本身不可变</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> <span class=\"title\">func3</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>（待）一般情况下，函数的返回值为某个对象时，如果将其声明为<code>const</code>时，多用于操作符的重载。</p>\n<h2 id=\"6-const限定符和static的区别（待总结完static来看）\"><a href=\"#6-const限定符和static的区别（待总结完static来看）\" class=\"headerlink\" title=\"6.const限定符和static的区别（待总结完static来看）\"></a>6.const限定符和static的区别（待总结完static来看）</h2><p>const定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。<br>static表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。<br>在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25; static关键字只能用于类定义体内部的声明中，定义时不能标示为static<br>在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。<br>const数据成员,只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。<br>const数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static const。<br>const成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。<br>static成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213512-d6ae0722b2ae42f9b60ed2eff799c6be.png\" alt=\"\"><br>其中关于static、const、static cosnt、const static成员的初始化问题：</p>\n<p>类里的const成员初始化<br> 在一个类里建立一个const时，不能给他初值<br> <img src=\"http://images.cnitblog.com/blog/460416/201310/06213513-3befd1d1772d455a8c46f0f095139d72.png\" alt=\"\"><br> 类里的static成员初始化：<br> 类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：<br>数据类型 类名::静态数据成员名=值<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213513-2d8b85aa88ad47e1b6170dd1d960f5bb.png\" alt=\"\"><br>类里的static cosnt 和 const static成员初始化（这两种写法是一致的！！）<br><img src=\"http://images.cnitblog.com/blog/460416/201310/06213514-e6e0265323ec44d88ab3331af53fb3e2.png\" alt=\"\"><br>   最后通过一个完整的例子展示以上结果：<br>   <img src=\"http://images.cnitblog.com/blog/460416/201310/06213515-ec5f6c035b9748a1a5849853853867e0.png\" alt=\"\"></p>\n<h2 id=\"7-参考\"><a href=\"#7-参考\" class=\"headerlink\" title=\"7.参考\"></a>7.参考</h2><p>1.C++ prime, Stanley<br>2.<a href=\"http://www.cnblogs.com/yc_sunniwell/archive/2010/07/14/1777416.html\" target=\"_blank\" rel=\"noopener\">C/C++中const关键字详解</a><br>3.<a href=\"http://www.cnblogs.com/jiabei521/p/3335676.html\" target=\"_blank\" rel=\"noopener\">C++中const关键字的使用方法</a><br>4.<a href=\"http://blog.csdn.net/wangkai_123456/article/details/76598917\" target=\"_blank\" rel=\"noopener\">C++ const的用法详解</a></p>"},{"title":"排序算法","date":"2017-11-29T01:25:49.000Z","mathjax":true,"top":true,"_content":"# 1.冒泡排序\n## 基本思想\n- 每一轮遍历一次数组：将每个元素与相邻元素比较，将较大者换到后方。每一轮遍历可将一个最大的数换到数组末尾；\n- 进行$len-1$轮遍历后，可确定数组有序。\n\n## [示例](http://louiszhai.github.io/2016/12/23/sort/#快速排序)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.gif\" width=\"70%\" height=\"60%\">\n\n<!-- more --> \n\n## 代码实现\n（1）冒泡排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\nvoid bubbleSort(int arr[], int len)\n{\n    if (arr == nullptr || len<=0)\n        return;\n    for (int i = 0; i < len-1; i++)         //len-1轮遍历\n        for (int j = 0; j < len - i-1; j++) //遍历数组\n        {\n            if (arr[j] > arr[j + 1])\n            {\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n}\n```\n（2）测试代码\n```C++\nint main() \n{\n    int arr[] = { 61, 17, 29, 22, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    bubbleSort(arr, len);\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n1 17 21 22 29 34 50 60 61 62 72\n```\n（3）简单改进\n思路：\n- 在每一轮迭代开始时，设置`flag`变量，初始化为`false`。若发生交换，则置为`true`。\n- 若有一轮迭代中未出现交换，则数组有序，结束排序。\n\n```C++\nvoid bubbleSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 0; i < len - 1; i++)         //len-1轮遍历\n    {\n        bool flag = false;                    //flag初始化为false\n        for (int j = 0; j < len - i - 1; j++) //遍历数组\n        {\n            if (arr[j] > arr[j + 1])\n            {\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n                flag = true;                  //若发生一次交换，则falg置为true\n            }\n        }\n        if (flag == false)                    //该轮迭代，未进行任何交换，数组已经有序\n            break;\n    }\n}\n```\n## 性能分析\n（1）时间复杂度\n对于设置标志变量`flag`之后的冒泡排序：\n- 最好情况下的时间复杂度为$O(n)$：\n - 当待排序列已有序时，总的比较次数为$n-1$，移动次数为0。\n- 最坏情况下的时间复杂度为$O(n^2)$；\n - 当待排序列逆序时，总的比较次数为$n(n-1)/2$，移动次数为$3n(n-1)/2$次。\n- 平均情况下的时间复杂度为$O(n^2)$。\n\n（2）空间复杂度\n空间复杂度为$O(1)$:\n - 冒泡排序排序过程中需要一个临时变量进行两两交换，所需要的额外空间为1。\n\n（3）稳定性\n冒泡排序在排序过程中，元素两两交换时，相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。\n\n# 2.选择排序\n## 基本思想\n- 每轮以第$i$个元素位置为初始最小值位置，选择出后方剩余元素中的最小值位置，将最小值元素与元素$i$交换；\n- 令$i$从$0$到$len-2$，进行$len-1$次选择和交换，即可使数组有序。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#算法思路-4)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F2.gif\" width=\"50%\" height=\"50%\">\n## 代码实现\n（1）选择排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid selectionSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 0; i < len - 1; i++)   //令i从0到len−2，进行len−1次选择和交换\n    { \n        int minIndex = i;\n        for (int j = i; j <len ; j++)\n        {\n            if (arr[j] < arr[minIndex])\n            {\n                minIndex = j;\n            }\n        }\n        int temp = arr[i];\n        arr[i] = arr[minIndex];\n        arr[minIndex] = temp;\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 61, 17, 29, 22, 100, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    selectionSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n61 17 29 22 100 34 60 72 21 50 1 62\n排序后序列：\n1 17 21 22 29 34 50 60 61 62 72 100\n```\n\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n^2)$（平均情况、最好情况、最坏情况下）。\n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n是不稳定的排序算法。\n- 原始序列：$8, 25, 25^*, 2$\n- 排序后：$2, 8, 25^*, 25$\n- 两个25的相对位置变化了，所以是不稳定的。\n\n# 3.插入排序\n## 基本思想\n- 以第0位置元素为有序部分，其余为无序部分。从第$i=1$个元素开始，逐个插入前方有序部分；\n- 对于每一轮插入，起始位置第$i$个位置元素的值记为`val`，$i$位置索引记为`hole`，若`hole`前方元素大于`val`，则将`hole`前方元素后移（`hole`前移），直到`hole`前方元素比`val`值小或`hole`为0，则`hole`位置确定。将`val`值插入`hole`处。每一轮插入，使得有序部分扩大1位。\n- 令$i$从1到$len−1$，经过$len-1$轮插入，可确定序列有序。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#实例演示-2)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F2.gif\" width=\"60%\" height=\"60%\">\n\n## 代码实现\n（1）插入排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid insertionSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 1; i < len; i++)             //令i从1到len−1，经过len−1轮插入\n    {\n        int val = arr[i];\n        int hole = i;\n        while (hole>0 && arr[hole - 1] > val) //直到hole前方元素比val值小或hole为0\n        {\n            arr[hole] = arr[hole-1];\n            hole--;\n        }\n        arr[hole] = val;\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 61, 17, 29, 22, 100, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    insertionSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n61 17 29 22 100 34 60 72 21 50 1 62\n排序后序列：\n1 17 21 22 29 34 50 60 61 62 72 100\n```\n## 性能分析\n（1）时间复杂度\n- 最好情况下的时间复杂度为$O(n)$：\n - 当待排序列已经有序时。\n- 最坏情况下的时间复杂度为$O(n^2)$：\n - 当待排序列“逆序”时。\n- 平均时间复杂度为$O(n^2)$；\n\n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n是稳定的排序算法。\n\n# 4.希尔排序\n## 基本思想\n- 选择希尔增量序列（$$D_M=N/2,D_{M-1}=D_M/2,...,1$$）。\n- 进行$D$间隔的插入排序。\n\n## 示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F.gif\" width=\"60%\" height=\"60%\">\n\n## 代码实现\n（1）希尔排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid shellSort(int arr[], int len)\n{\n    for (int d = len/2; d > 0; d /= 2)          //希尔增量序列\n        for (int i = 0; i < len; i += d)        //d间隔的插入排序\n        {\n            int val = arr[i];\n            int hole = i;\n            while (hole>=d && arr[hole - d] > val)\n            {\n                arr[hole] = arr[hole - d];\n                hole -= d;\n            }\n            arr[hole] = val;\n        }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 0 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    shellSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 0\n排序后序列：\n0 1 10 20 30 60 70 100\n```\n\n## 性能分析\n（1）时间复杂度\n不同的增量序列，会得到不同的时间复杂度。且对于很多增量序列，其时间复杂度无法准确给出。\n（2）空间复杂度\n空间复杂度为O(1)。\n（3）稳定性\n不稳定。\n- 单次直接插入排序是稳定的，它不会改变相同元素之间的相对顺序，但在多次不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，可能导致相同元素相对顺序发生变化。因此，希尔排序并不稳定。\n\n# 5.归并排序\n## 基本思想\n- 分治：通过新建存储空间，将原始数组分成左右两个数组，再**递归分解**左半部分，**递归分解**又半部分，直到得到大小为1的数组（也即递归出口条件）。对于各大小为1的小数组来说，它们各自都是有序的。\n- 归并：将左右两个有序的小数组，归并成一个有序大数组。\n\n## [示例](https://zh.wikipedia.org/wiki/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif\" width=\"40%\" height=\"40%\">\n\n## 代码实现\n（1）归并排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid merge(int arr[], int left[], int right[], int leftLength, int rightLength)\n{\n    // i用于标记arr数组索引\n    // j用于标记left数组索引\n    // k用于标记right数组索引\n    int i, j, k;    \n    i = j = k = 0;\n    while (j < leftLength && k < rightLength)\n    {\n        if (left[j] <= right[k]) arr[i++] = left[j++]; //当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性\n        else arr[i++] = right[k++];\n    }\n    while(j < leftLength) arr[i++] = left[j++];\n    while(k < rightLength) arr[i++] = right[k++];\n}\n\nvoid mergeSort(int arr[], int len)\n{\n    if (arr == nullptr || len < 2)                    //防御型编程及出口条件\n        return;\n    int leftLength = len / 2;\n    int rightLength = len - leftLength;\n    int* left = new int[leftLength];\n    int* right = new int[rightLength];\n    for (int i = 0; i < leftLength; i++)\n        left[i] = arr[i];\n    for (int i = leftLength; i < len; i++)\n        right[i-leftLength] = arr[i];\n    mergeSort(left, leftLength);                       //排序left数组\n    mergeSort(right, rightLength);                     //排序right数组\n    merge(arr,left, right, leftLength, rightLength);   //归并left数组和right数组成arr数组\n    delete[] left;\n    delete[] right;\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = {60, 10, 20, 100, 30, 70, 1};\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    mergeSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1\n排序后序列：\n1 10 20 30 60 70 100\n```\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n\\log n)$。(最好情况，最坏情况及平均情况下)\n（2）空间复杂度\n空间复杂度为$O(n)$。\n- 为了进行归并操作，需要开辟辅助空间。\n- 归并排序每次递归都要用到一个辅助表，长度与待排序的表长度相同，虽然递归次数是$O(log2n)$，但每次递归都会释放掉所占的辅助空间，所以下次递归的栈空间和辅助空间与这部分释放的空间就不相关了，因而空间复杂度还是$O(n)$。\n\n（3）稳定性\n是稳定的排序算法。\n- 在归并时，当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性。\n\n# 6.快速排序\n## [基本思想](https://royalbluewa3.cc/posts/67d771c4/#JS实现-5)\n- 从数组中选择一个元素作为”基准”(`pivot`)。\n- 分区(`partition`)：所有小于`pivot`的元素，都移其左侧至；所有大于`pivot`的元素，都移到其右侧。**一次分区操作结束后，`pivot`所处的位置就是最终排序后它的位置**。\n- 分治：对`pivot`左右两侧子集，分别递归执行上述两个步骤，直至所有子集只剩下一个元素为止（递归出口条件）。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#实例演示-6)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.gif\" width=\"65%\" height=\"55%\">\n\n## 代码实现\n（1）快速排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid swap(int arr[], int a, int b) \n{\n    int temp = arr[a];\n    arr[a] = arr[b];\n    arr[b] = temp;\n}\n\nint partition(int arr[], int start, int end)\n{\n    int pivot = arr[end];             //选取数组end位置元素为基准元素pivot\n    int pIndex = start;               //初始化pIndex为start\n    for (int i = start; i < end; i++) //从左至右遍历(除了最后的pivot)\n    {\n        if (arr[i] <= pivot)          //所有小于等于pivot的元素与pIndex所指向的元素交换位置\n        {\n            swap(arr, i, pIndex);\n            pIndex++;                  //一次交换后pIndex+1\n        }\n    }\n    swap(arr, pIndex, end);           //循环结束,交换pivot与pIndex指向元素的位置\n    return pIndex;\n}\n\n//随机选择一个基准元素pivot，然后将基准元素交换到数组end位置\nint randomizedPartition(int arr[], int start, int end)\n{\n    int pIndex = (rand() % (end - start + 1)) + start;\n    swap(arr, pIndex, end);\n    return partition(arr, start, end);\n}\n\nvoid quickSort(int arr[], int start, int end)\n{\n    if (start >= end)\n        return;\n    int pIndex = randomizedPartition(arr, start, end);\n    quickSort(arr, start, pIndex - 1);\n    quickSort(arr, pIndex + 1, end);\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 0 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n\tcout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    quickSort(arr, 0,len-1);\n\tcout << \"排序后序列：\" << endl;\n\tfor (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n\tcout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 0\n排序后序列：\n0 1 10 20 30 60 70 100\n```\n## [性能分析](http://harttle.land/2015/09/27/quick-sort.html)\n（1）时间复杂度\n- 平均时间复杂度：$O(n \\log n)$\n- 最好情况：$O(n \\log n)$\n- 最坏情况：$O(n^2)$\n\n注：上述快速排序的代码实现中，通过随机选取基准元素`pivot`，避免了最坏情况的发生。\n（2）空间复杂度\n- 最好情况：$O(\\log n)$\n - 注：因为快速排序的实现是递归调用的，而且每次函数调用中只使用了常数的空间，因此空间复杂度等于递归深度$O(\\log n)$。\n- 最坏情况下：$O(n)$\n - 注：上述快速排序的代码实现中，通过随机选取基准元素`pivot`，避免了最坏情况的发生。\n \n（3）稳定性\n不稳定。\n- 在分区操作中，小于等于`pivot`的元素分到左侧,大于`pivot`的元素分到右侧。\n- 若对于序列`a,b`，其中`a`和`b`相等。如果选到了`a`为`pivot`,那么在`b<=a`的情况下,`b`将会排在`a`的前面。\n- 因为有这样的可能性,所以快速排序算法是不稳定的。\n\n（4）评价\n它是处理大数据最快的排序算法之一。虽然快速排序最坏情况下的时间复杂度达到了$O(n^2)$，比如说顺序数列的快排。但它的期望时间是$O(nlogn)$，且O(nlogn)记号中隐含的常数因子很小，比复杂度稳定等于$O(nlogn)$的归并排序要小很多。所以对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。\n\n# 7.堆排序\n## [基本思想](https://royalbluewa3.cc/posts/67d771c4/#算法思路及演示)\n- 定义最大堆堆化函数(`maxHeapify`)：**保持**最大堆性质，是创建最大堆的核心子程序。\n- 创建最大堆(`buildMaxHeap`)：将一个数组改造成一个最大堆，接受数组和堆大小两个参数，`buildMaxHeap`将**自下而上**的调用`maxHeapify`来改造数组，建立最大堆。因为`maxHeapify`能够保证下标为$i$的结点之后的结点都满足最大堆的性质，所以自下而上的调用`maxHeapify`能够在改造过程中保持这一性质。如果最大堆的数量元素是$n$，那么`buildMaxHeap`从$Parent(n)$开始，往上依次调用`maxHeapify`。\n - 注：对于数组，下标从0开始，则对于给定的某结点的下标$i$，容易计算出该结点的父结点、子结点的下标：\n ```C++\n Parent(i) = floor((i - 1) / 2)     // i 的父节点下标\n Left(i) = 2i + 1                   // i 的左子节点下标\n Right(i) = 2(i + 1)                // i 的右子节点下标\n ```\n- 堆排序(`heapSort`)：`heapSort`先调用`buildMaxHeap`将数组改造为最大堆，然后将堆顶和堆底元素交换，之后将底部上升，最后重新调用`maxHeapify`保持最大堆性质。由于堆顶元素必然是堆中最大的元素，所以一次操作之后，堆中存在的最大元素被分离出堆，置于数组尾部，重复$n-1$次之后，数组排列完毕。\n\n## 示例\n最大堆堆化(`maxHeapify`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E5%A0%86%E5%A0%86%E5%8C%96.png\" width=\"50%\" height=\"50%\">\n创建最大堆(`buildMaxHeap`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%88%9B%E5%BB%BA%E6%9C%80%E5%A4%A7%E5%A0%86.png\" width=\"50%\" height=\"50%\">\n堆排序(`heapSort`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F.png\" width=\"50%\" height=\"50%\">\n\n## 代码实现\n（1）堆排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid swap(int arr[], int a, int b)\n{\n    int temp = arr[a];\n    arr[a] = arr[b];\n    arr[b] = temp;\n}\n\nvoid maxHeapify(int arr[], int index, int heapSize)\n{\n    int iMax, iLeft, iRight;\n    while (true)\n    {\n        iMax = index;\n        iLeft = 2 * index + 1;\n        iRight = 2 * index + 2;\n        if (iLeft < heapSize && arr[iLeft] > arr[iMax])\n            iMax = iLeft;\n        if (iRight <heapSize && arr[iRight]>arr[iMax])\n            iMax = iRight;\n        if (iMax != index)\n        {\n            swap(arr, iMax, index);\n            index = iMax;\n        }\n        else break;                         //若未发生交换，则已是最大堆\n    }\n}\n\nvoid buildMaxHeap(int arr[], int heapSize)\n{\n    int iParent = (heapSize - 2) / 2;       //自下而上的调用maxHeapify来改造数组\n    for (int i = iParent; i >= 0; i--)\n    {\n        maxHeapify(arr, i, heapSize);\n    }\n}\n\nvoid heapSort(int arr[], int heapSize)\n{\n    buildMaxHeap(arr, heapSize);\n    for (int i = heapSize - 1; i > 0; i--)   \n    {\n        swap(arr, 0, i);                     //将堆顶和堆底元素交换\n        maxHeapify(arr, 0, i);               //底部上升后，调用maxHeapify\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 88 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    heapSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 88\n排序后序列：\n1 10 20 30 60 70 88 100\n```\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n\\log n)$。\n - 1.建立堆的过程, 从length/2 一直处理到0, 时间复杂度为$O(n)$;\n - 2.调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为$O(\\log n)$;\n - 3.堆排序的过程由$n$次第2步完成, 时间复杂度为$O(n\\log n)$。\n \n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n不稳定。\n\n# 8.排序算法性能对比\n\n|排序类型|\t平均情况|\t最好情况|\t最坏情况|\t辅助空间|\t稳定性|\n|:--:|:--:|:--:|:--:|:--:|:--:|\n|冒泡排序|\t$O(n^2)$|\t$O(n)$|\t$O(n^2)$|\t$O(1)$|\t稳定|\n|选择排序|\t$O(n^2)$|\t$O(n^2)$|\t$O(n^2)$|\t$O(1)$|\t不稳定|\n|插入排序|\t$O(n^2)$|\t$O(n)$|\t$O(n^2)$|\t$O(1)$|\t稳定|\n|希尔排序|\t-|\t-|\t-|\t$O(1)$|\t不稳定|\n|归并排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n)$|\t稳定|\n|快速排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n^2)$|\t$O(\\log n)$|\t不稳定|\n|堆排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(1)$|\t不稳定|\n\n# 9.参考\n- [Sorting Algorithms, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwKedT2KfDMB9YA5DgASZb3U)\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [常见排序算法总结（javascript实现），Digital Station](https://royalbluewa3.cc/posts/67d771c4/#实例演示-1)\n","source":"_posts/排序算法.md","raw":"---\ntitle: 排序算法\ndate: 2017-11-29 9:25:49\nmathjax: true\ntop: true\ncategories: \n- 数据结构与算法\ntags:\n---\n# 1.冒泡排序\n## 基本思想\n- 每一轮遍历一次数组：将每个元素与相邻元素比较，将较大者换到后方。每一轮遍历可将一个最大的数换到数组末尾；\n- 进行$len-1$轮遍历后，可确定数组有序。\n\n## [示例](http://louiszhai.github.io/2016/12/23/sort/#快速排序)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.gif\" width=\"70%\" height=\"60%\">\n\n<!-- more --> \n\n## 代码实现\n（1）冒泡排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\nvoid bubbleSort(int arr[], int len)\n{\n    if (arr == nullptr || len<=0)\n        return;\n    for (int i = 0; i < len-1; i++)         //len-1轮遍历\n        for (int j = 0; j < len - i-1; j++) //遍历数组\n        {\n            if (arr[j] > arr[j + 1])\n            {\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }\n}\n```\n（2）测试代码\n```C++\nint main() \n{\n    int arr[] = { 61, 17, 29, 22, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    bubbleSort(arr, len);\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n1 17 21 22 29 34 50 60 61 62 72\n```\n（3）简单改进\n思路：\n- 在每一轮迭代开始时，设置`flag`变量，初始化为`false`。若发生交换，则置为`true`。\n- 若有一轮迭代中未出现交换，则数组有序，结束排序。\n\n```C++\nvoid bubbleSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 0; i < len - 1; i++)         //len-1轮遍历\n    {\n        bool flag = false;                    //flag初始化为false\n        for (int j = 0; j < len - i - 1; j++) //遍历数组\n        {\n            if (arr[j] > arr[j + 1])\n            {\n                int temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n                flag = true;                  //若发生一次交换，则falg置为true\n            }\n        }\n        if (flag == false)                    //该轮迭代，未进行任何交换，数组已经有序\n            break;\n    }\n}\n```\n## 性能分析\n（1）时间复杂度\n对于设置标志变量`flag`之后的冒泡排序：\n- 最好情况下的时间复杂度为$O(n)$：\n - 当待排序列已有序时，总的比较次数为$n-1$，移动次数为0。\n- 最坏情况下的时间复杂度为$O(n^2)$；\n - 当待排序列逆序时，总的比较次数为$n(n-1)/2$，移动次数为$3n(n-1)/2$次。\n- 平均情况下的时间复杂度为$O(n^2)$。\n\n（2）空间复杂度\n空间复杂度为$O(1)$:\n - 冒泡排序排序过程中需要一个临时变量进行两两交换，所需要的额外空间为1。\n\n（3）稳定性\n冒泡排序在排序过程中，元素两两交换时，相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。\n\n# 2.选择排序\n## 基本思想\n- 每轮以第$i$个元素位置为初始最小值位置，选择出后方剩余元素中的最小值位置，将最小值元素与元素$i$交换；\n- 令$i$从$0$到$len-2$，进行$len-1$次选择和交换，即可使数组有序。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#算法思路-4)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F2.gif\" width=\"50%\" height=\"50%\">\n## 代码实现\n（1）选择排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid selectionSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 0; i < len - 1; i++)   //令i从0到len−2，进行len−1次选择和交换\n    { \n        int minIndex = i;\n        for (int j = i; j <len ; j++)\n        {\n            if (arr[j] < arr[minIndex])\n            {\n                minIndex = j;\n            }\n        }\n        int temp = arr[i];\n        arr[i] = arr[minIndex];\n        arr[minIndex] = temp;\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 61, 17, 29, 22, 100, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    selectionSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n61 17 29 22 100 34 60 72 21 50 1 62\n排序后序列：\n1 17 21 22 29 34 50 60 61 62 72 100\n```\n\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n^2)$（平均情况、最好情况、最坏情况下）。\n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n是不稳定的排序算法。\n- 原始序列：$8, 25, 25^*, 2$\n- 排序后：$2, 8, 25^*, 25$\n- 两个25的相对位置变化了，所以是不稳定的。\n\n# 3.插入排序\n## 基本思想\n- 以第0位置元素为有序部分，其余为无序部分。从第$i=1$个元素开始，逐个插入前方有序部分；\n- 对于每一轮插入，起始位置第$i$个位置元素的值记为`val`，$i$位置索引记为`hole`，若`hole`前方元素大于`val`，则将`hole`前方元素后移（`hole`前移），直到`hole`前方元素比`val`值小或`hole`为0，则`hole`位置确定。将`val`值插入`hole`处。每一轮插入，使得有序部分扩大1位。\n- 令$i$从1到$len−1$，经过$len-1$轮插入，可确定序列有序。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#实例演示-2)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F2.gif\" width=\"60%\" height=\"60%\">\n\n## 代码实现\n（1）插入排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid insertionSort(int arr[], int len)\n{\n    if (arr == nullptr || len <= 0)\n        return;\n    for (int i = 1; i < len; i++)             //令i从1到len−1，经过len−1轮插入\n    {\n        int val = arr[i];\n        int hole = i;\n        while (hole>0 && arr[hole - 1] > val) //直到hole前方元素比val值小或hole为0\n        {\n            arr[hole] = arr[hole-1];\n            hole--;\n        }\n        arr[hole] = val;\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 61, 17, 29, 22, 100, 34, 60, 72, 21, 50, 1, 62 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    insertionSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n61 17 29 22 100 34 60 72 21 50 1 62\n排序后序列：\n1 17 21 22 29 34 50 60 61 62 72 100\n```\n## 性能分析\n（1）时间复杂度\n- 最好情况下的时间复杂度为$O(n)$：\n - 当待排序列已经有序时。\n- 最坏情况下的时间复杂度为$O(n^2)$：\n - 当待排序列“逆序”时。\n- 平均时间复杂度为$O(n^2)$；\n\n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n是稳定的排序算法。\n\n# 4.希尔排序\n## 基本思想\n- 选择希尔增量序列（$$D_M=N/2,D_{M-1}=D_M/2,...,1$$）。\n- 进行$D$间隔的插入排序。\n\n## 示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F.gif\" width=\"60%\" height=\"60%\">\n\n## 代码实现\n（1）希尔排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid shellSort(int arr[], int len)\n{\n    for (int d = len/2; d > 0; d /= 2)          //希尔增量序列\n        for (int i = 0; i < len; i += d)        //d间隔的插入排序\n        {\n            int val = arr[i];\n            int hole = i;\n            while (hole>=d && arr[hole - d] > val)\n            {\n                arr[hole] = arr[hole - d];\n                hole -= d;\n            }\n            arr[hole] = val;\n        }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 0 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    shellSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 0\n排序后序列：\n0 1 10 20 30 60 70 100\n```\n\n## 性能分析\n（1）时间复杂度\n不同的增量序列，会得到不同的时间复杂度。且对于很多增量序列，其时间复杂度无法准确给出。\n（2）空间复杂度\n空间复杂度为O(1)。\n（3）稳定性\n不稳定。\n- 单次直接插入排序是稳定的，它不会改变相同元素之间的相对顺序，但在多次不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，可能导致相同元素相对顺序发生变化。因此，希尔排序并不稳定。\n\n# 5.归并排序\n## 基本思想\n- 分治：通过新建存储空间，将原始数组分成左右两个数组，再**递归分解**左半部分，**递归分解**又半部分，直到得到大小为1的数组（也即递归出口条件）。对于各大小为1的小数组来说，它们各自都是有序的。\n- 归并：将左右两个有序的小数组，归并成一个有序大数组。\n\n## [示例](https://zh.wikipedia.org/wiki/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif\" width=\"40%\" height=\"40%\">\n\n## 代码实现\n（1）归并排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid merge(int arr[], int left[], int right[], int leftLength, int rightLength)\n{\n    // i用于标记arr数组索引\n    // j用于标记left数组索引\n    // k用于标记right数组索引\n    int i, j, k;    \n    i = j = k = 0;\n    while (j < leftLength && k < rightLength)\n    {\n        if (left[j] <= right[k]) arr[i++] = left[j++]; //当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性\n        else arr[i++] = right[k++];\n    }\n    while(j < leftLength) arr[i++] = left[j++];\n    while(k < rightLength) arr[i++] = right[k++];\n}\n\nvoid mergeSort(int arr[], int len)\n{\n    if (arr == nullptr || len < 2)                    //防御型编程及出口条件\n        return;\n    int leftLength = len / 2;\n    int rightLength = len - leftLength;\n    int* left = new int[leftLength];\n    int* right = new int[rightLength];\n    for (int i = 0; i < leftLength; i++)\n        left[i] = arr[i];\n    for (int i = leftLength; i < len; i++)\n        right[i-leftLength] = arr[i];\n    mergeSort(left, leftLength);                       //排序left数组\n    mergeSort(right, rightLength);                     //排序right数组\n    merge(arr,left, right, leftLength, rightLength);   //归并left数组和right数组成arr数组\n    delete[] left;\n    delete[] right;\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = {60, 10, 20, 100, 30, 70, 1};\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    mergeSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1\n排序后序列：\n1 10 20 30 60 70 100\n```\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n\\log n)$。(最好情况，最坏情况及平均情况下)\n（2）空间复杂度\n空间复杂度为$O(n)$。\n- 为了进行归并操作，需要开辟辅助空间。\n- 归并排序每次递归都要用到一个辅助表，长度与待排序的表长度相同，虽然递归次数是$O(log2n)$，但每次递归都会释放掉所占的辅助空间，所以下次递归的栈空间和辅助空间与这部分释放的空间就不相关了，因而空间复杂度还是$O(n)$。\n\n（3）稳定性\n是稳定的排序算法。\n- 在归并时，当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性。\n\n# 6.快速排序\n## [基本思想](https://royalbluewa3.cc/posts/67d771c4/#JS实现-5)\n- 从数组中选择一个元素作为”基准”(`pivot`)。\n- 分区(`partition`)：所有小于`pivot`的元素，都移其左侧至；所有大于`pivot`的元素，都移到其右侧。**一次分区操作结束后，`pivot`所处的位置就是最终排序后它的位置**。\n- 分治：对`pivot`左右两侧子集，分别递归执行上述两个步骤，直至所有子集只剩下一个元素为止（递归出口条件）。\n\n## [示例](https://royalbluewa3.cc/posts/67d771c4/#实例演示-6)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.gif\" width=\"65%\" height=\"55%\">\n\n## 代码实现\n（1）快速排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid swap(int arr[], int a, int b) \n{\n    int temp = arr[a];\n    arr[a] = arr[b];\n    arr[b] = temp;\n}\n\nint partition(int arr[], int start, int end)\n{\n    int pivot = arr[end];             //选取数组end位置元素为基准元素pivot\n    int pIndex = start;               //初始化pIndex为start\n    for (int i = start; i < end; i++) //从左至右遍历(除了最后的pivot)\n    {\n        if (arr[i] <= pivot)          //所有小于等于pivot的元素与pIndex所指向的元素交换位置\n        {\n            swap(arr, i, pIndex);\n            pIndex++;                  //一次交换后pIndex+1\n        }\n    }\n    swap(arr, pIndex, end);           //循环结束,交换pivot与pIndex指向元素的位置\n    return pIndex;\n}\n\n//随机选择一个基准元素pivot，然后将基准元素交换到数组end位置\nint randomizedPartition(int arr[], int start, int end)\n{\n    int pIndex = (rand() % (end - start + 1)) + start;\n    swap(arr, pIndex, end);\n    return partition(arr, start, end);\n}\n\nvoid quickSort(int arr[], int start, int end)\n{\n    if (start >= end)\n        return;\n    int pIndex = randomizedPartition(arr, start, end);\n    quickSort(arr, start, pIndex - 1);\n    quickSort(arr, pIndex + 1, end);\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 0 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n\tcout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    quickSort(arr, 0,len-1);\n\tcout << \"排序后序列：\" << endl;\n\tfor (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n\tcout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 0\n排序后序列：\n0 1 10 20 30 60 70 100\n```\n## [性能分析](http://harttle.land/2015/09/27/quick-sort.html)\n（1）时间复杂度\n- 平均时间复杂度：$O(n \\log n)$\n- 最好情况：$O(n \\log n)$\n- 最坏情况：$O(n^2)$\n\n注：上述快速排序的代码实现中，通过随机选取基准元素`pivot`，避免了最坏情况的发生。\n（2）空间复杂度\n- 最好情况：$O(\\log n)$\n - 注：因为快速排序的实现是递归调用的，而且每次函数调用中只使用了常数的空间，因此空间复杂度等于递归深度$O(\\log n)$。\n- 最坏情况下：$O(n)$\n - 注：上述快速排序的代码实现中，通过随机选取基准元素`pivot`，避免了最坏情况的发生。\n \n（3）稳定性\n不稳定。\n- 在分区操作中，小于等于`pivot`的元素分到左侧,大于`pivot`的元素分到右侧。\n- 若对于序列`a,b`，其中`a`和`b`相等。如果选到了`a`为`pivot`,那么在`b<=a`的情况下,`b`将会排在`a`的前面。\n- 因为有这样的可能性,所以快速排序算法是不稳定的。\n\n（4）评价\n它是处理大数据最快的排序算法之一。虽然快速排序最坏情况下的时间复杂度达到了$O(n^2)$，比如说顺序数列的快排。但它的期望时间是$O(nlogn)$，且O(nlogn)记号中隐含的常数因子很小，比复杂度稳定等于$O(nlogn)$的归并排序要小很多。所以对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。\n\n# 7.堆排序\n## [基本思想](https://royalbluewa3.cc/posts/67d771c4/#算法思路及演示)\n- 定义最大堆堆化函数(`maxHeapify`)：**保持**最大堆性质，是创建最大堆的核心子程序。\n- 创建最大堆(`buildMaxHeap`)：将一个数组改造成一个最大堆，接受数组和堆大小两个参数，`buildMaxHeap`将**自下而上**的调用`maxHeapify`来改造数组，建立最大堆。因为`maxHeapify`能够保证下标为$i$的结点之后的结点都满足最大堆的性质，所以自下而上的调用`maxHeapify`能够在改造过程中保持这一性质。如果最大堆的数量元素是$n$，那么`buildMaxHeap`从$Parent(n)$开始，往上依次调用`maxHeapify`。\n - 注：对于数组，下标从0开始，则对于给定的某结点的下标$i$，容易计算出该结点的父结点、子结点的下标：\n ```C++\n Parent(i) = floor((i - 1) / 2)     // i 的父节点下标\n Left(i) = 2i + 1                   // i 的左子节点下标\n Right(i) = 2(i + 1)                // i 的右子节点下标\n ```\n- 堆排序(`heapSort`)：`heapSort`先调用`buildMaxHeap`将数组改造为最大堆，然后将堆顶和堆底元素交换，之后将底部上升，最后重新调用`maxHeapify`保持最大堆性质。由于堆顶元素必然是堆中最大的元素，所以一次操作之后，堆中存在的最大元素被分离出堆，置于数组尾部，重复$n-1$次之后，数组排列完毕。\n\n## 示例\n最大堆堆化(`maxHeapify`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E5%A0%86%E5%A0%86%E5%8C%96.png\" width=\"50%\" height=\"50%\">\n创建最大堆(`buildMaxHeap`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%88%9B%E5%BB%BA%E6%9C%80%E5%A4%A7%E5%A0%86.png\" width=\"50%\" height=\"50%\">\n堆排序(`heapSort`)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F.png\" width=\"50%\" height=\"50%\">\n\n## 代码实现\n（1）堆排序代码实现\n```C++\n#include <iostream>\nusing namespace std;\n\nvoid swap(int arr[], int a, int b)\n{\n    int temp = arr[a];\n    arr[a] = arr[b];\n    arr[b] = temp;\n}\n\nvoid maxHeapify(int arr[], int index, int heapSize)\n{\n    int iMax, iLeft, iRight;\n    while (true)\n    {\n        iMax = index;\n        iLeft = 2 * index + 1;\n        iRight = 2 * index + 2;\n        if (iLeft < heapSize && arr[iLeft] > arr[iMax])\n            iMax = iLeft;\n        if (iRight <heapSize && arr[iRight]>arr[iMax])\n            iMax = iRight;\n        if (iMax != index)\n        {\n            swap(arr, iMax, index);\n            index = iMax;\n        }\n        else break;                         //若未发生交换，则已是最大堆\n    }\n}\n\nvoid buildMaxHeap(int arr[], int heapSize)\n{\n    int iParent = (heapSize - 2) / 2;       //自下而上的调用maxHeapify来改造数组\n    for (int i = iParent; i >= 0; i--)\n    {\n        maxHeapify(arr, i, heapSize);\n    }\n}\n\nvoid heapSort(int arr[], int heapSize)\n{\n    buildMaxHeap(arr, heapSize);\n    for (int i = heapSize - 1; i > 0; i--)   \n    {\n        swap(arr, 0, i);                     //将堆顶和堆底元素交换\n        maxHeapify(arr, 0, i);               //底部上升后，调用maxHeapify\n    }\n}\n```\n（2）测试代码\n```C++\nint main()\n{\n    int arr[] = { 60, 10, 20, 100, 30, 70, 1, 88 };\n    int len = (int) sizeof(arr) / sizeof(*arr);\n    cout << \"原序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    heapSort(arr, len);\n    cout << \"排序后序列：\" << endl;\n    for (int i = 0; i < len; i++)\n        cout << arr[i] << ' ';\n    cout << endl;\n    return 0;\n}\n```\n测试结果：\n```\n原序列：\n60 10 20 100 30 70 1 88\n排序后序列：\n1 10 20 30 60 70 88 100\n```\n## 性能分析\n（1）时间复杂度\n时间复杂度为$O(n\\log n)$。\n - 1.建立堆的过程, 从length/2 一直处理到0, 时间复杂度为$O(n)$;\n - 2.调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为$O(\\log n)$;\n - 3.堆排序的过程由$n$次第2步完成, 时间复杂度为$O(n\\log n)$。\n \n（2）空间复杂度\n空间复杂度为$O(1)$。\n（3）稳定性\n不稳定。\n\n# 8.排序算法性能对比\n\n|排序类型|\t平均情况|\t最好情况|\t最坏情况|\t辅助空间|\t稳定性|\n|:--:|:--:|:--:|:--:|:--:|:--:|\n|冒泡排序|\t$O(n^2)$|\t$O(n)$|\t$O(n^2)$|\t$O(1)$|\t稳定|\n|选择排序|\t$O(n^2)$|\t$O(n^2)$|\t$O(n^2)$|\t$O(1)$|\t不稳定|\n|插入排序|\t$O(n^2)$|\t$O(n)$|\t$O(n^2)$|\t$O(1)$|\t稳定|\n|希尔排序|\t-|\t-|\t-|\t$O(1)$|\t不稳定|\n|归并排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n)$|\t稳定|\n|快速排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n^2)$|\t$O(\\log n)$|\t不稳定|\n|堆排序|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(n\\log n)$|\t$O(1)$|\t不稳定|\n\n# 9.参考\n- [Sorting Algorithms, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwKedT2KfDMB9YA5DgASZb3U)\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [常见排序算法总结（javascript实现），Digital Station](https://royalbluewa3.cc/posts/67d771c4/#实例演示-1)\n","slug":"排序算法","published":1,"updated":"2018-01-31T13:39:48.032Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w1f004uqslp6rk57en2","content":"<h1 id=\"1-冒泡排序\"><a href=\"#1-冒泡排序\" class=\"headerlink\" title=\"1.冒泡排序\"></a>1.冒泡排序</h1><h2 id=\"基本思想\"><a href=\"#基本思想\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>每一轮遍历一次数组：将每个元素与相邻元素比较，将较大者换到后方。每一轮遍历可将一个最大的数换到数组末尾；</li>\n<li>进行$len-1$轮遍历后，可确定数组有序。</li>\n</ul>\n<h2 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><a href=\"http://louiszhai.github.io/2016/12/23/sort/#快速排序\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.gif\" width=\"70%\" height=\"60%\"></p>\n<a id=\"more\"></a> \n<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）冒泡排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bubbleSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len&lt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len<span class=\"number\">-1</span>; i++)         <span class=\"comment\">//len-1轮遍历</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; len - i<span class=\"number\">-1</span>; j++) <span class=\"comment\">//遍历数组</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &gt; arr[j + <span class=\"number\">1</span>])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = arr[j];</span><br><span class=\"line\">                arr[j] = arr[j + <span class=\"number\">1</span>];</span><br><span class=\"line\">                arr[j + <span class=\"number\">1</span>] = temp;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    bubbleSort(arr, len);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72</span><br></pre></td></tr></table></figure></p>\n<p>（3）简单改进<br>思路：</p>\n<ul>\n<li>在每一轮迭代开始时，设置<code>flag</code>变量，初始化为<code>false</code>。若发生交换，则置为<code>true</code>。</li>\n<li>若有一轮迭代中未出现交换，则数组有序，结束排序。</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bubbleSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len - <span class=\"number\">1</span>; i++)         <span class=\"comment\">//len-1轮遍历</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> flag = <span class=\"literal\">false</span>;                    <span class=\"comment\">//flag初始化为false</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; len - i - <span class=\"number\">1</span>; j++) <span class=\"comment\">//遍历数组</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &gt; arr[j + <span class=\"number\">1</span>])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = arr[j];</span><br><span class=\"line\">                arr[j] = arr[j + <span class=\"number\">1</span>];</span><br><span class=\"line\">                arr[j + <span class=\"number\">1</span>] = temp;</span><br><span class=\"line\">                flag = <span class=\"literal\">true</span>;                  <span class=\"comment\">//若发生一次交换，则falg置为true</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (flag == <span class=\"literal\">false</span>)                    <span class=\"comment\">//该轮迭代，未进行任何交换，数组已经有序</span></span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>对于设置标志变量<code>flag</code>之后的冒泡排序：</p>\n<ul>\n<li>最好情况下的时间复杂度为$O(n)$：<ul>\n<li>当待排序列已有序时，总的比较次数为$n-1$，移动次数为0。</li>\n</ul>\n</li>\n<li>最坏情况下的时间复杂度为$O(n^2)$；<ul>\n<li>当待排序列逆序时，总的比较次数为$n(n-1)/2$，移动次数为$3n(n-1)/2$次。</li>\n</ul>\n</li>\n<li>平均情况下的时间复杂度为$O(n^2)$。</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$:</p>\n<ul>\n<li>冒泡排序排序过程中需要一个临时变量进行两两交换，所需要的额外空间为1。</li>\n</ul>\n<p>（3）稳定性<br>冒泡排序在排序过程中，元素两两交换时，相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。</p>\n<h1 id=\"2-选择排序\"><a href=\"#2-选择排序\" class=\"headerlink\" title=\"2.选择排序\"></a>2.选择排序</h1><h2 id=\"基本思想-1\"><a href=\"#基本思想-1\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>每轮以第$i$个元素位置为初始最小值位置，选择出后方剩余元素中的最小值位置，将最小值元素与元素$i$交换；</li>\n<li>令$i$从$0$到$len-2$，进行$len-1$次选择和交换，即可使数组有序。</li>\n</ul>\n<h2 id=\"示例-1\"><a href=\"#示例-1\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#算法思路-4\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F2.gif\" width=\"50%\" height=\"50%\"></p>\n<h2 id=\"代码实现-1\"><a href=\"#代码实现-1\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）选择排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">selectionSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len - <span class=\"number\">1</span>; i++)   <span class=\"comment\">//令i从0到len−2，进行len−1次选择和交换</span></span><br><span class=\"line\">    &#123; </span><br><span class=\"line\">        <span class=\"keyword\">int</span> minIndex = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = i; j &lt;len ; j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &lt; arr[minIndex])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                minIndex = j;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = arr[i];</span><br><span class=\"line\">        arr[i] = arr[minIndex];</span><br><span class=\"line\">        arr[minIndex] = temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">100</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    selectionSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">61 17 29 22 100 34 60 72 21 50 1 62</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-1\"><a href=\"#性能分析-1\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n^2)$（平均情况、最好情况、最坏情况下）。<br>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>是不稳定的排序算法。</p>\n<ul>\n<li>原始序列：$8, 25, 25^*, 2$</li>\n<li>排序后：$2, 8, 25^*, 25$</li>\n<li>两个25的相对位置变化了，所以是不稳定的。</li>\n</ul>\n<h1 id=\"3-插入排序\"><a href=\"#3-插入排序\" class=\"headerlink\" title=\"3.插入排序\"></a>3.插入排序</h1><h2 id=\"基本思想-2\"><a href=\"#基本思想-2\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>以第0位置元素为有序部分，其余为无序部分。从第$i=1$个元素开始，逐个插入前方有序部分；</li>\n<li>对于每一轮插入，起始位置第$i$个位置元素的值记为<code>val</code>，$i$位置索引记为<code>hole</code>，若<code>hole</code>前方元素大于<code>val</code>，则将<code>hole</code>前方元素后移（<code>hole</code>前移），直到<code>hole</code>前方元素比<code>val</code>值小或<code>hole</code>为0，则<code>hole</code>位置确定。将<code>val</code>值插入<code>hole</code>处。每一轮插入，使得有序部分扩大1位。</li>\n<li>令$i$从1到$len−1$，经过$len-1$轮插入，可确定序列有序。</li>\n</ul>\n<h2 id=\"示例-2\"><a href=\"#示例-2\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-2\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F2.gif\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"代码实现-2\"><a href=\"#代码实现-2\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）插入排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">insertionSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; len; i++)             <span class=\"comment\">//令i从1到len−1，经过len−1轮插入</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> val = arr[i];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> hole = i;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (hole&gt;<span class=\"number\">0</span> &amp;&amp; arr[hole - <span class=\"number\">1</span>] &gt; val) <span class=\"comment\">//直到hole前方元素比val值小或hole为0</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            arr[hole] = arr[hole<span class=\"number\">-1</span>];</span><br><span class=\"line\">            hole--;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        arr[hole] = val;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">100</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    insertionSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">61 17 29 22 100 34 60 72 21 50 1 62</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-2\"><a href=\"#性能分析-2\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度</p>\n<ul>\n<li>最好情况下的时间复杂度为$O(n)$：<ul>\n<li>当待排序列已经有序时。</li>\n</ul>\n</li>\n<li>最坏情况下的时间复杂度为$O(n^2)$：<ul>\n<li>当待排序列“逆序”时。</li>\n</ul>\n</li>\n<li>平均时间复杂度为$O(n^2)$；</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>是稳定的排序算法。</p>\n<h1 id=\"4-希尔排序\"><a href=\"#4-希尔排序\" class=\"headerlink\" title=\"4.希尔排序\"></a>4.希尔排序</h1><h2 id=\"基本思想-3\"><a href=\"#基本思想-3\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>选择希尔增量序列（<script type=\"math/tex\">D_M=N/2,D_{M-1}=D_M/2,...,1</script>）。</li>\n<li>进行$D$间隔的插入排序。</li>\n</ul>\n<h2 id=\"示例-3\"><a href=\"#示例-3\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F.gif\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"代码实现-3\"><a href=\"#代码实现-3\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）希尔排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">shellSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> d = len/<span class=\"number\">2</span>; d &gt; <span class=\"number\">0</span>; d /= <span class=\"number\">2</span>)          <span class=\"comment\">//希尔增量序列</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i += d)        <span class=\"comment\">//d间隔的插入排序</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> val = arr[i];</span><br><span class=\"line\">            <span class=\"keyword\">int</span> hole = i;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (hole&gt;=d &amp;&amp; arr[hole - d] &gt; val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                arr[hole] = arr[hole - d];</span><br><span class=\"line\">                hole -= d;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            arr[hole] = val;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    shellSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 0</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">0 1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-3\"><a href=\"#性能分析-3\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>不同的增量序列，会得到不同的时间复杂度。且对于很多增量序列，其时间复杂度无法准确给出。<br>（2）空间复杂度<br>空间复杂度为O(1)。<br>（3）稳定性<br>不稳定。</p>\n<ul>\n<li>单次直接插入排序是稳定的，它不会改变相同元素之间的相对顺序，但在多次不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，可能导致相同元素相对顺序发生变化。因此，希尔排序并不稳定。</li>\n</ul>\n<h1 id=\"5-归并排序\"><a href=\"#5-归并排序\" class=\"headerlink\" title=\"5.归并排序\"></a>5.归并排序</h1><h2 id=\"基本思想-4\"><a href=\"#基本思想-4\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>分治：通过新建存储空间，将原始数组分成左右两个数组，再<strong>递归分解</strong>左半部分，<strong>递归分解</strong>又半部分，直到得到大小为1的数组（也即递归出口条件）。对于各大小为1的小数组来说，它们各自都是有序的。</li>\n<li>归并：将左右两个有序的小数组，归并成一个有序大数组。</li>\n</ul>\n<h2 id=\"示例-4\"><a href=\"#示例-4\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://zh.wikipedia.org/wiki/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif\" width=\"40%\" height=\"40%\"></p>\n<h2 id=\"代码实现-4\"><a href=\"#代码实现-4\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）归并排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">merge</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> left[], <span class=\"keyword\">int</span> right[], <span class=\"keyword\">int</span> leftLength, <span class=\"keyword\">int</span> rightLength)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// i用于标记arr数组索引</span></span><br><span class=\"line\">    <span class=\"comment\">// j用于标记left数组索引</span></span><br><span class=\"line\">    <span class=\"comment\">// k用于标记right数组索引</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> i, j, k;    </span><br><span class=\"line\">    i = j = k = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &lt; leftLength &amp;&amp; k &lt; rightLength)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (left[j] &lt;= right[k]) arr[i++] = left[j++]; <span class=\"comment\">//当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> arr[i++] = right[k++];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j &lt; leftLength) arr[i++] = left[j++];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(k &lt; rightLength) arr[i++] = right[k++];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mergeSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt; <span class=\"number\">2</span>)                    <span class=\"comment\">//防御型编程及出口条件</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> leftLength = len / <span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> rightLength = len - leftLength;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* left = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[leftLength];</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* right = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[rightLength];</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; leftLength; i++)</span><br><span class=\"line\">        left[i] = arr[i];</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = leftLength; i &lt; len; i++)</span><br><span class=\"line\">        right[i-leftLength] = arr[i];</span><br><span class=\"line\">    mergeSort(left, leftLength);                       <span class=\"comment\">//排序left数组</span></span><br><span class=\"line\">    mergeSort(right, rightLength);                     <span class=\"comment\">//排序right数组</span></span><br><span class=\"line\">    merge(arr,left, right, leftLength, rightLength);   <span class=\"comment\">//归并left数组和right数组成arr数组</span></span><br><span class=\"line\">    <span class=\"keyword\">delete</span>[] left;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span>[] right;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123;<span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    mergeSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-4\"><a href=\"#性能分析-4\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n\\log n)$。(最好情况，最坏情况及平均情况下)<br>（2）空间复杂度<br>空间复杂度为$O(n)$。</p>\n<ul>\n<li>为了进行归并操作，需要开辟辅助空间。</li>\n<li>归并排序每次递归都要用到一个辅助表，长度与待排序的表长度相同，虽然递归次数是$O(log2n)$，但每次递归都会释放掉所占的辅助空间，所以下次递归的栈空间和辅助空间与这部分释放的空间就不相关了，因而空间复杂度还是$O(n)$。</li>\n</ul>\n<p>（3）稳定性<br>是稳定的排序算法。</p>\n<ul>\n<li>在归并时，当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性。</li>\n</ul>\n<h1 id=\"6-快速排序\"><a href=\"#6-快速排序\" class=\"headerlink\" title=\"6.快速排序\"></a>6.快速排序</h1><h2 id=\"基本思想-5\"><a href=\"#基本思想-5\" class=\"headerlink\" title=\"基本思想\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#JS实现-5\" target=\"_blank\" rel=\"noopener\">基本思想</a></h2><ul>\n<li>从数组中选择一个元素作为”基准”(<code>pivot</code>)。</li>\n<li>分区(<code>partition</code>)：所有小于<code>pivot</code>的元素，都移其左侧至；所有大于<code>pivot</code>的元素，都移到其右侧。<strong>一次分区操作结束后，<code>pivot</code>所处的位置就是最终排序后它的位置</strong>。</li>\n<li>分治：对<code>pivot</code>左右两侧子集，分别递归执行上述两个步骤，直至所有子集只剩下一个元素为止（递归出口条件）。</li>\n</ul>\n<h2 id=\"示例-5\"><a href=\"#示例-5\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-6\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.gif\" width=\"65%\" height=\"55%\"></p>\n<h2 id=\"代码实现-5\"><a href=\"#代码实现-5\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）快速排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> temp = arr[a];</span><br><span class=\"line\">    arr[a] = arr[b];</span><br><span class=\"line\">    arr[b] = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pivot = arr[end];             <span class=\"comment\">//选取数组end位置元素为基准元素pivot</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = start;               <span class=\"comment\">//初始化pIndex为start</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = start; i &lt; end; i++) <span class=\"comment\">//从左至右遍历(除了最后的pivot)</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (arr[i] &lt;= pivot)          <span class=\"comment\">//所有小于等于pivot的元素与pIndex所指向的元素交换位置</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(arr, i, pIndex);</span><br><span class=\"line\">            pIndex++;                  <span class=\"comment\">//一次交换后pIndex+1</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    swap(arr, pIndex, end);           <span class=\"comment\">//循环结束,交换pivot与pIndex指向元素的位置</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//随机选择一个基准元素pivot，然后将基准元素交换到数组end位置</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">randomizedPartition</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = (rand() % (end - start + <span class=\"number\">1</span>)) + start;</span><br><span class=\"line\">    swap(arr, pIndex, end);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> partition(arr, start, end);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (start &gt;= end)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = randomizedPartition(arr, start, end);</span><br><span class=\"line\">    quickSort(arr, start, pIndex - <span class=\"number\">1</span>);</span><br><span class=\"line\">    quickSort(arr, pIndex + <span class=\"number\">1</span>, end);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    quickSort(arr, <span class=\"number\">0</span>,len<span class=\"number\">-1</span>);</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">true<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 0</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">0 1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-5\"><a href=\"#性能分析-5\" class=\"headerlink\" title=\"性能分析\"></a><a href=\"http://harttle.land/2015/09/27/quick-sort.html\" target=\"_blank\" rel=\"noopener\">性能分析</a></h2><p>（1）时间复杂度</p>\n<ul>\n<li>平均时间复杂度：$O(n \\log n)$</li>\n<li>最好情况：$O(n \\log n)$</li>\n<li>最坏情况：$O(n^2)$</li>\n</ul>\n<p>注：上述快速排序的代码实现中，通过随机选取基准元素<code>pivot</code>，避免了最坏情况的发生。<br>（2）空间复杂度</p>\n<ul>\n<li>最好情况：$O(\\log n)$<ul>\n<li>注：因为快速排序的实现是递归调用的，而且每次函数调用中只使用了常数的空间，因此空间复杂度等于递归深度$O(\\log n)$。</li>\n</ul>\n</li>\n<li>最坏情况下：$O(n)$<ul>\n<li>注：上述快速排序的代码实现中，通过随机选取基准元素<code>pivot</code>，避免了最坏情况的发生。</li>\n</ul>\n</li>\n</ul>\n<p>（3）稳定性<br>不稳定。</p>\n<ul>\n<li>在分区操作中，小于等于<code>pivot</code>的元素分到左侧,大于<code>pivot</code>的元素分到右侧。</li>\n<li>若对于序列<code>a,b</code>，其中<code>a</code>和<code>b</code>相等。如果选到了<code>a</code>为<code>pivot</code>,那么在<code>b&lt;=a</code>的情况下,<code>b</code>将会排在<code>a</code>的前面。</li>\n<li>因为有这样的可能性,所以快速排序算法是不稳定的。</li>\n</ul>\n<p>（4）评价<br>它是处理大数据最快的排序算法之一。虽然快速排序最坏情况下的时间复杂度达到了$O(n^2)$，比如说顺序数列的快排。但它的期望时间是$O(nlogn)$，且O(nlogn)记号中隐含的常数因子很小，比复杂度稳定等于$O(nlogn)$的归并排序要小很多。所以对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。</p>\n<h1 id=\"7-堆排序\"><a href=\"#7-堆排序\" class=\"headerlink\" title=\"7.堆排序\"></a>7.堆排序</h1><h2 id=\"基本思想-6\"><a href=\"#基本思想-6\" class=\"headerlink\" title=\"基本思想\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#算法思路及演示\" target=\"_blank\" rel=\"noopener\">基本思想</a></h2><ul>\n<li>定义最大堆堆化函数(<code>maxHeapify</code>)：<strong>保持</strong>最大堆性质，是创建最大堆的核心子程序。</li>\n<li><p>创建最大堆(<code>buildMaxHeap</code>)：将一个数组改造成一个最大堆，接受数组和堆大小两个参数，<code>buildMaxHeap</code>将<strong>自下而上</strong>的调用<code>maxHeapify</code>来改造数组，建立最大堆。因为<code>maxHeapify</code>能够保证下标为$i$的结点之后的结点都满足最大堆的性质，所以自下而上的调用<code>maxHeapify</code>能够在改造过程中保持这一性质。如果最大堆的数量元素是$n$，那么<code>buildMaxHeap</code>从$Parent(n)$开始，往上依次调用<code>maxHeapify</code>。</p>\n<ul>\n<li>注：对于数组，下标从0开始，则对于给定的某结点的下标$i$，容易计算出该结点的父结点、子结点的下标：<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Parent(i) = <span class=\"built_in\">floor</span>((i - <span class=\"number\">1</span>) / <span class=\"number\">2</span>)     <span class=\"comment\">// i 的父节点下标</span></span><br><span class=\"line\">Left(i) = <span class=\"number\">2</span>i + <span class=\"number\">1</span>                   <span class=\"comment\">// i 的左子节点下标</span></span><br><span class=\"line\">Right(i) = <span class=\"number\">2</span>(i + <span class=\"number\">1</span>)                <span class=\"comment\">// i 的右子节点下标</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>堆排序(<code>heapSort</code>)：<code>heapSort</code>先调用<code>buildMaxHeap</code>将数组改造为最大堆，然后将堆顶和堆底元素交换，之后将底部上升，最后重新调用<code>maxHeapify</code>保持最大堆性质。由于堆顶元素必然是堆中最大的元素，所以一次操作之后，堆中存在的最大元素被分离出堆，置于数组尾部，重复$n-1$次之后，数组排列完毕。</p>\n</li>\n</ul>\n<h2 id=\"示例-6\"><a href=\"#示例-6\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p>最大堆堆化(<code>maxHeapify</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E5%A0%86%E5%A0%86%E5%8C%96.png\" width=\"50%\" height=\"50%\"><br>创建最大堆(<code>buildMaxHeap</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%88%9B%E5%BB%BA%E6%9C%80%E5%A4%A7%E5%A0%86.png\" width=\"50%\" height=\"50%\"><br>堆排序(<code>heapSort</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F.png\" width=\"50%\" height=\"50%\"></p>\n<h2 id=\"代码实现-6\"><a href=\"#代码实现-6\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）堆排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> temp = arr[a];</span><br><span class=\"line\">    arr[a] = arr[b];</span><br><span class=\"line\">    arr[b] = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">maxHeapify</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> iMax, iLeft, iRight;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        iMax = index;</span><br><span class=\"line\">        iLeft = <span class=\"number\">2</span> * index + <span class=\"number\">1</span>;</span><br><span class=\"line\">        iRight = <span class=\"number\">2</span> * index + <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iLeft &lt; heapSize &amp;&amp; arr[iLeft] &gt; arr[iMax])</span><br><span class=\"line\">            iMax = iLeft;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iRight &lt;heapSize &amp;&amp; arr[iRight]&gt;arr[iMax])</span><br><span class=\"line\">            iMax = iRight;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iMax != index)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(arr, iMax, index);</span><br><span class=\"line\">            index = iMax;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">break</span>;                         <span class=\"comment\">//若未发生交换，则已是最大堆</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">buildMaxHeap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> iParent = (heapSize - <span class=\"number\">2</span>) / <span class=\"number\">2</span>;       <span class=\"comment\">//自下而上的调用maxHeapify来改造数组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = iParent; i &gt;= <span class=\"number\">0</span>; i--)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        maxHeapify(arr, i, heapSize);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">heapSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    buildMaxHeap(arr, heapSize);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = heapSize - <span class=\"number\">1</span>; i &gt; <span class=\"number\">0</span>; i--)   </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        swap(arr, <span class=\"number\">0</span>, i);                     <span class=\"comment\">//将堆顶和堆底元素交换</span></span><br><span class=\"line\">        maxHeapify(arr, <span class=\"number\">0</span>, i);               <span class=\"comment\">//底部上升后，调用maxHeapify</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">88</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    heapSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 88</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 10 20 30 60 70 88 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-6\"><a href=\"#性能分析-6\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n\\log n)$。</p>\n<ul>\n<li>1.建立堆的过程, 从length/2 一直处理到0, 时间复杂度为$O(n)$;</li>\n<li>2.调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为$O(\\log n)$;</li>\n<li>3.堆排序的过程由$n$次第2步完成, 时间复杂度为$O(n\\log n)$。</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>不稳定。</p>\n<h1 id=\"8-排序算法性能对比\"><a href=\"#8-排序算法性能对比\" class=\"headerlink\" title=\"8.排序算法性能对比\"></a>8.排序算法性能对比</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">排序类型</th>\n<th style=\"text-align:center\">平均情况</th>\n<th style=\"text-align:center\">最好情况</th>\n<th style=\"text-align:center\">最坏情况</th>\n<th style=\"text-align:center\">辅助空间</th>\n<th style=\"text-align:center\">稳定性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">冒泡排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">选择排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">插入排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">希尔排序</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">归并排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">快速排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(\\log n)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">堆排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"9-参考\"><a href=\"#9-参考\" class=\"headerlink\" title=\"9.参考\"></a>9.参考</h1><ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwKedT2KfDMB9YA5DgASZb3U\" target=\"_blank\" rel=\"noopener\">Sorting Algorithms, mycodeschool</a></li>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-1\" target=\"_blank\" rel=\"noopener\">常见排序算法总结（javascript实现），Digital Station</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-冒泡排序\"><a href=\"#1-冒泡排序\" class=\"headerlink\" title=\"1.冒泡排序\"></a>1.冒泡排序</h1><h2 id=\"基本思想\"><a href=\"#基本思想\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>每一轮遍历一次数组：将每个元素与相邻元素比较，将较大者换到后方。每一轮遍历可将一个最大的数换到数组末尾；</li>\n<li>进行$len-1$轮遍历后，可确定数组有序。</li>\n</ul>\n<h2 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><a href=\"http://louiszhai.github.io/2016/12/23/sort/#快速排序\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.gif\" width=\"70%\" height=\"60%\"></p>","more":"<h2 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）冒泡排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bubbleSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len&lt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len<span class=\"number\">-1</span>; i++)         <span class=\"comment\">//len-1轮遍历</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; len - i<span class=\"number\">-1</span>; j++) <span class=\"comment\">//遍历数组</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &gt; arr[j + <span class=\"number\">1</span>])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = arr[j];</span><br><span class=\"line\">                arr[j] = arr[j + <span class=\"number\">1</span>];</span><br><span class=\"line\">                arr[j + <span class=\"number\">1</span>] = temp;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    bubbleSort(arr, len);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72</span><br></pre></td></tr></table></figure></p>\n<p>（3）简单改进<br>思路：</p>\n<ul>\n<li>在每一轮迭代开始时，设置<code>flag</code>变量，初始化为<code>false</code>。若发生交换，则置为<code>true</code>。</li>\n<li>若有一轮迭代中未出现交换，则数组有序，结束排序。</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">bubbleSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len - <span class=\"number\">1</span>; i++)         <span class=\"comment\">//len-1轮遍历</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> flag = <span class=\"literal\">false</span>;                    <span class=\"comment\">//flag初始化为false</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; len - i - <span class=\"number\">1</span>; j++) <span class=\"comment\">//遍历数组</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &gt; arr[j + <span class=\"number\">1</span>])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = arr[j];</span><br><span class=\"line\">                arr[j] = arr[j + <span class=\"number\">1</span>];</span><br><span class=\"line\">                arr[j + <span class=\"number\">1</span>] = temp;</span><br><span class=\"line\">                flag = <span class=\"literal\">true</span>;                  <span class=\"comment\">//若发生一次交换，则falg置为true</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (flag == <span class=\"literal\">false</span>)                    <span class=\"comment\">//该轮迭代，未进行任何交换，数组已经有序</span></span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"性能分析\"><a href=\"#性能分析\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>对于设置标志变量<code>flag</code>之后的冒泡排序：</p>\n<ul>\n<li>最好情况下的时间复杂度为$O(n)$：<ul>\n<li>当待排序列已有序时，总的比较次数为$n-1$，移动次数为0。</li>\n</ul>\n</li>\n<li>最坏情况下的时间复杂度为$O(n^2)$；<ul>\n<li>当待排序列逆序时，总的比较次数为$n(n-1)/2$，移动次数为$3n(n-1)/2$次。</li>\n</ul>\n</li>\n<li>平均情况下的时间复杂度为$O(n^2)$。</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$:</p>\n<ul>\n<li>冒泡排序排序过程中需要一个临时变量进行两两交换，所需要的额外空间为1。</li>\n</ul>\n<p>（3）稳定性<br>冒泡排序在排序过程中，元素两两交换时，相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。</p>\n<h1 id=\"2-选择排序\"><a href=\"#2-选择排序\" class=\"headerlink\" title=\"2.选择排序\"></a>2.选择排序</h1><h2 id=\"基本思想-1\"><a href=\"#基本思想-1\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>每轮以第$i$个元素位置为初始最小值位置，选择出后方剩余元素中的最小值位置，将最小值元素与元素$i$交换；</li>\n<li>令$i$从$0$到$len-2$，进行$len-1$次选择和交换，即可使数组有序。</li>\n</ul>\n<h2 id=\"示例-1\"><a href=\"#示例-1\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#算法思路-4\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F2.gif\" width=\"50%\" height=\"50%\"></p>\n<h2 id=\"代码实现-1\"><a href=\"#代码实现-1\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）选择排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">selectionSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len - <span class=\"number\">1</span>; i++)   <span class=\"comment\">//令i从0到len−2，进行len−1次选择和交换</span></span><br><span class=\"line\">    &#123; </span><br><span class=\"line\">        <span class=\"keyword\">int</span> minIndex = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = i; j &lt;len ; j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (arr[j] &lt; arr[minIndex])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                minIndex = j;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = arr[i];</span><br><span class=\"line\">        arr[i] = arr[minIndex];</span><br><span class=\"line\">        arr[minIndex] = temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">100</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    selectionSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">61 17 29 22 100 34 60 72 21 50 1 62</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-1\"><a href=\"#性能分析-1\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n^2)$（平均情况、最好情况、最坏情况下）。<br>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>是不稳定的排序算法。</p>\n<ul>\n<li>原始序列：$8, 25, 25^*, 2$</li>\n<li>排序后：$2, 8, 25^*, 25$</li>\n<li>两个25的相对位置变化了，所以是不稳定的。</li>\n</ul>\n<h1 id=\"3-插入排序\"><a href=\"#3-插入排序\" class=\"headerlink\" title=\"3.插入排序\"></a>3.插入排序</h1><h2 id=\"基本思想-2\"><a href=\"#基本思想-2\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>以第0位置元素为有序部分，其余为无序部分。从第$i=1$个元素开始，逐个插入前方有序部分；</li>\n<li>对于每一轮插入，起始位置第$i$个位置元素的值记为<code>val</code>，$i$位置索引记为<code>hole</code>，若<code>hole</code>前方元素大于<code>val</code>，则将<code>hole</code>前方元素后移（<code>hole</code>前移），直到<code>hole</code>前方元素比<code>val</code>值小或<code>hole</code>为0，则<code>hole</code>位置确定。将<code>val</code>值插入<code>hole</code>处。每一轮插入，使得有序部分扩大1位。</li>\n<li>令$i$从1到$len−1$，经过$len-1$轮插入，可确定序列有序。</li>\n</ul>\n<h2 id=\"示例-2\"><a href=\"#示例-2\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-2\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F2.gif\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"代码实现-2\"><a href=\"#代码实现-2\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）插入排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">insertionSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt;= <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; len; i++)             <span class=\"comment\">//令i从1到len−1，经过len−1轮插入</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> val = arr[i];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> hole = i;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (hole&gt;<span class=\"number\">0</span> &amp;&amp; arr[hole - <span class=\"number\">1</span>] &gt; val) <span class=\"comment\">//直到hole前方元素比val值小或hole为0</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            arr[hole] = arr[hole<span class=\"number\">-1</span>];</span><br><span class=\"line\">            hole--;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        arr[hole] = val;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">61</span>, <span class=\"number\">17</span>, <span class=\"number\">29</span>, <span class=\"number\">22</span>, <span class=\"number\">100</span>, <span class=\"number\">34</span>, <span class=\"number\">60</span>, <span class=\"number\">72</span>, <span class=\"number\">21</span>, <span class=\"number\">50</span>, <span class=\"number\">1</span>, <span class=\"number\">62</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    insertionSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">61 17 29 22 100 34 60 72 21 50 1 62</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 17 21 22 29 34 50 60 61 62 72 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-2\"><a href=\"#性能分析-2\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度</p>\n<ul>\n<li>最好情况下的时间复杂度为$O(n)$：<ul>\n<li>当待排序列已经有序时。</li>\n</ul>\n</li>\n<li>最坏情况下的时间复杂度为$O(n^2)$：<ul>\n<li>当待排序列“逆序”时。</li>\n</ul>\n</li>\n<li>平均时间复杂度为$O(n^2)$；</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>是稳定的排序算法。</p>\n<h1 id=\"4-希尔排序\"><a href=\"#4-希尔排序\" class=\"headerlink\" title=\"4.希尔排序\"></a>4.希尔排序</h1><h2 id=\"基本思想-3\"><a href=\"#基本思想-3\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>选择希尔增量序列（<script type=\"math/tex\">D_M=N/2,D_{M-1}=D_M/2,...,1</script>）。</li>\n<li>进行$D$间隔的插入排序。</li>\n</ul>\n<h2 id=\"示例-3\"><a href=\"#示例-3\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F.gif\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"代码实现-3\"><a href=\"#代码实现-3\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）希尔排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">shellSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> d = len/<span class=\"number\">2</span>; d &gt; <span class=\"number\">0</span>; d /= <span class=\"number\">2</span>)          <span class=\"comment\">//希尔增量序列</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i += d)        <span class=\"comment\">//d间隔的插入排序</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> val = arr[i];</span><br><span class=\"line\">            <span class=\"keyword\">int</span> hole = i;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (hole&gt;=d &amp;&amp; arr[hole - d] &gt; val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                arr[hole] = arr[hole - d];</span><br><span class=\"line\">                hole -= d;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            arr[hole] = val;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    shellSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 0</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">0 1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-3\"><a href=\"#性能分析-3\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>不同的增量序列，会得到不同的时间复杂度。且对于很多增量序列，其时间复杂度无法准确给出。<br>（2）空间复杂度<br>空间复杂度为O(1)。<br>（3）稳定性<br>不稳定。</p>\n<ul>\n<li>单次直接插入排序是稳定的，它不会改变相同元素之间的相对顺序，但在多次不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，可能导致相同元素相对顺序发生变化。因此，希尔排序并不稳定。</li>\n</ul>\n<h1 id=\"5-归并排序\"><a href=\"#5-归并排序\" class=\"headerlink\" title=\"5.归并排序\"></a>5.归并排序</h1><h2 id=\"基本思想-4\"><a href=\"#基本思想-4\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h2><ul>\n<li>分治：通过新建存储空间，将原始数组分成左右两个数组，再<strong>递归分解</strong>左半部分，<strong>递归分解</strong>又半部分，直到得到大小为1的数组（也即递归出口条件）。对于各大小为1的小数组来说，它们各自都是有序的。</li>\n<li>归并：将左右两个有序的小数组，归并成一个有序大数组。</li>\n</ul>\n<h2 id=\"示例-4\"><a href=\"#示例-4\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://zh.wikipedia.org/wiki/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif\" width=\"40%\" height=\"40%\"></p>\n<h2 id=\"代码实现-4\"><a href=\"#代码实现-4\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）归并排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">merge</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> left[], <span class=\"keyword\">int</span> right[], <span class=\"keyword\">int</span> leftLength, <span class=\"keyword\">int</span> rightLength)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// i用于标记arr数组索引</span></span><br><span class=\"line\">    <span class=\"comment\">// j用于标记left数组索引</span></span><br><span class=\"line\">    <span class=\"comment\">// k用于标记right数组索引</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> i, j, k;    </span><br><span class=\"line\">    i = j = k = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &lt; leftLength &amp;&amp; k &lt; rightLength)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (left[j] &lt;= right[k]) arr[i++] = left[j++]; <span class=\"comment\">//当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> arr[i++] = right[k++];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j &lt; leftLength) arr[i++] = left[j++];</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(k &lt; rightLength) arr[i++] = right[k++];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mergeSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> len)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (arr == <span class=\"literal\">nullptr</span> || len &lt; <span class=\"number\">2</span>)                    <span class=\"comment\">//防御型编程及出口条件</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> leftLength = len / <span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> rightLength = len - leftLength;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* left = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[leftLength];</span><br><span class=\"line\">    <span class=\"keyword\">int</span>* right = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[rightLength];</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; leftLength; i++)</span><br><span class=\"line\">        left[i] = arr[i];</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = leftLength; i &lt; len; i++)</span><br><span class=\"line\">        right[i-leftLength] = arr[i];</span><br><span class=\"line\">    mergeSort(left, leftLength);                       <span class=\"comment\">//排序left数组</span></span><br><span class=\"line\">    mergeSort(right, rightLength);                     <span class=\"comment\">//排序right数组</span></span><br><span class=\"line\">    merge(arr,left, right, leftLength, rightLength);   <span class=\"comment\">//归并left数组和right数组成arr数组</span></span><br><span class=\"line\">    <span class=\"keyword\">delete</span>[] left;</span><br><span class=\"line\">    <span class=\"keyword\">delete</span>[] right;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123;<span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>&#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    mergeSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-4\"><a href=\"#性能分析-4\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n\\log n)$。(最好情况，最坏情况及平均情况下)<br>（2）空间复杂度<br>空间复杂度为$O(n)$。</p>\n<ul>\n<li>为了进行归并操作，需要开辟辅助空间。</li>\n<li>归并排序每次递归都要用到一个辅助表，长度与待排序的表长度相同，虽然递归次数是$O(log2n)$，但每次递归都会释放掉所占的辅助空间，所以下次递归的栈空间和辅助空间与这部分释放的空间就不相关了，因而空间复杂度还是$O(n)$。</li>\n</ul>\n<p>（3）稳定性<br>是稳定的排序算法。</p>\n<ul>\n<li>在归并时，当两元素相等时，把处在前面序列的元素保存在结果序列的前面，保证了稳定性。</li>\n</ul>\n<h1 id=\"6-快速排序\"><a href=\"#6-快速排序\" class=\"headerlink\" title=\"6.快速排序\"></a>6.快速排序</h1><h2 id=\"基本思想-5\"><a href=\"#基本思想-5\" class=\"headerlink\" title=\"基本思想\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#JS实现-5\" target=\"_blank\" rel=\"noopener\">基本思想</a></h2><ul>\n<li>从数组中选择一个元素作为”基准”(<code>pivot</code>)。</li>\n<li>分区(<code>partition</code>)：所有小于<code>pivot</code>的元素，都移其左侧至；所有大于<code>pivot</code>的元素，都移到其右侧。<strong>一次分区操作结束后，<code>pivot</code>所处的位置就是最终排序后它的位置</strong>。</li>\n<li>分治：对<code>pivot</code>左右两侧子集，分别递归执行上述两个步骤，直至所有子集只剩下一个元素为止（递归出口条件）。</li>\n</ul>\n<h2 id=\"示例-5\"><a href=\"#示例-5\" class=\"headerlink\" title=\"示例\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-6\" target=\"_blank\" rel=\"noopener\">示例</a></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.gif\" width=\"65%\" height=\"55%\"></p>\n<h2 id=\"代码实现-5\"><a href=\"#代码实现-5\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）快速排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> temp = arr[a];</span><br><span class=\"line\">    arr[a] = arr[b];</span><br><span class=\"line\">    arr[b] = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pivot = arr[end];             <span class=\"comment\">//选取数组end位置元素为基准元素pivot</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = start;               <span class=\"comment\">//初始化pIndex为start</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = start; i &lt; end; i++) <span class=\"comment\">//从左至右遍历(除了最后的pivot)</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (arr[i] &lt;= pivot)          <span class=\"comment\">//所有小于等于pivot的元素与pIndex所指向的元素交换位置</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(arr, i, pIndex);</span><br><span class=\"line\">            pIndex++;                  <span class=\"comment\">//一次交换后pIndex+1</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    swap(arr, pIndex, end);           <span class=\"comment\">//循环结束,交换pivot与pIndex指向元素的位置</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//随机选择一个基准元素pivot，然后将基准元素交换到数组end位置</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">randomizedPartition</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = (rand() % (end - start + <span class=\"number\">1</span>)) + start;</span><br><span class=\"line\">    swap(arr, pIndex, end);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> partition(arr, start, end);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (start &gt;= end)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> pIndex = randomizedPartition(arr, start, end);</span><br><span class=\"line\">    quickSort(arr, start, pIndex - <span class=\"number\">1</span>);</span><br><span class=\"line\">    quickSort(arr, pIndex + <span class=\"number\">1</span>, end);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    quickSort(arr, <span class=\"number\">0</span>,len<span class=\"number\">-1</span>);</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">true<span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">true<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 0</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">0 1 10 20 30 60 70 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-5\"><a href=\"#性能分析-5\" class=\"headerlink\" title=\"性能分析\"></a><a href=\"http://harttle.land/2015/09/27/quick-sort.html\" target=\"_blank\" rel=\"noopener\">性能分析</a></h2><p>（1）时间复杂度</p>\n<ul>\n<li>平均时间复杂度：$O(n \\log n)$</li>\n<li>最好情况：$O(n \\log n)$</li>\n<li>最坏情况：$O(n^2)$</li>\n</ul>\n<p>注：上述快速排序的代码实现中，通过随机选取基准元素<code>pivot</code>，避免了最坏情况的发生。<br>（2）空间复杂度</p>\n<ul>\n<li>最好情况：$O(\\log n)$<ul>\n<li>注：因为快速排序的实现是递归调用的，而且每次函数调用中只使用了常数的空间，因此空间复杂度等于递归深度$O(\\log n)$。</li>\n</ul>\n</li>\n<li>最坏情况下：$O(n)$<ul>\n<li>注：上述快速排序的代码实现中，通过随机选取基准元素<code>pivot</code>，避免了最坏情况的发生。</li>\n</ul>\n</li>\n</ul>\n<p>（3）稳定性<br>不稳定。</p>\n<ul>\n<li>在分区操作中，小于等于<code>pivot</code>的元素分到左侧,大于<code>pivot</code>的元素分到右侧。</li>\n<li>若对于序列<code>a,b</code>，其中<code>a</code>和<code>b</code>相等。如果选到了<code>a</code>为<code>pivot</code>,那么在<code>b&lt;=a</code>的情况下,<code>b</code>将会排在<code>a</code>的前面。</li>\n<li>因为有这样的可能性,所以快速排序算法是不稳定的。</li>\n</ul>\n<p>（4）评价<br>它是处理大数据最快的排序算法之一。虽然快速排序最坏情况下的时间复杂度达到了$O(n^2)$，比如说顺序数列的快排。但它的期望时间是$O(nlogn)$，且O(nlogn)记号中隐含的常数因子很小，比复杂度稳定等于$O(nlogn)$的归并排序要小很多。所以对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。</p>\n<h1 id=\"7-堆排序\"><a href=\"#7-堆排序\" class=\"headerlink\" title=\"7.堆排序\"></a>7.堆排序</h1><h2 id=\"基本思想-6\"><a href=\"#基本思想-6\" class=\"headerlink\" title=\"基本思想\"></a><a href=\"https://royalbluewa3.cc/posts/67d771c4/#算法思路及演示\" target=\"_blank\" rel=\"noopener\">基本思想</a></h2><ul>\n<li>定义最大堆堆化函数(<code>maxHeapify</code>)：<strong>保持</strong>最大堆性质，是创建最大堆的核心子程序。</li>\n<li><p>创建最大堆(<code>buildMaxHeap</code>)：将一个数组改造成一个最大堆，接受数组和堆大小两个参数，<code>buildMaxHeap</code>将<strong>自下而上</strong>的调用<code>maxHeapify</code>来改造数组，建立最大堆。因为<code>maxHeapify</code>能够保证下标为$i$的结点之后的结点都满足最大堆的性质，所以自下而上的调用<code>maxHeapify</code>能够在改造过程中保持这一性质。如果最大堆的数量元素是$n$，那么<code>buildMaxHeap</code>从$Parent(n)$开始，往上依次调用<code>maxHeapify</code>。</p>\n<ul>\n<li>注：对于数组，下标从0开始，则对于给定的某结点的下标$i$，容易计算出该结点的父结点、子结点的下标：<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Parent(i) = <span class=\"built_in\">floor</span>((i - <span class=\"number\">1</span>) / <span class=\"number\">2</span>)     <span class=\"comment\">// i 的父节点下标</span></span><br><span class=\"line\">Left(i) = <span class=\"number\">2</span>i + <span class=\"number\">1</span>                   <span class=\"comment\">// i 的左子节点下标</span></span><br><span class=\"line\">Right(i) = <span class=\"number\">2</span>(i + <span class=\"number\">1</span>)                <span class=\"comment\">// i 的右子节点下标</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>堆排序(<code>heapSort</code>)：<code>heapSort</code>先调用<code>buildMaxHeap</code>将数组改造为最大堆，然后将堆顶和堆底元素交换，之后将底部上升，最后重新调用<code>maxHeapify</code>保持最大堆性质。由于堆顶元素必然是堆中最大的元素，所以一次操作之后，堆中存在的最大元素被分离出堆，置于数组尾部，重复$n-1$次之后，数组排列完毕。</p>\n</li>\n</ul>\n<h2 id=\"示例-6\"><a href=\"#示例-6\" class=\"headerlink\" title=\"示例\"></a>示例</h2><p>最大堆堆化(<code>maxHeapify</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E5%A0%86%E5%A0%86%E5%8C%96.png\" width=\"50%\" height=\"50%\"><br>创建最大堆(<code>buildMaxHeap</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%88%9B%E5%BB%BA%E6%9C%80%E5%A4%A7%E5%A0%86.png\" width=\"50%\" height=\"50%\"><br>堆排序(<code>heapSort</code>)：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F.png\" width=\"50%\" height=\"50%\"></p>\n<h2 id=\"代码实现-6\"><a href=\"#代码实现-6\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h2><p>（1）堆排序代码实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> temp = arr[a];</span><br><span class=\"line\">    arr[a] = arr[b];</span><br><span class=\"line\">    arr[b] = temp;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">maxHeapify</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> iMax, iLeft, iRight;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        iMax = index;</span><br><span class=\"line\">        iLeft = <span class=\"number\">2</span> * index + <span class=\"number\">1</span>;</span><br><span class=\"line\">        iRight = <span class=\"number\">2</span> * index + <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iLeft &lt; heapSize &amp;&amp; arr[iLeft] &gt; arr[iMax])</span><br><span class=\"line\">            iMax = iLeft;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iRight &lt;heapSize &amp;&amp; arr[iRight]&gt;arr[iMax])</span><br><span class=\"line\">            iMax = iRight;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (iMax != index)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(arr, iMax, index);</span><br><span class=\"line\">            index = iMax;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">break</span>;                         <span class=\"comment\">//若未发生交换，则已是最大堆</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">buildMaxHeap</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> iParent = (heapSize - <span class=\"number\">2</span>) / <span class=\"number\">2</span>;       <span class=\"comment\">//自下而上的调用maxHeapify来改造数组</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = iParent; i &gt;= <span class=\"number\">0</span>; i--)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        maxHeapify(arr, i, heapSize);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">heapSort</span><span class=\"params\">(<span class=\"keyword\">int</span> arr[], <span class=\"keyword\">int</span> heapSize)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    buildMaxHeap(arr, heapSize);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = heapSize - <span class=\"number\">1</span>; i &gt; <span class=\"number\">0</span>; i--)   </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        swap(arr, <span class=\"number\">0</span>, i);                     <span class=\"comment\">//将堆顶和堆底元素交换</span></span><br><span class=\"line\">        maxHeapify(arr, <span class=\"number\">0</span>, i);               <span class=\"comment\">//底部上升后，调用maxHeapify</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> arr[] = &#123; <span class=\"number\">60</span>, <span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">100</span>, <span class=\"number\">30</span>, <span class=\"number\">70</span>, <span class=\"number\">1</span>, <span class=\"number\">88</span> &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> len = (<span class=\"keyword\">int</span>) <span class=\"keyword\">sizeof</span>(arr) / <span class=\"keyword\">sizeof</span>(*arr);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"原序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    heapSort(arr, len);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"排序后序列：\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原序列：</span><br><span class=\"line\">60 10 20 100 30 70 1 88</span><br><span class=\"line\">排序后序列：</span><br><span class=\"line\">1 10 20 30 60 70 88 100</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"性能分析-6\"><a href=\"#性能分析-6\" class=\"headerlink\" title=\"性能分析\"></a>性能分析</h2><p>（1）时间复杂度<br>时间复杂度为$O(n\\log n)$。</p>\n<ul>\n<li>1.建立堆的过程, 从length/2 一直处理到0, 时间复杂度为$O(n)$;</li>\n<li>2.调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为$O(\\log n)$;</li>\n<li>3.堆排序的过程由$n$次第2步完成, 时间复杂度为$O(n\\log n)$。</li>\n</ul>\n<p>（2）空间复杂度<br>空间复杂度为$O(1)$。<br>（3）稳定性<br>不稳定。</p>\n<h1 id=\"8-排序算法性能对比\"><a href=\"#8-排序算法性能对比\" class=\"headerlink\" title=\"8.排序算法性能对比\"></a>8.排序算法性能对比</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">排序类型</th>\n<th style=\"text-align:center\">平均情况</th>\n<th style=\"text-align:center\">最好情况</th>\n<th style=\"text-align:center\">最坏情况</th>\n<th style=\"text-align:center\">辅助空间</th>\n<th style=\"text-align:center\">稳定性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">冒泡排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">选择排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">插入排序</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">希尔排序</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">归并排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n)$</td>\n<td style=\"text-align:center\">稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">快速排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n^2)$</td>\n<td style=\"text-align:center\">$O(\\log n)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">堆排序</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(n\\log n)$</td>\n<td style=\"text-align:center\">$O(1)$</td>\n<td style=\"text-align:center\">不稳定</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"9-参考\"><a href=\"#9-参考\" class=\"headerlink\" title=\"9.参考\"></a>9.参考</h1><ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwKedT2KfDMB9YA5DgASZb3U\" target=\"_blank\" rel=\"noopener\">Sorting Algorithms, mycodeschool</a></li>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"https://royalbluewa3.cc/posts/67d771c4/#实例演示-1\" target=\"_blank\" rel=\"noopener\">常见排序算法总结（javascript实现），Digital Station</a></li>\n</ul>"},{"title":"栈与队列","date":"2017-11-22T07:49:49.000Z","mathjax":true,"_content":"## 一、栈的概念\n栈（stack）是限定仅在表尾进行插入和删除操作的线性表：\n（1）允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom）；\n（2）栈又称为后进先出（Last In First Out）的线性表，简称LIFO；\n（3）栈的插入操作，叫做进栈，也称压栈、入栈；\n（4）栈的删除操作，叫做出栈。\n栈的抽象数据类型：\n```C++\nADT 栈(stack)\nData\n    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。\nOperation\n    InitStack(*S):    初始化操作，建立一个空栈S。\n    DestroyStack(*S): 若栈存在，则销毁它。\n    ClearStack(*S):   将栈清空。\n    StackEmpty(S):    若栈为空，返回true，否则返回false。\n    Top(S, *e):       若栈存在且非空，用e返回S的栈顶元素。\n    Push(*S, e):      若栈S存在，插入新元素e到栈S中并成为栈顶元素。\n    Pop(*S, *e):      删除栈S中栈顶元素，并用e返回其值。\n    StackLength(S):   返回栈S的元素个数。\nendADT\n```\n栈示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"40%\" height=\"40%\">\n<!-- more --> \n## 二、栈的顺序存储结构——顺序栈\n### 2.1 实现\n要保证`Push()`、`Pop()`的时间复杂度为O(1)，故需**将数组下标为0的一端作为栈底，另一端为栈顶，进行插入/删除操作**。\n通常定义一个`top`变量来指示栈顶元素在数组中的位置，若存储栈的长度为`StackSize`，则栈顶位置`top`必须小于`StackSize`。当栈存在一个元素时，`top`等于0，因此通常把空栈的判定条件定为`top`等于-1。\n注：在下述模版实现中以`count`来统计栈的元素数量。初始值为0，表示空。`count==capacity`，表示满。\n顺序栈示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86%E5%9B%BE.jpg\" width=\"80%\" height=\"80%\">\n### 2.2 常见操作\n入栈：判是否栈已满，若未满，栈顶标记`top++`，`top`处插入元素，时间复杂度：O(1)\n出栈：判是否为空栈，若非空，栈顶标记`top--`，时间复杂度：O(1)\n### 2.3 C++模版实现\n（1）栈的具体实现：\n```C++\n#include <iostream>\nusing namespace std;\n\n//栈的抽象数据类型\ntemplate<typename T>\nclass ArrayStack\n{\npublic:\n    ArrayStack(int s = 10);          //默认的栈容量为10\n    ~ArrayStack();\npublic:\n    T top();\t\t\t     //获取栈顶元素\n    void push(T t);\t\t     //压栈操作\n    T pop();\t\t\t     //弹栈操作\n    bool isEmpty();\t\t     //判空操作\n    int size();\t\t\t     //求栈的大小\nprivate:\n    int count;\t\t\t     //记录栈的元素数量\n    int capacity;\t\t     //栈的容量\n    T * array;\t\t\t     //底层为数组\n};\n\n//栈的具体实现\n/*构造函数*/\ntemplate <typename T>\nArrayStack<T>::ArrayStack(int s = 10):count(0), capacity(s), array(nullptr)\n{\n    array = new T[capacity];\n}\n/*析构函数*/\ntemplate<typename T>\nArrayStack<T>::~ArrayStack()\n{\n    if (array)\n    {\n        delete[] array;\n        array = nullptr;\n    }\n}\n/*栈的判空操作*/\ntemplate <typename T>\nbool ArrayStack<T>::isEmpty()\n{\n    return count == 0;           //栈元素个数为0时为栈空\n}\n/*返回栈的大小*/\ntemplate <typename  T>\nint ArrayStack<T>::size()\n{\n    return count;\n}\n/*插入元素*/\ntemplate <typename T>\nvoid ArrayStack<T>::push(T t)\n{\n    if (count != capacity)       //先判断是否栈满\n    {\n        array[count++] = t;\t\n    }\n}\n/*弹栈*/\ntemplate <typename T>\nT ArrayStack<T>::pop()\n{\n    if (count != 0)              //先判断是否是空栈\n    {\n        return array[--count];\n    }\n}\n/*获取栈顶元素*/\ntemplate <typename T>\nT ArrayStack<T>::top()\n{\n    if (count != 0)\n    {\n        return array[count - 1];\n    }\n}\n```\n\n（3）栈的测试代码：\n```C++\nint main()\n{\n    ArrayStack<int> p(5);\n    for (int i = 0; i < 5; i++)\n    {\n        p.push(i);\n    }\n    cout << \"栈的大小:\"<<p.size() << endl;\n    cout << \"栈是否为空:\"<<p.isEmpty() << endl;\n    cout << \"栈顶元素：\"<<p.top() << endl;\n    cout << \"依次出栈:\" << endl;\n    while (!p.isEmpty())\n    {\n        cout << p.pop() << endl;\n    }\n    return 0;\n}\n```\n测试结果：\n```\n栈的大小:5\n栈是否为空:0\n栈顶元素：4\n依次出栈:\n4\n3\n2\n1\n0\n```\n\n入栈示例图:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%85%A5%E6%A0%88.png\" width=\"80%\" height=\"80%\">\n出栈示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%87%BA%E6%A0%88.png\" width=\"80%\" height=\"80%\">\n## 三、栈的链式存储结构——链栈\n### 3.1 实现\n对于单链表，在表头插入/删除的时间复杂度为O(1)，在表尾插入/删除的时间复杂度为O(n)。为保证栈的`Push()`、`Pop()`的时间复杂度为O(1)，故**链栈以单链表的头部为栈顶（进行插入/删除操作），链表尾部作为栈底**。通常设置`top`指针，记录栈顶位置，链栈为空就是`top`指针等于`NULL`的时候。\n[示例](https://www.youtube.com/watch?v=MuwxQ2IB8lQ&index=16&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"70%\" height=\"60%\">\n### 3.2 常见操作\n1.入栈：同链表在首位置插入结点操作：无需判栈满，新建结点，待插入结点指向头指针`top`所指向的内容；头指针`top`指向待插入结点。时间复杂度:O(1)。\n2.出栈：同链表在首位置删除结点操作：判栈是否空，若非空(`top!=NULL`)，栈顶指针`top`指向第2个结点，释放第一个结点空间。时间复杂度：O(1)。\n\n### 3.3 C++模版实现\n（1）栈的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n/*链表节点结构*/\ntemplate<typename T>\nclass Node\n{\npublic:\n    Node():next(nullptr){};\n    Node(T x):value(x), next(nullptr){};\npublic:\n    T value;\n    Node<T>* next;\n};\n\n/*栈的抽象数据结构*/\ntemplate<typename T>\nclass LinkStack\n{\npublic: \n    LinkStack();\n    ~LinkStack();\npublic:\n    void push(T x);\n    T pop();\n    T top();\n    bool isEmpty();\n    int size();\nprivate:\n    Node<T>* head;\n    int count; //记录栈的结点个数\n};\n\n/*栈的具体实现*/\n/*构造函数*/\ntemplate<typename T>\nLinkStack<T>::LinkStack() :head(nullptr), count(0)\n{\n}\n\n/*析构函数*/\ntemplate<typename T>\nLinkStack<T>::~LinkStack()\n{\n    while (head != nullptr)\n    {\n        Node<T>* temp = head;\n        head = head->next;\n        delete temp;\n    }\n    /*\n    while (!isEmpty())\n    {\n        pop();\n    }\n    */\n}\n\n/*入栈*/\ntemplate<typename T>\nvoid LinkStack<T>::push(T x)\n{\n    Node<T>* temp = new Node<T>(x);\n    temp->next = head;\n    head = temp;\n    count++;\n}\n\n/*出栈*/\ntemplate<typename T>\nT LinkStack<T>::pop()\n{\n    if (count != 0)  //栈空判断\n    {\n        Node<T>* temp = head;\n        head = head->next;\n        T val = temp->value;\n        delete temp;\n        temp = nullptr;\n        count--;\n        return val;\n    }\n}\n\n/*获取栈顶元素*/\ntemplate<typename T>\nT LinkStack<T>::top()\n{\n    if (count != 0)\n\t{\n        return head->value;\n    }\n}\n\n/*栈的判空操作*/\ntemplate<typename T>\nbool LinkStack<T>::isEmpty()\n{\n    return count == 0;\n}\n\n/*返回栈的大小*/\ntemplate<typename T>\nint LinkStack<T>::size()\n{\n    return count;\n}\n```\n（4）栈的测试代码\n```C++\nint main()\n{\n\t//测试一\n    LinkStack<int> stack;\n    stack.push(1);\n    stack.push(2);\n    stack.push(3);\n    stack.push(4);\n    cout << \"栈的大小:\" << stack.size() << endl;\n    cout << \"栈顶元素:\" << stack.top() << endl;\n    while (!stack.isEmpty())\n    {\n        stack.pop();\n    }\n    cout << \"栈的大小:\" << stack.size() << endl;\n\t//测试二\n    LinkStack<string> stack2;\n    stack2.push(\"How\");\n    stack2.push(\"are\");\n    stack2.push(\"you\");\n    cout << \"栈的大小:\" << stack2.size() << endl;\n    cout << \"栈顶元素:\" << stack2.top() << endl;\n    while (!stack2.isEmpty())\n\t{\n        stack2.pop();\n    }\n    cout << \"栈的大小:\" << stack2.size() << endl;\n    return 0;\n}\n```\n测试结果：\n```\n//测试一\n栈的大小:4\n栈顶元素:4\n栈的大小:0\n//测试2\n栈的大小:3\n栈顶元素:you\n栈的大小:0\n```\n\n[示例](https://www.youtube.com/watch?v=MuwxQ2IB8lQ&index=16&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\n入栈：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%85%A5%E6%A0%88.jpg\" width=\"100%\" height=\"100%\">\n出栈：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%87%BA%E6%A0%88.jpg\" width=\"100%\" height=\"100%\">\n\n## 四、队列的概念\n队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表：\n（1）允许插入的一端称为队尾（rear），允许删除的一端称为队头（front）；\n（2）队列是一种先进先出（First In First Out）的线性表，简称FIFO；\n（3）队列的插入操作，叫做入队；\n（4）队列的删除操作，叫做出队。\n队列的抽象数据类型：\n```C\nADT 队列(Queue)\nData\n    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。\nOperation\n    InitQueue(*Q):    初始化操作，建立一个空队列Q。\n    DestroyQueue(*Q): 若队列Q存在，则销毁它。\n    ClearQueue(*Q):   将队列Q清空。\n    QueueEmpty(Q):    若队列Q为空，返回true，否则返回false。\n    GetFront(Q, *e):  若队列Q存在且非空，用e返回队列Q的队头元素。\n    EnQueue(*Q, e):   若队列Q存在，插入新元素e到队列Q中并成为队尾元素。\n    DeQueue(*Q, *e):  删除队列Q中队头元素，并用e返回其值。\n    QueueLength(Q):   返回队列Q的元素个数\nendADT\n```\n队列示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"60%\" height=\"60%\">\n## 五、队列的顺序存储结构——顺序队列\n### 5.1 实现\n若采用数组实现简单顺序队列，则：\n（1）数组下标为0的一端就是队头，进行出队操作；\n（2）入队操作只需在队尾增加元素，不需要移动任何元素，时间复杂度为O(1)；\n（3）出队操作需要队列中的所有元素向前移动，时间复杂度为O(n)。(若采用把队首标志往后移动，时间复杂度是O(1)，但那样会造成数组空间的“流失”。)\n为了保证出队和入队操作的时间复杂度都为O(1)且不会造成数组空间的“流失”，故通常顺序队列的实现采用循环队列。\n循环队列：把数组看出一个首尾相连的圆环，删除元素时将队首标志往后移动，添加元素时若数组尾部已经没有空间，则考虑数组头部的空间是否空闲，如果是，则在数组头部进行插入：\n（1）判断队列为空：`begin==end`（初始化时`begin=0`，`end=0`）\n（2）判断队列满：`begin`与`end`之间隔一空位，即`(end + 1) % capacity == begin`\n（3）队列长度计算：`(end - begin + capacity) % capacity`\n- 若$end - begin\\geq0$，则$end - begin$即为队列元素个数。\n- 若$end - begin<0$，则$(end - begin + capacity)$为队列元素个数。\n- 上式`(end - begin + capacity) % capacity`照顾了这两种情况。\n\n（4）前移`begin`或`end`时，下一位置计算方法：`begin = (begin + 1) % capacity`或`end = (end + 1) % capacity`\n循环队列示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B1.jpg\" width=\"55%\" height=\"55%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B2.jpg\" width=\"55%\" height=\"55%\">\n\n### 5.2 常见操作\n入队：判队列是否满，若未满，则在队尾处插入元素，队尾指针`end`前移。时间复杂度：O(1)。\n出队：判队列是否为空，若不空，则队首指针`begin`前移。时间复杂度：O(1)。\n### 5.3 类模版实现\n（1）循环队列的的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n/*循环队列的抽象数据类型*/\ntemplate<typename T>\nclass LoopQueue\n{\npublic:\n    LoopQueue(int c);\n    ~LoopQueue();\npublic:\n    bool push(T x);      //入队列\n    bool pop();          //出队列\n    T front();           //队首元素\n    bool isEmpty();      //队列的判空\n    int size();          //队列的大小\nprivate:\n    int begin;           //队首标志\n    int end;             //队尾标志\n    int capacity;        //数组容量\n    T* queue;            //数组\n};\n\n/*队列的具体实现*/\ntemplate<typename T>\nLoopQueue<T>::LoopQueue(int c = 10) :capacity(c), begin(0), end(0), queue(nullptr)\n{\n    queue = new T[capacity];\n}\n\ntemplate<typename T>\nLoopQueue<T>::~LoopQueue()\n{\n    if(queue)\n    {\n        delete[] queue;\n        queue=nullptr;\n    }\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::push(T x)\n{\n    if (end + 1 % capacity == begin) //判断队列是否已满\n        return false;\n    queue[end] = x;\n    end = (end + 1) % capacity;\n    return true;\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::pop()\n{\n    if (begin == end)//判断队列是否为空\n        return false;\n    begin = (begin + 1) % capacity;\n    return true;\n}\n\ntemplate<typename T>\nT LoopQueue<T>::front()\n{\n    if (begin != end)\n        return queue[begin];\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::isEmpty()\n{\n    return begin==end;\n}\n\ntemplate<typename T>\nint LoopQueue<T>::size()\n{\n    return (end - begin + capacity) % capacity;  //计算队列长度\n}\n```\n（3）循环队列代码测试\n```C++\nint main()\n{\n    //测试一\n    LoopQueue<int> queue(6);\n    queue.push(1);\n    queue.push(2);\n    queue.push(3);\n    queue.push(4);\n    cout << \"队列长度\" << queue.size() << endl;\n    while (!queue.isEmpty())\n    {\n        cout << queue.front() << endl;\n        queue.pop();\n    }\n    //测试二\n    LoopQueue<string> queue2(6);\n    queue2.push(\"How\");\n    queue2.push(\"are\");\n    queue2.push(\"you\");\n    cout << \"队列长度\" << queue2.size() << endl;\n    while (!queue2.isEmpty())\n    {\n        cout << queue2.front() << endl;\n        queue2.pop();\n    }\n    return 0;\n}\n```\n测试结果：\n```\n//测试一\n队列长度4\n1\n2\n3\n4\n//测试二\n队列长度3\nHow\nare\nyou\n```\n## 六、队列的链式存储结构——链式队列\n### 6.1 实现\n对于单链表，在表头进行插入/删除的时间复杂度为O(1)，在表尾进行插入/删除的时间复杂度为O(n)。故，为了保证入队和出队的时间复杂度为O(1)，以链表的头指针head为队头指针front，进行出队操作；在链表尾部设置队尾指针rear，进行入队操作。\n[示例](https://www.youtube.com/watch?v=A5_XdiK4J8A&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&index=24)：\n链式队列示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"100%\" height=\"60%\">\n链式队列各状态示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%90%84%E7%8A%B6%E6%80%81.jpg\" width=\"60%\" height=\"50%\">\n### 6.2 常见操作\n1.**入队**：判队列是否为空，若为空(`count==0`)，则`front`指针和`rear`指针均置为插入结点指针；若队列非空，则在`rear`处插入结点。时间复杂度：O(1)。\n2.**出队**：判队列是否为空，若不空(`count!=0`)，判队列是否只有一个元素(`count==1`)，若只有一个元素，则删除结点，`front`指针和`rear`指针均置为`nullptr`(`front=rear=nullptr`)；否则，在`front`处删除结点。时间复杂度：O(1)。\n注1：在本章中，顺序栈、链式栈及链式队列中，**都通过私有变量`count`来帮助记录元素或结点个数**。\n注2：下述链式栈的模版实现，**只用了头指针`front`和尾指针`rear`，未使用头结点或尾结点**。\n### 6.3 类模版实现\n（1）链式队列的的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n//链表节点\ntemplate<typename T>\nclass Node\n{\npublic:\n    Node() :next(nullptr){};\n    Node(T x) :value(x), next(nullptr){};\npublic:\n    T value;\n    Node* next;\n};\n\n//队列的抽象数据类型\ntemplate<typename T>\nclass LinkQueue\n{\npublic:\n    LinkQueue();\n    ~LinkQueue();\npublic:\n    void push(T x);      //入队\n    bool pop();          //出队\n    T Front();           //为了避免和队头指针重名front，故大写\n    int size();          //队列大小\n    bool isEmpty();      //队列是否为空\nprivate:\n    Node<T>* front;      //队头指针\n    Node<T>* rear;       //队尾指针\n    int count;           //记录结点个数\n};\n\n//队列的具体实现\ntemplate<typename T>\nLinkQueue<T>::LinkQueue() :front(nullptr), rear(nullptr), count(0)\n{\n}\n\ntemplate<typename T>\nLinkQueue<T>::~LinkQueue()\n{\n    while (front != nullptr)\n    {\n        Node<T>* temp = front;\n        front = front->next;\n        delete temp;\n    }\n}\n\ntemplate<typename T>\nvoid LinkQueue<T>::push(T x)\n{\n    if (count==0)                 //若为空，front指针和rear指针均置为插入结点指针\n    {\n        Node<T>* temp = new Node<T>(x);\n        front = rear = temp;      \n        count++;\n    }\n    else                          //若非空，则在rear处插入结点\n    {\n        Node<T>* temp = new Node<T>(x);\n        rear->next = temp;\n        rear = temp;\n        count++;\n    }\n}\n\ntemplate<typename T>\nbool LinkQueue<T>::pop()\n{\n    if (count==0)                 //若为空，则返回false\n        return false;\n    else if (count==1)            //若只有一个元素，则删除结点，front和rear均置为nullptr\n    {\n        delete front;\n        front = rear = nullptr;\n        count--;\n    }\n    else                          //否则，在front处删除结点\n    {\n        Node<T>* temp = front;\n        front = front->next;\n        delete temp;\n        count--;\n    }\n}\n\ntemplate<typename T>\nT LinkQueue<T>::Front()\n{\n    if (count != 0)\n        return front->value;\n}\n\ntemplate<typename T>\nint LinkQueue<T>::size()\n{\n    return count;\n}\n\ntemplate<typename T>\nbool LinkQueue<T>::isEmpty()\n{\n    return count == 0;\n}\n```\n\n（2）链式队列的代码测试\n```C++\nint main()\n{\n    //测试一\n    LinkQueue<int> queue;\n    queue.push(1);\n    queue.push(2);\n    queue.push(3);\n    queue.push(4);\n    cout << \"队列长度：\" << queue.size() << endl;\n    while (!queue.isEmpty())\n    {\n        cout << queue.Front() << endl;\n        queue.pop();\n    }\n    //测试二\n    LinkQueue<string> queue2;\n    queue2.push(\"How\");\n    queue2.push(\"are\");\n    queue2.push(\"you\");\n    cout << \"队列长度：\" << queue2.size() << endl;\n    while (!queue2.isEmpty())\n    {\n        cout << queue2.Front() << endl;\n        queue2.pop();\n    }\n    return 0;\n}\n\n```\n运行结果：\n```\n//测试1\n队列长度：4\n1\n2\n3\n4\n//测试2\n队列长度：3\nHow\nare\nyou\n```\n示例：\n入队：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%85%A5%E9%98%9F.JPG\" width=\"100%\" height=\"70%\">\n出队：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%87%BA%E9%98%9F.jpg\" width=\"100%\" height=\"70%\">\n## 七、参考\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [数据结构图文解析之：栈的简介及C++模板实现](http://www.cnblogs.com/QG-whz/p/5170418.html)\n- [数据结构图文解析之：队列详解与C++模板实现](http://www.cnblogs.com/QG-whz/p/5171123.html)\n\n\n\n\n\n","source":"_posts/栈与队列.md","raw":"---\ntitle: 栈与队列\ndate: 2017-11-22 15:49:49\nmathjax: true\ncategories: \n- 数据结构与算法\ntags:\n- 栈\n- 队列\n---\n## 一、栈的概念\n栈（stack）是限定仅在表尾进行插入和删除操作的线性表：\n（1）允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom）；\n（2）栈又称为后进先出（Last In First Out）的线性表，简称LIFO；\n（3）栈的插入操作，叫做进栈，也称压栈、入栈；\n（4）栈的删除操作，叫做出栈。\n栈的抽象数据类型：\n```C++\nADT 栈(stack)\nData\n    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。\nOperation\n    InitStack(*S):    初始化操作，建立一个空栈S。\n    DestroyStack(*S): 若栈存在，则销毁它。\n    ClearStack(*S):   将栈清空。\n    StackEmpty(S):    若栈为空，返回true，否则返回false。\n    Top(S, *e):       若栈存在且非空，用e返回S的栈顶元素。\n    Push(*S, e):      若栈S存在，插入新元素e到栈S中并成为栈顶元素。\n    Pop(*S, *e):      删除栈S中栈顶元素，并用e返回其值。\n    StackLength(S):   返回栈S的元素个数。\nendADT\n```\n栈示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"40%\" height=\"40%\">\n<!-- more --> \n## 二、栈的顺序存储结构——顺序栈\n### 2.1 实现\n要保证`Push()`、`Pop()`的时间复杂度为O(1)，故需**将数组下标为0的一端作为栈底，另一端为栈顶，进行插入/删除操作**。\n通常定义一个`top`变量来指示栈顶元素在数组中的位置，若存储栈的长度为`StackSize`，则栈顶位置`top`必须小于`StackSize`。当栈存在一个元素时，`top`等于0，因此通常把空栈的判定条件定为`top`等于-1。\n注：在下述模版实现中以`count`来统计栈的元素数量。初始值为0，表示空。`count==capacity`，表示满。\n顺序栈示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86%E5%9B%BE.jpg\" width=\"80%\" height=\"80%\">\n### 2.2 常见操作\n入栈：判是否栈已满，若未满，栈顶标记`top++`，`top`处插入元素，时间复杂度：O(1)\n出栈：判是否为空栈，若非空，栈顶标记`top--`，时间复杂度：O(1)\n### 2.3 C++模版实现\n（1）栈的具体实现：\n```C++\n#include <iostream>\nusing namespace std;\n\n//栈的抽象数据类型\ntemplate<typename T>\nclass ArrayStack\n{\npublic:\n    ArrayStack(int s = 10);          //默认的栈容量为10\n    ~ArrayStack();\npublic:\n    T top();\t\t\t     //获取栈顶元素\n    void push(T t);\t\t     //压栈操作\n    T pop();\t\t\t     //弹栈操作\n    bool isEmpty();\t\t     //判空操作\n    int size();\t\t\t     //求栈的大小\nprivate:\n    int count;\t\t\t     //记录栈的元素数量\n    int capacity;\t\t     //栈的容量\n    T * array;\t\t\t     //底层为数组\n};\n\n//栈的具体实现\n/*构造函数*/\ntemplate <typename T>\nArrayStack<T>::ArrayStack(int s = 10):count(0), capacity(s), array(nullptr)\n{\n    array = new T[capacity];\n}\n/*析构函数*/\ntemplate<typename T>\nArrayStack<T>::~ArrayStack()\n{\n    if (array)\n    {\n        delete[] array;\n        array = nullptr;\n    }\n}\n/*栈的判空操作*/\ntemplate <typename T>\nbool ArrayStack<T>::isEmpty()\n{\n    return count == 0;           //栈元素个数为0时为栈空\n}\n/*返回栈的大小*/\ntemplate <typename  T>\nint ArrayStack<T>::size()\n{\n    return count;\n}\n/*插入元素*/\ntemplate <typename T>\nvoid ArrayStack<T>::push(T t)\n{\n    if (count != capacity)       //先判断是否栈满\n    {\n        array[count++] = t;\t\n    }\n}\n/*弹栈*/\ntemplate <typename T>\nT ArrayStack<T>::pop()\n{\n    if (count != 0)              //先判断是否是空栈\n    {\n        return array[--count];\n    }\n}\n/*获取栈顶元素*/\ntemplate <typename T>\nT ArrayStack<T>::top()\n{\n    if (count != 0)\n    {\n        return array[count - 1];\n    }\n}\n```\n\n（3）栈的测试代码：\n```C++\nint main()\n{\n    ArrayStack<int> p(5);\n    for (int i = 0; i < 5; i++)\n    {\n        p.push(i);\n    }\n    cout << \"栈的大小:\"<<p.size() << endl;\n    cout << \"栈是否为空:\"<<p.isEmpty() << endl;\n    cout << \"栈顶元素：\"<<p.top() << endl;\n    cout << \"依次出栈:\" << endl;\n    while (!p.isEmpty())\n    {\n        cout << p.pop() << endl;\n    }\n    return 0;\n}\n```\n测试结果：\n```\n栈的大小:5\n栈是否为空:0\n栈顶元素：4\n依次出栈:\n4\n3\n2\n1\n0\n```\n\n入栈示例图:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%85%A5%E6%A0%88.png\" width=\"80%\" height=\"80%\">\n出栈示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%87%BA%E6%A0%88.png\" width=\"80%\" height=\"80%\">\n## 三、栈的链式存储结构——链栈\n### 3.1 实现\n对于单链表，在表头插入/删除的时间复杂度为O(1)，在表尾插入/删除的时间复杂度为O(n)。为保证栈的`Push()`、`Pop()`的时间复杂度为O(1)，故**链栈以单链表的头部为栈顶（进行插入/删除操作），链表尾部作为栈底**。通常设置`top`指针，记录栈顶位置，链栈为空就是`top`指针等于`NULL`的时候。\n[示例](https://www.youtube.com/watch?v=MuwxQ2IB8lQ&index=16&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"70%\" height=\"60%\">\n### 3.2 常见操作\n1.入栈：同链表在首位置插入结点操作：无需判栈满，新建结点，待插入结点指向头指针`top`所指向的内容；头指针`top`指向待插入结点。时间复杂度:O(1)。\n2.出栈：同链表在首位置删除结点操作：判栈是否空，若非空(`top!=NULL`)，栈顶指针`top`指向第2个结点，释放第一个结点空间。时间复杂度：O(1)。\n\n### 3.3 C++模版实现\n（1）栈的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n/*链表节点结构*/\ntemplate<typename T>\nclass Node\n{\npublic:\n    Node():next(nullptr){};\n    Node(T x):value(x), next(nullptr){};\npublic:\n    T value;\n    Node<T>* next;\n};\n\n/*栈的抽象数据结构*/\ntemplate<typename T>\nclass LinkStack\n{\npublic: \n    LinkStack();\n    ~LinkStack();\npublic:\n    void push(T x);\n    T pop();\n    T top();\n    bool isEmpty();\n    int size();\nprivate:\n    Node<T>* head;\n    int count; //记录栈的结点个数\n};\n\n/*栈的具体实现*/\n/*构造函数*/\ntemplate<typename T>\nLinkStack<T>::LinkStack() :head(nullptr), count(0)\n{\n}\n\n/*析构函数*/\ntemplate<typename T>\nLinkStack<T>::~LinkStack()\n{\n    while (head != nullptr)\n    {\n        Node<T>* temp = head;\n        head = head->next;\n        delete temp;\n    }\n    /*\n    while (!isEmpty())\n    {\n        pop();\n    }\n    */\n}\n\n/*入栈*/\ntemplate<typename T>\nvoid LinkStack<T>::push(T x)\n{\n    Node<T>* temp = new Node<T>(x);\n    temp->next = head;\n    head = temp;\n    count++;\n}\n\n/*出栈*/\ntemplate<typename T>\nT LinkStack<T>::pop()\n{\n    if (count != 0)  //栈空判断\n    {\n        Node<T>* temp = head;\n        head = head->next;\n        T val = temp->value;\n        delete temp;\n        temp = nullptr;\n        count--;\n        return val;\n    }\n}\n\n/*获取栈顶元素*/\ntemplate<typename T>\nT LinkStack<T>::top()\n{\n    if (count != 0)\n\t{\n        return head->value;\n    }\n}\n\n/*栈的判空操作*/\ntemplate<typename T>\nbool LinkStack<T>::isEmpty()\n{\n    return count == 0;\n}\n\n/*返回栈的大小*/\ntemplate<typename T>\nint LinkStack<T>::size()\n{\n    return count;\n}\n```\n（4）栈的测试代码\n```C++\nint main()\n{\n\t//测试一\n    LinkStack<int> stack;\n    stack.push(1);\n    stack.push(2);\n    stack.push(3);\n    stack.push(4);\n    cout << \"栈的大小:\" << stack.size() << endl;\n    cout << \"栈顶元素:\" << stack.top() << endl;\n    while (!stack.isEmpty())\n    {\n        stack.pop();\n    }\n    cout << \"栈的大小:\" << stack.size() << endl;\n\t//测试二\n    LinkStack<string> stack2;\n    stack2.push(\"How\");\n    stack2.push(\"are\");\n    stack2.push(\"you\");\n    cout << \"栈的大小:\" << stack2.size() << endl;\n    cout << \"栈顶元素:\" << stack2.top() << endl;\n    while (!stack2.isEmpty())\n\t{\n        stack2.pop();\n    }\n    cout << \"栈的大小:\" << stack2.size() << endl;\n    return 0;\n}\n```\n测试结果：\n```\n//测试一\n栈的大小:4\n栈顶元素:4\n栈的大小:0\n//测试2\n栈的大小:3\n栈顶元素:you\n栈的大小:0\n```\n\n[示例](https://www.youtube.com/watch?v=MuwxQ2IB8lQ&index=16&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)：\n入栈：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%85%A5%E6%A0%88.jpg\" width=\"100%\" height=\"100%\">\n出栈：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%87%BA%E6%A0%88.jpg\" width=\"100%\" height=\"100%\">\n\n## 四、队列的概念\n队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表：\n（1）允许插入的一端称为队尾（rear），允许删除的一端称为队头（front）；\n（2）队列是一种先进先出（First In First Out）的线性表，简称FIFO；\n（3）队列的插入操作，叫做入队；\n（4）队列的删除操作，叫做出队。\n队列的抽象数据类型：\n```C\nADT 队列(Queue)\nData\n    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。\nOperation\n    InitQueue(*Q):    初始化操作，建立一个空队列Q。\n    DestroyQueue(*Q): 若队列Q存在，则销毁它。\n    ClearQueue(*Q):   将队列Q清空。\n    QueueEmpty(Q):    若队列Q为空，返回true，否则返回false。\n    GetFront(Q, *e):  若队列Q存在且非空，用e返回队列Q的队头元素。\n    EnQueue(*Q, e):   若队列Q存在，插入新元素e到队列Q中并成为队尾元素。\n    DeQueue(*Q, *e):  删除队列Q中队头元素，并用e返回其值。\n    QueueLength(Q):   返回队列Q的元素个数\nendADT\n```\n队列示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"60%\" height=\"60%\">\n## 五、队列的顺序存储结构——顺序队列\n### 5.1 实现\n若采用数组实现简单顺序队列，则：\n（1）数组下标为0的一端就是队头，进行出队操作；\n（2）入队操作只需在队尾增加元素，不需要移动任何元素，时间复杂度为O(1)；\n（3）出队操作需要队列中的所有元素向前移动，时间复杂度为O(n)。(若采用把队首标志往后移动，时间复杂度是O(1)，但那样会造成数组空间的“流失”。)\n为了保证出队和入队操作的时间复杂度都为O(1)且不会造成数组空间的“流失”，故通常顺序队列的实现采用循环队列。\n循环队列：把数组看出一个首尾相连的圆环，删除元素时将队首标志往后移动，添加元素时若数组尾部已经没有空间，则考虑数组头部的空间是否空闲，如果是，则在数组头部进行插入：\n（1）判断队列为空：`begin==end`（初始化时`begin=0`，`end=0`）\n（2）判断队列满：`begin`与`end`之间隔一空位，即`(end + 1) % capacity == begin`\n（3）队列长度计算：`(end - begin + capacity) % capacity`\n- 若$end - begin\\geq0$，则$end - begin$即为队列元素个数。\n- 若$end - begin<0$，则$(end - begin + capacity)$为队列元素个数。\n- 上式`(end - begin + capacity) % capacity`照顾了这两种情况。\n\n（4）前移`begin`或`end`时，下一位置计算方法：`begin = (begin + 1) % capacity`或`end = (end + 1) % capacity`\n循环队列示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B1.jpg\" width=\"55%\" height=\"55%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B2.jpg\" width=\"55%\" height=\"55%\">\n\n### 5.2 常见操作\n入队：判队列是否满，若未满，则在队尾处插入元素，队尾指针`end`前移。时间复杂度：O(1)。\n出队：判队列是否为空，若不空，则队首指针`begin`前移。时间复杂度：O(1)。\n### 5.3 类模版实现\n（1）循环队列的的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n/*循环队列的抽象数据类型*/\ntemplate<typename T>\nclass LoopQueue\n{\npublic:\n    LoopQueue(int c);\n    ~LoopQueue();\npublic:\n    bool push(T x);      //入队列\n    bool pop();          //出队列\n    T front();           //队首元素\n    bool isEmpty();      //队列的判空\n    int size();          //队列的大小\nprivate:\n    int begin;           //队首标志\n    int end;             //队尾标志\n    int capacity;        //数组容量\n    T* queue;            //数组\n};\n\n/*队列的具体实现*/\ntemplate<typename T>\nLoopQueue<T>::LoopQueue(int c = 10) :capacity(c), begin(0), end(0), queue(nullptr)\n{\n    queue = new T[capacity];\n}\n\ntemplate<typename T>\nLoopQueue<T>::~LoopQueue()\n{\n    if(queue)\n    {\n        delete[] queue;\n        queue=nullptr;\n    }\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::push(T x)\n{\n    if (end + 1 % capacity == begin) //判断队列是否已满\n        return false;\n    queue[end] = x;\n    end = (end + 1) % capacity;\n    return true;\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::pop()\n{\n    if (begin == end)//判断队列是否为空\n        return false;\n    begin = (begin + 1) % capacity;\n    return true;\n}\n\ntemplate<typename T>\nT LoopQueue<T>::front()\n{\n    if (begin != end)\n        return queue[begin];\n}\n\ntemplate<typename T>\nbool LoopQueue<T>::isEmpty()\n{\n    return begin==end;\n}\n\ntemplate<typename T>\nint LoopQueue<T>::size()\n{\n    return (end - begin + capacity) % capacity;  //计算队列长度\n}\n```\n（3）循环队列代码测试\n```C++\nint main()\n{\n    //测试一\n    LoopQueue<int> queue(6);\n    queue.push(1);\n    queue.push(2);\n    queue.push(3);\n    queue.push(4);\n    cout << \"队列长度\" << queue.size() << endl;\n    while (!queue.isEmpty())\n    {\n        cout << queue.front() << endl;\n        queue.pop();\n    }\n    //测试二\n    LoopQueue<string> queue2(6);\n    queue2.push(\"How\");\n    queue2.push(\"are\");\n    queue2.push(\"you\");\n    cout << \"队列长度\" << queue2.size() << endl;\n    while (!queue2.isEmpty())\n    {\n        cout << queue2.front() << endl;\n        queue2.pop();\n    }\n    return 0;\n}\n```\n测试结果：\n```\n//测试一\n队列长度4\n1\n2\n3\n4\n//测试二\n队列长度3\nHow\nare\nyou\n```\n## 六、队列的链式存储结构——链式队列\n### 6.1 实现\n对于单链表，在表头进行插入/删除的时间复杂度为O(1)，在表尾进行插入/删除的时间复杂度为O(n)。故，为了保证入队和出队的时间复杂度为O(1)，以链表的头指针head为队头指针front，进行出队操作；在链表尾部设置队尾指针rear，进行入队操作。\n[示例](https://www.youtube.com/watch?v=A5_XdiK4J8A&list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&index=24)：\n链式队列示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"100%\" height=\"60%\">\n链式队列各状态示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%90%84%E7%8A%B6%E6%80%81.jpg\" width=\"60%\" height=\"50%\">\n### 6.2 常见操作\n1.**入队**：判队列是否为空，若为空(`count==0`)，则`front`指针和`rear`指针均置为插入结点指针；若队列非空，则在`rear`处插入结点。时间复杂度：O(1)。\n2.**出队**：判队列是否为空，若不空(`count!=0`)，判队列是否只有一个元素(`count==1`)，若只有一个元素，则删除结点，`front`指针和`rear`指针均置为`nullptr`(`front=rear=nullptr`)；否则，在`front`处删除结点。时间复杂度：O(1)。\n注1：在本章中，顺序栈、链式栈及链式队列中，**都通过私有变量`count`来帮助记录元素或结点个数**。\n注2：下述链式栈的模版实现，**只用了头指针`front`和尾指针`rear`，未使用头结点或尾结点**。\n### 6.3 类模版实现\n（1）链式队列的的具体实现\n```C++\n#include <iostream>\n#include <string>\nusing namespace std;\n\n//链表节点\ntemplate<typename T>\nclass Node\n{\npublic:\n    Node() :next(nullptr){};\n    Node(T x) :value(x), next(nullptr){};\npublic:\n    T value;\n    Node* next;\n};\n\n//队列的抽象数据类型\ntemplate<typename T>\nclass LinkQueue\n{\npublic:\n    LinkQueue();\n    ~LinkQueue();\npublic:\n    void push(T x);      //入队\n    bool pop();          //出队\n    T Front();           //为了避免和队头指针重名front，故大写\n    int size();          //队列大小\n    bool isEmpty();      //队列是否为空\nprivate:\n    Node<T>* front;      //队头指针\n    Node<T>* rear;       //队尾指针\n    int count;           //记录结点个数\n};\n\n//队列的具体实现\ntemplate<typename T>\nLinkQueue<T>::LinkQueue() :front(nullptr), rear(nullptr), count(0)\n{\n}\n\ntemplate<typename T>\nLinkQueue<T>::~LinkQueue()\n{\n    while (front != nullptr)\n    {\n        Node<T>* temp = front;\n        front = front->next;\n        delete temp;\n    }\n}\n\ntemplate<typename T>\nvoid LinkQueue<T>::push(T x)\n{\n    if (count==0)                 //若为空，front指针和rear指针均置为插入结点指针\n    {\n        Node<T>* temp = new Node<T>(x);\n        front = rear = temp;      \n        count++;\n    }\n    else                          //若非空，则在rear处插入结点\n    {\n        Node<T>* temp = new Node<T>(x);\n        rear->next = temp;\n        rear = temp;\n        count++;\n    }\n}\n\ntemplate<typename T>\nbool LinkQueue<T>::pop()\n{\n    if (count==0)                 //若为空，则返回false\n        return false;\n    else if (count==1)            //若只有一个元素，则删除结点，front和rear均置为nullptr\n    {\n        delete front;\n        front = rear = nullptr;\n        count--;\n    }\n    else                          //否则，在front处删除结点\n    {\n        Node<T>* temp = front;\n        front = front->next;\n        delete temp;\n        count--;\n    }\n}\n\ntemplate<typename T>\nT LinkQueue<T>::Front()\n{\n    if (count != 0)\n        return front->value;\n}\n\ntemplate<typename T>\nint LinkQueue<T>::size()\n{\n    return count;\n}\n\ntemplate<typename T>\nbool LinkQueue<T>::isEmpty()\n{\n    return count == 0;\n}\n```\n\n（2）链式队列的代码测试\n```C++\nint main()\n{\n    //测试一\n    LinkQueue<int> queue;\n    queue.push(1);\n    queue.push(2);\n    queue.push(3);\n    queue.push(4);\n    cout << \"队列长度：\" << queue.size() << endl;\n    while (!queue.isEmpty())\n    {\n        cout << queue.Front() << endl;\n        queue.pop();\n    }\n    //测试二\n    LinkQueue<string> queue2;\n    queue2.push(\"How\");\n    queue2.push(\"are\");\n    queue2.push(\"you\");\n    cout << \"队列长度：\" << queue2.size() << endl;\n    while (!queue2.isEmpty())\n    {\n        cout << queue2.Front() << endl;\n        queue2.pop();\n    }\n    return 0;\n}\n\n```\n运行结果：\n```\n//测试1\n队列长度：4\n1\n2\n3\n4\n//测试2\n队列长度：3\nHow\nare\nyou\n```\n示例：\n入队：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%85%A5%E9%98%9F.JPG\" width=\"100%\" height=\"70%\">\n出队：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%87%BA%E9%98%9F.jpg\" width=\"100%\" height=\"70%\">\n## 七、参考\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [数据结构图文解析之：栈的简介及C++模板实现](http://www.cnblogs.com/QG-whz/p/5170418.html)\n- [数据结构图文解析之：队列详解与C++模板实现](http://www.cnblogs.com/QG-whz/p/5171123.html)\n\n\n\n\n\n","slug":"栈与队列","published":1,"updated":"2018-02-01T06:26:23.463Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w1g004wqslphkt7jd36","content":"<h2 id=\"一、栈的概念\"><a href=\"#一、栈的概念\" class=\"headerlink\" title=\"一、栈的概念\"></a>一、栈的概念</h2><p>栈（stack）是限定仅在表尾进行插入和删除操作的线性表：<br>（1）允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom）；<br>（2）栈又称为后进先出（Last In First Out）的线性表，简称LIFO；<br>（3）栈的插入操作，叫做进栈，也称压栈、入栈；<br>（4）栈的删除操作，叫做出栈。<br>栈的抽象数据类型：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 栈(<span class=\"built_in\">stack</span>)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    InitStack(*S):    初始化操作，建立一个空栈S。</span><br><span class=\"line\">    DestroyStack(*S): 若栈存在，则销毁它。</span><br><span class=\"line\">    ClearStack(*S):   将栈清空。</span><br><span class=\"line\">    StackEmpty(S):    若栈为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    Top(S, *e):       若栈存在且非空，用e返回S的栈顶元素。</span><br><span class=\"line\">    Push(*S, e):      若栈S存在，插入新元素e到栈S中并成为栈顶元素。</span><br><span class=\"line\">    Pop(*S, *e):      删除栈S中栈顶元素，并用e返回其值。</span><br><span class=\"line\">    StackLength(S):   返回栈S的元素个数。</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<p>栈示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"40%\" height=\"40%\"><br><a id=\"more\"></a> </p>\n<h2 id=\"二、栈的顺序存储结构——顺序栈\"><a href=\"#二、栈的顺序存储结构——顺序栈\" class=\"headerlink\" title=\"二、栈的顺序存储结构——顺序栈\"></a>二、栈的顺序存储结构——顺序栈</h2><h3 id=\"2-1-实现\"><a href=\"#2-1-实现\" class=\"headerlink\" title=\"2.1 实现\"></a>2.1 实现</h3><p>要保证<code>Push()</code>、<code>Pop()</code>的时间复杂度为O(1)，故需<strong>将数组下标为0的一端作为栈底，另一端为栈顶，进行插入/删除操作</strong>。<br>通常定义一个<code>top</code>变量来指示栈顶元素在数组中的位置，若存储栈的长度为<code>StackSize</code>，则栈顶位置<code>top</code>必须小于<code>StackSize</code>。当栈存在一个元素时，<code>top</code>等于0，因此通常把空栈的判定条件定为<code>top</code>等于-1。<br>注：在下述模版实现中以<code>count</code>来统计栈的元素数量。初始值为0，表示空。<code>count==capacity</code>，表示满。<br>顺序栈示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86%E5%9B%BE.jpg\" width=\"80%\" height=\"80%\"></p>\n<h3 id=\"2-2-常见操作\"><a href=\"#2-2-常见操作\" class=\"headerlink\" title=\"2.2 常见操作\"></a>2.2 常见操作</h3><p>入栈：判是否栈已满，若未满，栈顶标记<code>top++</code>，<code>top</code>处插入元素，时间复杂度：O(1)<br>出栈：判是否为空栈，若非空，栈顶标记<code>top--</code>，时间复杂度：O(1)</p>\n<h3 id=\"2-3-C-模版实现\"><a href=\"#2-3-C-模版实现\" class=\"headerlink\" title=\"2.3 C++模版实现\"></a>2.3 C++模版实现</h3><p>（1）栈的具体实现：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//栈的抽象数据类型</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ArrayStack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    ArrayStack(<span class=\"keyword\">int</span> s = <span class=\"number\">10</span>);          <span class=\"comment\">//默认的栈容量为10</span></span><br><span class=\"line\">    ~ArrayStack();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">top</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//获取栈顶元素</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T t)</span></span>;\t\t     <span class=\"comment\">//压栈操作</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">pop</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//弹栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;\t\t     <span class=\"comment\">//判空操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//求栈的大小</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count;\t\t\t     <span class=\"comment\">//记录栈的元素数量</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> capacity;\t\t     <span class=\"comment\">//栈的容量</span></span><br><span class=\"line\">    T * <span class=\"built_in\">array</span>;\t\t\t     <span class=\"comment\">//底层为数组</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//栈的具体实现</span></span><br><span class=\"line\"><span class=\"comment\">/*构造函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">ArrayStack&lt;T&gt;::ArrayStack(<span class=\"keyword\">int</span> s = <span class=\"number\">10</span>):count(<span class=\"number\">0</span>), capacity(s), <span class=\"built_in\">array</span>(<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">array</span> = <span class=\"keyword\">new</span> T[capacity];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*析构函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">ArrayStack&lt;T&gt;::~ArrayStack()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">array</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span>[] <span class=\"built_in\">array</span>;</span><br><span class=\"line\">        <span class=\"built_in\">array</span> = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*栈的判空操作*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> ArrayStack&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;           <span class=\"comment\">//栈元素个数为0时为栈空</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*返回栈的大小*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span>  T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> ArrayStack&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*插入元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> ArrayStack&lt;T&gt;::push(T t)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != capacity)       <span class=\"comment\">//先判断是否栈满</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">array</span>[count++] = t;\t</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*弹栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T ArrayStack&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)              <span class=\"comment\">//先判断是否是空栈</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">array</span>[--count];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*获取栈顶元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T ArrayStack&lt;T&gt;::top()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">array</span>[count - <span class=\"number\">1</span>];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）栈的测试代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ArrayStack&lt;<span class=\"keyword\">int</span>&gt; p(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p.push(i);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span>&lt;&lt;p.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈是否为空:\"</span>&lt;&lt;p.isEmpty() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素：\"</span>&lt;&lt;p.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"依次出栈:\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!p.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; p.pop() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">栈的大小:5</span><br><span class=\"line\">栈是否为空:0</span><br><span class=\"line\">栈顶元素：4</span><br><span class=\"line\">依次出栈:</span><br><span class=\"line\">4</span><br><span class=\"line\">3</span><br><span class=\"line\">2</span><br><span class=\"line\">1</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure></p>\n<p>入栈示例图:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%85%A5%E6%A0%88.png\" width=\"80%\" height=\"80%\"><br>出栈示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%87%BA%E6%A0%88.png\" width=\"80%\" height=\"80%\"></p>\n<h2 id=\"三、栈的链式存储结构——链栈\"><a href=\"#三、栈的链式存储结构——链栈\" class=\"headerlink\" title=\"三、栈的链式存储结构——链栈\"></a>三、栈的链式存储结构——链栈</h2><h3 id=\"3-1-实现\"><a href=\"#3-1-实现\" class=\"headerlink\" title=\"3.1 实现\"></a>3.1 实现</h3><p>对于单链表，在表头插入/删除的时间复杂度为O(1)，在表尾插入/删除的时间复杂度为O(n)。为保证栈的<code>Push()</code>、<code>Pop()</code>的时间复杂度为O(1)，故<strong>链栈以单链表的头部为栈顶（进行插入/删除操作），链表尾部作为栈底</strong>。通常设置<code>top</code>指针，记录栈顶位置，链栈为空就是<code>top</code>指针等于<code>NULL</code>的时候。<br><a href=\"https://www.youtube.com/watch?v=MuwxQ2IB8lQ&amp;index=16&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"70%\" height=\"60%\"></p>\n<h3 id=\"3-2-常见操作\"><a href=\"#3-2-常见操作\" class=\"headerlink\" title=\"3.2 常见操作\"></a>3.2 常见操作</h3><p>1.入栈：同链表在首位置插入结点操作：无需判栈满，新建结点，待插入结点指向头指针<code>top</code>所指向的内容；头指针<code>top</code>指向待插入结点。时间复杂度:O(1)。<br>2.出栈：同链表在首位置删除结点操作：判栈是否空，若非空(<code>top!=NULL</code>)，栈顶指针<code>top</code>指向第2个结点，释放第一个结点空间。时间复杂度：O(1)。</p>\n<h3 id=\"3-3-C-模版实现\"><a href=\"#3-3-C-模版实现\" class=\"headerlink\" title=\"3.3 C++模版实现\"></a>3.3 C++模版实现</h3><p>（1）栈的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*链表节点结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    Node():next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\">    Node(T x):value(x), next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    T value;</span><br><span class=\"line\">    Node&lt;T&gt;* next;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的抽象数据结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LinkStack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>: </span><br><span class=\"line\">    LinkStack();</span><br><span class=\"line\">    ~LinkStack();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">pop</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">top</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    Node&lt;T&gt;* head;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count; <span class=\"comment\">//记录栈的结点个数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的具体实现*/</span></span><br><span class=\"line\"><span class=\"comment\">/*构造函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkStack&lt;T&gt;::LinkStack() :head(<span class=\"literal\">nullptr</span>), count(<span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*析构函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkStack&lt;T&gt;::~LinkStack()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = head;</span><br><span class=\"line\">        head = head-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    while (!isEmpty())</span></span><br><span class=\"line\"><span class=\"comment\">    &#123;</span></span><br><span class=\"line\"><span class=\"comment\">        pop();</span></span><br><span class=\"line\"><span class=\"comment\">    &#125;</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*入栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> LinkStack&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">    temp-&gt;next = head;</span><br><span class=\"line\">    head = temp;</span><br><span class=\"line\">    count++;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*出栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkStack&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)  <span class=\"comment\">//栈空判断</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = head;</span><br><span class=\"line\">        head = head-&gt;next;</span><br><span class=\"line\">        T val = temp-&gt;value;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">        temp = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> val;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*获取栈顶元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkStack&lt;T&gt;::top()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">true&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head-&gt;value;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的判空操作*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkStack&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*返回栈的大小*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LinkStack&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（4）栈的测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">true<span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LinkStack&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">stack</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">stack</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">stack</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">true<span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LinkStack&lt;<span class=\"built_in\">string</span>&gt; stack2;</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; stack2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素:\"</span> &lt;&lt; stack2.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!stack2.isEmpty())</span><br><span class=\"line\">true&#123;</span><br><span class=\"line\">        stack2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; stack2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试一</span><br><span class=\"line\">栈的大小:4</span><br><span class=\"line\">栈顶元素:4</span><br><span class=\"line\">栈的大小:0</span><br><span class=\"line\">//测试2</span><br><span class=\"line\">栈的大小:3</span><br><span class=\"line\">栈顶元素:you</span><br><span class=\"line\">栈的大小:0</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://www.youtube.com/watch?v=MuwxQ2IB8lQ&amp;index=16&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>入栈：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%85%A5%E6%A0%88.jpg\" width=\"100%\" height=\"100%\"><br>出栈：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%87%BA%E6%A0%88.jpg\" width=\"100%\" height=\"100%\"></p>\n<h2 id=\"四、队列的概念\"><a href=\"#四、队列的概念\" class=\"headerlink\" title=\"四、队列的概念\"></a>四、队列的概念</h2><p>队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表：<br>（1）允许插入的一端称为队尾（rear），允许删除的一端称为队头（front）；<br>（2）队列是一种先进先出（First In First Out）的线性表，简称FIFO；<br>（3）队列的插入操作，叫做入队；<br>（4）队列的删除操作，叫做出队。<br>队列的抽象数据类型：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 队列(Queue)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    InitQueue(*Q):    初始化操作，建立一个空队列Q。</span><br><span class=\"line\">    DestroyQueue(*Q): 若队列Q存在，则销毁它。</span><br><span class=\"line\">    ClearQueue(*Q):   将队列Q清空。</span><br><span class=\"line\">    QueueEmpty(Q):    若队列Q为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    GetFront(Q, *e):  若队列Q存在且非空，用e返回队列Q的队头元素。</span><br><span class=\"line\">    EnQueue(*Q, e):   若队列Q存在，插入新元素e到队列Q中并成为队尾元素。</span><br><span class=\"line\">    DeQueue(*Q, *e):  删除队列Q中队头元素，并用e返回其值。</span><br><span class=\"line\">    QueueLength(Q):   返回队列Q的元素个数</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<p>队列示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"五、队列的顺序存储结构——顺序队列\"><a href=\"#五、队列的顺序存储结构——顺序队列\" class=\"headerlink\" title=\"五、队列的顺序存储结构——顺序队列\"></a>五、队列的顺序存储结构——顺序队列</h2><h3 id=\"5-1-实现\"><a href=\"#5-1-实现\" class=\"headerlink\" title=\"5.1 实现\"></a>5.1 实现</h3><p>若采用数组实现简单顺序队列，则：<br>（1）数组下标为0的一端就是队头，进行出队操作；<br>（2）入队操作只需在队尾增加元素，不需要移动任何元素，时间复杂度为O(1)；<br>（3）出队操作需要队列中的所有元素向前移动，时间复杂度为O(n)。(若采用把队首标志往后移动，时间复杂度是O(1)，但那样会造成数组空间的“流失”。)<br>为了保证出队和入队操作的时间复杂度都为O(1)且不会造成数组空间的“流失”，故通常顺序队列的实现采用循环队列。<br>循环队列：把数组看出一个首尾相连的圆环，删除元素时将队首标志往后移动，添加元素时若数组尾部已经没有空间，则考虑数组头部的空间是否空闲，如果是，则在数组头部进行插入：<br>（1）判断队列为空：<code>begin==end</code>（初始化时<code>begin=0</code>，<code>end=0</code>）<br>（2）判断队列满：<code>begin</code>与<code>end</code>之间隔一空位，即<code>(end + 1) % capacity == begin</code><br>（3）队列长度计算：<code>(end - begin + capacity) % capacity</code></p>\n<ul>\n<li>若$end - begin\\geq0$，则$end - begin$即为队列元素个数。</li>\n<li>若$end - begin&lt;0$，则$(end - begin + capacity)$为队列元素个数。</li>\n<li>上式<code>(end - begin + capacity) % capacity</code>照顾了这两种情况。</li>\n</ul>\n<p>（4）前移<code>begin</code>或<code>end</code>时，下一位置计算方法：<code>begin = (begin + 1) % capacity</code>或<code>end = (end + 1) % capacity</code><br>循环队列示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B1.jpg\" width=\"55%\" height=\"55%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B2.jpg\" width=\"55%\" height=\"55%\"></p>\n<h3 id=\"5-2-常见操作\"><a href=\"#5-2-常见操作\" class=\"headerlink\" title=\"5.2 常见操作\"></a>5.2 常见操作</h3><p>入队：判队列是否满，若未满，则在队尾处插入元素，队尾指针<code>end</code>前移。时间复杂度：O(1)。<br>出队：判队列是否为空，若不空，则队首指针<code>begin</code>前移。时间复杂度：O(1)。</p>\n<h3 id=\"5-3-类模版实现\"><a href=\"#5-3-类模版实现\" class=\"headerlink\" title=\"5.3 类模版实现\"></a>5.3 类模版实现</h3><p>（1）循环队列的的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*循环队列的抽象数据类型*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LoopQueue</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    LoopQueue(<span class=\"keyword\">int</span> c);</span><br><span class=\"line\">    ~LoopQueue();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;      <span class=\"comment\">//入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">pop</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//出队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">front</span><span class=\"params\">()</span></span>;           <span class=\"comment\">//队首元素</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;      <span class=\"comment\">//队列的判空</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//队列的大小</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> begin;           <span class=\"comment\">//队首标志</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> end;             <span class=\"comment\">//队尾标志</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> capacity;        <span class=\"comment\">//数组容量</span></span><br><span class=\"line\">    T* <span class=\"built_in\">queue</span>;            <span class=\"comment\">//数组</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*队列的具体实现*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LoopQueue&lt;T&gt;::LoopQueue(<span class=\"keyword\">int</span> c = <span class=\"number\">10</span>) :capacity(c), begin(<span class=\"number\">0</span>), end(<span class=\"number\">0</span>), <span class=\"built_in\">queue</span>(<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span> = <span class=\"keyword\">new</span> T[capacity];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LoopQueue&lt;T&gt;::~LoopQueue()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"built_in\">queue</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span>[] <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (end + <span class=\"number\">1</span> % capacity == begin) <span class=\"comment\">//判断队列是否已满</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>[end] = x;</span><br><span class=\"line\">    end = (end + <span class=\"number\">1</span>) % capacity;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (begin == end)<span class=\"comment\">//判断队列是否为空</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    begin = (begin + <span class=\"number\">1</span>) % capacity;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LoopQueue&lt;T&gt;::front()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (begin != end)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">queue</span>[begin];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> begin==end;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LoopQueue&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (end - begin + capacity) % capacity;  <span class=\"comment\">//计算队列长度</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）循环队列代码测试<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LoopQueue&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">queue</span>(<span class=\"number\">6</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度\"</span> &lt;&lt; <span class=\"built_in\">queue</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">queue</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">queue</span>.front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LoopQueue&lt;<span class=\"built_in\">string</span>&gt; queue2(<span class=\"number\">6</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度\"</span> &lt;&lt; queue2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!queue2.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; queue2.front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        queue2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试一</span><br><span class=\"line\">队列长度4</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">//测试二</span><br><span class=\"line\">队列长度3</span><br><span class=\"line\">How</span><br><span class=\"line\">are</span><br><span class=\"line\">you</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"六、队列的链式存储结构——链式队列\"><a href=\"#六、队列的链式存储结构——链式队列\" class=\"headerlink\" title=\"六、队列的链式存储结构——链式队列\"></a>六、队列的链式存储结构——链式队列</h2><h3 id=\"6-1-实现\"><a href=\"#6-1-实现\" class=\"headerlink\" title=\"6.1 实现\"></a>6.1 实现</h3><p>对于单链表，在表头进行插入/删除的时间复杂度为O(1)，在表尾进行插入/删除的时间复杂度为O(n)。故，为了保证入队和出队的时间复杂度为O(1)，以链表的头指针head为队头指针front，进行出队操作；在链表尾部设置队尾指针rear，进行入队操作。<br><a href=\"https://www.youtube.com/watch?v=A5_XdiK4J8A&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;index=24\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>链式队列示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"100%\" height=\"60%\"><br>链式队列各状态示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%90%84%E7%8A%B6%E6%80%81.jpg\" width=\"60%\" height=\"50%\"></p>\n<h3 id=\"6-2-常见操作\"><a href=\"#6-2-常见操作\" class=\"headerlink\" title=\"6.2 常见操作\"></a>6.2 常见操作</h3><p>1.<strong>入队</strong>：判队列是否为空，若为空(<code>count==0</code>)，则<code>front</code>指针和<code>rear</code>指针均置为插入结点指针；若队列非空，则在<code>rear</code>处插入结点。时间复杂度：O(1)。<br>2.<strong>出队</strong>：判队列是否为空，若不空(<code>count!=0</code>)，判队列是否只有一个元素(<code>count==1</code>)，若只有一个元素，则删除结点，<code>front</code>指针和<code>rear</code>指针均置为<code>nullptr</code>(<code>front=rear=nullptr</code>)；否则，在<code>front</code>处删除结点。时间复杂度：O(1)。<br>注1：在本章中，顺序栈、链式栈及链式队列中，<strong>都通过私有变量<code>count</code>来帮助记录元素或结点个数</strong>。<br>注2：下述链式栈的模版实现，<strong>只用了头指针<code>front</code>和尾指针<code>rear</code>，未使用头结点或尾结点</strong>。</p>\n<h3 id=\"6-3-类模版实现\"><a href=\"#6-3-类模版实现\" class=\"headerlink\" title=\"6.3 类模版实现\"></a>6.3 类模版实现</h3><p>（1）链式队列的的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//链表节点</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    Node() :next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\">    Node(T x) :value(x), next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    T value;</span><br><span class=\"line\">    Node* next;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//队列的抽象数据类型</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LinkQueue</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    LinkQueue();</span><br><span class=\"line\">    ~LinkQueue();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;      <span class=\"comment\">//入队</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">pop</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//出队</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Front</span><span class=\"params\">()</span></span>;           <span class=\"comment\">//为了避免和队头指针重名front，故大写</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//队列大小</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;      <span class=\"comment\">//队列是否为空</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    Node&lt;T&gt;* front;      <span class=\"comment\">//队头指针</span></span><br><span class=\"line\">    Node&lt;T&gt;* rear;       <span class=\"comment\">//队尾指针</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> count;           <span class=\"comment\">//记录结点个数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//队列的具体实现</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkQueue&lt;T&gt;::LinkQueue() :front(<span class=\"literal\">nullptr</span>), rear(<span class=\"literal\">nullptr</span>), count(<span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkQueue&lt;T&gt;::~LinkQueue()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (front != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = front;</span><br><span class=\"line\">        front = front-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> LinkQueue&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count==<span class=\"number\">0</span>)                 <span class=\"comment\">//若为空，front指针和rear指针均置为插入结点指针</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">        front = rear = temp;      </span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>                          <span class=\"comment\">//若非空，则在rear处插入结点</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">        rear-&gt;next = temp;</span><br><span class=\"line\">        rear = temp;</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkQueue&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count==<span class=\"number\">0</span>)                 <span class=\"comment\">//若为空，则返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (count==<span class=\"number\">1</span>)            <span class=\"comment\">//若只有一个元素，则删除结点，front和rear均置为nullptr</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> front;</span><br><span class=\"line\">        front = rear = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>                          <span class=\"comment\">//否则，在front处删除结点</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = front;</span><br><span class=\"line\">        front = front-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkQueue&lt;T&gt;::Front()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> front-&gt;value;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LinkQueue&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkQueue&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）链式队列的代码测试<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LinkQueue&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度：\"</span> &lt;&lt; <span class=\"built_in\">queue</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">queue</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">queue</span>.Front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LinkQueue&lt;<span class=\"built_in\">string</span>&gt; queue2;</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度：\"</span> &lt;&lt; queue2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!queue2.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; queue2.Front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        queue2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>运行结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试1</span><br><span class=\"line\">队列长度：4</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">//测试2</span><br><span class=\"line\">队列长度：3</span><br><span class=\"line\">How</span><br><span class=\"line\">are</span><br><span class=\"line\">you</span><br></pre></td></tr></table></figure></p>\n<p>示例：<br>入队：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%85%A5%E9%98%9F.JPG\" width=\"100%\" height=\"70%\"><br>出队：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%87%BA%E9%98%9F.jpg\" width=\"100%\" height=\"70%\"></p>\n<h2 id=\"七、参考\"><a href=\"#七、参考\" class=\"headerlink\" title=\"七、参考\"></a>七、参考</h2><ul>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"http://www.cnblogs.com/QG-whz/p/5170418.html\" target=\"_blank\" rel=\"noopener\">数据结构图文解析之：栈的简介及C++模板实现</a></li>\n<li><a href=\"http://www.cnblogs.com/QG-whz/p/5171123.html\" target=\"_blank\" rel=\"noopener\">数据结构图文解析之：队列详解与C++模板实现</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"一、栈的概念\"><a href=\"#一、栈的概念\" class=\"headerlink\" title=\"一、栈的概念\"></a>一、栈的概念</h2><p>栈（stack）是限定仅在表尾进行插入和删除操作的线性表：<br>（1）允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom）；<br>（2）栈又称为后进先出（Last In First Out）的线性表，简称LIFO；<br>（3）栈的插入操作，叫做进栈，也称压栈、入栈；<br>（4）栈的删除操作，叫做出栈。<br>栈的抽象数据类型：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 栈(<span class=\"built_in\">stack</span>)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    InitStack(*S):    初始化操作，建立一个空栈S。</span><br><span class=\"line\">    DestroyStack(*S): 若栈存在，则销毁它。</span><br><span class=\"line\">    ClearStack(*S):   将栈清空。</span><br><span class=\"line\">    StackEmpty(S):    若栈为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    Top(S, *e):       若栈存在且非空，用e返回S的栈顶元素。</span><br><span class=\"line\">    Push(*S, e):      若栈S存在，插入新元素e到栈S中并成为栈顶元素。</span><br><span class=\"line\">    Pop(*S, *e):      删除栈S中栈顶元素，并用e返回其值。</span><br><span class=\"line\">    StackLength(S):   返回栈S的元素个数。</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<p>栈示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"40%\" height=\"40%\"><br>","more":"</p>\n<h2 id=\"二、栈的顺序存储结构——顺序栈\"><a href=\"#二、栈的顺序存储结构——顺序栈\" class=\"headerlink\" title=\"二、栈的顺序存储结构——顺序栈\"></a>二、栈的顺序存储结构——顺序栈</h2><h3 id=\"2-1-实现\"><a href=\"#2-1-实现\" class=\"headerlink\" title=\"2.1 实现\"></a>2.1 实现</h3><p>要保证<code>Push()</code>、<code>Pop()</code>的时间复杂度为O(1)，故需<strong>将数组下标为0的一端作为栈底，另一端为栈顶，进行插入/删除操作</strong>。<br>通常定义一个<code>top</code>变量来指示栈顶元素在数组中的位置，若存储栈的长度为<code>StackSize</code>，则栈顶位置<code>top</code>必须小于<code>StackSize</code>。当栈存在一个元素时，<code>top</code>等于0，因此通常把空栈的判定条件定为<code>top</code>等于-1。<br>注：在下述模版实现中以<code>count</code>来统计栈的元素数量。初始值为0，表示空。<code>count==capacity</code>，表示满。<br>顺序栈示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E6%A0%88%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86%E5%9B%BE.jpg\" width=\"80%\" height=\"80%\"></p>\n<h3 id=\"2-2-常见操作\"><a href=\"#2-2-常见操作\" class=\"headerlink\" title=\"2.2 常见操作\"></a>2.2 常见操作</h3><p>入栈：判是否栈已满，若未满，栈顶标记<code>top++</code>，<code>top</code>处插入元素，时间复杂度：O(1)<br>出栈：判是否为空栈，若非空，栈顶标记<code>top--</code>，时间复杂度：O(1)</p>\n<h3 id=\"2-3-C-模版实现\"><a href=\"#2-3-C-模版实现\" class=\"headerlink\" title=\"2.3 C++模版实现\"></a>2.3 C++模版实现</h3><p>（1）栈的具体实现：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//栈的抽象数据类型</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ArrayStack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    ArrayStack(<span class=\"keyword\">int</span> s = <span class=\"number\">10</span>);          <span class=\"comment\">//默认的栈容量为10</span></span><br><span class=\"line\">    ~ArrayStack();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">top</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//获取栈顶元素</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T t)</span></span>;\t\t     <span class=\"comment\">//压栈操作</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">pop</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//弹栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;\t\t     <span class=\"comment\">//判空操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;\t\t\t     <span class=\"comment\">//求栈的大小</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count;\t\t\t     <span class=\"comment\">//记录栈的元素数量</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> capacity;\t\t     <span class=\"comment\">//栈的容量</span></span><br><span class=\"line\">    T * <span class=\"built_in\">array</span>;\t\t\t     <span class=\"comment\">//底层为数组</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//栈的具体实现</span></span><br><span class=\"line\"><span class=\"comment\">/*构造函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">ArrayStack&lt;T&gt;::ArrayStack(<span class=\"keyword\">int</span> s = <span class=\"number\">10</span>):count(<span class=\"number\">0</span>), capacity(s), <span class=\"built_in\">array</span>(<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">array</span> = <span class=\"keyword\">new</span> T[capacity];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*析构函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">ArrayStack&lt;T&gt;::~ArrayStack()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"built_in\">array</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span>[] <span class=\"built_in\">array</span>;</span><br><span class=\"line\">        <span class=\"built_in\">array</span> = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*栈的判空操作*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> ArrayStack&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;           <span class=\"comment\">//栈元素个数为0时为栈空</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*返回栈的大小*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span>  T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> ArrayStack&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*插入元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> ArrayStack&lt;T&gt;::push(T t)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != capacity)       <span class=\"comment\">//先判断是否栈满</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">array</span>[count++] = t;\t</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*弹栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T ArrayStack&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)              <span class=\"comment\">//先判断是否是空栈</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">array</span>[--count];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">/*获取栈顶元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T ArrayStack&lt;T&gt;::top()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">array</span>[count - <span class=\"number\">1</span>];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）栈的测试代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ArrayStack&lt;<span class=\"keyword\">int</span>&gt; p(<span class=\"number\">5</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">5</span>; i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p.push(i);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span>&lt;&lt;p.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈是否为空:\"</span>&lt;&lt;p.isEmpty() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素：\"</span>&lt;&lt;p.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"依次出栈:\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!p.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; p.pop() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">栈的大小:5</span><br><span class=\"line\">栈是否为空:0</span><br><span class=\"line\">栈顶元素：4</span><br><span class=\"line\">依次出栈:</span><br><span class=\"line\">4</span><br><span class=\"line\">3</span><br><span class=\"line\">2</span><br><span class=\"line\">1</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure></p>\n<p>入栈示例图:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%85%A5%E6%A0%88.png\" width=\"80%\" height=\"80%\"><br>出栈示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%A1%BA%E5%BA%8F%E6%A0%88_%E5%87%BA%E6%A0%88.png\" width=\"80%\" height=\"80%\"></p>\n<h2 id=\"三、栈的链式存储结构——链栈\"><a href=\"#三、栈的链式存储结构——链栈\" class=\"headerlink\" title=\"三、栈的链式存储结构——链栈\"></a>三、栈的链式存储结构——链栈</h2><h3 id=\"3-1-实现\"><a href=\"#3-1-实现\" class=\"headerlink\" title=\"3.1 实现\"></a>3.1 实现</h3><p>对于单链表，在表头插入/删除的时间复杂度为O(1)，在表尾插入/删除的时间复杂度为O(n)。为保证栈的<code>Push()</code>、<code>Pop()</code>的时间复杂度为O(1)，故<strong>链栈以单链表的头部为栈顶（进行插入/删除操作），链表尾部作为栈底</strong>。通常设置<code>top</code>指针，记录栈顶位置，链栈为空就是<code>top</code>指针等于<code>NULL</code>的时候。<br><a href=\"https://www.youtube.com/watch?v=MuwxQ2IB8lQ&amp;index=16&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"70%\" height=\"60%\"></p>\n<h3 id=\"3-2-常见操作\"><a href=\"#3-2-常见操作\" class=\"headerlink\" title=\"3.2 常见操作\"></a>3.2 常见操作</h3><p>1.入栈：同链表在首位置插入结点操作：无需判栈满，新建结点，待插入结点指向头指针<code>top</code>所指向的内容；头指针<code>top</code>指向待插入结点。时间复杂度:O(1)。<br>2.出栈：同链表在首位置删除结点操作：判栈是否空，若非空(<code>top!=NULL</code>)，栈顶指针<code>top</code>指向第2个结点，释放第一个结点空间。时间复杂度：O(1)。</p>\n<h3 id=\"3-3-C-模版实现\"><a href=\"#3-3-C-模版实现\" class=\"headerlink\" title=\"3.3 C++模版实现\"></a>3.3 C++模版实现</h3><p>（1）栈的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*链表节点结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    Node():next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\">    Node(T x):value(x), next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    T value;</span><br><span class=\"line\">    Node&lt;T&gt;* next;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的抽象数据结构*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LinkStack</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>: </span><br><span class=\"line\">    LinkStack();</span><br><span class=\"line\">    ~LinkStack();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">pop</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">top</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    Node&lt;T&gt;* head;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count; <span class=\"comment\">//记录栈的结点个数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的具体实现*/</span></span><br><span class=\"line\"><span class=\"comment\">/*构造函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkStack&lt;T&gt;::LinkStack() :head(<span class=\"literal\">nullptr</span>), count(<span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*析构函数*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkStack&lt;T&gt;::~LinkStack()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (head != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = head;</span><br><span class=\"line\">        head = head-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">    while (!isEmpty())</span></span><br><span class=\"line\"><span class=\"comment\">    &#123;</span></span><br><span class=\"line\"><span class=\"comment\">        pop();</span></span><br><span class=\"line\"><span class=\"comment\">    &#125;</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*入栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> LinkStack&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">    temp-&gt;next = head;</span><br><span class=\"line\">    head = temp;</span><br><span class=\"line\">    count++;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*出栈*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkStack&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)  <span class=\"comment\">//栈空判断</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = head;</span><br><span class=\"line\">        head = head-&gt;next;</span><br><span class=\"line\">        T val = temp-&gt;value;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">        temp = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> val;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*获取栈顶元素*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkStack&lt;T&gt;::top()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">true&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head-&gt;value;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*栈的判空操作*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkStack&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*返回栈的大小*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LinkStack&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（4）栈的测试代码<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">true<span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LinkStack&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">stack</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">stack</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">stack</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; <span class=\"built_in\">stack</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">true<span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LinkStack&lt;<span class=\"built_in\">string</span>&gt; stack2;</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    stack2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; stack2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈顶元素:\"</span> &lt;&lt; stack2.top() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!stack2.isEmpty())</span><br><span class=\"line\">true&#123;</span><br><span class=\"line\">        stack2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"栈的大小:\"</span> &lt;&lt; stack2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试一</span><br><span class=\"line\">栈的大小:4</span><br><span class=\"line\">栈顶元素:4</span><br><span class=\"line\">栈的大小:0</span><br><span class=\"line\">//测试2</span><br><span class=\"line\">栈的大小:3</span><br><span class=\"line\">栈顶元素:you</span><br><span class=\"line\">栈的大小:0</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://www.youtube.com/watch?v=MuwxQ2IB8lQ&amp;index=16&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>入栈：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%85%A5%E6%A0%88.jpg\" width=\"100%\" height=\"100%\"><br>出栈：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E6%A0%88_%E5%87%BA%E6%A0%88.jpg\" width=\"100%\" height=\"100%\"></p>\n<h2 id=\"四、队列的概念\"><a href=\"#四、队列的概念\" class=\"headerlink\" title=\"四、队列的概念\"></a>四、队列的概念</h2><p>队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表：<br>（1）允许插入的一端称为队尾（rear），允许删除的一端称为队头（front）；<br>（2）队列是一种先进先出（First In First Out）的线性表，简称FIFO；<br>（3）队列的插入操作，叫做入队；<br>（4）队列的删除操作，叫做出队。<br>队列的抽象数据类型：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 队列(Queue)</span><br><span class=\"line\">Data</span><br><span class=\"line\">    同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。</span><br><span class=\"line\">Operation</span><br><span class=\"line\">    InitQueue(*Q):    初始化操作，建立一个空队列Q。</span><br><span class=\"line\">    DestroyQueue(*Q): 若队列Q存在，则销毁它。</span><br><span class=\"line\">    ClearQueue(*Q):   将队列Q清空。</span><br><span class=\"line\">    QueueEmpty(Q):    若队列Q为空，返回<span class=\"literal\">true</span>，否则返回<span class=\"literal\">false</span>。</span><br><span class=\"line\">    GetFront(Q, *e):  若队列Q存在且非空，用e返回队列Q的队头元素。</span><br><span class=\"line\">    EnQueue(*Q, e):   若队列Q存在，插入新元素e到队列Q中并成为队尾元素。</span><br><span class=\"line\">    DeQueue(*Q, *e):  删除队列Q中队头元素，并用e返回其值。</span><br><span class=\"line\">    QueueLength(Q):   返回队列Q的元素个数</span><br><span class=\"line\">endADT</span><br></pre></td></tr></table></figure></p>\n<p>队列示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B%E5%9B%BE.JPG\" width=\"60%\" height=\"60%\"></p>\n<h2 id=\"五、队列的顺序存储结构——顺序队列\"><a href=\"#五、队列的顺序存储结构——顺序队列\" class=\"headerlink\" title=\"五、队列的顺序存储结构——顺序队列\"></a>五、队列的顺序存储结构——顺序队列</h2><h3 id=\"5-1-实现\"><a href=\"#5-1-实现\" class=\"headerlink\" title=\"5.1 实现\"></a>5.1 实现</h3><p>若采用数组实现简单顺序队列，则：<br>（1）数组下标为0的一端就是队头，进行出队操作；<br>（2）入队操作只需在队尾增加元素，不需要移动任何元素，时间复杂度为O(1)；<br>（3）出队操作需要队列中的所有元素向前移动，时间复杂度为O(n)。(若采用把队首标志往后移动，时间复杂度是O(1)，但那样会造成数组空间的“流失”。)<br>为了保证出队和入队操作的时间复杂度都为O(1)且不会造成数组空间的“流失”，故通常顺序队列的实现采用循环队列。<br>循环队列：把数组看出一个首尾相连的圆环，删除元素时将队首标志往后移动，添加元素时若数组尾部已经没有空间，则考虑数组头部的空间是否空闲，如果是，则在数组头部进行插入：<br>（1）判断队列为空：<code>begin==end</code>（初始化时<code>begin=0</code>，<code>end=0</code>）<br>（2）判断队列满：<code>begin</code>与<code>end</code>之间隔一空位，即<code>(end + 1) % capacity == begin</code><br>（3）队列长度计算：<code>(end - begin + capacity) % capacity</code></p>\n<ul>\n<li>若$end - begin\\geq0$，则$end - begin$即为队列元素个数。</li>\n<li>若$end - begin&lt;0$，则$(end - begin + capacity)$为队列元素个数。</li>\n<li>上式<code>(end - begin + capacity) % capacity</code>照顾了这两种情况。</li>\n</ul>\n<p>（4）前移<code>begin</code>或<code>end</code>时，下一位置计算方法：<code>begin = (begin + 1) % capacity</code>或<code>end = (end + 1) % capacity</code><br>循环队列示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B1.jpg\" width=\"55%\" height=\"55%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97%E7%A4%BA%E4%BE%8B2.jpg\" width=\"55%\" height=\"55%\"></p>\n<h3 id=\"5-2-常见操作\"><a href=\"#5-2-常见操作\" class=\"headerlink\" title=\"5.2 常见操作\"></a>5.2 常见操作</h3><p>入队：判队列是否满，若未满，则在队尾处插入元素，队尾指针<code>end</code>前移。时间复杂度：O(1)。<br>出队：判队列是否为空，若不空，则队首指针<code>begin</code>前移。时间复杂度：O(1)。</p>\n<h3 id=\"5-3-类模版实现\"><a href=\"#5-3-类模版实现\" class=\"headerlink\" title=\"5.3 类模版实现\"></a>5.3 类模版实现</h3><p>（1）循环队列的的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*循环队列的抽象数据类型*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LoopQueue</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    LoopQueue(<span class=\"keyword\">int</span> c);</span><br><span class=\"line\">    ~LoopQueue();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;      <span class=\"comment\">//入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">pop</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//出队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">front</span><span class=\"params\">()</span></span>;           <span class=\"comment\">//队首元素</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;      <span class=\"comment\">//队列的判空</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//队列的大小</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> begin;           <span class=\"comment\">//队首标志</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> end;             <span class=\"comment\">//队尾标志</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> capacity;        <span class=\"comment\">//数组容量</span></span><br><span class=\"line\">    T* <span class=\"built_in\">queue</span>;            <span class=\"comment\">//数组</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/*队列的具体实现*/</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LoopQueue&lt;T&gt;::LoopQueue(<span class=\"keyword\">int</span> c = <span class=\"number\">10</span>) :capacity(c), begin(<span class=\"number\">0</span>), end(<span class=\"number\">0</span>), <span class=\"built_in\">queue</span>(<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span> = <span class=\"keyword\">new</span> T[capacity];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LoopQueue&lt;T&gt;::~LoopQueue()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"built_in\">queue</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span>[] <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (end + <span class=\"number\">1</span> % capacity == begin) <span class=\"comment\">//判断队列是否已满</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>[end] = x;</span><br><span class=\"line\">    end = (end + <span class=\"number\">1</span>) % capacity;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (begin == end)<span class=\"comment\">//判断队列是否为空</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    begin = (begin + <span class=\"number\">1</span>) % capacity;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LoopQueue&lt;T&gt;::front()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (begin != end)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">queue</span>[begin];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LoopQueue&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> begin==end;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LoopQueue&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (end - begin + capacity) % capacity;  <span class=\"comment\">//计算队列长度</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（3）循环队列代码测试<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LoopQueue&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">queue</span>(<span class=\"number\">6</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度\"</span> &lt;&lt; <span class=\"built_in\">queue</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">queue</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">queue</span>.front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LoopQueue&lt;<span class=\"built_in\">string</span>&gt; queue2(<span class=\"number\">6</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度\"</span> &lt;&lt; queue2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!queue2.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; queue2.front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        queue2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试一</span><br><span class=\"line\">队列长度4</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">//测试二</span><br><span class=\"line\">队列长度3</span><br><span class=\"line\">How</span><br><span class=\"line\">are</span><br><span class=\"line\">you</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"六、队列的链式存储结构——链式队列\"><a href=\"#六、队列的链式存储结构——链式队列\" class=\"headerlink\" title=\"六、队列的链式存储结构——链式队列\"></a>六、队列的链式存储结构——链式队列</h2><h3 id=\"6-1-实现\"><a href=\"#6-1-实现\" class=\"headerlink\" title=\"6.1 实现\"></a>6.1 实现</h3><p>对于单链表，在表头进行插入/删除的时间复杂度为O(1)，在表尾进行插入/删除的时间复杂度为O(n)。故，为了保证入队和出队的时间复杂度为O(1)，以链表的头指针head为队头指针front，进行出队操作；在链表尾部设置队尾指针rear，进行入队操作。<br><a href=\"https://www.youtube.com/watch?v=A5_XdiK4J8A&amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;index=24\" target=\"_blank\" rel=\"noopener\">示例</a>：<br>链式队列示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E7%A4%BA%E6%84%8F%E5%9B%BE.JPG\" width=\"100%\" height=\"60%\"><br>链式队列各状态示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%90%84%E7%8A%B6%E6%80%81.jpg\" width=\"60%\" height=\"50%\"></p>\n<h3 id=\"6-2-常见操作\"><a href=\"#6-2-常见操作\" class=\"headerlink\" title=\"6.2 常见操作\"></a>6.2 常见操作</h3><p>1.<strong>入队</strong>：判队列是否为空，若为空(<code>count==0</code>)，则<code>front</code>指针和<code>rear</code>指针均置为插入结点指针；若队列非空，则在<code>rear</code>处插入结点。时间复杂度：O(1)。<br>2.<strong>出队</strong>：判队列是否为空，若不空(<code>count!=0</code>)，判队列是否只有一个元素(<code>count==1</code>)，若只有一个元素，则删除结点，<code>front</code>指针和<code>rear</code>指针均置为<code>nullptr</code>(<code>front=rear=nullptr</code>)；否则，在<code>front</code>处删除结点。时间复杂度：O(1)。<br>注1：在本章中，顺序栈、链式栈及链式队列中，<strong>都通过私有变量<code>count</code>来帮助记录元素或结点个数</strong>。<br>注2：下述链式栈的模版实现，<strong>只用了头指针<code>front</code>和尾指针<code>rear</code>，未使用头结点或尾结点</strong>。</p>\n<h3 id=\"6-3-类模版实现\"><a href=\"#6-3-类模版实现\" class=\"headerlink\" title=\"6.3 类模版实现\"></a>6.3 类模版实现</h3><p>（1）链式队列的的具体实现<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//链表节点</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    Node() :next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\">    Node(T x) :value(x), next(<span class=\"literal\">nullptr</span>)&#123;&#125;;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    T value;</span><br><span class=\"line\">    Node* next;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//队列的抽象数据类型</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LinkQueue</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    LinkQueue();</span><br><span class=\"line\">    ~LinkQueue();</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(T x)</span></span>;      <span class=\"comment\">//入队</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">pop</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//出队</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Front</span><span class=\"params\">()</span></span>;           <span class=\"comment\">//为了避免和队头指针重名front，故大写</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">size</span><span class=\"params\">()</span></span>;          <span class=\"comment\">//队列大小</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isEmpty</span><span class=\"params\">()</span></span>;      <span class=\"comment\">//队列是否为空</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    Node&lt;T&gt;* front;      <span class=\"comment\">//队头指针</span></span><br><span class=\"line\">    Node&lt;T&gt;* rear;       <span class=\"comment\">//队尾指针</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> count;           <span class=\"comment\">//记录结点个数</span></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//队列的具体实现</span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkQueue&lt;T&gt;::LinkQueue() :front(<span class=\"literal\">nullptr</span>), rear(<span class=\"literal\">nullptr</span>), count(<span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">LinkQueue&lt;T&gt;::~LinkQueue()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (front != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = front;</span><br><span class=\"line\">        front = front-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span> LinkQueue&lt;T&gt;::push(T x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count==<span class=\"number\">0</span>)                 <span class=\"comment\">//若为空，front指针和rear指针均置为插入结点指针</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">        front = rear = temp;      </span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>                          <span class=\"comment\">//若非空，则在rear处插入结点</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = <span class=\"keyword\">new</span> Node&lt;T&gt;(x);</span><br><span class=\"line\">        rear-&gt;next = temp;</span><br><span class=\"line\">        rear = temp;</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkQueue&lt;T&gt;::pop()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count==<span class=\"number\">0</span>)                 <span class=\"comment\">//若为空，则返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (count==<span class=\"number\">1</span>)            <span class=\"comment\">//若只有一个元素，则删除结点，front和rear均置为nullptr</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> front;</span><br><span class=\"line\">        front = rear = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span>                          <span class=\"comment\">//否则，在front处删除结点</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node&lt;T&gt;* temp = front;</span><br><span class=\"line\">        front = front-&gt;next;</span><br><span class=\"line\">        <span class=\"keyword\">delete</span> temp;</span><br><span class=\"line\">        count--;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\">T LinkQueue&lt;T&gt;::Front()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (count != <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> front-&gt;value;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">int</span> LinkQueue&lt;T&gt;::size()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">bool</span> LinkQueue&lt;T&gt;::isEmpty()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> count == <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>（2）链式队列的代码测试<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//测试一</span></span><br><span class=\"line\">    LinkQueue&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">2</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>.push(<span class=\"number\">4</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度：\"</span> &lt;&lt; <span class=\"built_in\">queue</span>.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"built_in\">queue</span>.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"built_in\">queue</span>.Front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        <span class=\"built_in\">queue</span>.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//测试二</span></span><br><span class=\"line\">    LinkQueue&lt;<span class=\"built_in\">string</span>&gt; queue2;</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"How\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"are\"</span>);</span><br><span class=\"line\">    queue2.push(<span class=\"string\">\"you\"</span>);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"队列长度：\"</span> &lt;&lt; queue2.size() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!queue2.isEmpty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; queue2.Front() &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        queue2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>运行结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试1</span><br><span class=\"line\">队列长度：4</span><br><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">//测试2</span><br><span class=\"line\">队列长度：3</span><br><span class=\"line\">How</span><br><span class=\"line\">are</span><br><span class=\"line\">you</span><br></pre></td></tr></table></figure></p>\n<p>示例：<br>入队：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%85%A5%E9%98%9F.JPG\" width=\"100%\" height=\"70%\"><br>出队：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/%E9%93%BE%E5%BC%8F%E9%98%9F%E5%88%97%E5%87%BA%E9%98%9F.jpg\" width=\"100%\" height=\"70%\"></p>\n<h2 id=\"七、参考\"><a href=\"#七、参考\" class=\"headerlink\" title=\"七、参考\"></a>七、参考</h2><ul>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"http://www.cnblogs.com/QG-whz/p/5170418.html\" target=\"_blank\" rel=\"noopener\">数据结构图文解析之：栈的简介及C++模板实现</a></li>\n<li><a href=\"http://www.cnblogs.com/QG-whz/p/5171123.html\" target=\"_blank\" rel=\"noopener\">数据结构图文解析之：队列详解与C++模板实现</a></li>\n</ul>"},{"title":"树","date":"2017-11-26T13:12:00.000Z","mathjax":true,"_content":"# 1.树的基本概念\n## 1.1 树的定义\n树是$n(n≥0)$个结点的有限集：\n- $n=0$时称为空树；\n- 对于任意一颗非空树($n>0$)，它具备以下性质：\n - 有且仅有一个特定的称为根（Root）的结点，根结点唯一； \n - 当$n＞1$时，其余结点可分为$m(m>0)$个互不相交的有限集 $T_1$、$T_2$、... 、$T_m$，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。子树的个数没有限制，但它们一定互不相交。\n \n<!-- more --> \n\n## 1.2 相关概念\n- 结点分类：根节点、内部结点、叶结点或终端结点。\n- 结点的关系：\n - 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点。\n - 孩子节点：一个节点含有的子树的根节点称为该节点的子节点。\n - 兄弟节点：具有相同父节点的节点互称为兄弟节点。\n- 结点的度：结点拥有的子树数。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点；除根结点之外，分支结点也称为内部结点。\n- 树的度：树的度是树内各结点的度的最大值。\n- 结点的深度（Depth）：结点$n$的深度为从根结点到$n$的唯一路径长，根结点的深度为0（或1，两种表示方法都有）；\n- 结点的层次（Level）：从根开始定义起，根为第0层（或1，两种表示方法都有），根的子节点为第1层，以此类推。同结点的深度；\n- 树的深度：深度最大的叶结点的深度就是树的深度。\n- 结点的高度（Height）：对于任意节点$n$，$n$的高度为任一叶结点到$n$的最长路径长，所有叶结点的高度为0（或1，两种表示方法都有）；\n - 对于高度，类比于想知道一栋楼房的高度，从下往上数看有几层。\n- 树的高度：根结点的高度就是树的高度。\n- 总结：树的高度和深度是相等的。但对于树中相同深度的每个结点来说，它们的高度不一定相同，反之亦然。\n\n示例：\n- 结点分类及关系示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%A4%BA%E4%BE%8B%E5%9B%BE.jpeg\" width=\"50%\" height=\"50%\">\n- 结点的深度与高度示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E9%AB%98%E5%BA%A6.JPG\" width=\"50%\" height=\"50%\">\n- 结点的层次示例图（同结点的深度）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E5%B1%82%E6%AC%A1.JPG\" width=\"50%\" height=\"50%\">\n- 树的深度和高度示例图（树的深度等于树的高度）:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6.png\" width=\"50%\" height=\"50%\">\n\n# 2.二叉树\n## 2.1 二叉树的定义\n二叉树：二叉树是$n$个结点的有限集合，该集合或者为空集（空二叉树），或者由一个根结点和两棵互不相交的，分别称为根结点的左子树和右子树的二叉树组成。\n\n二叉树的特点：\n- 每个结点最多有两棵子树，所以二叉树中不存在度大于2的结点；\n- 左子树和右子树是有顺序的，次序不能任意颠倒；\n- 即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。\n\n特殊二叉树：\n- 斜二叉树：所有的结点都只有左子树的二叉树叫左斜树，所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。斜树有很明显的特点，就是每一层都只有一个结点，结点的个数与二叉树的深度相同。\n- 满二叉树/完美二叉树：在一棵二叉树中，如果所有分支节点都存在左子树跟右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树或完美二叉树。\n- 完全二叉树：对一棵具有$n$个结点的二叉树按层序编号，如果编号为$i$（$1≤i≤n$） 的结点与同样深度的满二叉树中编号为$i$的结点在二叉树中位置完全相同，则称为完全二叉树。\n- 示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%89%B9%E6%AE%8A%E4%BA%8C%E5%8F%89%E6%A0%91.jpg\" width=\"100%\" height=\"100%\">\n\n## 2.2 二叉树的性质（待）\n- 性质1： 在二叉树的第$i$层上至多有$2^i-1$个结点（$i≥1$）。\n- 性质2： 深度为$k$的二叉树至多有$2^k-1$个结点（$k≥1$）。\n- 性质3： 对任何一棵二叉树T，如果其叶结点数为 $n_0$，度为2的非叶结点个数为 $n_2$，则$n_0=n_2+1$。\n- 性质4： 具有$n$个结点的完全二叉树的深度为$|log_2n+1|$（$|x|$表示不大于$x$的最大整数）。\n- 性质5： 如果对一棵有$n$个结点的完全二叉树，其结点按层序编号（从第1层到第层，每层从左到右），对任一结点$i$（$1≤i≤n$）有：\n - 如果$i=1$，则结点$i$是二叉树的根，无双亲；如果$i>1$，则其是双亲结点。\n - 如果$2i>n$，则结点$i$无左孩子（结点$i$为叶子结点）；否则其左孩子是结点$2i$。\n - 如果$2i+1>n$，则结点$i$无右孩子；否则其右孩子是结点$2i+1$。\n\n## 2.3 二叉树的存储结构\n### 2.3.1 顺序存储结构\n二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系，比如双亲与孩子的关系，左右兄弟的关系等。\n**顺序存储结构一般只用于完全二叉树**。完全二叉树的顺序存储示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"50%\">\n对于一般的二叉树，尽管层序编号不能反映逻辑关系，但是可以将其按完全二叉树编号，只不过将不存在的结点设置为`NULL`。示例：\n<img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B2.jpg\" width=\"70%\" height=\"50%\">\n假设对于一棵深度为$k$的右斜树，它只有$k$个结点，却需要分配$2^k-1$个存储单元空间，这显然会造成空间浪费。所以，顺序存储结构一般只用于完全二叉树。\n \n### 2.3.2 链表存储\n二叉树每个结点最多有两个孩子，设计一个数据域和两个指针域来储存，这样的链表叫做二叉链表。 \n二叉链表的结点结构定义代码：\n```C\n/* 二叉树的二叉链表结点结构定义 */\ntypedef struct BiTNode                  \n{\n    ElemType data; /* 结点数据 */                    \n    struct BiTNode *lchild, *rchild; /* 左右孩子指针 */\n} BiTNode, *BiTree;\n```\n二叉树的链表存储示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%93%BE%E8%A1%A8%E5%AD%98%E5%82%A8.jpg\" width=\"60%\" height=\"70%\">\n\n## 2.4 二叉树的遍历\n二叉树的遍历是指从根结点出发，按照某种次序依次“访问”二叉树中所有结点。“访问”是指对节点的进行某种操作，例如输出节点的值。\n二叉树的遍历方式主要分为：\n- 宽度优先(Breadth-first)：层序遍历(Level-order Traversal)\n- 深度优先(Depth-first)：前序遍历(Preorder Traversal)、中序遍历(Inorder Traversal)、后序遍历(Postorder Traversal)\n \n### 2.4.1 前序遍历\n先访问根结点，然后前序遍历左子树，再前序遍历右子树（根左右）。\n如图所示，遍历的顺序为：ABDGHCEIF。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码：\n```C++\n//1.递归前序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x):data(x),left(nullptr),right(nullptr){}\n};\n\nvoid preOrder(Node* root) //递归前序遍历\n{\n    if (root == nullptr)\n        return;\n    cout << root->data<<' ';\n    preOrder(root->left);\n    preOrder(root->right);\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root -> right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n                5\n              /   \\\n             3    10\n            / \\   / \\\n           2   4 9  20\n\t*/\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    preOrder(root);\n}\n```\n测试结果：\n```\n5 3 2 4 10 9 20\n```\n```C++\n//2.非递归前序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid preOrder(Node* root)       //非递归前序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    Node* p = root;\n    while (p || !s.empty())     //直到p空且栈空\n    {\n        //代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  \n        while (p)\n        {\n            cout << p->data <<' ';\n            s.push(p);\n            p = p->left;\n        }\n        //代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  \n        if (!s.empty())\n        {\n            p = s.top();\n            s.pop();\n            //进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  \n            p = p->right;\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n               5\n             /   \\\n            3    10\n           / \\   / \\\n          2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    preOrder(root);\n}\n```\n测试结果：\n```\n5 3 2 4 10 9 20\n```\n### 2.4.2 中序遍历\n中序遍历根结点的左子树，然后访问根结点，最后中序遍历右子树（左根右）。\n如图所示，遍历的顺序为：GDHBAEICF。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码：\n```C++\n//1.递归中序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid inOrder(Node* root) //递归中序遍历\n{\n    if (root == nullptr)\n        return;\n    inOrder(root->left);\n    cout << root->data << ' ';\n    inOrder(root->right);\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n        5\n      /   \\\n     3    10\n    / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    inOrder(root);\n}\n```\n测试结果：\n```\n2 3 4 5 9 10 20\n```\n```C++\n//2.非递归中序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid inOrder(Node* root)                  //非递归中序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    Node* p = root;\n    while (p || !s.empty())               //直到p空且栈空\n    {\n        //代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  \n        while (p)\n        {\n            s.push(p);\n            p = p->left;\n        }\n        //代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  \n        if (!s.empty())\n        {\n            p = s.top();\n            s.pop();\n            cout << p->data << ' ';       //与非递归前序遍历的唯一区别\n            //进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  \n            p = p->right;\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    inOrder(root);\n}\n```\n测试结果：\n```\n2 3 4 5 9 10 20\n```\n### 2.4.3 后序遍历\n后序遍历根结点的左子树，然后后序遍历根结点的右子树，最后访问根结点（左右根）。\n如图所示，遍历的顺序为：GHDBIEFCA。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码:\n```C++\n//1.递归后序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid postOrder(Node* root) //递归后序遍历\n{\n    if (root == nullptr)\n        return;\n    postOrder(root->left);\n    postOrder(root->right);\n    cout << root->data << ' ';\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    postOrder(root);\n}\n```\n测试结果：\n```\n2 4 3 9 20 10 5\n```\n```C++\n//2.非递归后序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid postOrder(Node* root)       //非递归后序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    //pCur:当前访问节点，pLastVisit:上次访问节点  \n    Node* pCur = root;\n    Node* pLastVisit = nullptr;\n    //先把pCur移动到左子树最下边  \n    while (pCur)\n    {\n        s.push(pCur);\n        pCur = pCur->left;\n    }\n    while (!s.empty())\n    {\n        //走到这里，pCur都是空，并已经遍历到左子树底端(看成扩充二叉树，则空，亦是某棵树的左孩子)  \n        pCur = s.top();\n        s.pop();\n        //一个根节点被访问的前提是：无右子树或右子树已被访问过  \n        if (pCur->right == nullptr || pCur->right == pLastVisit)\n        {\n            cout << pCur->data << ' ';\n            //修改最近被访问的节点  \n            pLastVisit = pCur;\n        }\n        else\n        {\n            //根节点再次入栈  \n            s.push(pCur);\n            //进入右子树，且可肯定右子树一定不为空  \n            pCur = pCur->right;\n            while (pCur)\n            {\n                s.push(pCur);\n                pCur = pCur->left;\n            }\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n          5\n        /   \\\n       3    10\n      / \\   / \\\n     2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    postOrder(root);\n}\n```\n测试结果：\n```\n2 4 3 9 20 10 5\n```\n### 2.4.4 层序遍历\n从根结点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。如图所示，遍历的顺序为：ABCDEFGHI。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码:\n```C++\n//层序遍历\n#include<iostream>\n#include <queue>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x):data(x),left(nullptr),right(nullptr){}\n};\n\nvoid levelOrder(Node* root)\n{\n    if (root == nullptr)\n        return;\n    queue<Node*> q;              //借助队列，实现二叉树的层序遍历\n    q.push(root);\n    while (!q.empty())\n    {\n        Node* temp = q.front();\n        cout << temp->data << ' ';\n        q.pop();\n        if (temp->left != nullptr)\n            q.push(temp->left);\n        if (temp->right != nullptr)\n            q.push(temp->right);\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    levelOrder(root);\n}\n```\n测试代码：\n```\n5 3 10 2 4 9 20\n```\n# 3.二叉搜索树\n二叉搜索树(Binary Search Tree)，是指一棵空树或者具有下列性质的二叉树：\n- 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；\n- 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；\n- 任意节点的左、右子树也分别为二叉查找树；\n- 没有键值相等的节点。\n\n示例：\n<img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%A4%BA%E4%BE%8B.png\" width=\"30%\" height=\"30%\">\n（补充二叉搜索树的插入操作和删除操作的代码。以及各操作的时间复杂度分析。）\n# 4.平衡二叉树\n平衡因子(Balance Factor)：$BF(T)=h_L-h_R$。其中，$h_L$和$h_R$分别为$T$的左、右子树的高度。\n平衡二叉树(Balance Binary Tree)：在二叉搜索树的基础上，任一结点的左、右子树的高度差的绝对值（平衡因子）不超过1，即$BF(T)\\leq1$。\n示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A4%BA%E4%BE%8B.JPG\" width=\"80%\" height=\"80%\">\n（补充平衡二叉树的调整方式及代码。以及各操作的时间复杂度分析。）\n\n# 5.堆\n堆(heap)的两个特性：\n- 用数组表示的完全二叉树。\n- 任一结点的值都大于（或小于）其左右孩子结点的值。\n\n将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。\n示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%A0%86%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n（补充堆的基本操作代码。以及各操作的时间复杂度分析。[排序算法](http://zhanglimin.com/2017/11/29/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/)中堆排序一节已有。）\n# 6.哈夫曼树\n给定$n$个权值作为$n$个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。\n（补充哈夫曼树的构造、哈夫曼编码）\n# 7.参考资料\n- [Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [How To Not Be Stumped By Trees, Vaidehi Joshi](https://medium.com/basecs/how-to-not-be-stumped-by-trees-5f36208f68a7)\n- [二叉树前序、中序、后序遍历非递归写法的透彻解析，苏叔叔](http://blog.csdn.net/zhangxiangdavaid/article/details/37115355)\n","source":"_posts/树.md","raw":"---\ntitle: 树\ndate: 2017-11-26 21:12:00\nmathjax: true\ncategories: \n- 数据结构与算法\ntags:\n- 栈\n- 队列\n---\n# 1.树的基本概念\n## 1.1 树的定义\n树是$n(n≥0)$个结点的有限集：\n- $n=0$时称为空树；\n- 对于任意一颗非空树($n>0$)，它具备以下性质：\n - 有且仅有一个特定的称为根（Root）的结点，根结点唯一； \n - 当$n＞1$时，其余结点可分为$m(m>0)$个互不相交的有限集 $T_1$、$T_2$、... 、$T_m$，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。子树的个数没有限制，但它们一定互不相交。\n \n<!-- more --> \n\n## 1.2 相关概念\n- 结点分类：根节点、内部结点、叶结点或终端结点。\n- 结点的关系：\n - 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点。\n - 孩子节点：一个节点含有的子树的根节点称为该节点的子节点。\n - 兄弟节点：具有相同父节点的节点互称为兄弟节点。\n- 结点的度：结点拥有的子树数。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点；除根结点之外，分支结点也称为内部结点。\n- 树的度：树的度是树内各结点的度的最大值。\n- 结点的深度（Depth）：结点$n$的深度为从根结点到$n$的唯一路径长，根结点的深度为0（或1，两种表示方法都有）；\n- 结点的层次（Level）：从根开始定义起，根为第0层（或1，两种表示方法都有），根的子节点为第1层，以此类推。同结点的深度；\n- 树的深度：深度最大的叶结点的深度就是树的深度。\n- 结点的高度（Height）：对于任意节点$n$，$n$的高度为任一叶结点到$n$的最长路径长，所有叶结点的高度为0（或1，两种表示方法都有）；\n - 对于高度，类比于想知道一栋楼房的高度，从下往上数看有几层。\n- 树的高度：根结点的高度就是树的高度。\n- 总结：树的高度和深度是相等的。但对于树中相同深度的每个结点来说，它们的高度不一定相同，反之亦然。\n\n示例：\n- 结点分类及关系示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%A4%BA%E4%BE%8B%E5%9B%BE.jpeg\" width=\"50%\" height=\"50%\">\n- 结点的深度与高度示例图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E9%AB%98%E5%BA%A6.JPG\" width=\"50%\" height=\"50%\">\n- 结点的层次示例图（同结点的深度）：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E5%B1%82%E6%AC%A1.JPG\" width=\"50%\" height=\"50%\">\n- 树的深度和高度示例图（树的深度等于树的高度）:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6.png\" width=\"50%\" height=\"50%\">\n\n# 2.二叉树\n## 2.1 二叉树的定义\n二叉树：二叉树是$n$个结点的有限集合，该集合或者为空集（空二叉树），或者由一个根结点和两棵互不相交的，分别称为根结点的左子树和右子树的二叉树组成。\n\n二叉树的特点：\n- 每个结点最多有两棵子树，所以二叉树中不存在度大于2的结点；\n- 左子树和右子树是有顺序的，次序不能任意颠倒；\n- 即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。\n\n特殊二叉树：\n- 斜二叉树：所有的结点都只有左子树的二叉树叫左斜树，所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。斜树有很明显的特点，就是每一层都只有一个结点，结点的个数与二叉树的深度相同。\n- 满二叉树/完美二叉树：在一棵二叉树中，如果所有分支节点都存在左子树跟右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树或完美二叉树。\n- 完全二叉树：对一棵具有$n$个结点的二叉树按层序编号，如果编号为$i$（$1≤i≤n$） 的结点与同样深度的满二叉树中编号为$i$的结点在二叉树中位置完全相同，则称为完全二叉树。\n- 示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%89%B9%E6%AE%8A%E4%BA%8C%E5%8F%89%E6%A0%91.jpg\" width=\"100%\" height=\"100%\">\n\n## 2.2 二叉树的性质（待）\n- 性质1： 在二叉树的第$i$层上至多有$2^i-1$个结点（$i≥1$）。\n- 性质2： 深度为$k$的二叉树至多有$2^k-1$个结点（$k≥1$）。\n- 性质3： 对任何一棵二叉树T，如果其叶结点数为 $n_0$，度为2的非叶结点个数为 $n_2$，则$n_0=n_2+1$。\n- 性质4： 具有$n$个结点的完全二叉树的深度为$|log_2n+1|$（$|x|$表示不大于$x$的最大整数）。\n- 性质5： 如果对一棵有$n$个结点的完全二叉树，其结点按层序编号（从第1层到第层，每层从左到右），对任一结点$i$（$1≤i≤n$）有：\n - 如果$i=1$，则结点$i$是二叉树的根，无双亲；如果$i>1$，则其是双亲结点。\n - 如果$2i>n$，则结点$i$无左孩子（结点$i$为叶子结点）；否则其左孩子是结点$2i$。\n - 如果$2i+1>n$，则结点$i$无右孩子；否则其右孩子是结点$2i+1$。\n\n## 2.3 二叉树的存储结构\n### 2.3.1 顺序存储结构\n二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系，比如双亲与孩子的关系，左右兄弟的关系等。\n**顺序存储结构一般只用于完全二叉树**。完全二叉树的顺序存储示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"50%\">\n对于一般的二叉树，尽管层序编号不能反映逻辑关系，但是可以将其按完全二叉树编号，只不过将不存在的结点设置为`NULL`。示例：\n<img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B2.jpg\" width=\"70%\" height=\"50%\">\n假设对于一棵深度为$k$的右斜树，它只有$k$个结点，却需要分配$2^k-1$个存储单元空间，这显然会造成空间浪费。所以，顺序存储结构一般只用于完全二叉树。\n \n### 2.3.2 链表存储\n二叉树每个结点最多有两个孩子，设计一个数据域和两个指针域来储存，这样的链表叫做二叉链表。 \n二叉链表的结点结构定义代码：\n```C\n/* 二叉树的二叉链表结点结构定义 */\ntypedef struct BiTNode                  \n{\n    ElemType data; /* 结点数据 */                    \n    struct BiTNode *lchild, *rchild; /* 左右孩子指针 */\n} BiTNode, *BiTree;\n```\n二叉树的链表存储示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%93%BE%E8%A1%A8%E5%AD%98%E5%82%A8.jpg\" width=\"60%\" height=\"70%\">\n\n## 2.4 二叉树的遍历\n二叉树的遍历是指从根结点出发，按照某种次序依次“访问”二叉树中所有结点。“访问”是指对节点的进行某种操作，例如输出节点的值。\n二叉树的遍历方式主要分为：\n- 宽度优先(Breadth-first)：层序遍历(Level-order Traversal)\n- 深度优先(Depth-first)：前序遍历(Preorder Traversal)、中序遍历(Inorder Traversal)、后序遍历(Postorder Traversal)\n \n### 2.4.1 前序遍历\n先访问根结点，然后前序遍历左子树，再前序遍历右子树（根左右）。\n如图所示，遍历的顺序为：ABDGHCEIF。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码：\n```C++\n//1.递归前序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x):data(x),left(nullptr),right(nullptr){}\n};\n\nvoid preOrder(Node* root) //递归前序遍历\n{\n    if (root == nullptr)\n        return;\n    cout << root->data<<' ';\n    preOrder(root->left);\n    preOrder(root->right);\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root -> right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n                5\n              /   \\\n             3    10\n            / \\   / \\\n           2   4 9  20\n\t*/\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    preOrder(root);\n}\n```\n测试结果：\n```\n5 3 2 4 10 9 20\n```\n```C++\n//2.非递归前序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid preOrder(Node* root)       //非递归前序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    Node* p = root;\n    while (p || !s.empty())     //直到p空且栈空\n    {\n        //代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  \n        while (p)\n        {\n            cout << p->data <<' ';\n            s.push(p);\n            p = p->left;\n        }\n        //代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  \n        if (!s.empty())\n        {\n            p = s.top();\n            s.pop();\n            //进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  \n            p = p->right;\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n               5\n             /   \\\n            3    10\n           / \\   / \\\n          2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    preOrder(root);\n}\n```\n测试结果：\n```\n5 3 2 4 10 9 20\n```\n### 2.4.2 中序遍历\n中序遍历根结点的左子树，然后访问根结点，最后中序遍历右子树（左根右）。\n如图所示，遍历的顺序为：GDHBAEICF。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码：\n```C++\n//1.递归中序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid inOrder(Node* root) //递归中序遍历\n{\n    if (root == nullptr)\n        return;\n    inOrder(root->left);\n    cout << root->data << ' ';\n    inOrder(root->right);\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n        5\n      /   \\\n     3    10\n    / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    inOrder(root);\n}\n```\n测试结果：\n```\n2 3 4 5 9 10 20\n```\n```C++\n//2.非递归中序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid inOrder(Node* root)                  //非递归中序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    Node* p = root;\n    while (p || !s.empty())               //直到p空且栈空\n    {\n        //代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  \n        while (p)\n        {\n            s.push(p);\n            p = p->left;\n        }\n        //代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  \n        if (!s.empty())\n        {\n            p = s.top();\n            s.pop();\n            cout << p->data << ' ';       //与非递归前序遍历的唯一区别\n            //进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  \n            p = p->right;\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    inOrder(root);\n}\n```\n测试结果：\n```\n2 3 4 5 9 10 20\n```\n### 2.4.3 后序遍历\n后序遍历根结点的左子树，然后后序遍历根结点的右子树，最后访问根结点（左右根）。\n如图所示，遍历的顺序为：GHDBIEFCA。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码:\n```C++\n//1.递归后序遍历\n#include <iostream>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid postOrder(Node* root) //递归后序遍历\n{\n    if (root == nullptr)\n        return;\n    postOrder(root->left);\n    postOrder(root->right);\n    cout << root->data << ' ';\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    postOrder(root);\n}\n```\n测试结果：\n```\n2 4 3 9 20 10 5\n```\n```C++\n//2.非递归后序遍历\n#include <iostream>\n#include <stack>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x) :data(x), left(nullptr), right(nullptr){}\n};\n\nvoid postOrder(Node* root)       //非递归后序遍历\n{\n    if (root == nullptr)\n        return;\n    stack<Node*> s;\n    //pCur:当前访问节点，pLastVisit:上次访问节点  \n    Node* pCur = root;\n    Node* pLastVisit = nullptr;\n    //先把pCur移动到左子树最下边  \n    while (pCur)\n    {\n        s.push(pCur);\n        pCur = pCur->left;\n    }\n    while (!s.empty())\n    {\n        //走到这里，pCur都是空，并已经遍历到左子树底端(看成扩充二叉树，则空，亦是某棵树的左孩子)  \n        pCur = s.top();\n        s.pop();\n        //一个根节点被访问的前提是：无右子树或右子树已被访问过  \n        if (pCur->right == nullptr || pCur->right == pLastVisit)\n        {\n            cout << pCur->data << ' ';\n            //修改最近被访问的节点  \n            pLastVisit = pCur;\n        }\n        else\n        {\n            //根节点再次入栈  \n            s.push(pCur);\n            //进入右子树，且可肯定右子树一定不为空  \n            pCur = pCur->right;\n            while (pCur)\n            {\n                s.push(pCur);\n                pCur = pCur->left;\n            }\n        }\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n          5\n        /   \\\n       3    10\n      / \\   / \\\n     2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    postOrder(root);\n}\n```\n测试结果：\n```\n2 4 3 9 20 10 5\n```\n### 2.4.4 层序遍历\n从根结点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。如图所示，遍历的顺序为：ABCDEFGHI。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\">\n代码:\n```C++\n//层序遍历\n#include<iostream>\n#include <queue>\nusing namespace std;\n\nstruct Node\n{\n    int data;\n    Node* left;\n    Node* right;\n    Node(int x):data(x),left(nullptr),right(nullptr){}\n};\n\nvoid levelOrder(Node* root)\n{\n    if (root == nullptr)\n        return;\n    queue<Node*> q;              //借助队列，实现二叉树的层序遍历\n    q.push(root);\n    while (!q.empty())\n    {\n        Node* temp = q.front();\n        cout << temp->data << ' ';\n        q.pop();\n        if (temp->left != nullptr)\n            q.push(temp->left);\n        if (temp->right != nullptr)\n            q.push(temp->right);\n    }\n}\n\nNode* Insert(Node* root, int data)\n{\n    if (root == nullptr)\n    {\n        root = new Node(data);\n    }\n    else if (data <= root->data) root->left = Insert(root->left, data);\n    else root->right = Insert(root->right, data);\n    return root;\n}\n\nint main()\n{\n    /*创建树：\n         5\n       /   \\\n      3    10\n     / \\   / \\\n    2   4 9  20\n    */\n    Node* root = nullptr;\n    root = Insert(root, 5); root = Insert(root, 10);\n    root = Insert(root, 3); root = Insert(root, 2);\n    root = Insert(root, 4); root = Insert(root, 9);\n    root = Insert(root, 20);\n    levelOrder(root);\n}\n```\n测试代码：\n```\n5 3 10 2 4 9 20\n```\n# 3.二叉搜索树\n二叉搜索树(Binary Search Tree)，是指一棵空树或者具有下列性质的二叉树：\n- 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；\n- 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；\n- 任意节点的左、右子树也分别为二叉查找树；\n- 没有键值相等的节点。\n\n示例：\n<img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%A4%BA%E4%BE%8B.png\" width=\"30%\" height=\"30%\">\n（补充二叉搜索树的插入操作和删除操作的代码。以及各操作的时间复杂度分析。）\n# 4.平衡二叉树\n平衡因子(Balance Factor)：$BF(T)=h_L-h_R$。其中，$h_L$和$h_R$分别为$T$的左、右子树的高度。\n平衡二叉树(Balance Binary Tree)：在二叉搜索树的基础上，任一结点的左、右子树的高度差的绝对值（平衡因子）不超过1，即$BF(T)\\leq1$。\n示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A4%BA%E4%BE%8B.JPG\" width=\"80%\" height=\"80%\">\n（补充平衡二叉树的调整方式及代码。以及各操作的时间复杂度分析。）\n\n# 5.堆\n堆(heap)的两个特性：\n- 用数组表示的完全二叉树。\n- 任一结点的值都大于（或小于）其左右孩子结点的值。\n\n将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。\n示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%A0%86%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n（补充堆的基本操作代码。以及各操作的时间复杂度分析。[排序算法](http://zhanglimin.com/2017/11/29/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/)中堆排序一节已有。）\n# 6.哈夫曼树\n给定$n$个权值作为$n$个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。\n（补充哈夫曼树的构造、哈夫曼编码）\n# 7.参考资料\n- [Data Structures, mycodeschool](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P)\n- [数据结构，浙江大学](http://www.icourse163.org/course/ZJU-93001)\n- [程序设计与算法专项课程，北京大学](https://www.coursera.org/specializations/biancheng-suanfa)\n- [How To Not Be Stumped By Trees, Vaidehi Joshi](https://medium.com/basecs/how-to-not-be-stumped-by-trees-5f36208f68a7)\n- [二叉树前序、中序、后序遍历非递归写法的透彻解析，苏叔叔](http://blog.csdn.net/zhangxiangdavaid/article/details/37115355)\n","slug":"树","published":1,"updated":"2018-01-26T06:40:16.140Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w1h004xqslpx2zkdg8q","content":"<h1 id=\"1-树的基本概念\"><a href=\"#1-树的基本概念\" class=\"headerlink\" title=\"1.树的基本概念\"></a>1.树的基本概念</h1><h2 id=\"1-1-树的定义\"><a href=\"#1-1-树的定义\" class=\"headerlink\" title=\"1.1 树的定义\"></a>1.1 树的定义</h2><p>树是$n(n≥0)$个结点的有限集：</p>\n<ul>\n<li>$n=0$时称为空树；</li>\n<li>对于任意一颗非空树($n&gt;0$)，它具备以下性质：<ul>\n<li>有且仅有一个特定的称为根（Root）的结点，根结点唯一； </li>\n<li>当$n＞1$时，其余结点可分为$m(m&gt;0)$个互不相交的有限集 $T_1$、$T_2$、… 、$T_m$，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。子树的个数没有限制，但它们一定互不相交。</li>\n</ul>\n</li>\n</ul>\n<a id=\"more\"></a> \n<h2 id=\"1-2-相关概念\"><a href=\"#1-2-相关概念\" class=\"headerlink\" title=\"1.2 相关概念\"></a>1.2 相关概念</h2><ul>\n<li>结点分类：根节点、内部结点、叶结点或终端结点。</li>\n<li>结点的关系：<ul>\n<li>父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点。</li>\n<li>孩子节点：一个节点含有的子树的根节点称为该节点的子节点。</li>\n<li>兄弟节点：具有相同父节点的节点互称为兄弟节点。</li>\n</ul>\n</li>\n<li>结点的度：结点拥有的子树数。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点；除根结点之外，分支结点也称为内部结点。</li>\n<li>树的度：树的度是树内各结点的度的最大值。</li>\n<li>结点的深度（Depth）：结点$n$的深度为从根结点到$n$的唯一路径长，根结点的深度为0（或1，两种表示方法都有）；</li>\n<li>结点的层次（Level）：从根开始定义起，根为第0层（或1，两种表示方法都有），根的子节点为第1层，以此类推。同结点的深度；</li>\n<li>树的深度：深度最大的叶结点的深度就是树的深度。</li>\n<li>结点的高度（Height）：对于任意节点$n$，$n$的高度为任一叶结点到$n$的最长路径长，所有叶结点的高度为0（或1，两种表示方法都有）；<ul>\n<li>对于高度，类比于想知道一栋楼房的高度，从下往上数看有几层。</li>\n</ul>\n</li>\n<li>树的高度：根结点的高度就是树的高度。</li>\n<li>总结：树的高度和深度是相等的。但对于树中相同深度的每个结点来说，它们的高度不一定相同，反之亦然。</li>\n</ul>\n<p>示例：</p>\n<ul>\n<li>结点分类及关系示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%A4%BA%E4%BE%8B%E5%9B%BE.jpeg\" width=\"50%\" height=\"50%\"></li>\n<li>结点的深度与高度示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E9%AB%98%E5%BA%A6.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>结点的层次示例图（同结点的深度）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E5%B1%82%E6%AC%A1.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>树的深度和高度示例图（树的深度等于树的高度）:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6.png\" width=\"50%\" height=\"50%\"></li>\n</ul>\n<h1 id=\"2-二叉树\"><a href=\"#2-二叉树\" class=\"headerlink\" title=\"2.二叉树\"></a>2.二叉树</h1><h2 id=\"2-1-二叉树的定义\"><a href=\"#2-1-二叉树的定义\" class=\"headerlink\" title=\"2.1 二叉树的定义\"></a>2.1 二叉树的定义</h2><p>二叉树：二叉树是$n$个结点的有限集合，该集合或者为空集（空二叉树），或者由一个根结点和两棵互不相交的，分别称为根结点的左子树和右子树的二叉树组成。</p>\n<p>二叉树的特点：</p>\n<ul>\n<li>每个结点最多有两棵子树，所以二叉树中不存在度大于2的结点；</li>\n<li>左子树和右子树是有顺序的，次序不能任意颠倒；</li>\n<li>即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。</li>\n</ul>\n<p>特殊二叉树：</p>\n<ul>\n<li>斜二叉树：所有的结点都只有左子树的二叉树叫左斜树，所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。斜树有很明显的特点，就是每一层都只有一个结点，结点的个数与二叉树的深度相同。</li>\n<li>满二叉树/完美二叉树：在一棵二叉树中，如果所有分支节点都存在左子树跟右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树或完美二叉树。</li>\n<li>完全二叉树：对一棵具有$n$个结点的二叉树按层序编号，如果编号为$i$（$1≤i≤n$） 的结点与同样深度的满二叉树中编号为$i$的结点在二叉树中位置完全相同，则称为完全二叉树。</li>\n<li>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%89%B9%E6%AE%8A%E4%BA%8C%E5%8F%89%E6%A0%91.jpg\" width=\"100%\" height=\"100%\"></li>\n</ul>\n<h2 id=\"2-2-二叉树的性质（待）\"><a href=\"#2-2-二叉树的性质（待）\" class=\"headerlink\" title=\"2.2 二叉树的性质（待）\"></a>2.2 二叉树的性质（待）</h2><ul>\n<li>性质1： 在二叉树的第$i$层上至多有$2^i-1$个结点（$i≥1$）。</li>\n<li>性质2： 深度为$k$的二叉树至多有$2^k-1$个结点（$k≥1$）。</li>\n<li>性质3： 对任何一棵二叉树T，如果其叶结点数为 $n_0$，度为2的非叶结点个数为 $n_2$，则$n_0=n_2+1$。</li>\n<li>性质4： 具有$n$个结点的完全二叉树的深度为$|log_2n+1|$（$|x|$表示不大于$x$的最大整数）。</li>\n<li>性质5： 如果对一棵有$n$个结点的完全二叉树，其结点按层序编号（从第1层到第层，每层从左到右），对任一结点$i$（$1≤i≤n$）有：<ul>\n<li>如果$i=1$，则结点$i$是二叉树的根，无双亲；如果$i&gt;1$，则其是双亲结点。</li>\n<li>如果$2i&gt;n$，则结点$i$无左孩子（结点$i$为叶子结点）；否则其左孩子是结点$2i$。</li>\n<li>如果$2i+1&gt;n$，则结点$i$无右孩子；否则其右孩子是结点$2i+1$。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-3-二叉树的存储结构\"><a href=\"#2-3-二叉树的存储结构\" class=\"headerlink\" title=\"2.3 二叉树的存储结构\"></a>2.3 二叉树的存储结构</h2><h3 id=\"2-3-1-顺序存储结构\"><a href=\"#2-3-1-顺序存储结构\" class=\"headerlink\" title=\"2.3.1 顺序存储结构\"></a>2.3.1 顺序存储结构</h3><p>二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系，比如双亲与孩子的关系，左右兄弟的关系等。<br><strong>顺序存储结构一般只用于完全二叉树</strong>。完全二叉树的顺序存储示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"50%\"><br>对于一般的二叉树，尽管层序编号不能反映逻辑关系，但是可以将其按完全二叉树编号，只不过将不存在的结点设置为<code>NULL</code>。示例：<br><img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B2.jpg\" width=\"70%\" height=\"50%\"><br>假设对于一棵深度为$k$的右斜树，它只有$k$个结点，却需要分配$2^k-1$个存储单元空间，这显然会造成空间浪费。所以，顺序存储结构一般只用于完全二叉树。</p>\n<h3 id=\"2-3-2-链表存储\"><a href=\"#2-3-2-链表存储\" class=\"headerlink\" title=\"2.3.2 链表存储\"></a>2.3.2 链表存储</h3><p>二叉树每个结点最多有两个孩子，设计一个数据域和两个指针域来储存，这样的链表叫做二叉链表。<br>二叉链表的结点结构定义代码：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 二叉树的二叉链表结点结构定义 */</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span>                  </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data; <span class=\"comment\">/* 结点数据 */</span>                    </span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span> <span class=\"comment\">/* 左右孩子指针 */</span></span><br><span class=\"line\">&#125; BiTNode, *BiTree;</span><br></pre></td></tr></table></figure></p>\n<p>二叉树的链表存储示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%93%BE%E8%A1%A8%E5%AD%98%E5%82%A8.jpg\" width=\"60%\" height=\"70%\"></p>\n<h2 id=\"2-4-二叉树的遍历\"><a href=\"#2-4-二叉树的遍历\" class=\"headerlink\" title=\"2.4 二叉树的遍历\"></a>2.4 二叉树的遍历</h2><p>二叉树的遍历是指从根结点出发，按照某种次序依次“访问”二叉树中所有结点。“访问”是指对节点的进行某种操作，例如输出节点的值。<br>二叉树的遍历方式主要分为：</p>\n<ul>\n<li>宽度优先(Breadth-first)：层序遍历(Level-order Traversal)</li>\n<li>深度优先(Depth-first)：前序遍历(Preorder Traversal)、中序遍历(Inorder Traversal)、后序遍历(Postorder Traversal)</li>\n</ul>\n<h3 id=\"2-4-1-前序遍历\"><a href=\"#2-4-1-前序遍历\" class=\"headerlink\" title=\"2.4.1 前序遍历\"></a>2.4.1 前序遍历</h3><p>先访问根结点，然后前序遍历左子树，再前序遍历右子树（根左右）。<br>如图所示，遍历的顺序为：ABDGHCEIF。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归前序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x):data(x),left(<span class=\"literal\">nullptr</span>),right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归前序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data&lt;&lt;<span class=\"string\">' '</span>;</span><br><span class=\"line\">    preOrder(root-&gt;left);</span><br><span class=\"line\">    preOrder(root-&gt;right);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root -&gt; right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">                5</span></span><br><span class=\"line\"><span class=\"comment\">              /   \\</span></span><br><span class=\"line\"><span class=\"comment\">             3    10</span></span><br><span class=\"line\"><span class=\"comment\">            / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">           2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">\t*/</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    preOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 2 4 10 9 20</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归前序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(Node* root)</span>       <span class=\"comment\">//非递归前序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    Node* p = root;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (p || !s.empty())     <span class=\"comment\">//直到p空且栈空</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  </span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (p)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; p-&gt;data &lt;&lt;<span class=\"string\">' '</span>;</span><br><span class=\"line\">            s.push(p);</span><br><span class=\"line\">            p = p-&gt;left;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p = s.top();</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  </span></span><br><span class=\"line\">            p = p-&gt;right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">               5</span></span><br><span class=\"line\"><span class=\"comment\">             /   \\</span></span><br><span class=\"line\"><span class=\"comment\">            3    10</span></span><br><span class=\"line\"><span class=\"comment\">           / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">          2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    preOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 2 4 10 9 20</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-2-中序遍历\"><a href=\"#2-4-2-中序遍历\" class=\"headerlink\" title=\"2.4.2 中序遍历\"></a>2.4.2 中序遍历</h3><p>中序遍历根结点的左子树，然后访问根结点，最后中序遍历右子树（左根右）。<br>如图所示，遍历的顺序为：GDHBAEICF。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归中序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归中序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    inOrder(root-&gt;left);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    inOrder(root-&gt;right);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">        5</span></span><br><span class=\"line\"><span class=\"comment\">      /   \\</span></span><br><span class=\"line\"><span class=\"comment\">     3    10</span></span><br><span class=\"line\"><span class=\"comment\">    / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    inOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 3 4 5 9 10 20</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归中序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inOrder</span><span class=\"params\">(Node* root)</span>                  <span class=\"comment\">//非递归中序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    Node* p = root;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (p || !s.empty())               <span class=\"comment\">//直到p空且栈空</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  </span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (p)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(p);</span><br><span class=\"line\">            p = p-&gt;left;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p = s.top();</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; p-&gt;data &lt;&lt; <span class=\"string\">' '</span>;       <span class=\"comment\">//与非递归前序遍历的唯一区别</span></span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  </span></span><br><span class=\"line\">            p = p-&gt;right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    inOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 3 4 5 9 10 20</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-3-后序遍历\"><a href=\"#2-4-3-后序遍历\" class=\"headerlink\" title=\"2.4.3 后序遍历\"></a>2.4.3 后序遍历</h3><p>后序遍历根结点的左子树，然后后序遍历根结点的右子树，最后访问根结点（左右根）。<br>如图所示，遍历的顺序为：GHDBIEFCA。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归后序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">postOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归后序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    postOrder(root-&gt;left);</span><br><span class=\"line\">    postOrder(root-&gt;right);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    postOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 4 3 9 20 10 5</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归后序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">postOrder</span><span class=\"params\">(Node* root)</span>       <span class=\"comment\">//非递归后序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    <span class=\"comment\">//pCur:当前访问节点，pLastVisit:上次访问节点  </span></span><br><span class=\"line\">    Node* pCur = root;</span><br><span class=\"line\">    Node* pLastVisit = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    <span class=\"comment\">//先把pCur移动到左子树最下边  </span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (pCur)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        s.push(pCur);</span><br><span class=\"line\">        pCur = pCur-&gt;left;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//走到这里，pCur都是空，并已经遍历到左子树底端(看成扩充二叉树，则空，亦是某棵树的左孩子)  </span></span><br><span class=\"line\">        pCur = s.top();</span><br><span class=\"line\">        s.pop();</span><br><span class=\"line\">        <span class=\"comment\">//一个根节点被访问的前提是：无右子树或右子树已被访问过  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (pCur-&gt;right == <span class=\"literal\">nullptr</span> || pCur-&gt;right == pLastVisit)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; pCur-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">            <span class=\"comment\">//修改最近被访问的节点  </span></span><br><span class=\"line\">            pLastVisit = pCur;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//根节点再次入栈  </span></span><br><span class=\"line\">            s.push(pCur);</span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，且可肯定右子树一定不为空  </span></span><br><span class=\"line\">            pCur = pCur-&gt;right;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (pCur)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                s.push(pCur);</span><br><span class=\"line\">                pCur = pCur-&gt;left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">          5</span></span><br><span class=\"line\"><span class=\"comment\">        /   \\</span></span><br><span class=\"line\"><span class=\"comment\">       3    10</span></span><br><span class=\"line\"><span class=\"comment\">      / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">     2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    postOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 4 3 9 20 10 5</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-4-层序遍历\"><a href=\"#2-4-4-层序遍历\" class=\"headerlink\" title=\"2.4.4 层序遍历\"></a>2.4.4 层序遍历</h3><p>从根结点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。如图所示，遍历的顺序为：ABCDEFGHI。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//层序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x):data(x),left(<span class=\"literal\">nullptr</span>),right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">levelOrder</span><span class=\"params\">(Node* root)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;Node*&gt; q;              <span class=\"comment\">//借助队列，实现二叉树的层序遍历</span></span><br><span class=\"line\">    q.push(root);</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!q.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node* temp = q.front();</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; temp-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">        q.pop();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp-&gt;left != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            q.push(temp-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp-&gt;right != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            q.push(temp-&gt;right);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    levelOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 10 2 4 9 20</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"3-二叉搜索树\"><a href=\"#3-二叉搜索树\" class=\"headerlink\" title=\"3.二叉搜索树\"></a>3.二叉搜索树</h1><p>二叉搜索树(Binary Search Tree)，是指一棵空树或者具有下列性质的二叉树：</p>\n<ul>\n<li>若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；</li>\n<li>若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；</li>\n<li>任意节点的左、右子树也分别为二叉查找树；</li>\n<li>没有键值相等的节点。</li>\n</ul>\n<p>示例：<br><img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%A4%BA%E4%BE%8B.png\" width=\"30%\" height=\"30%\"><br>（补充二叉搜索树的插入操作和删除操作的代码。以及各操作的时间复杂度分析。）</p>\n<h1 id=\"4-平衡二叉树\"><a href=\"#4-平衡二叉树\" class=\"headerlink\" title=\"4.平衡二叉树\"></a>4.平衡二叉树</h1><p>平衡因子(Balance Factor)：$BF(T)=h_L-h_R$。其中，$h_L$和$h_R$分别为$T$的左、右子树的高度。<br>平衡二叉树(Balance Binary Tree)：在二叉搜索树的基础上，任一结点的左、右子树的高度差的绝对值（平衡因子）不超过1，即$BF(T)\\leq1$。<br>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A4%BA%E4%BE%8B.JPG\" width=\"80%\" height=\"80%\"><br>（补充平衡二叉树的调整方式及代码。以及各操作的时间复杂度分析。）</p>\n<h1 id=\"5-堆\"><a href=\"#5-堆\" class=\"headerlink\" title=\"5.堆\"></a>5.堆</h1><p>堆(heap)的两个特性：</p>\n<ul>\n<li>用数组表示的完全二叉树。</li>\n<li>任一结点的值都大于（或小于）其左右孩子结点的值。</li>\n</ul>\n<p>将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。<br>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%A0%86%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"><br>（补充堆的基本操作代码。以及各操作的时间复杂度分析。<a href=\"http://zhanglimin.com/2017/11/29/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">排序算法</a>中堆排序一节已有。）</p>\n<h1 id=\"6-哈夫曼树\"><a href=\"#6-哈夫曼树\" class=\"headerlink\" title=\"6.哈夫曼树\"></a>6.哈夫曼树</h1><p>给定$n$个权值作为$n$个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。<br>（补充哈夫曼树的构造、哈夫曼编码）</p>\n<h1 id=\"7-参考资料\"><a href=\"#7-参考资料\" class=\"headerlink\" title=\"7.参考资料\"></a>7.参考资料</h1><ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a></li>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"https://medium.com/basecs/how-to-not-be-stumped-by-trees-5f36208f68a7\" target=\"_blank\" rel=\"noopener\">How To Not Be Stumped By Trees, Vaidehi Joshi</a></li>\n<li><a href=\"http://blog.csdn.net/zhangxiangdavaid/article/details/37115355\" target=\"_blank\" rel=\"noopener\">二叉树前序、中序、后序遍历非递归写法的透彻解析，苏叔叔</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-树的基本概念\"><a href=\"#1-树的基本概念\" class=\"headerlink\" title=\"1.树的基本概念\"></a>1.树的基本概念</h1><h2 id=\"1-1-树的定义\"><a href=\"#1-1-树的定义\" class=\"headerlink\" title=\"1.1 树的定义\"></a>1.1 树的定义</h2><p>树是$n(n≥0)$个结点的有限集：</p>\n<ul>\n<li>$n=0$时称为空树；</li>\n<li>对于任意一颗非空树($n&gt;0$)，它具备以下性质：<ul>\n<li>有且仅有一个特定的称为根（Root）的结点，根结点唯一； </li>\n<li>当$n＞1$时，其余结点可分为$m(m&gt;0)$个互不相交的有限集 $T_1$、$T_2$、… 、$T_m$，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。子树的个数没有限制，但它们一定互不相交。</li>\n</ul>\n</li>\n</ul>","more":"<h2 id=\"1-2-相关概念\"><a href=\"#1-2-相关概念\" class=\"headerlink\" title=\"1.2 相关概念\"></a>1.2 相关概念</h2><ul>\n<li>结点分类：根节点、内部结点、叶结点或终端结点。</li>\n<li>结点的关系：<ul>\n<li>父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点。</li>\n<li>孩子节点：一个节点含有的子树的根节点称为该节点的子节点。</li>\n<li>兄弟节点：具有相同父节点的节点互称为兄弟节点。</li>\n</ul>\n</li>\n<li>结点的度：结点拥有的子树数。度为0的结点称为叶结点或终端结点；度不为0的结点称为非终端结点或分支结点；除根结点之外，分支结点也称为内部结点。</li>\n<li>树的度：树的度是树内各结点的度的最大值。</li>\n<li>结点的深度（Depth）：结点$n$的深度为从根结点到$n$的唯一路径长，根结点的深度为0（或1，两种表示方法都有）；</li>\n<li>结点的层次（Level）：从根开始定义起，根为第0层（或1，两种表示方法都有），根的子节点为第1层，以此类推。同结点的深度；</li>\n<li>树的深度：深度最大的叶结点的深度就是树的深度。</li>\n<li>结点的高度（Height）：对于任意节点$n$，$n$的高度为任一叶结点到$n$的最长路径长，所有叶结点的高度为0（或1，两种表示方法都有）；<ul>\n<li>对于高度，类比于想知道一栋楼房的高度，从下往上数看有几层。</li>\n</ul>\n</li>\n<li>树的高度：根结点的高度就是树的高度。</li>\n<li>总结：树的高度和深度是相等的。但对于树中相同深度的每个结点来说，它们的高度不一定相同，反之亦然。</li>\n</ul>\n<p>示例：</p>\n<ul>\n<li>结点分类及关系示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E5%88%86%E7%B1%BB%E5%8F%8A%E5%85%B3%E7%B3%BB%E7%A4%BA%E4%BE%8B%E5%9B%BE.jpeg\" width=\"50%\" height=\"50%\"></li>\n<li>结点的深度与高度示例图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E9%AB%98%E5%BA%A6.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>结点的层次示例图（同结点的深度）：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%BB%93%E7%82%B9%E7%9A%84%E5%B1%82%E6%AC%A1.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>树的深度和高度示例图（树的深度等于树的高度）:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%92%8C%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6.png\" width=\"50%\" height=\"50%\"></li>\n</ul>\n<h1 id=\"2-二叉树\"><a href=\"#2-二叉树\" class=\"headerlink\" title=\"2.二叉树\"></a>2.二叉树</h1><h2 id=\"2-1-二叉树的定义\"><a href=\"#2-1-二叉树的定义\" class=\"headerlink\" title=\"2.1 二叉树的定义\"></a>2.1 二叉树的定义</h2><p>二叉树：二叉树是$n$个结点的有限集合，该集合或者为空集（空二叉树），或者由一个根结点和两棵互不相交的，分别称为根结点的左子树和右子树的二叉树组成。</p>\n<p>二叉树的特点：</p>\n<ul>\n<li>每个结点最多有两棵子树，所以二叉树中不存在度大于2的结点；</li>\n<li>左子树和右子树是有顺序的，次序不能任意颠倒；</li>\n<li>即使树中某结点只有一棵子树，也要区分它是左子树还是右子树。</li>\n</ul>\n<p>特殊二叉树：</p>\n<ul>\n<li>斜二叉树：所有的结点都只有左子树的二叉树叫左斜树，所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。斜树有很明显的特点，就是每一层都只有一个结点，结点的个数与二叉树的深度相同。</li>\n<li>满二叉树/完美二叉树：在一棵二叉树中，如果所有分支节点都存在左子树跟右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树或完美二叉树。</li>\n<li>完全二叉树：对一棵具有$n$个结点的二叉树按层序编号，如果编号为$i$（$1≤i≤n$） 的结点与同样深度的满二叉树中编号为$i$的结点在二叉树中位置完全相同，则称为完全二叉树。</li>\n<li>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E7%89%B9%E6%AE%8A%E4%BA%8C%E5%8F%89%E6%A0%91.jpg\" width=\"100%\" height=\"100%\"></li>\n</ul>\n<h2 id=\"2-2-二叉树的性质（待）\"><a href=\"#2-2-二叉树的性质（待）\" class=\"headerlink\" title=\"2.2 二叉树的性质（待）\"></a>2.2 二叉树的性质（待）</h2><ul>\n<li>性质1： 在二叉树的第$i$层上至多有$2^i-1$个结点（$i≥1$）。</li>\n<li>性质2： 深度为$k$的二叉树至多有$2^k-1$个结点（$k≥1$）。</li>\n<li>性质3： 对任何一棵二叉树T，如果其叶结点数为 $n_0$，度为2的非叶结点个数为 $n_2$，则$n_0=n_2+1$。</li>\n<li>性质4： 具有$n$个结点的完全二叉树的深度为$|log_2n+1|$（$|x|$表示不大于$x$的最大整数）。</li>\n<li>性质5： 如果对一棵有$n$个结点的完全二叉树，其结点按层序编号（从第1层到第层，每层从左到右），对任一结点$i$（$1≤i≤n$）有：<ul>\n<li>如果$i=1$，则结点$i$是二叉树的根，无双亲；如果$i&gt;1$，则其是双亲结点。</li>\n<li>如果$2i&gt;n$，则结点$i$无左孩子（结点$i$为叶子结点）；否则其左孩子是结点$2i$。</li>\n<li>如果$2i+1&gt;n$，则结点$i$无右孩子；否则其右孩子是结点$2i+1$。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-3-二叉树的存储结构\"><a href=\"#2-3-二叉树的存储结构\" class=\"headerlink\" title=\"2.3 二叉树的存储结构\"></a>2.3 二叉树的存储结构</h2><h3 id=\"2-3-1-顺序存储结构\"><a href=\"#2-3-1-顺序存储结构\" class=\"headerlink\" title=\"2.3.1 顺序存储结构\"></a>2.3.1 顺序存储结构</h3><p>二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置，也就是数组的下标要能体现结点之间的逻辑关系，比如双亲与孩子的关系，左右兄弟的关系等。<br><strong>顺序存储结构一般只用于完全二叉树</strong>。完全二叉树的顺序存储示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"50%\"><br>对于一般的二叉树，尽管层序编号不能反映逻辑关系，但是可以将其按完全二叉树编号，只不过将不存在的结点设置为<code>NULL</code>。示例：<br><img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%A1%BA%E5%BA%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B2.jpg\" width=\"70%\" height=\"50%\"><br>假设对于一棵深度为$k$的右斜树，它只有$k$个结点，却需要分配$2^k-1$个存储单元空间，这显然会造成空间浪费。所以，顺序存储结构一般只用于完全二叉树。</p>\n<h3 id=\"2-3-2-链表存储\"><a href=\"#2-3-2-链表存储\" class=\"headerlink\" title=\"2.3.2 链表存储\"></a>2.3.2 链表存储</h3><p>二叉树每个结点最多有两个孩子，设计一个数据域和两个指针域来储存，这样的链表叫做二叉链表。<br>二叉链表的结点结构定义代码：<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* 二叉树的二叉链表结点结构定义 */</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span>                  </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    ElemType data; <span class=\"comment\">/* 结点数据 */</span>                    </span><br><span class=\"line\">    <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">BiTNode</span> *<span class=\"title\">lchild</span>, *<span class=\"title\">rchild</span>;</span> <span class=\"comment\">/* 左右孩子指针 */</span></span><br><span class=\"line\">&#125; BiTNode, *BiTree;</span><br></pre></td></tr></table></figure></p>\n<p>二叉树的链表存储示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91_%E9%93%BE%E8%A1%A8%E5%AD%98%E5%82%A8.jpg\" width=\"60%\" height=\"70%\"></p>\n<h2 id=\"2-4-二叉树的遍历\"><a href=\"#2-4-二叉树的遍历\" class=\"headerlink\" title=\"2.4 二叉树的遍历\"></a>2.4 二叉树的遍历</h2><p>二叉树的遍历是指从根结点出发，按照某种次序依次“访问”二叉树中所有结点。“访问”是指对节点的进行某种操作，例如输出节点的值。<br>二叉树的遍历方式主要分为：</p>\n<ul>\n<li>宽度优先(Breadth-first)：层序遍历(Level-order Traversal)</li>\n<li>深度优先(Depth-first)：前序遍历(Preorder Traversal)、中序遍历(Inorder Traversal)、后序遍历(Postorder Traversal)</li>\n</ul>\n<h3 id=\"2-4-1-前序遍历\"><a href=\"#2-4-1-前序遍历\" class=\"headerlink\" title=\"2.4.1 前序遍历\"></a>2.4.1 前序遍历</h3><p>先访问根结点，然后前序遍历左子树，再前序遍历右子树（根左右）。<br>如图所示，遍历的顺序为：ABDGHCEIF。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归前序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x):data(x),left(<span class=\"literal\">nullptr</span>),right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归前序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data&lt;&lt;<span class=\"string\">' '</span>;</span><br><span class=\"line\">    preOrder(root-&gt;left);</span><br><span class=\"line\">    preOrder(root-&gt;right);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root -&gt; right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">                5</span></span><br><span class=\"line\"><span class=\"comment\">              /   \\</span></span><br><span class=\"line\"><span class=\"comment\">             3    10</span></span><br><span class=\"line\"><span class=\"comment\">            / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">           2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">\t*/</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    preOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 2 4 10 9 20</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归前序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(Node* root)</span>       <span class=\"comment\">//非递归前序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    Node* p = root;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (p || !s.empty())     <span class=\"comment\">//直到p空且栈空</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  </span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (p)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; p-&gt;data &lt;&lt;<span class=\"string\">' '</span>;</span><br><span class=\"line\">            s.push(p);</span><br><span class=\"line\">            p = p-&gt;left;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p = s.top();</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  </span></span><br><span class=\"line\">            p = p-&gt;right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">               5</span></span><br><span class=\"line\"><span class=\"comment\">             /   \\</span></span><br><span class=\"line\"><span class=\"comment\">            3    10</span></span><br><span class=\"line\"><span class=\"comment\">           / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">          2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    preOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 2 4 10 9 20</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-2-中序遍历\"><a href=\"#2-4-2-中序遍历\" class=\"headerlink\" title=\"2.4.2 中序遍历\"></a>2.4.2 中序遍历</h3><p>中序遍历根结点的左子树，然后访问根结点，最后中序遍历右子树（左根右）。<br>如图所示，遍历的顺序为：GDHBAEICF。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归中序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归中序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    inOrder(root-&gt;left);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">    inOrder(root-&gt;right);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">        5</span></span><br><span class=\"line\"><span class=\"comment\">      /   \\</span></span><br><span class=\"line\"><span class=\"comment\">     3    10</span></span><br><span class=\"line\"><span class=\"comment\">    / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    inOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 3 4 5 9 10 20</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归中序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">inOrder</span><span class=\"params\">(Node* root)</span>                  <span class=\"comment\">//非递归中序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    Node* p = root;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (p || !s.empty())               <span class=\"comment\">//直到p空且栈空</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(i)一直遍历到左子树最下边，边遍历边保存根节点到栈中  </span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (p)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(p);</span><br><span class=\"line\">            p = p-&gt;left;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//代码段(ii)当p为空时，说明已经到达左子树最下边，这时需要出栈了  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p = s.top();</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; p-&gt;data &lt;&lt; <span class=\"string\">' '</span>;       <span class=\"comment\">//与非递归前序遍历的唯一区别</span></span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，开始新的一轮左子树遍历(这是递归的自我实现)  </span></span><br><span class=\"line\">            p = p-&gt;right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    inOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 3 4 5 9 10 20</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-3-后序遍历\"><a href=\"#2-4-3-后序遍历\" class=\"headerlink\" title=\"2.4.3 后序遍历\"></a>2.4.3 后序遍历</h3><p>后序遍历根结点的左子树，然后后序遍历根结点的右子树，最后访问根结点（左右根）。<br>如图所示，遍历的顺序为：GHDBIEFCA。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//1.递归后序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">postOrder</span><span class=\"params\">(Node* root)</span> <span class=\"comment\">//递归后序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    postOrder(root-&gt;left);</span><br><span class=\"line\">    postOrder(root-&gt;right);</span><br><span class=\"line\">    <span class=\"built_in\">cout</span> &lt;&lt; root-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    postOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 4 3 9 20 10 5</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//2.非递归后序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stack&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x) :data(x), left(<span class=\"literal\">nullptr</span>), right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">postOrder</span><span class=\"params\">(Node* root)</span>       <span class=\"comment\">//非递归后序遍历</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;Node*&gt; s;</span><br><span class=\"line\">    <span class=\"comment\">//pCur:当前访问节点，pLastVisit:上次访问节点  </span></span><br><span class=\"line\">    Node* pCur = root;</span><br><span class=\"line\">    Node* pLastVisit = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    <span class=\"comment\">//先把pCur移动到左子树最下边  </span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (pCur)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        s.push(pCur);</span><br><span class=\"line\">        pCur = pCur-&gt;left;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!s.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"comment\">//走到这里，pCur都是空，并已经遍历到左子树底端(看成扩充二叉树，则空，亦是某棵树的左孩子)  </span></span><br><span class=\"line\">        pCur = s.top();</span><br><span class=\"line\">        s.pop();</span><br><span class=\"line\">        <span class=\"comment\">//一个根节点被访问的前提是：无右子树或右子树已被访问过  </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (pCur-&gt;right == <span class=\"literal\">nullptr</span> || pCur-&gt;right == pLastVisit)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; pCur-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">            <span class=\"comment\">//修改最近被访问的节点  </span></span><br><span class=\"line\">            pLastVisit = pCur;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//根节点再次入栈  </span></span><br><span class=\"line\">            s.push(pCur);</span><br><span class=\"line\">            <span class=\"comment\">//进入右子树，且可肯定右子树一定不为空  </span></span><br><span class=\"line\">            pCur = pCur-&gt;right;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (pCur)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                s.push(pCur);</span><br><span class=\"line\">                pCur = pCur-&gt;left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">          5</span></span><br><span class=\"line\"><span class=\"comment\">        /   \\</span></span><br><span class=\"line\"><span class=\"comment\">       3    10</span></span><br><span class=\"line\"><span class=\"comment\">      / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">     2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    postOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>测试结果：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2 4 3 9 20 10 5</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-4-4-层序遍历\"><a href=\"#2-4-4-层序遍历\" class=\"headerlink\" title=\"2.4.4 层序遍历\"></a>2.4.4 层序遍历</h3><p>从根结点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。如图所示，遍历的顺序为：ABCDEFGHI。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86.jpg\" width=\"40%\" height=\"40%\"><br>代码:<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//层序遍历</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span><span class=\"meta-string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Node</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> data;</span><br><span class=\"line\">    Node* left;</span><br><span class=\"line\">    Node* right;</span><br><span class=\"line\">    Node(<span class=\"keyword\">int</span> x):data(x),left(<span class=\"literal\">nullptr</span>),right(<span class=\"literal\">nullptr</span>)&#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">levelOrder</span><span class=\"params\">(Node* root)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;Node*&gt; q;              <span class=\"comment\">//借助队列，实现二叉树的层序遍历</span></span><br><span class=\"line\">    q.push(root);</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!q.empty())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        Node* temp = q.front();</span><br><span class=\"line\">        <span class=\"built_in\">cout</span> &lt;&lt; temp-&gt;data &lt;&lt; <span class=\"string\">' '</span>;</span><br><span class=\"line\">        q.pop();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp-&gt;left != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            q.push(temp-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (temp-&gt;right != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            q.push(temp-&gt;right);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">Node* <span class=\"title\">Insert</span><span class=\"params\">(Node* root, <span class=\"keyword\">int</span> data)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (root == <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        root = <span class=\"keyword\">new</span> Node(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (data &lt;= root-&gt;data) root-&gt;left = Insert(root-&gt;left, data);</span><br><span class=\"line\">    <span class=\"keyword\">else</span> root-&gt;right = Insert(root-&gt;right, data);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> root;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/*创建树：</span></span><br><span class=\"line\"><span class=\"comment\">         5</span></span><br><span class=\"line\"><span class=\"comment\">       /   \\</span></span><br><span class=\"line\"><span class=\"comment\">      3    10</span></span><br><span class=\"line\"><span class=\"comment\">     / \\   / \\</span></span><br><span class=\"line\"><span class=\"comment\">    2   4 9  20</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    Node* root = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">5</span>); root = Insert(root, <span class=\"number\">10</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">3</span>); root = Insert(root, <span class=\"number\">2</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">4</span>); root = Insert(root, <span class=\"number\">9</span>);</span><br><span class=\"line\">    root = Insert(root, <span class=\"number\">20</span>);</span><br><span class=\"line\">    levelOrder(root);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>测试代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">5 3 10 2 4 9 20</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"3-二叉搜索树\"><a href=\"#3-二叉搜索树\" class=\"headerlink\" title=\"3.二叉搜索树\"></a>3.二叉搜索树</h1><p>二叉搜索树(Binary Search Tree)，是指一棵空树或者具有下列性质的二叉树：</p>\n<ul>\n<li>若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；</li>\n<li>若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值；</li>\n<li>任意节点的左、右子树也分别为二叉查找树；</li>\n<li>没有键值相等的节点。</li>\n</ul>\n<p>示例：<br><img src=\"\nhttp://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%A4%BA%E4%BE%8B.png\" width=\"30%\" height=\"30%\"><br>（补充二叉搜索树的插入操作和删除操作的代码。以及各操作的时间复杂度分析。）</p>\n<h1 id=\"4-平衡二叉树\"><a href=\"#4-平衡二叉树\" class=\"headerlink\" title=\"4.平衡二叉树\"></a>4.平衡二叉树</h1><p>平衡因子(Balance Factor)：$BF(T)=h_L-h_R$。其中，$h_L$和$h_R$分别为$T$的左、右子树的高度。<br>平衡二叉树(Balance Binary Tree)：在二叉搜索树的基础上，任一结点的左、右子树的高度差的绝对值（平衡因子）不超过1，即$BF(T)\\leq1$。<br>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E7%A4%BA%E4%BE%8B.JPG\" width=\"80%\" height=\"80%\"><br>（补充平衡二叉树的调整方式及代码。以及各操作的时间复杂度分析。）</p>\n<h1 id=\"5-堆\"><a href=\"#5-堆\" class=\"headerlink\" title=\"5.堆\"></a>5.堆</h1><p>堆(heap)的两个特性：</p>\n<ul>\n<li>用数组表示的完全二叉树。</li>\n<li>任一结点的值都大于（或小于）其左右孩子结点的值。</li>\n</ul>\n<p>将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。<br>示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%A0%91/%E5%A0%86%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"><br>（补充堆的基本操作代码。以及各操作的时间复杂度分析。<a href=\"http://zhanglimin.com/2017/11/29/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/\" target=\"_blank\" rel=\"noopener\">排序算法</a>中堆排序一节已有。）</p>\n<h1 id=\"6-哈夫曼树\"><a href=\"#6-哈夫曼树\" class=\"headerlink\" title=\"6.哈夫曼树\"></a>6.哈夫曼树</h1><p>给定$n$个权值作为$n$个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。<br>（补充哈夫曼树的构造、哈夫曼编码）</p>\n<h1 id=\"7-参考资料\"><a href=\"#7-参考资料\" class=\"headerlink\" title=\"7.参考资料\"></a>7.参考资料</h1><ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P\" target=\"_blank\" rel=\"noopener\">Data Structures, mycodeschool</a></li>\n<li><a href=\"http://www.icourse163.org/course/ZJU-93001\" target=\"_blank\" rel=\"noopener\">数据结构，浙江大学</a></li>\n<li><a href=\"https://www.coursera.org/specializations/biancheng-suanfa\" target=\"_blank\" rel=\"noopener\">程序设计与算法专项课程，北京大学</a></li>\n<li><a href=\"https://medium.com/basecs/how-to-not-be-stumped-by-trees-5f36208f68a7\" target=\"_blank\" rel=\"noopener\">How To Not Be Stumped By Trees, Vaidehi Joshi</a></li>\n<li><a href=\"http://blog.csdn.net/zhangxiangdavaid/article/details/37115355\" target=\"_blank\" rel=\"noopener\">二叉树前序、中序、后序遍历非递归写法的透彻解析，苏叔叔</a></li>\n</ul>"},{"title":"支持向量机","mathjax":true,"top":true,"date":"2017-12-12T09:40:50.000Z","_content":"　　支持向量机(support vector machine, SVM)是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。线性支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题。\n　　支持向量机学习方法包含构建由简至繁的模型：**线性可分支持向量机**、**线性支持向量机**、**非线性支持向量机**：\n\n - **线性可分支持向量机**：适用于训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器，即线性可分支持向量机，又称为**硬间隔支持向量机**；\n - **线性支持向量机**：适用于训练数据近似线性可分，也就是存在一些特异点，将这些特异点去除后的样本线性可分（现实中的数据经常是线性不可分的）。通过软间隔最大化，也学习一个线性的分类器，即线性支持向量机，又称为**软间隔支持向量机**；\n - **非线性支持向量机**：适用于训练数据线性不可分，通过核技巧即软间隔最大化，学习非线性支持向量机。\n<!-- more --> \n\n**注**：\n**核函数**：核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。\n**核技巧**：通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法成为核技巧。\n　　\n# 一、基本概念\n（1）SVM的**分离超平面**：\n$$w^*\\cdot x+b^*=0\\tag{1}$$\n（2）SVM的**分类决策函数**为：\n$$f(x)=sign(w^* \\cdot x+b^*)\\tag{2}$$\n**注**：函数值只有正负1，二分类。\n（3）**函数间隔**：\n　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为：\n$$\\hat{\\gamma_i}=y_i(w \\cdot x_i+b)\\tag{3}$$\n　　定义超平面$(w,b)$关于训练集$T$的函数间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的函数间隔之最小值，即：\n$$\\hat{\\gamma}=\\min_{i=1,...,m}\\hat{\\gamma_i}\\tag{4}$$\n**注1**：函数间隔大于0，表示$w \\cdot x_i+b$与$y_i$同号，分类正确；$|w \\cdot x_i+b|$值越大，离分离超平面越远，分类预测的确信程度越高。所以用$y_i(w \\cdot x_i+b)$来表示分类的正确性和确信度，这就是函数间隔。\n**注2**：函数间隔可以表示分类预测的正确性及确信程度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例的改变$w$和$b$，例如将它们改变为$2w$和$2b$，超平面并没有改变，但函数间隔却成为原来的2倍。故需对超平面的法向量$w$加某些约束，如规范化$||w||=1$，使得间隔是确定的。此时，函数间隔即几何间隔。\n（4）**几何间隔**：\n　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔为：\n$$\\gamma_i=y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\tag{5}$$\n　　定义超平面$(w,b)$关于训练集$T$的几何间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的几何间隔之最小值，即：\n$$\\gamma=\\min_{i=1,...,m}\\gamma_i\\tag{6}$$\n**注**：超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔即**实例点到分离超平面的带符号的距离**，由[点到直线的距离公式](https://baike.baidu.com/item/%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E8%B7%9D%E7%A6%BB/8673346)可推出。\n　　从函数间隔和几何间隔的定义（式(3)~(6)）可知，函数间隔和几何间隔有如下关系：\n$$\\begin{align*}\n\\gamma_i=\\frac{\\hat{\\gamma_i}}{||w||}\\tag{7}\\\\\n\\gamma=\\frac{\\hat{\\gamma}}{||w||}\\tag{8}\n\\end{align*} $$\n**注**：如果$||w||=1$，那么函数间隔和几何间隔相等。如果超平面参数$w$和$b$成比例地改变，超平面没有改变，函数间隔按此比例改变，而几何间隔不变。\n\n# 二、线性可分支持向量机\n　　支持向量机学习的基本思想是求解能够**正确划分训练数据集**并且**几何间隔最大**的分离超平面。\n　　对**线性可分**的训练数据集，线性可分分离超平面有无穷多个，但几何间隔最大的分离超平面是唯一的。这里的间隔最大化又称为**硬间隔最大化**。\n　　此时，学习到的线性分类器，称为**线性可分支持向量机**或**硬间隔支持向量机**。\n注：几何间隔最大化的直观解释：对训练数据集找到的几何间隔最大化的超平面意味着以充分大的确信程度对训练数据进行分类。也就是说，不仅将正负实例分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力。\n## 2.1 原始最优化问题\n　　（1）求最大间隔分离超平面的问题，可以表示为下面的约束最优化问题：\n$$\\begin{align*}\n\\max_{w,b}\\; &\\gamma \\tag{9}\\\\\ns.t.\\; & y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\geq\\gamma,\\;  i=1,2,...,m\\tag{10}\n\\end{align*} $$\n注：即我们希望最大化超平面$(w,b)$关于训练数据集的几何间隔$\\gamma$，约束条件表示的是超平面$(w,b)$关于每个训练样本点的几何间隔至少是$\\gamma$。\n　　（2）根据函数间隔与几何间隔的关系式(8)，约束问题可以等价于：\n$$\\begin{align*}\n\\max_{w,b}\\; &\\frac{\\hat{\\gamma}}{||w||}\\tag{11}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq\\hat{\\gamma},\\; i=1,2,...,m\\tag{12}\n\\end{align*} $$\n　　（3）由于式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解（见注解），因此可以取$\\hat{\\gamma}=1$。将$\\hat{\\gamma}=1$代入式(11~12)的最优化问题，且最大化$\\frac{1}{||w||}$和最小化$\\frac{1}{2}||w||^2$是等价的，于是就得到下面的线性可分支持向量机学习的最优化问题：\n$$\\begin{align*}\n\\min_{w,b}\\; &\\frac{1}{2}||w||^2 \\tag{13}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)-1\\geq0,\\, i=1,2,...,m\\tag{14}\n\\end{align*}$$\n　　这是一个凸优化问题中的凸二次规划问题。\n　　如果求出了约束条件最优化问题式(13)~(14)的解`$w^*$`，`$b^*$`，那么就可以得到最大间隔分离超平面`$w^*\\cdot x+b^*=0$`及分类决策函数`$f(x)=sign(w^* \\cdot x+b^*)$`，即线性可分支持向量机模型。\n**注**：式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解。假设将$w$和$b$按比例改变为$\\lambda w$和$\\lambda b$，这时函数间隔成为$\\lambda \\hat{\\gamma}$。函数间隔的这一改变既对式(12)的不等数约束没有影响，又对式(11)的目标函数的优化没有影响，也就是说，它产生一个等价的最优化问题。\n## 2.2 支持向量和间隔边界\n　　在线性可分的情况下，**训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量**。支持向量是使约束条件式(14)等号成立的点，即\n$$y_i(w\\cdot x_i+ b)-1=0\\tag{15}$$\n　　对$y_i=+1$的正例点，支持向量在超平面\n$$H_1:w \\cdot x+b=1\\tag{16}$$\n　　对$y_i=-1$的负例点，支持向量在超平面\n$$H_2:w \\cdot x+b=-1\\tag{17}$$\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/SVM/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%92%8C%E9%97%B4%E9%9A%94%E8%BE%B9%E7%95%8C.JPG\" width=\"50%\" height=\"50%\">\n　　　　　　　　　　　　　　　　　图1，支持向量和间隔边界\n　　如图1，在$H_1$和$H_2$上的点就是**支持向量**，$H_1$和$H_2$称为**间隔边界**，$H_1$与$H_2$之间的距离称为**间隔**(margin)。\n注1：$H_1$与$H_2$平行，并且没有实例点落在它们中间。在$H_1$与$H_2$之间形成一条长带，**分离超平面与它们平行且位于它们中央**。长带的宽度，即$H_1$与$H_2$之间的距离称为间隔。因为$H_1$和$H_2$的函数间隔为1，故各自与分离超平面的几何间隔为$\\frac{1}{||w||}$，即**间隔为$\\frac{2}{||w||}$。**\n注2：在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。如果移动支持向量改变所求的解；但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的。**由于支持向量在确定分离超平面中起着决定性作用，所以将这种分类模型称为支持向量机**。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。\n## 2.3 对偶最优化问题\n　　为了求解线性可分支持向量机的最优化问题（式(13)~(14)），将它作为**原始最优化问题**，应用拉格朗日对偶性，通过求解**对偶问题**(dual problem)得到**原始问题**(primal problem)的最优解，这就是线性可分支持向量机的**对偶算法**。这样做的优点，**一是对偶问题往往更容易求解，二是自然引入核函数，进而推广到非线性分类问题**。\n　　（1）构建拉格朗日函数\n　　对每一个不等式约束，引进拉格朗日乘子$\\alpha_i\\geq0,\\ i=1,2,..,m$，定义拉格朗日函数：\n$$L(w,b,\\alpha)=\\frac{1}{2}||w||^2+\\sum_{i=1}^{m}\\alpha_i(1-y_i(w\\cdot x_i+b))\\tag{18}$$\n　　式中，$\\alpha=(\\alpha_1,\\alpha_2,...,\\alpha_m)^T$为拉格朗日乘子向量。\n　　（2）对偶问题\n　　根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：\n$$\\max_\\alpha\\, \\min_{w,b}L(w,b,\\alpha)$$\n　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\alpha)$对$w,b$的极小，再求对$\\alpha$的极大。\n　　（3）对偶问题——求$\\min\\limits_{w,b}L(w,b,\\alpha)$\n　　将拉格朗日函数$L(w,b,\\alpha)$分别对$w,b$求偏导数并令其等于0，\n$$\\nabla_wL(w,b,\\alpha)=w-\\sum_{i=1}^{m}\\alpha_i y_i x_i=0\\\\\n\\nabla_bL(w,b,\\alpha)=-\\sum_{i=1}^{m}\\alpha_i y_i=0$$\n　　得，\n$$\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_i y_i x_i\\tag{19}\\\\\n\\sum_{i=1}^{m}\\alpha_i y_i=0\\tag{20}\n\\end{align*} $$\n　　将式(19)代入拉格朗日函数（式(18)），并利用式(20),即得\n$$\\min_{w,b}L(w,b,\\alpha)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i$$\n　　（4）对偶问题——求$\\min_{w,b}L(w,b,\\alpha)$对$\\alpha$的极大，即是对偶问题\n$$\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{21}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\n\\end{align*} $$\n　　（5）将上式(21)的目标函数由求极大转换成为求极小，就得到下面与之等价的**对偶最优化问题**：\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{22}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\tag{23}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{24}\n\\end{align*}$$\n　　考虑原始最优问题(式(13)~(14))和对偶最优化问题(式(22)~(24))，原始问题满足**定理C.2(见书中，此处略)**的条件，故存在$w^*$,$\\alpha^*$，$w^*$是原问题的解，$\\alpha^*$是对偶问题的解。**这意味着求解原始问题(式(13)~(14))可以转换为求解对偶问题(式(22)~(24))**。\n　　依据定理C.3(见书中，此处略)，**`$w^*$`和`$\\alpha^*$`分别是原始问题和对偶问题的解的充要条件是`$w^*$`，`$\\alpha^*$`满足KKT条件**。\n## 2.4 KKT条件\n原问题可行：　　\n$y_i(w^*\\cdot x_i+b^*)-1\\geq0,\\; i=1,2,...,m \\tag{25}$\n互补松弛条件(complementary slackness):\n$\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1)=0,\\; i=1,2,...,m \\tag{26}$\n对偶可行：\n$\\alpha_i^*\\geq0,\\; i=1,2,...,m \\tag{27}$\n对偶内在优化：\n$\\nabla_wL(w^*,b^*,\\alpha^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{28}$\n$\\nabla_bL(w^*,b^*,\\alpha^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{29}$\n\n## 2.5 对偶问题最优解与原始问题最优解的对应关系\n　　设$\\alpha=(\\alpha_1,\\alpha_2,...,\\alpha_m)^T$是对偶最优化问题(式(22)~(24))的解，则存在下标$j$，使得$\\alpha_j>0$，并可按下式求得原始最优化问题(式(13)~(14))的解$w^*$,$b^*$：\n$$\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i \\tag{30}\\\\\nb^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}\n\\end{align*}$$\n**注1**：$w^*$从KKT条件中式(28)中直接得出。\n**注2**：$b^*$的得出：从KKT条件知道，至少有一个$\\alpha_j^*>0$（反证法，假设$\\alpha^*=0$，由式(28)得$w^*=0$，而$w^*=0$不是原始最优化问题(式(13)~(14))的解，矛盾）。结合KKT中互补松弛条件(式(26))，对此$j$有：\n$y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{32}$\n将$w^*$的解(式(30))代入式(32)并注意到$y_j^2=1$，即得\n$b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}$\n　　\n　　求得解$w^*$，$b^*$后，**分离超平面**可写成：\n$$\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{33}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{34}\n\\end{align*}$$\n　　**分类决策函数**可写成：\n$$\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{35}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{36}\n\\end{align*}$$\n　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。**式(36)称为线性可分支持向量机的对偶形式**。\n　　综上，对于给定的线性可分训练数据集，可以首先求对偶问题（式(22)~(24)）的解$\\alpha^*$；再利用式(30)和式(31)求得原始问题的解$w^*$和$b^*$；从而得到分离超平面及分类决策函数。这种算法称为**线性可分支持向量机的对偶学习算法**，是线性可分支持向量机的基本算法。\n\n## 2.6 支持向量\n在线性可分支持向量机中，由式(30)和式(31)可知，**`$w^*$`和`$b^*$`只依赖于训练数据中对应于`$\\alpha_i^*>0$`的样本点`$(x_i,y_i)$`**，而其他样本点对`$w^*$`和`$b^*$`没有影响。**将训练数据中对应于`$\\alpha_i^*>0$`的实例点`$x_i \\in R^n$`称为支持向量**。\n支持向量一定在间隔边界上。由KKT互补松弛条件(式(26))可知，对应于于`$\\alpha_i^*>0$`的实例`$x_i$`，有\n$$y_i(w^*\\cdot x_i+b^*)-1=0$$\n或\n$$w^*\\cdot x_i+b^*=\\pm1$$\n即$x_i$一定在间隔边界上。这里的支持向量的定义与前面给出的支持向量的定义是一致的。\n\n# 三、线性支持向量机\n\n## 2.1 原始最优化问题\n**线性不可分的线性支持向量机的原始问题**如下：\n$$\\begin{align*}\n\\min_{w,b,\\xi}\\; & \\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i \\tag{37}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq1-\\xi_i, \\; i=1,2,...,m\\tag{38}\\\\\n& \\xi_i\\geq0,\\; i=1,2,...,m\\tag{39}\n\\end{align*}$$\n**注1**：线性不可分意味着某些样本点$(x_i,y_i)$不能满足函数间隔大于等于1的约束条件（式(14)）。为了解决这个问题，可以对每个样本点$(x_i,y_i)$引进一个松弛变量$\\xi_i\\geq0$，使函数间隔加上松弛变量大于等于1。这样约束条件变为式(38)。\n**注2**：同时，对每一个松弛变量$\\xi_i$，支付一个代价$\\xi_i$。目标函数由原来的$\\frac{1}{2}||w||^2$变成式(37)。这里，$C>0$称为惩罚参数，一般由应用问题决定，$C$值大时对误分类的惩罚增大，$C$值小时对误分类的惩罚减小。最小化目标函数式(37)包含两层含义：使$\\frac{1}{2}||w||^2$尽量小即间隔尽量大，同时使误分类点的个数尽量小，$C$是调和二者的系数。\n　　有了上面的思路，可以和训练数据集线性可分时一样来考虑训练数据集线性不可分时的线性支持向量机学习问题。相应于硬间隔最大化，它称为**软间隔最大化**。\n　　原问题式(37)~式(39)是一个凸二次规划问题，因而关于$(w,b,\\xi)$的解是存在的。\n　　设原问题式(37)~式(39)的解是`$w^*$`，`$b^*$`，于是可以得到分离超平面`$w^* \\cdot x + b^* =0$`及分类决策函数`$f(x)=sign(w^* \\cdot x + b^*)$`。成这样的模型为训练样本线性不可分时的线性支持向量机，简称**线性支持向量机**。\n## 2.2 对偶最优化问题\n（1）构建拉格朗日函数\n　　原始最优化问题（式(37)~(39)）的拉格朗日函数是\n$$\nL(w,b,\\xi,\\alpha,\\mu)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i-\\sum_{i=1}^{m}\\alpha_i(y_i(w\\cdot x_i+b)-1+\\xi_i)-\\sum_{i=1}^{m}\\mu_i\\xi_i\n\\tag{40}\n$$\n　　其中，$\\alpha_i\\geq0,\\mu_i\\geq0$.\n（2）对偶问题\n　　对偶问题是拉格朗日函数的极大极小问题：\n$$\\max_\\alpha\\; \\min_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$$\n　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\xi,\\alpha,\\mu)$对$w,b,\\xi$的极小，再求对$\\alpha$的极大。\n（3）对偶问题——求$\\min\\limits_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$\n　　通过\n$$\\begin{align*}\n\\nabla_wL(w,b,\\xi,\\alpha,\\mu)=w-\\sum_{i=1}^{m}\\alpha_i y_ix_i=0\\\\\n\\nabla_bL(w,b,\\xi,\\alpha,\\mu)=-\\sum_{i=1}^{m}\\alpha_i y_i=0\\\\\n\\nabla_{\\xi}L(w,b,\\xi,\\alpha,\\mu)=C-\\alpha_i-\\mu_i=0\n\\end{align*}$$\n　　得\n$$\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_iy_ix_i\\tag{41}\\\\\n\\sum_{i=1}^{m}\\alpha_iy_i=0\\tag{42}\\\\\nC-\\alpha_i-\\mu_i=0\\tag{43}\n\\end{align*}$$\n　　将式(41)到式(43)代入式(40)，得\n$$\\min_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i$$\n（4）对偶问题——求$\\min\\limits_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)$对$\\alpha$的极大，即得对偶问题\n$$\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{44}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{45}\\\\\n& C-\\alpha_i-\\mu_i=0\\tag{46}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{47}\\\\\n& \\mu_i\\geq0,\\; i=1,2,...,m\\tag{48}\n\\end{align*} \n$$\n　　将对偶最优化问题式(44)~式(48)进行变换：利用等式约束式(46)消去$\\mu_i$，从而只留下变量$\\alpha_i$，并将约束式(46)~式(48)写成\n$$0\\leq\\alpha_i\\leq C\\tag{49}$$\n（5）再将对目标函数求极大极小转为求极小，于是得到**对偶问题**(50)~(52).\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{50}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{51}\\\\\n& 0\\leq \\alpha_i\\leq C,\\;i=1,2,...m\\tag{52}\\\\\n\\end{align*}$$\n　　综上，原始最优化问题(式(37)～式(39))的对偶最优化问题为式(50)~式(51)。可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数。\n　　有定理可证，**求解原始问题(式(37)～式(39))可以转换为求解对偶问题式(50)~式(52)**。\n　　有定理可证，**`$w^*$`和`$\\alpha^*$`分别是原始问题和对偶问题的解的充要条件是`$w^*$`，`$\\alpha^*$`满足KKT条件**。\n## 2.3 KKT条件\n原问题可行：\n$$\\begin{align*}\ny_i(w^*\\cdot x_i+ & b^*)-1+\\xi_i^*\\geq0 \\tag{53} \\\\\n& \\xi_i^*\\geq0 \\tag{54}\n\\end{align*}$$\n互补松弛条件(complementary slackness):\n$$\\begin{align*}\n\\alpha_i^*(y_i(w^*\\cdot x_i & + b^*)-1 +\\xi_i^*)=0 \\tag{55}\\\\\n& \\mu_i^*\\xi_i^*=0\\tag{56}\n\\end{align*}$$\n对偶问题可行：\n$$\\begin{align*}\n\\alpha_i^*\\geq0 \\tag{57}\\\\\n\\mu_i^*\\geq0 \\tag{58}\n\\end{align*}$$\n对偶内在优化：\n$$\\begin{align*}\n\\nabla_wL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{59}\\\\\n\\nabla_bL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{60}\\\\\n\\nabla_{\\xi}L(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=C-\\alpha_i^*-\\mu_i^*=0 \\tag{61}\n\\end{align*}$$\n\n## 2.4 对偶问题最优解与原始问题最优解的对应关系\n　　设`$\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)$`是对偶问题（式(50)~式(52)）的一个解，若存在`$\\alpha^*$`的一个分量`$\\alpha_j^*$`，`$0<\\alpha_j^* < C$`，则原始问题式（(37)～式(39)）的解`$w^*,b^*$`可按下式求得：\n$$\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i\\tag{62}\\\\\nb^*=y_j-\\sum_{i=1}^{m}y_i\\alpha_i^*(x_i\\cdot x_j)\\tag{63}\n\\end{align*}$$\n**注1**：`$w^*$`从KKT条件中式(59)中直接得出。\n**注2**：`$b^*$`的得出：从KKT条件知道，至少有一个`$0<\\alpha_j^* < C$`（反证法，假设`$\\alpha^*=0$`，由式(59)得`$w^*=0$`，而`$w^*=0$`不是原始最优化问题(式(37)～式(39)的解，矛盾）。结合KKT中互补松弛条件(式(55)~式(56))，对此$j$有：\n`$y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{64}$`\n将`$w^*$`的解(式(62))代入式(64)并注意到`$y_j^2=1$`，即得式(63)。（结合式(61)和(56)，此时的$$\\xi_j^*=0$$）\n　　求得解`$w^*$`，`$b^*$`后，**分离超平面**可写成：\n$$\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{65}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{66}\n\\end{align*}$$\n　　**分类决策函数**可写成：\n$$\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{67}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{68}\n\\end{align*}$$\n　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。**式(68)称为线性支持向量机的对偶形式**。\n## 2.5 支持向量\n　　**软间隔的支持向量**：在线性不可分的情况下，将对偶问题（式(50)~式(52)）的解`$\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)$`中**对应于`$\\alpha_i^*>0$`的样本点`$(x_i,y_i)$`的实例`$x_i$`称为支持向量。**\n　　结合互补松弛条件（式(55)~式(56)）及式(61)，得\n$$\n\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1+\\xi_i^*)=0, i=1,2,...,m\\\\\n(C-\\alpha_i^*)\\xi_i^*=0\n$$\n　　软间隔的支持向量$x_i$**或者在间隔边界上，或者在间隔边界与分离超平面之间，或者在分离超平面误分一侧。**\n\n- `$\\alpha_i^*=0$`时：非支持向量，`$\\xi_i=0$`，没犯错，远离间隔边界或在间隔边界上；\n- `$0<\\alpha_i^*<C$`时：支持向量，`$\\xi_i=0$`，支持向量`$x_i$`在在间隔边界上，决定了`$b^*$`；\n- `$\\alpha_i^*=C$`时：支持向量，`$\\xi_i \\neq 0$`,`$\\xi_i>0$`，`$\\xi_i$`记录了违反间隔边界的数量或大小\n - `$0<\\xi_i < 1$`：分类正确,`$x_i$`落在间隔边界与分离超平面之间；\n - `$\\xi_i = 1 $`：`$w^*\\cdot x_i+b^*=0$`,`$x_i$`落在分离超平面上；\n - `$\\xi_i >1 $`：样本点分类错误，`$x_i$`落在分离超平面误分一侧。\n\n# 四、非线性支持向量机\n　　对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，通常分类问题是非线性的，这时可以使用非线性支持向量机，其主要特点是利用核技巧。\n　　用线性分类方法求解非线性分类问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练数据中学习分类模型。核技巧就属于这样的方法。\n## 4.1 核函数的定义\n　　假设$X$是输入空间，$H$是特征空间，如果存在一个从$X$到$H$的映射函数：\n$$\\phi(x):X\\rightarrow H$$\n　　使得所有$x,z\\in X$,函数$K(x,z)$满足条件：\n$$K(x,z)=\\phi(x)\\cdot \\phi(z)$$\n　　则称$K(x,z)$为核函数，$\\phi(x)$为映射函数，式中$\\phi(x)\\cdot \\phi(z)$为$\\phi(x)$和$\\phi(z)$的内积。\n　　**核技巧的想法是：在学习与预测中只定义核函数$K(x,z)$,而不是显示地定义映射函数$\\phi$。通常，直接计算$K(x,z)$比较容易，而通过$\\phi(x)$和$\\phi(z)$计算$K(x,z)$并不容易。**注意，$\\phi$是输入空间$R^n$到特征空间$H$的映射，特征空间$H$一般是高维的，甚至是无穷维的。\n## 4.2 核技巧在支持向量机中的应用\n　　我们注意到在线性支持向量机的对偶问题中，无论是在目标函数还是在决策函数(分离超平面)都只涉及输入实例与实例之间的内积。\n　　在对偶问题的目标函数(式(50))中的内积`$x_i\\cdot x_j$`可以用核函数`$K(x_i,x_j)=\\phi(x_i)\\cdot \\phi(x_j)$`来代替。此时对偶问题的目标函数变为：\n　　$$W(\\alpha)=\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i \\tag{69}$$\n　　同样，分类决策函数中的内积也可以用核函数代替，而分类决策函数变为：\n　　$$f(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i \\phi(x) \\cdot \\phi(x_i)+b^*) \\\\\n　　=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i K(x \\cdot x_i)+b^*)   \\tag{70}$$\n　　这等价于经过映射函数$\\phi$将原来的输入空间变换到一个新的特征空间，将输入空间中的内积$x_i \\cdot x_j$变换为特征空间中的内积$\\phi(x_i) \\cdot \\phi(x_j)$，在新的特征空间里从训练样本中学习线性支持向量机。当映射函数是非线性时，学习到的含有核函数的支持向量机是非线性分类模型。\n　　也就是说，在核函数`$K(x,z)$`给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是在隐式地特征空间进行的，不需要显示地定义特征空间和映射函数。这样的技巧称为核技巧，它是巧妙地利用线性分类学习方法与核函数解决非线性问题的技术。\n##  4.3 常用核函数\n　　（1）多项式核函数：\n$$K(x,z)=(\\gamma \\cdot x\\cdot z+ \\zeta)^p  \\tag{71}$$\n　　式中，$\\gamma\\in R$且$\\gamma>0$,$\\zeta\\in R$且$\\zeta\\geq0$\n　　特殊情况：线性核：$K_1(x,z)=(1 \\cdot x\\cdot z+0)^1$\n　　（2）高斯核函数：\n$$K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2}) \\tag{72}$$\n　　或写成$K(x,z)=exp(-\\gamma||x-z||^2)$,$\\gamma>0$\n　　**注**：正态分布的PDF为：$f(x;\\mu,\\sigma)= \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x-\\mu)^2}{2{\\sigma}^2})$\n## 4.４ 非线性支持向量机学习算法\n　　如上所述，利用核技巧，可以将线性分类的学习方法应用到非线性分类问题中去。将线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机对偶形式中的内积换成核函数。\n　　（1）选取适当的核函数$K(x,z)$和适当的参数$C$，构造并求解最优化问题\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{73}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{74}\\\\\n& 0\\leq \\alpha_i\\leq C,\\; i=1,2,...m\\tag{75}\\\\\n\\end{align*} \n$$\n　　求得最优解`$\\alpha^*=(\\alpha^*_1,\\alpha^*_2,...,\\alpha^*_m)$`.\n　　(2)选择`$\\alpha^*$`的一个正分量`$0<\\alpha^*_j < C$`，计算\n$$b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_iK(x_i \\cdot x_j)$$\n　　(3)构造决策函数：\n$$f(x)=sign(w^*\\cdot x+b^*)=sign(\\sum_{i=1}^{m}\\alpha^*_iy_iK(x\\cdot x_i)+b^*)$$\n\n# 五、SMO算法（待补）\nSMO算法的思想： \n（1）SMO是一种启发式算法，选择两个变量固定其他变量，针对选择的两个变量构造二次规划问题，二次规划问题可以直接得到解析解；SMO算法将原问题 不断地分解为子问题并对子问题进行求解进而达到求解原问题的目的； \n（2）之所以选择每次更新两个变量是因为目标函数中的第二个约束，若固定其他的变量，那么最后一个变量也随之确定，因此需要更新两个变量。 \n# 六、SVM优缺点（待补）\n1.优点\n（1）可用于线性/非线性分类，也可以用于回归；\n（2）低泛化误差；\n（3）容易解释；\n（4）计算复杂度较低；\n（5）处理小样本，非线性，高维数问题；\n2.缺点\n（1）对参数和核函数的选择比较敏感；\n（2）原始的SVM只比较擅长处理二分类问题；\n# 七、参考资料\n- 李航，统计学习方法\n- [林轩田，机器学习技法](https://www.youtube.com/watch?v=A-GxGCCAIrg&list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- 周志华，机器学习\n\n\n","source":"_posts/支持向量机.md","raw":"---\ntitle: 支持向量机\nmathjax: true\ntop: true\ndate: 2017-12-12 17:40:50\ncategories: \n- 机器学习\ntags:\n- 线性可分支持向量机\n- 线性支持向量机\n- 非线性支持向量机\n- 核函数\n- smo算法\n---\n　　支持向量机(support vector machine, SVM)是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。线性支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题。\n　　支持向量机学习方法包含构建由简至繁的模型：**线性可分支持向量机**、**线性支持向量机**、**非线性支持向量机**：\n\n - **线性可分支持向量机**：适用于训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器，即线性可分支持向量机，又称为**硬间隔支持向量机**；\n - **线性支持向量机**：适用于训练数据近似线性可分，也就是存在一些特异点，将这些特异点去除后的样本线性可分（现实中的数据经常是线性不可分的）。通过软间隔最大化，也学习一个线性的分类器，即线性支持向量机，又称为**软间隔支持向量机**；\n - **非线性支持向量机**：适用于训练数据线性不可分，通过核技巧即软间隔最大化，学习非线性支持向量机。\n<!-- more --> \n\n**注**：\n**核函数**：核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。\n**核技巧**：通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法成为核技巧。\n　　\n# 一、基本概念\n（1）SVM的**分离超平面**：\n$$w^*\\cdot x+b^*=0\\tag{1}$$\n（2）SVM的**分类决策函数**为：\n$$f(x)=sign(w^* \\cdot x+b^*)\\tag{2}$$\n**注**：函数值只有正负1，二分类。\n（3）**函数间隔**：\n　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为：\n$$\\hat{\\gamma_i}=y_i(w \\cdot x_i+b)\\tag{3}$$\n　　定义超平面$(w,b)$关于训练集$T$的函数间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的函数间隔之最小值，即：\n$$\\hat{\\gamma}=\\min_{i=1,...,m}\\hat{\\gamma_i}\\tag{4}$$\n**注1**：函数间隔大于0，表示$w \\cdot x_i+b$与$y_i$同号，分类正确；$|w \\cdot x_i+b|$值越大，离分离超平面越远，分类预测的确信程度越高。所以用$y_i(w \\cdot x_i+b)$来表示分类的正确性和确信度，这就是函数间隔。\n**注2**：函数间隔可以表示分类预测的正确性及确信程度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例的改变$w$和$b$，例如将它们改变为$2w$和$2b$，超平面并没有改变，但函数间隔却成为原来的2倍。故需对超平面的法向量$w$加某些约束，如规范化$||w||=1$，使得间隔是确定的。此时，函数间隔即几何间隔。\n（4）**几何间隔**：\n　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔为：\n$$\\gamma_i=y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\tag{5}$$\n　　定义超平面$(w,b)$关于训练集$T$的几何间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的几何间隔之最小值，即：\n$$\\gamma=\\min_{i=1,...,m}\\gamma_i\\tag{6}$$\n**注**：超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔即**实例点到分离超平面的带符号的距离**，由[点到直线的距离公式](https://baike.baidu.com/item/%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E8%B7%9D%E7%A6%BB/8673346)可推出。\n　　从函数间隔和几何间隔的定义（式(3)~(6)）可知，函数间隔和几何间隔有如下关系：\n$$\\begin{align*}\n\\gamma_i=\\frac{\\hat{\\gamma_i}}{||w||}\\tag{7}\\\\\n\\gamma=\\frac{\\hat{\\gamma}}{||w||}\\tag{8}\n\\end{align*} $$\n**注**：如果$||w||=1$，那么函数间隔和几何间隔相等。如果超平面参数$w$和$b$成比例地改变，超平面没有改变，函数间隔按此比例改变，而几何间隔不变。\n\n# 二、线性可分支持向量机\n　　支持向量机学习的基本思想是求解能够**正确划分训练数据集**并且**几何间隔最大**的分离超平面。\n　　对**线性可分**的训练数据集，线性可分分离超平面有无穷多个，但几何间隔最大的分离超平面是唯一的。这里的间隔最大化又称为**硬间隔最大化**。\n　　此时，学习到的线性分类器，称为**线性可分支持向量机**或**硬间隔支持向量机**。\n注：几何间隔最大化的直观解释：对训练数据集找到的几何间隔最大化的超平面意味着以充分大的确信程度对训练数据进行分类。也就是说，不仅将正负实例分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力。\n## 2.1 原始最优化问题\n　　（1）求最大间隔分离超平面的问题，可以表示为下面的约束最优化问题：\n$$\\begin{align*}\n\\max_{w,b}\\; &\\gamma \\tag{9}\\\\\ns.t.\\; & y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\geq\\gamma,\\;  i=1,2,...,m\\tag{10}\n\\end{align*} $$\n注：即我们希望最大化超平面$(w,b)$关于训练数据集的几何间隔$\\gamma$，约束条件表示的是超平面$(w,b)$关于每个训练样本点的几何间隔至少是$\\gamma$。\n　　（2）根据函数间隔与几何间隔的关系式(8)，约束问题可以等价于：\n$$\\begin{align*}\n\\max_{w,b}\\; &\\frac{\\hat{\\gamma}}{||w||}\\tag{11}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq\\hat{\\gamma},\\; i=1,2,...,m\\tag{12}\n\\end{align*} $$\n　　（3）由于式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解（见注解），因此可以取$\\hat{\\gamma}=1$。将$\\hat{\\gamma}=1$代入式(11~12)的最优化问题，且最大化$\\frac{1}{||w||}$和最小化$\\frac{1}{2}||w||^2$是等价的，于是就得到下面的线性可分支持向量机学习的最优化问题：\n$$\\begin{align*}\n\\min_{w,b}\\; &\\frac{1}{2}||w||^2 \\tag{13}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)-1\\geq0,\\, i=1,2,...,m\\tag{14}\n\\end{align*}$$\n　　这是一个凸优化问题中的凸二次规划问题。\n　　如果求出了约束条件最优化问题式(13)~(14)的解`$w^*$`，`$b^*$`，那么就可以得到最大间隔分离超平面`$w^*\\cdot x+b^*=0$`及分类决策函数`$f(x)=sign(w^* \\cdot x+b^*)$`，即线性可分支持向量机模型。\n**注**：式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解。假设将$w$和$b$按比例改变为$\\lambda w$和$\\lambda b$，这时函数间隔成为$\\lambda \\hat{\\gamma}$。函数间隔的这一改变既对式(12)的不等数约束没有影响，又对式(11)的目标函数的优化没有影响，也就是说，它产生一个等价的最优化问题。\n## 2.2 支持向量和间隔边界\n　　在线性可分的情况下，**训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量**。支持向量是使约束条件式(14)等号成立的点，即\n$$y_i(w\\cdot x_i+ b)-1=0\\tag{15}$$\n　　对$y_i=+1$的正例点，支持向量在超平面\n$$H_1:w \\cdot x+b=1\\tag{16}$$\n　　对$y_i=-1$的负例点，支持向量在超平面\n$$H_2:w \\cdot x+b=-1\\tag{17}$$\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/SVM/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%92%8C%E9%97%B4%E9%9A%94%E8%BE%B9%E7%95%8C.JPG\" width=\"50%\" height=\"50%\">\n　　　　　　　　　　　　　　　　　图1，支持向量和间隔边界\n　　如图1，在$H_1$和$H_2$上的点就是**支持向量**，$H_1$和$H_2$称为**间隔边界**，$H_1$与$H_2$之间的距离称为**间隔**(margin)。\n注1：$H_1$与$H_2$平行，并且没有实例点落在它们中间。在$H_1$与$H_2$之间形成一条长带，**分离超平面与它们平行且位于它们中央**。长带的宽度，即$H_1$与$H_2$之间的距离称为间隔。因为$H_1$和$H_2$的函数间隔为1，故各自与分离超平面的几何间隔为$\\frac{1}{||w||}$，即**间隔为$\\frac{2}{||w||}$。**\n注2：在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。如果移动支持向量改变所求的解；但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的。**由于支持向量在确定分离超平面中起着决定性作用，所以将这种分类模型称为支持向量机**。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。\n## 2.3 对偶最优化问题\n　　为了求解线性可分支持向量机的最优化问题（式(13)~(14)），将它作为**原始最优化问题**，应用拉格朗日对偶性，通过求解**对偶问题**(dual problem)得到**原始问题**(primal problem)的最优解，这就是线性可分支持向量机的**对偶算法**。这样做的优点，**一是对偶问题往往更容易求解，二是自然引入核函数，进而推广到非线性分类问题**。\n　　（1）构建拉格朗日函数\n　　对每一个不等式约束，引进拉格朗日乘子$\\alpha_i\\geq0,\\ i=1,2,..,m$，定义拉格朗日函数：\n$$L(w,b,\\alpha)=\\frac{1}{2}||w||^2+\\sum_{i=1}^{m}\\alpha_i(1-y_i(w\\cdot x_i+b))\\tag{18}$$\n　　式中，$\\alpha=(\\alpha_1,\\alpha_2,...,\\alpha_m)^T$为拉格朗日乘子向量。\n　　（2）对偶问题\n　　根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：\n$$\\max_\\alpha\\, \\min_{w,b}L(w,b,\\alpha)$$\n　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\alpha)$对$w,b$的极小，再求对$\\alpha$的极大。\n　　（3）对偶问题——求$\\min\\limits_{w,b}L(w,b,\\alpha)$\n　　将拉格朗日函数$L(w,b,\\alpha)$分别对$w,b$求偏导数并令其等于0，\n$$\\nabla_wL(w,b,\\alpha)=w-\\sum_{i=1}^{m}\\alpha_i y_i x_i=0\\\\\n\\nabla_bL(w,b,\\alpha)=-\\sum_{i=1}^{m}\\alpha_i y_i=0$$\n　　得，\n$$\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_i y_i x_i\\tag{19}\\\\\n\\sum_{i=1}^{m}\\alpha_i y_i=0\\tag{20}\n\\end{align*} $$\n　　将式(19)代入拉格朗日函数（式(18)），并利用式(20),即得\n$$\\min_{w,b}L(w,b,\\alpha)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i$$\n　　（4）对偶问题——求$\\min_{w,b}L(w,b,\\alpha)$对$\\alpha$的极大，即是对偶问题\n$$\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{21}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\n\\end{align*} $$\n　　（5）将上式(21)的目标函数由求极大转换成为求极小，就得到下面与之等价的**对偶最优化问题**：\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{22}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\tag{23}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{24}\n\\end{align*}$$\n　　考虑原始最优问题(式(13)~(14))和对偶最优化问题(式(22)~(24))，原始问题满足**定理C.2(见书中，此处略)**的条件，故存在$w^*$,$\\alpha^*$，$w^*$是原问题的解，$\\alpha^*$是对偶问题的解。**这意味着求解原始问题(式(13)~(14))可以转换为求解对偶问题(式(22)~(24))**。\n　　依据定理C.3(见书中，此处略)，**`$w^*$`和`$\\alpha^*$`分别是原始问题和对偶问题的解的充要条件是`$w^*$`，`$\\alpha^*$`满足KKT条件**。\n## 2.4 KKT条件\n原问题可行：　　\n$y_i(w^*\\cdot x_i+b^*)-1\\geq0,\\; i=1,2,...,m \\tag{25}$\n互补松弛条件(complementary slackness):\n$\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1)=0,\\; i=1,2,...,m \\tag{26}$\n对偶可行：\n$\\alpha_i^*\\geq0,\\; i=1,2,...,m \\tag{27}$\n对偶内在优化：\n$\\nabla_wL(w^*,b^*,\\alpha^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{28}$\n$\\nabla_bL(w^*,b^*,\\alpha^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{29}$\n\n## 2.5 对偶问题最优解与原始问题最优解的对应关系\n　　设$\\alpha=(\\alpha_1,\\alpha_2,...,\\alpha_m)^T$是对偶最优化问题(式(22)~(24))的解，则存在下标$j$，使得$\\alpha_j>0$，并可按下式求得原始最优化问题(式(13)~(14))的解$w^*$,$b^*$：\n$$\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i \\tag{30}\\\\\nb^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}\n\\end{align*}$$\n**注1**：$w^*$从KKT条件中式(28)中直接得出。\n**注2**：$b^*$的得出：从KKT条件知道，至少有一个$\\alpha_j^*>0$（反证法，假设$\\alpha^*=0$，由式(28)得$w^*=0$，而$w^*=0$不是原始最优化问题(式(13)~(14))的解，矛盾）。结合KKT中互补松弛条件(式(26))，对此$j$有：\n$y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{32}$\n将$w^*$的解(式(30))代入式(32)并注意到$y_j^2=1$，即得\n$b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}$\n　　\n　　求得解$w^*$，$b^*$后，**分离超平面**可写成：\n$$\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{33}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{34}\n\\end{align*}$$\n　　**分类决策函数**可写成：\n$$\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{35}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{36}\n\\end{align*}$$\n　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。**式(36)称为线性可分支持向量机的对偶形式**。\n　　综上，对于给定的线性可分训练数据集，可以首先求对偶问题（式(22)~(24)）的解$\\alpha^*$；再利用式(30)和式(31)求得原始问题的解$w^*$和$b^*$；从而得到分离超平面及分类决策函数。这种算法称为**线性可分支持向量机的对偶学习算法**，是线性可分支持向量机的基本算法。\n\n## 2.6 支持向量\n在线性可分支持向量机中，由式(30)和式(31)可知，**`$w^*$`和`$b^*$`只依赖于训练数据中对应于`$\\alpha_i^*>0$`的样本点`$(x_i,y_i)$`**，而其他样本点对`$w^*$`和`$b^*$`没有影响。**将训练数据中对应于`$\\alpha_i^*>0$`的实例点`$x_i \\in R^n$`称为支持向量**。\n支持向量一定在间隔边界上。由KKT互补松弛条件(式(26))可知，对应于于`$\\alpha_i^*>0$`的实例`$x_i$`，有\n$$y_i(w^*\\cdot x_i+b^*)-1=0$$\n或\n$$w^*\\cdot x_i+b^*=\\pm1$$\n即$x_i$一定在间隔边界上。这里的支持向量的定义与前面给出的支持向量的定义是一致的。\n\n# 三、线性支持向量机\n\n## 2.1 原始最优化问题\n**线性不可分的线性支持向量机的原始问题**如下：\n$$\\begin{align*}\n\\min_{w,b,\\xi}\\; & \\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i \\tag{37}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq1-\\xi_i, \\; i=1,2,...,m\\tag{38}\\\\\n& \\xi_i\\geq0,\\; i=1,2,...,m\\tag{39}\n\\end{align*}$$\n**注1**：线性不可分意味着某些样本点$(x_i,y_i)$不能满足函数间隔大于等于1的约束条件（式(14)）。为了解决这个问题，可以对每个样本点$(x_i,y_i)$引进一个松弛变量$\\xi_i\\geq0$，使函数间隔加上松弛变量大于等于1。这样约束条件变为式(38)。\n**注2**：同时，对每一个松弛变量$\\xi_i$，支付一个代价$\\xi_i$。目标函数由原来的$\\frac{1}{2}||w||^2$变成式(37)。这里，$C>0$称为惩罚参数，一般由应用问题决定，$C$值大时对误分类的惩罚增大，$C$值小时对误分类的惩罚减小。最小化目标函数式(37)包含两层含义：使$\\frac{1}{2}||w||^2$尽量小即间隔尽量大，同时使误分类点的个数尽量小，$C$是调和二者的系数。\n　　有了上面的思路，可以和训练数据集线性可分时一样来考虑训练数据集线性不可分时的线性支持向量机学习问题。相应于硬间隔最大化，它称为**软间隔最大化**。\n　　原问题式(37)~式(39)是一个凸二次规划问题，因而关于$(w,b,\\xi)$的解是存在的。\n　　设原问题式(37)~式(39)的解是`$w^*$`，`$b^*$`，于是可以得到分离超平面`$w^* \\cdot x + b^* =0$`及分类决策函数`$f(x)=sign(w^* \\cdot x + b^*)$`。成这样的模型为训练样本线性不可分时的线性支持向量机，简称**线性支持向量机**。\n## 2.2 对偶最优化问题\n（1）构建拉格朗日函数\n　　原始最优化问题（式(37)~(39)）的拉格朗日函数是\n$$\nL(w,b,\\xi,\\alpha,\\mu)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i-\\sum_{i=1}^{m}\\alpha_i(y_i(w\\cdot x_i+b)-1+\\xi_i)-\\sum_{i=1}^{m}\\mu_i\\xi_i\n\\tag{40}\n$$\n　　其中，$\\alpha_i\\geq0,\\mu_i\\geq0$.\n（2）对偶问题\n　　对偶问题是拉格朗日函数的极大极小问题：\n$$\\max_\\alpha\\; \\min_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$$\n　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\xi,\\alpha,\\mu)$对$w,b,\\xi$的极小，再求对$\\alpha$的极大。\n（3）对偶问题——求$\\min\\limits_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$\n　　通过\n$$\\begin{align*}\n\\nabla_wL(w,b,\\xi,\\alpha,\\mu)=w-\\sum_{i=1}^{m}\\alpha_i y_ix_i=0\\\\\n\\nabla_bL(w,b,\\xi,\\alpha,\\mu)=-\\sum_{i=1}^{m}\\alpha_i y_i=0\\\\\n\\nabla_{\\xi}L(w,b,\\xi,\\alpha,\\mu)=C-\\alpha_i-\\mu_i=0\n\\end{align*}$$\n　　得\n$$\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_iy_ix_i\\tag{41}\\\\\n\\sum_{i=1}^{m}\\alpha_iy_i=0\\tag{42}\\\\\nC-\\alpha_i-\\mu_i=0\\tag{43}\n\\end{align*}$$\n　　将式(41)到式(43)代入式(40)，得\n$$\\min_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i$$\n（4）对偶问题——求$\\min\\limits_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)$对$\\alpha$的极大，即得对偶问题\n$$\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{44}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{45}\\\\\n& C-\\alpha_i-\\mu_i=0\\tag{46}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{47}\\\\\n& \\mu_i\\geq0,\\; i=1,2,...,m\\tag{48}\n\\end{align*} \n$$\n　　将对偶最优化问题式(44)~式(48)进行变换：利用等式约束式(46)消去$\\mu_i$，从而只留下变量$\\alpha_i$，并将约束式(46)~式(48)写成\n$$0\\leq\\alpha_i\\leq C\\tag{49}$$\n（5）再将对目标函数求极大极小转为求极小，于是得到**对偶问题**(50)~(52).\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{50}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{51}\\\\\n& 0\\leq \\alpha_i\\leq C,\\;i=1,2,...m\\tag{52}\\\\\n\\end{align*}$$\n　　综上，原始最优化问题(式(37)～式(39))的对偶最优化问题为式(50)~式(51)。可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数。\n　　有定理可证，**求解原始问题(式(37)～式(39))可以转换为求解对偶问题式(50)~式(52)**。\n　　有定理可证，**`$w^*$`和`$\\alpha^*$`分别是原始问题和对偶问题的解的充要条件是`$w^*$`，`$\\alpha^*$`满足KKT条件**。\n## 2.3 KKT条件\n原问题可行：\n$$\\begin{align*}\ny_i(w^*\\cdot x_i+ & b^*)-1+\\xi_i^*\\geq0 \\tag{53} \\\\\n& \\xi_i^*\\geq0 \\tag{54}\n\\end{align*}$$\n互补松弛条件(complementary slackness):\n$$\\begin{align*}\n\\alpha_i^*(y_i(w^*\\cdot x_i & + b^*)-1 +\\xi_i^*)=0 \\tag{55}\\\\\n& \\mu_i^*\\xi_i^*=0\\tag{56}\n\\end{align*}$$\n对偶问题可行：\n$$\\begin{align*}\n\\alpha_i^*\\geq0 \\tag{57}\\\\\n\\mu_i^*\\geq0 \\tag{58}\n\\end{align*}$$\n对偶内在优化：\n$$\\begin{align*}\n\\nabla_wL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{59}\\\\\n\\nabla_bL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{60}\\\\\n\\nabla_{\\xi}L(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=C-\\alpha_i^*-\\mu_i^*=0 \\tag{61}\n\\end{align*}$$\n\n## 2.4 对偶问题最优解与原始问题最优解的对应关系\n　　设`$\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)$`是对偶问题（式(50)~式(52)）的一个解，若存在`$\\alpha^*$`的一个分量`$\\alpha_j^*$`，`$0<\\alpha_j^* < C$`，则原始问题式（(37)～式(39)）的解`$w^*,b^*$`可按下式求得：\n$$\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i\\tag{62}\\\\\nb^*=y_j-\\sum_{i=1}^{m}y_i\\alpha_i^*(x_i\\cdot x_j)\\tag{63}\n\\end{align*}$$\n**注1**：`$w^*$`从KKT条件中式(59)中直接得出。\n**注2**：`$b^*$`的得出：从KKT条件知道，至少有一个`$0<\\alpha_j^* < C$`（反证法，假设`$\\alpha^*=0$`，由式(59)得`$w^*=0$`，而`$w^*=0$`不是原始最优化问题(式(37)～式(39)的解，矛盾）。结合KKT中互补松弛条件(式(55)~式(56))，对此$j$有：\n`$y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{64}$`\n将`$w^*$`的解(式(62))代入式(64)并注意到`$y_j^2=1$`，即得式(63)。（结合式(61)和(56)，此时的$$\\xi_j^*=0$$）\n　　求得解`$w^*$`，`$b^*$`后，**分离超平面**可写成：\n$$\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{65}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{66}\n\\end{align*}$$\n　　**分类决策函数**可写成：\n$$\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{67}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{68}\n\\end{align*}$$\n　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。**式(68)称为线性支持向量机的对偶形式**。\n## 2.5 支持向量\n　　**软间隔的支持向量**：在线性不可分的情况下，将对偶问题（式(50)~式(52)）的解`$\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)$`中**对应于`$\\alpha_i^*>0$`的样本点`$(x_i,y_i)$`的实例`$x_i$`称为支持向量。**\n　　结合互补松弛条件（式(55)~式(56)）及式(61)，得\n$$\n\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1+\\xi_i^*)=0, i=1,2,...,m\\\\\n(C-\\alpha_i^*)\\xi_i^*=0\n$$\n　　软间隔的支持向量$x_i$**或者在间隔边界上，或者在间隔边界与分离超平面之间，或者在分离超平面误分一侧。**\n\n- `$\\alpha_i^*=0$`时：非支持向量，`$\\xi_i=0$`，没犯错，远离间隔边界或在间隔边界上；\n- `$0<\\alpha_i^*<C$`时：支持向量，`$\\xi_i=0$`，支持向量`$x_i$`在在间隔边界上，决定了`$b^*$`；\n- `$\\alpha_i^*=C$`时：支持向量，`$\\xi_i \\neq 0$`,`$\\xi_i>0$`，`$\\xi_i$`记录了违反间隔边界的数量或大小\n - `$0<\\xi_i < 1$`：分类正确,`$x_i$`落在间隔边界与分离超平面之间；\n - `$\\xi_i = 1 $`：`$w^*\\cdot x_i+b^*=0$`,`$x_i$`落在分离超平面上；\n - `$\\xi_i >1 $`：样本点分类错误，`$x_i$`落在分离超平面误分一侧。\n\n# 四、非线性支持向量机\n　　对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，通常分类问题是非线性的，这时可以使用非线性支持向量机，其主要特点是利用核技巧。\n　　用线性分类方法求解非线性分类问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练数据中学习分类模型。核技巧就属于这样的方法。\n## 4.1 核函数的定义\n　　假设$X$是输入空间，$H$是特征空间，如果存在一个从$X$到$H$的映射函数：\n$$\\phi(x):X\\rightarrow H$$\n　　使得所有$x,z\\in X$,函数$K(x,z)$满足条件：\n$$K(x,z)=\\phi(x)\\cdot \\phi(z)$$\n　　则称$K(x,z)$为核函数，$\\phi(x)$为映射函数，式中$\\phi(x)\\cdot \\phi(z)$为$\\phi(x)$和$\\phi(z)$的内积。\n　　**核技巧的想法是：在学习与预测中只定义核函数$K(x,z)$,而不是显示地定义映射函数$\\phi$。通常，直接计算$K(x,z)$比较容易，而通过$\\phi(x)$和$\\phi(z)$计算$K(x,z)$并不容易。**注意，$\\phi$是输入空间$R^n$到特征空间$H$的映射，特征空间$H$一般是高维的，甚至是无穷维的。\n## 4.2 核技巧在支持向量机中的应用\n　　我们注意到在线性支持向量机的对偶问题中，无论是在目标函数还是在决策函数(分离超平面)都只涉及输入实例与实例之间的内积。\n　　在对偶问题的目标函数(式(50))中的内积`$x_i\\cdot x_j$`可以用核函数`$K(x_i,x_j)=\\phi(x_i)\\cdot \\phi(x_j)$`来代替。此时对偶问题的目标函数变为：\n　　$$W(\\alpha)=\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i \\tag{69}$$\n　　同样，分类决策函数中的内积也可以用核函数代替，而分类决策函数变为：\n　　$$f(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i \\phi(x) \\cdot \\phi(x_i)+b^*) \\\\\n　　=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i K(x \\cdot x_i)+b^*)   \\tag{70}$$\n　　这等价于经过映射函数$\\phi$将原来的输入空间变换到一个新的特征空间，将输入空间中的内积$x_i \\cdot x_j$变换为特征空间中的内积$\\phi(x_i) \\cdot \\phi(x_j)$，在新的特征空间里从训练样本中学习线性支持向量机。当映射函数是非线性时，学习到的含有核函数的支持向量机是非线性分类模型。\n　　也就是说，在核函数`$K(x,z)$`给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是在隐式地特征空间进行的，不需要显示地定义特征空间和映射函数。这样的技巧称为核技巧，它是巧妙地利用线性分类学习方法与核函数解决非线性问题的技术。\n##  4.3 常用核函数\n　　（1）多项式核函数：\n$$K(x,z)=(\\gamma \\cdot x\\cdot z+ \\zeta)^p  \\tag{71}$$\n　　式中，$\\gamma\\in R$且$\\gamma>0$,$\\zeta\\in R$且$\\zeta\\geq0$\n　　特殊情况：线性核：$K_1(x,z)=(1 \\cdot x\\cdot z+0)^1$\n　　（2）高斯核函数：\n$$K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2}) \\tag{72}$$\n　　或写成$K(x,z)=exp(-\\gamma||x-z||^2)$,$\\gamma>0$\n　　**注**：正态分布的PDF为：$f(x;\\mu,\\sigma)= \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x-\\mu)^2}{2{\\sigma}^2})$\n## 4.４ 非线性支持向量机学习算法\n　　如上所述，利用核技巧，可以将线性分类的学习方法应用到非线性分类问题中去。将线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机对偶形式中的内积换成核函数。\n　　（1）选取适当的核函数$K(x,z)$和适当的参数$C$，构造并求解最优化问题\n$$\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{73}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{74}\\\\\n& 0\\leq \\alpha_i\\leq C,\\; i=1,2,...m\\tag{75}\\\\\n\\end{align*} \n$$\n　　求得最优解`$\\alpha^*=(\\alpha^*_1,\\alpha^*_2,...,\\alpha^*_m)$`.\n　　(2)选择`$\\alpha^*$`的一个正分量`$0<\\alpha^*_j < C$`，计算\n$$b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_iK(x_i \\cdot x_j)$$\n　　(3)构造决策函数：\n$$f(x)=sign(w^*\\cdot x+b^*)=sign(\\sum_{i=1}^{m}\\alpha^*_iy_iK(x\\cdot x_i)+b^*)$$\n\n# 五、SMO算法（待补）\nSMO算法的思想： \n（1）SMO是一种启发式算法，选择两个变量固定其他变量，针对选择的两个变量构造二次规划问题，二次规划问题可以直接得到解析解；SMO算法将原问题 不断地分解为子问题并对子问题进行求解进而达到求解原问题的目的； \n（2）之所以选择每次更新两个变量是因为目标函数中的第二个约束，若固定其他的变量，那么最后一个变量也随之确定，因此需要更新两个变量。 \n# 六、SVM优缺点（待补）\n1.优点\n（1）可用于线性/非线性分类，也可以用于回归；\n（2）低泛化误差；\n（3）容易解释；\n（4）计算复杂度较低；\n（5）处理小样本，非线性，高维数问题；\n2.缺点\n（1）对参数和核函数的选择比较敏感；\n（2）原始的SVM只比较擅长处理二分类问题；\n# 七、参考资料\n- 李航，统计学习方法\n- [林轩田，机器学习技法](https://www.youtube.com/watch?v=A-GxGCCAIrg&list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)\n- [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)\n- 周志华，机器学习\n\n\n","slug":"支持向量机","published":1,"updated":"2018-11-16T09:09:13.262Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w2n005tqslppv6kx5eo","content":"<p>　　支持向量机(support vector machine, SVM)是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。线性支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题。<br>　　支持向量机学习方法包含构建由简至繁的模型：<strong>线性可分支持向量机</strong>、<strong>线性支持向量机</strong>、<strong>非线性支持向量机</strong>：</p>\n<ul>\n<li><strong>线性可分支持向量机</strong>：适用于训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器，即线性可分支持向量机，又称为<strong>硬间隔支持向量机</strong>；</li>\n<li><strong>线性支持向量机</strong>：适用于训练数据近似线性可分，也就是存在一些特异点，将这些特异点去除后的样本线性可分（现实中的数据经常是线性不可分的）。通过软间隔最大化，也学习一个线性的分类器，即线性支持向量机，又称为<strong>软间隔支持向量机</strong>；</li>\n<li><strong>非线性支持向量机</strong>：适用于训练数据线性不可分，通过核技巧即软间隔最大化，学习非线性支持向量机。<a id=\"more\"></a> \n</li>\n</ul>\n<p><strong>注</strong>：<br><strong>核函数</strong>：核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。<br><strong>核技巧</strong>：通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法成为核技巧。\n　　</p>\n<h1 id=\"一、基本概念\"><a href=\"#一、基本概念\" class=\"headerlink\" title=\"一、基本概念\"></a>一、基本概念</h1><p>（1）SVM的<strong>分离超平面</strong>：</p>\n<script type=\"math/tex; mode=display\">w^*\\cdot x+b^*=0\\tag{1}</script><p>（2）SVM的<strong>分类决策函数</strong>为：</p>\n<script type=\"math/tex; mode=display\">f(x)=sign(w^* \\cdot x+b^*)\\tag{2}</script><p><strong>注</strong>：函数值只有正负1，二分类。<br>（3）<strong>函数间隔</strong>：<br>　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为：</p>\n<script type=\"math/tex; mode=display\">\\hat{\\gamma_i}=y_i(w \\cdot x_i+b)\\tag{3}</script><p>　　定义超平面$(w,b)$关于训练集$T$的函数间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的函数间隔之最小值，即：</p>\n<script type=\"math/tex; mode=display\">\\hat{\\gamma}=\\min_{i=1,...,m}\\hat{\\gamma_i}\\tag{4}</script><p><strong>注1</strong>：函数间隔大于0，表示$w \\cdot x_i+b$与$y_i$同号，分类正确；$|w \\cdot x_i+b|$值越大，离分离超平面越远，分类预测的确信程度越高。所以用$y_i(w \\cdot x_i+b)$来表示分类的正确性和确信度，这就是函数间隔。<br><strong>注2</strong>：函数间隔可以表示分类预测的正确性及确信程度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例的改变$w$和$b$，例如将它们改变为$2w$和$2b$，超平面并没有改变，但函数间隔却成为原来的2倍。故需对超平面的法向量$w$加某些约束，如规范化$||w||=1$，使得间隔是确定的。此时，函数间隔即几何间隔。<br>（4）<strong>几何间隔</strong>：<br>　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔为：</p>\n<script type=\"math/tex; mode=display\">\\gamma_i=y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\tag{5}</script><p>　　定义超平面$(w,b)$关于训练集$T$的几何间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的几何间隔之最小值，即：</p>\n<script type=\"math/tex; mode=display\">\\gamma=\\min_{i=1,...,m}\\gamma_i\\tag{6}</script><p><strong>注</strong>：超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔即<strong>实例点到分离超平面的带符号的距离</strong>，由<a href=\"https://baike.baidu.com/item/%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E8%B7%9D%E7%A6%BB/8673346\" target=\"_blank\" rel=\"noopener\">点到直线的距离公式</a>可推出。<br>　　从函数间隔和几何间隔的定义（式(3)~(6)）可知，函数间隔和几何间隔有如下关系：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\gamma_i=\\frac{\\hat{\\gamma_i}}{||w||}\\tag{7}\\\\\n\\gamma=\\frac{\\hat{\\gamma}}{||w||}\\tag{8}\n\\end{align*}</script><p><strong>注</strong>：如果$||w||=1$，那么函数间隔和几何间隔相等。如果超平面参数$w$和$b$成比例地改变，超平面没有改变，函数间隔按此比例改变，而几何间隔不变。</p>\n<h1 id=\"二、线性可分支持向量机\"><a href=\"#二、线性可分支持向量机\" class=\"headerlink\" title=\"二、线性可分支持向量机\"></a>二、线性可分支持向量机</h1><p>　　支持向量机学习的基本思想是求解能够<strong>正确划分训练数据集</strong>并且<strong>几何间隔最大</strong>的分离超平面。<br>　　对<strong>线性可分</strong>的训练数据集，线性可分分离超平面有无穷多个，但几何间隔最大的分离超平面是唯一的。这里的间隔最大化又称为<strong>硬间隔最大化</strong>。<br>　　此时，学习到的线性分类器，称为<strong>线性可分支持向量机</strong>或<strong>硬间隔支持向量机</strong>。<br>注：几何间隔最大化的直观解释：对训练数据集找到的几何间隔最大化的超平面意味着以充分大的确信程度对训练数据进行分类。也就是说，不仅将正负实例分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力。</p>\n<h2 id=\"2-1-原始最优化问题\"><a href=\"#2-1-原始最优化问题\" class=\"headerlink\" title=\"2.1 原始最优化问题\"></a>2.1 原始最优化问题</h2><p>　　（1）求最大间隔分离超平面的问题，可以表示为下面的约束最优化问题：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{w,b}\\; &\\gamma \\tag{9}\\\\\ns.t.\\; & y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\geq\\gamma,\\;  i=1,2,...,m\\tag{10}\n\\end{align*}</script><p>注：即我们希望最大化超平面$(w,b)$关于训练数据集的几何间隔$\\gamma$，约束条件表示的是超平面$(w,b)$关于每个训练样本点的几何间隔至少是$\\gamma$。<br>　　（2）根据函数间隔与几何间隔的关系式(8)，约束问题可以等价于：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{w,b}\\; &\\frac{\\hat{\\gamma}}{||w||}\\tag{11}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq\\hat{\\gamma},\\; i=1,2,...,m\\tag{12}\n\\end{align*}</script><p>　　（3）由于式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解（见注解），因此可以取$\\hat{\\gamma}=1$。将$\\hat{\\gamma}=1$代入式(11~12)的最优化问题，且最大化$\\frac{1}{||w||}$和最小化$\\frac{1}{2}||w||^2$是等价的，于是就得到下面的线性可分支持向量机学习的最优化问题：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{w,b}\\; &\\frac{1}{2}||w||^2 \\tag{13}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)-1\\geq0,\\, i=1,2,...,m\\tag{14}\n\\end{align*}</script><p>　　这是一个凸优化问题中的凸二次规划问题。<br>　　如果求出了约束条件最优化问题式(13)~(14)的解<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>，那么就可以得到最大间隔分离超平面<script type=\"math/tex\">w^*\\cdot x+b^*=0</script>及分类决策函数<script type=\"math/tex\">f(x)=sign(w^* \\cdot x+b^*)</script>，即线性可分支持向量机模型。<br><strong>注</strong>：式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解。假设将$w$和$b$按比例改变为$\\lambda w$和$\\lambda b$，这时函数间隔成为$\\lambda \\hat{\\gamma}$。函数间隔的这一改变既对式(12)的不等数约束没有影响，又对式(11)的目标函数的优化没有影响，也就是说，它产生一个等价的最优化问题。</p>\n<h2 id=\"2-2-支持向量和间隔边界\"><a href=\"#2-2-支持向量和间隔边界\" class=\"headerlink\" title=\"2.2 支持向量和间隔边界\"></a>2.2 支持向量和间隔边界</h2><p>　　在线性可分的情况下，<strong>训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量</strong>。支持向量是使约束条件式(14)等号成立的点，即</p>\n<script type=\"math/tex; mode=display\">y_i(w\\cdot x_i+ b)-1=0\\tag{15}</script><p>　　对$y_i=+1$的正例点，支持向量在超平面</p>\n<script type=\"math/tex; mode=display\">H_1:w \\cdot x+b=1\\tag{16}</script><p>　　对$y_i=-1$的负例点，支持向量在超平面</p>\n<script type=\"math/tex; mode=display\">H_2:w \\cdot x+b=-1\\tag{17}</script><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/SVM/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%92%8C%E9%97%B4%E9%9A%94%E8%BE%B9%E7%95%8C.JPG\" width=\"50%\" height=\"50%\"><br>　　　　　　　　　　　　　　　　　图1，支持向量和间隔边界<br>　　如图1，在$H_1$和$H_2$上的点就是<strong>支持向量</strong>，$H_1$和$H_2$称为<strong>间隔边界</strong>，$H_1$与$H_2$之间的距离称为<strong>间隔</strong>(margin)。<br>注1：$H_1$与$H_2$平行，并且没有实例点落在它们中间。在$H_1$与$H_2$之间形成一条长带，<strong>分离超平面与它们平行且位于它们中央</strong>。长带的宽度，即$H_1$与$H_2$之间的距离称为间隔。因为$H_1$和$H_2$的函数间隔为1，故各自与分离超平面的几何间隔为$\\frac{1}{||w||}$，即<strong>间隔为$\\frac{2}{||w||}$。</strong><br>注2：在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。如果移动支持向量改变所求的解；但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的。<strong>由于支持向量在确定分离超平面中起着决定性作用，所以将这种分类模型称为支持向量机</strong>。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。</p>\n<h2 id=\"2-3-对偶最优化问题\"><a href=\"#2-3-对偶最优化问题\" class=\"headerlink\" title=\"2.3 对偶最优化问题\"></a>2.3 对偶最优化问题</h2><p>　　为了求解线性可分支持向量机的最优化问题（式(13)~(14)），将它作为<strong>原始最优化问题</strong>，应用拉格朗日对偶性，通过求解<strong>对偶问题</strong>(dual problem)得到<strong>原始问题</strong>(primal problem)的最优解，这就是线性可分支持向量机的<strong>对偶算法</strong>。这样做的优点，<strong>一是对偶问题往往更容易求解，二是自然引入核函数，进而推广到非线性分类问题</strong>。<br>　　（1）构建拉格朗日函数<br>　　对每一个不等式约束，引进拉格朗日乘子$\\alpha_i\\geq0,\\ i=1,2,..,m$，定义拉格朗日函数：</p>\n<script type=\"math/tex; mode=display\">L(w,b,\\alpha)=\\frac{1}{2}||w||^2+\\sum_{i=1}^{m}\\alpha_i(1-y_i(w\\cdot x_i+b))\\tag{18}</script><p>　　式中，$\\alpha=(\\alpha_1,\\alpha_2,…,\\alpha_m)^T$为拉格朗日乘子向量。<br>　　（2）对偶问题<br>　　根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：</p>\n<script type=\"math/tex; mode=display\">\\max_\\alpha\\, \\min_{w,b}L(w,b,\\alpha)</script><p>　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\alpha)$对$w,b$的极小，再求对$\\alpha$的极大。<br>　　（3）对偶问题——求$\\min\\limits_{w,b}L(w,b,\\alpha)$<br>　　将拉格朗日函数$L(w,b,\\alpha)$分别对$w,b$求偏导数并令其等于0，</p>\n<script type=\"math/tex; mode=display\">\\nabla_wL(w,b,\\alpha)=w-\\sum_{i=1}^{m}\\alpha_i y_i x_i=0\\\\\n\\nabla_bL(w,b,\\alpha)=-\\sum_{i=1}^{m}\\alpha_i y_i=0</script><p>　　得，</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_i y_i x_i\\tag{19}\\\\\n\\sum_{i=1}^{m}\\alpha_i y_i=0\\tag{20}\n\\end{align*}</script><p>　　将式(19)代入拉格朗日函数（式(18)），并利用式(20),即得</p>\n<script type=\"math/tex; mode=display\">\\min_{w,b}L(w,b,\\alpha)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i</script><p>　　（4）对偶问题——求$\\min_{w,b}L(w,b,\\alpha)$对$\\alpha$的极大，即是对偶问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{21}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\n\\end{align*}</script><p>　　（5）将上式(21)的目标函数由求极大转换成为求极小，就得到下面与之等价的<strong>对偶最优化问题</strong>：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{22}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\tag{23}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{24}\n\\end{align*}</script><p>　　考虑原始最优问题(式(13)~(14))和对偶最优化问题(式(22)~(24))，原始问题满足<strong>定理C.2(见书中，此处略)</strong>的条件，故存在$w^<em>$,$\\alpha^</em>$，$w^<em>$是原问题的解，$\\alpha^</em>$是对偶问题的解。<strong>这意味着求解原始问题(式(13)~(14))可以转换为求解对偶问题(式(22)~(24))</strong>。<br>　　依据定理C.3(见书中，此处略)，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">\\alpha^*</script>分别是原始问题和对偶问题的解的充要条件是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">\\alpha^*</script>满足KKT条件</strong>。</p>\n<h2 id=\"2-4-KKT条件\"><a href=\"#2-4-KKT条件\" class=\"headerlink\" title=\"2.4 KKT条件\"></a>2.4 KKT条件</h2><p>原问题可行：　　<br>$y_i(w^<em>\\cdot x_i+b^</em>)-1\\geq0,\\; i=1,2,…,m \\tag{25}$<br>互补松弛条件(complementary slackness):<br>$\\alpha_i^<em>(y_i(w^</em>\\cdot x_i+b^<em>)-1)=0,\\; i=1,2,…,m \\tag{26}$<br>对偶可行：<br>$\\alpha_i^</em>\\geq0,\\; i=1,2,…,m \\tag{27}$<br>对偶内在优化：<br>$\\nabla_wL(w^<em>,b^</em>,\\alpha^<em>)=w^</em>-\\sum_{i=1}^{m}\\alpha_i^<em>y_ix_i=0 \\tag{28}$<br>$\\nabla_bL(w^</em>,b^<em>,\\alpha^</em>)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{29}$</p>\n<h2 id=\"2-5-对偶问题最优解与原始问题最优解的对应关系\"><a href=\"#2-5-对偶问题最优解与原始问题最优解的对应关系\" class=\"headerlink\" title=\"2.5 对偶问题最优解与原始问题最优解的对应关系\"></a>2.5 对偶问题最优解与原始问题最优解的对应关系</h2><p>　　设$\\alpha=(\\alpha_1,\\alpha_2,…,\\alpha_m)^T$是对偶最优化问题(式(22)~(24))的解，则存在下标$j$，使得$\\alpha_j&gt;0$，并可按下式求得原始最优化问题(式(13)~(14))的解$w^<em>$,$b^</em>$：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i \\tag{30}\\\\\nb^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}\n\\end{align*}</script><p><strong>注1</strong>：$w^<em>$从KKT条件中式(28)中直接得出。<br><strong>注2</strong>：$b^</em>$的得出：从KKT条件知道，至少有一个$\\alpha_j^<em>&gt;0$（反证法，假设$\\alpha^</em>=0$，由式(28)得$w^<em>=0$，而$w^</em>=0$不是原始最优化问题(式(13)~(14))的解，矛盾）。结合KKT中互补松弛条件(式(26))，对此$j$有：<br>$y_j(w^<em> \\cdot x_j + b^</em>)-1=0 \\tag{32}$<br>将$w^<em>$的解(式(30))代入式(32)并注意到$y_j^2=1$，即得<br>$b^</em>=y_j-\\sum_{i=1}^{m}\\alpha_i^<em>y_i(x_i\\cdot x_j) \\tag{31}$<br>　　<br>　　求得解$w^</em>$，$b^<em>$后，<em>*分离超平面</em></em>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{33}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{34}\n\\end{align*}</script><p>　　<strong>分类决策函数</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{35}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{36}\n\\end{align*}</script><p>　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。<strong>式(36)称为线性可分支持向量机的对偶形式</strong>。<br>　　综上，对于给定的线性可分训练数据集，可以首先求对偶问题（式(22)~(24)）的解$\\alpha^<em>$；再利用式(30)和式(31)求得原始问题的解$w^</em>$和$b^<em>$；从而得到分离超平面及分类决策函数。这种算法称为<em>*线性可分支持向量机的对偶学习算法</em></em>，是线性可分支持向量机的基本算法。</p>\n<h2 id=\"2-6-支持向量\"><a href=\"#2-6-支持向量\" class=\"headerlink\" title=\"2.6 支持向量\"></a>2.6 支持向量</h2><p>在线性可分支持向量机中，由式(30)和式(31)可知，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">b^*</script>只依赖于训练数据中对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的样本点<script type=\"math/tex\">(x_i,y_i)</script></strong>，而其他样本点对<script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">b^*</script>没有影响。<strong>将训练数据中对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的实例点<script type=\"math/tex\">x_i \\in R^n</script>称为支持向量</strong>。<br>支持向量一定在间隔边界上。由KKT互补松弛条件(式(26))可知，对应于于<script type=\"math/tex\">\\alpha_i^*>0</script>的实例<script type=\"math/tex\">x_i</script>，有</p>\n<script type=\"math/tex; mode=display\">y_i(w^*\\cdot x_i+b^*)-1=0</script><p>或</p>\n<script type=\"math/tex; mode=display\">w^*\\cdot x_i+b^*=\\pm1</script><p>即$x_i$一定在间隔边界上。这里的支持向量的定义与前面给出的支持向量的定义是一致的。</p>\n<h1 id=\"三、线性支持向量机\"><a href=\"#三、线性支持向量机\" class=\"headerlink\" title=\"三、线性支持向量机\"></a>三、线性支持向量机</h1><h2 id=\"2-1-原始最优化问题-1\"><a href=\"#2-1-原始最优化问题-1\" class=\"headerlink\" title=\"2.1 原始最优化问题\"></a>2.1 原始最优化问题</h2><p><strong>线性不可分的线性支持向量机的原始问题</strong>如下：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{w,b,\\xi}\\; & \\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i \\tag{37}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq1-\\xi_i, \\; i=1,2,...,m\\tag{38}\\\\\n& \\xi_i\\geq0,\\; i=1,2,...,m\\tag{39}\n\\end{align*}</script><p><strong>注1</strong>：线性不可分意味着某些样本点$(x_i,y_i)$不能满足函数间隔大于等于1的约束条件（式(14)）。为了解决这个问题，可以对每个样本点$(x_i,y_i)$引进一个松弛变量$\\xi_i\\geq0$，使函数间隔加上松弛变量大于等于1。这样约束条件变为式(38)。<br><strong>注2</strong>：同时，对每一个松弛变量$\\xi_i$，支付一个代价$\\xi_i$。目标函数由原来的$\\frac{1}{2}||w||^2$变成式(37)。这里，$C&gt;0$称为惩罚参数，一般由应用问题决定，$C$值大时对误分类的惩罚增大，$C$值小时对误分类的惩罚减小。最小化目标函数式(37)包含两层含义：使$\\frac{1}{2}||w||^2$尽量小即间隔尽量大，同时使误分类点的个数尽量小，$C$是调和二者的系数。<br>　　有了上面的思路，可以和训练数据集线性可分时一样来考虑训练数据集线性不可分时的线性支持向量机学习问题。相应于硬间隔最大化，它称为<strong>软间隔最大化</strong>。<br>　　原问题式(37)~式(39)是一个凸二次规划问题，因而关于$(w,b,\\xi)$的解是存在的。<br>　　设原问题式(37)~式(39)的解是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>，于是可以得到分离超平面<script type=\"math/tex\">w^* \\cdot x + b^* =0</script>及分类决策函数<script type=\"math/tex\">f(x)=sign(w^* \\cdot x + b^*)</script>。成这样的模型为训练样本线性不可分时的线性支持向量机，简称<strong>线性支持向量机</strong>。</p>\n<h2 id=\"2-2-对偶最优化问题\"><a href=\"#2-2-对偶最优化问题\" class=\"headerlink\" title=\"2.2 对偶最优化问题\"></a>2.2 对偶最优化问题</h2><p>（1）构建拉格朗日函数<br>　　原始最优化问题（式(37)~(39)）的拉格朗日函数是</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\xi,\\alpha,\\mu)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i-\\sum_{i=1}^{m}\\alpha_i(y_i(w\\cdot x_i+b)-1+\\xi_i)-\\sum_{i=1}^{m}\\mu_i\\xi_i\n\\tag{40}</script><p>　　其中，$\\alpha_i\\geq0,\\mu_i\\geq0$.<br>（2）对偶问题<br>　　对偶问题是拉格朗日函数的极大极小问题：</p>\n<script type=\"math/tex; mode=display\">\\max_\\alpha\\; \\min_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)</script><p>　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\xi,\\alpha,\\mu)$对$w,b,\\xi$的极小，再求对$\\alpha$的极大。<br>（3）对偶问题——求$\\min\\limits_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$<br>　　通过</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\nabla_wL(w,b,\\xi,\\alpha,\\mu)=w-\\sum_{i=1}^{m}\\alpha_i y_ix_i=0\\\\\n\\nabla_bL(w,b,\\xi,\\alpha,\\mu)=-\\sum_{i=1}^{m}\\alpha_i y_i=0\\\\\n\\nabla_{\\xi}L(w,b,\\xi,\\alpha,\\mu)=C-\\alpha_i-\\mu_i=0\n\\end{align*}</script><p>　　得</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_iy_ix_i\\tag{41}\\\\\n\\sum_{i=1}^{m}\\alpha_iy_i=0\\tag{42}\\\\\nC-\\alpha_i-\\mu_i=0\\tag{43}\n\\end{align*}</script><p>　　将式(41)到式(43)代入式(40)，得</p>\n<script type=\"math/tex; mode=display\">\\min_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i</script><p>（4）对偶问题——求$\\min\\limits_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)$对$\\alpha$的极大，即得对偶问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{44}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{45}\\\\\n& C-\\alpha_i-\\mu_i=0\\tag{46}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{47}\\\\\n& \\mu_i\\geq0,\\; i=1,2,...,m\\tag{48}\n\\end{align*}</script><p>　　将对偶最优化问题式(44)~式(48)进行变换：利用等式约束式(46)消去$\\mu_i$，从而只留下变量$\\alpha_i$，并将约束式(46)~式(48)写成</p>\n<script type=\"math/tex; mode=display\">0\\leq\\alpha_i\\leq C\\tag{49}</script><p>（5）再将对目标函数求极大极小转为求极小，于是得到<strong>对偶问题</strong>(50)~(52).</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{50}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{51}\\\\\n& 0\\leq \\alpha_i\\leq C,\\;i=1,2,...m\\tag{52}\\\\\n\\end{align*}</script><p>　　综上，原始最优化问题(式(37)～式(39))的对偶最优化问题为式(50)~式(51)。可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数。<br>　　有定理可证，<strong>求解原始问题(式(37)～式(39))可以转换为求解对偶问题式(50)~式(52)</strong>。<br>　　有定理可证，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">\\alpha^*</script>分别是原始问题和对偶问题的解的充要条件是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">\\alpha^*</script>满足KKT条件</strong>。</p>\n<h2 id=\"2-3-KKT条件\"><a href=\"#2-3-KKT条件\" class=\"headerlink\" title=\"2.3 KKT条件\"></a>2.3 KKT条件</h2><p>原问题可行：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\ny_i(w^*\\cdot x_i+ & b^*)-1+\\xi_i^*\\geq0 \\tag{53} \\\\\n& \\xi_i^*\\geq0 \\tag{54}\n\\end{align*}</script><p>互补松弛条件(complementary slackness):</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\alpha_i^*(y_i(w^*\\cdot x_i & + b^*)-1 +\\xi_i^*)=0 \\tag{55}\\\\\n& \\mu_i^*\\xi_i^*=0\\tag{56}\n\\end{align*}</script><p>对偶问题可行：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\alpha_i^*\\geq0 \\tag{57}\\\\\n\\mu_i^*\\geq0 \\tag{58}\n\\end{align*}</script><p>对偶内在优化：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\nabla_wL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{59}\\\\\n\\nabla_bL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{60}\\\\\n\\nabla_{\\xi}L(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=C-\\alpha_i^*-\\mu_i^*=0 \\tag{61}\n\\end{align*}</script><h2 id=\"2-4-对偶问题最优解与原始问题最优解的对应关系\"><a href=\"#2-4-对偶问题最优解与原始问题最优解的对应关系\" class=\"headerlink\" title=\"2.4 对偶问题最优解与原始问题最优解的对应关系\"></a>2.4 对偶问题最优解与原始问题最优解的对应关系</h2><p>　　设<script type=\"math/tex\">\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)</script>是对偶问题（式(50)~式(52)）的一个解，若存在<script type=\"math/tex\">\\alpha^*</script>的一个分量<script type=\"math/tex\">\\alpha_j^*</script>，<script type=\"math/tex\">0<\\alpha_j^* < C</script>，则原始问题式（(37)～式(39)）的解<script type=\"math/tex\">w^*,b^*</script>可按下式求得：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i\\tag{62}\\\\\nb^*=y_j-\\sum_{i=1}^{m}y_i\\alpha_i^*(x_i\\cdot x_j)\\tag{63}\n\\end{align*}</script><p><strong>注1</strong>：<script type=\"math/tex\">w^*</script>从KKT条件中式(59)中直接得出。<br><strong>注2</strong>：<script type=\"math/tex\">b^*</script>的得出：从KKT条件知道，至少有一个<script type=\"math/tex\">0<\\alpha_j^* < C</script>（反证法，假设<script type=\"math/tex\">\\alpha^*=0</script>，由式(59)得<script type=\"math/tex\">w^*=0</script>，而<script type=\"math/tex\">w^*=0</script>不是原始最优化问题(式(37)～式(39)的解，矛盾）。结合KKT中互补松弛条件(式(55)~式(56))，对此$j$有：</p>\n<script type=\"math/tex; mode=display\">y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{64}</script><p>将<script type=\"math/tex\">w^*</script>的解(式(62))代入式(64)并注意到<script type=\"math/tex\">y_j^2=1</script>，即得式(63)。（结合式(61)和(56)，此时的<script type=\"math/tex\">\\xi_j^*=0</script>）<br>　　求得解<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>后，<strong>分离超平面</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{65}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{66}\n\\end{align*}</script><p>　　<strong>分类决策函数</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{67}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{68}\n\\end{align*}</script><p>　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。<strong>式(68)称为线性支持向量机的对偶形式</strong>。</p>\n<h2 id=\"2-5-支持向量\"><a href=\"#2-5-支持向量\" class=\"headerlink\" title=\"2.5 支持向量\"></a>2.5 支持向量</h2><p>　　<strong>软间隔的支持向量</strong>：在线性不可分的情况下，将对偶问题（式(50)~式(52)）的解<script type=\"math/tex\">\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)</script>中<strong>对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的样本点<script type=\"math/tex\">(x_i,y_i)</script>的实例<script type=\"math/tex\">x_i</script>称为支持向量。</strong><br>　　结合互补松弛条件（式(55)~式(56)）及式(61)，得</p>\n<script type=\"math/tex; mode=display\">\n\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1+\\xi_i^*)=0, i=1,2,...,m\\\\\n(C-\\alpha_i^*)\\xi_i^*=0</script><p>　　软间隔的支持向量$x_i$<strong>或者在间隔边界上，或者在间隔边界与分离超平面之间，或者在分离超平面误分一侧。</strong></p>\n<ul>\n<li><script type=\"math/tex\">\\alpha_i^*=0</script>时：非支持向量，<script type=\"math/tex\">\\xi_i=0</script>，没犯错，远离间隔边界或在间隔边界上；</li>\n<li><script type=\"math/tex\">0<\\alpha_i^*<C</script>时：支持向量，<script type=\"math/tex\">\\xi_i=0</script>，支持向量<script type=\"math/tex\">x_i</script>在在间隔边界上，决定了<script type=\"math/tex\">b^*</script>；</li>\n<li><script type=\"math/tex\">\\alpha_i^*=C</script>时：支持向量，<script type=\"math/tex\">\\xi_i \\neq 0</script>,<script type=\"math/tex\">\\xi_i>0</script>，<script type=\"math/tex\">\\xi_i</script>记录了违反间隔边界的数量或大小<ul>\n<li><script type=\"math/tex\">0<\\xi_i < 1</script>：分类正确,<script type=\"math/tex\">x_i</script>落在间隔边界与分离超平面之间；</li>\n<li><script type=\"math/tex\">\\xi_i = 1</script>：<script type=\"math/tex\">w^*\\cdot x_i+b^*=0</script>,<script type=\"math/tex\">x_i</script>落在分离超平面上；</li>\n<li><script type=\"math/tex\">\\xi_i >1</script>：样本点分类错误，<script type=\"math/tex\">x_i</script>落在分离超平面误分一侧。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、非线性支持向量机\"><a href=\"#四、非线性支持向量机\" class=\"headerlink\" title=\"四、非线性支持向量机\"></a>四、非线性支持向量机</h1><p>　　对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，通常分类问题是非线性的，这时可以使用非线性支持向量机，其主要特点是利用核技巧。<br>　　用线性分类方法求解非线性分类问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练数据中学习分类模型。核技巧就属于这样的方法。</p>\n<h2 id=\"4-1-核函数的定义\"><a href=\"#4-1-核函数的定义\" class=\"headerlink\" title=\"4.1 核函数的定义\"></a>4.1 核函数的定义</h2><p>　　假设$X$是输入空间，$H$是特征空间，如果存在一个从$X$到$H$的映射函数：</p>\n<script type=\"math/tex; mode=display\">\\phi(x):X\\rightarrow H</script><p>　　使得所有$x,z\\in X$,函数$K(x,z)$满足条件：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=\\phi(x)\\cdot \\phi(z)</script><p>　　则称$K(x,z)$为核函数，$\\phi(x)$为映射函数，式中$\\phi(x)\\cdot \\phi(z)$为$\\phi(x)$和$\\phi(z)$的内积。<br>　　<strong>核技巧的想法是：在学习与预测中只定义核函数$K(x,z)$,而不是显示地定义映射函数$\\phi$。通常，直接计算$K(x,z)$比较容易，而通过$\\phi(x)$和$\\phi(z)$计算$K(x,z)$并不容易。</strong>注意，$\\phi$是输入空间$R^n$到特征空间$H$的映射，特征空间$H$一般是高维的，甚至是无穷维的。</p>\n<h2 id=\"4-2-核技巧在支持向量机中的应用\"><a href=\"#4-2-核技巧在支持向量机中的应用\" class=\"headerlink\" title=\"4.2 核技巧在支持向量机中的应用\"></a>4.2 核技巧在支持向量机中的应用</h2><p>　　我们注意到在线性支持向量机的对偶问题中，无论是在目标函数还是在决策函数(分离超平面)都只涉及输入实例与实例之间的内积。<br>　　在对偶问题的目标函数(式(50))中的内积<script type=\"math/tex\">x_i\\cdot x_j</script>可以用核函数<script type=\"math/tex\">K(x_i,x_j)=\\phi(x_i)\\cdot \\phi(x_j)</script>来代替。此时对偶问题的目标函数变为：<br>　　<script type=\"math/tex\">W(\\alpha)=\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i \\tag{69}</script><br>　　同样，分类决策函数中的内积也可以用核函数代替，而分类决策函数变为：<br>　　<script type=\"math/tex\">f(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i \\phi(x) \\cdot \\phi(x_i)+b^*) \\\\\n　　=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i K(x \\cdot x_i)+b^*)   \\tag{70}</script><br>　　这等价于经过映射函数$\\phi$将原来的输入空间变换到一个新的特征空间，将输入空间中的内积$x_i \\cdot x_j$变换为特征空间中的内积$\\phi(x_i) \\cdot \\phi(x_j)$，在新的特征空间里从训练样本中学习线性支持向量机。当映射函数是非线性时，学习到的含有核函数的支持向量机是非线性分类模型。<br>　　也就是说，在核函数<script type=\"math/tex\">K(x,z)</script>给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是在隐式地特征空间进行的，不需要显示地定义特征空间和映射函数。这样的技巧称为核技巧，它是巧妙地利用线性分类学习方法与核函数解决非线性问题的技术。</p>\n<h2 id=\"4-3-常用核函数\"><a href=\"#4-3-常用核函数\" class=\"headerlink\" title=\"4.3 常用核函数\"></a>4.3 常用核函数</h2><p>　　（1）多项式核函数：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=(\\gamma \\cdot x\\cdot z+ \\zeta)^p  \\tag{71}</script><p>　　式中，$\\gamma\\in R$且$\\gamma&gt;0$,$\\zeta\\in R$且$\\zeta\\geq0$<br>　　特殊情况：线性核：$K_1(x,z)=(1 \\cdot x\\cdot z+0)^1$<br>　　（2）高斯核函数：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2}) \\tag{72}</script><p>　　或写成$K(x,z)=exp(-\\gamma||x-z||^2)$,$\\gamma&gt;0$<br>　　<strong>注</strong>：正态分布的PDF为：$f(x;\\mu,\\sigma)= \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x-\\mu)^2}{2{\\sigma}^2})$</p>\n<h2 id=\"4-４-非线性支持向量机学习算法\"><a href=\"#4-４-非线性支持向量机学习算法\" class=\"headerlink\" title=\"4.４ 非线性支持向量机学习算法\"></a>4.４ 非线性支持向量机学习算法</h2><p>　　如上所述，利用核技巧，可以将线性分类的学习方法应用到非线性分类问题中去。将线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机对偶形式中的内积换成核函数。<br>　　（1）选取适当的核函数$K(x,z)$和适当的参数$C$，构造并求解最优化问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{73}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{74}\\\\\n& 0\\leq \\alpha_i\\leq C,\\; i=1,2,...m\\tag{75}\\\\\n\\end{align*}</script><p>　　求得最优解<script type=\"math/tex\">\\alpha^*=(\\alpha^*_1,\\alpha^*_2,...,\\alpha^*_m)</script>.<br>　　(2)选择<script type=\"math/tex\">\\alpha^*</script>的一个正分量<script type=\"math/tex\">0<\\alpha^*_j < C</script>，计算</p>\n<script type=\"math/tex; mode=display\">b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_iK(x_i \\cdot x_j)</script><p>　　(3)构造决策函数：</p>\n<script type=\"math/tex; mode=display\">f(x)=sign(w^*\\cdot x+b^*)=sign(\\sum_{i=1}^{m}\\alpha^*_iy_iK(x\\cdot x_i)+b^*)</script><h1 id=\"五、SMO算法（待补）\"><a href=\"#五、SMO算法（待补）\" class=\"headerlink\" title=\"五、SMO算法（待补）\"></a>五、SMO算法（待补）</h1><p>SMO算法的思想：<br>（1）SMO是一种启发式算法，选择两个变量固定其他变量，针对选择的两个变量构造二次规划问题，二次规划问题可以直接得到解析解；SMO算法将原问题 不断地分解为子问题并对子问题进行求解进而达到求解原问题的目的；<br>（2）之所以选择每次更新两个变量是因为目标函数中的第二个约束，若固定其他的变量，那么最后一个变量也随之确定，因此需要更新两个变量。 </p>\n<h1 id=\"六、SVM优缺点（待补）\"><a href=\"#六、SVM优缺点（待补）\" class=\"headerlink\" title=\"六、SVM优缺点（待补）\"></a>六、SVM优缺点（待补）</h1><p>1.优点<br>（1）可用于线性/非线性分类，也可以用于回归；<br>（2）低泛化误差；<br>（3）容易解释；<br>（4）计算复杂度较低；<br>（5）处理小样本，非线性，高维数问题；<br>2.缺点<br>（1）对参数和核函数的选择比较敏感；<br>（2）原始的SVM只比较擅长处理二分类问题；</p>\n<h1 id=\"七、参考资料\"><a href=\"#七、参考资料\" class=\"headerlink\" title=\"七、参考资料\"></a>七、参考资料</h1><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/watch?v=A-GxGCCAIrg&amp;list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\">Andrew Ng, Machine Learning</a></li>\n<li>周志华，机器学习</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>　　支持向量机(support vector machine, SVM)是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。线性支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题。<br>　　支持向量机学习方法包含构建由简至繁的模型：<strong>线性可分支持向量机</strong>、<strong>线性支持向量机</strong>、<strong>非线性支持向量机</strong>：</p>\n<ul>\n<li><strong>线性可分支持向量机</strong>：适用于训练数据线性可分，通过硬间隔最大化，学习一个线性的分类器，即线性可分支持向量机，又称为<strong>硬间隔支持向量机</strong>；</li>\n<li><strong>线性支持向量机</strong>：适用于训练数据近似线性可分，也就是存在一些特异点，将这些特异点去除后的样本线性可分（现实中的数据经常是线性不可分的）。通过软间隔最大化，也学习一个线性的分类器，即线性支持向量机，又称为<strong>软间隔支持向量机</strong>；</li>\n<li><strong>非线性支持向量机</strong>：适用于训练数据线性不可分，通过核技巧即软间隔最大化，学习非线性支持向量机。","more":"</li>\n</ul>\n<p><strong>注</strong>：<br><strong>核函数</strong>：核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。<br><strong>核技巧</strong>：通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法成为核技巧。\n　　</p>\n<h1 id=\"一、基本概念\"><a href=\"#一、基本概念\" class=\"headerlink\" title=\"一、基本概念\"></a>一、基本概念</h1><p>（1）SVM的<strong>分离超平面</strong>：</p>\n<script type=\"math/tex; mode=display\">w^*\\cdot x+b^*=0\\tag{1}</script><p>（2）SVM的<strong>分类决策函数</strong>为：</p>\n<script type=\"math/tex; mode=display\">f(x)=sign(w^* \\cdot x+b^*)\\tag{2}</script><p><strong>注</strong>：函数值只有正负1，二分类。<br>（3）<strong>函数间隔</strong>：<br>　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为：</p>\n<script type=\"math/tex; mode=display\">\\hat{\\gamma_i}=y_i(w \\cdot x_i+b)\\tag{3}</script><p>　　定义超平面$(w,b)$关于训练集$T$的函数间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的函数间隔之最小值，即：</p>\n<script type=\"math/tex; mode=display\">\\hat{\\gamma}=\\min_{i=1,...,m}\\hat{\\gamma_i}\\tag{4}</script><p><strong>注1</strong>：函数间隔大于0，表示$w \\cdot x_i+b$与$y_i$同号，分类正确；$|w \\cdot x_i+b|$值越大，离分离超平面越远，分类预测的确信程度越高。所以用$y_i(w \\cdot x_i+b)$来表示分类的正确性和确信度，这就是函数间隔。<br><strong>注2</strong>：函数间隔可以表示分类预测的正确性及确信程度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例的改变$w$和$b$，例如将它们改变为$2w$和$2b$，超平面并没有改变，但函数间隔却成为原来的2倍。故需对超平面的法向量$w$加某些约束，如规范化$||w||=1$，使得间隔是确定的。此时，函数间隔即几何间隔。<br>（4）<strong>几何间隔</strong>：<br>　　定义超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔为：</p>\n<script type=\"math/tex; mode=display\">\\gamma_i=y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\tag{5}</script><p>　　定义超平面$(w,b)$关于训练集$T$的几何间隔为超平面$(w,b)$关于所有样本点$(x_i,y_i)$的几何间隔之最小值，即：</p>\n<script type=\"math/tex; mode=display\">\\gamma=\\min_{i=1,...,m}\\gamma_i\\tag{6}</script><p><strong>注</strong>：超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔即<strong>实例点到分离超平面的带符号的距离</strong>，由<a href=\"https://baike.baidu.com/item/%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E8%B7%9D%E7%A6%BB/8673346\" target=\"_blank\" rel=\"noopener\">点到直线的距离公式</a>可推出。<br>　　从函数间隔和几何间隔的定义（式(3)~(6)）可知，函数间隔和几何间隔有如下关系：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\gamma_i=\\frac{\\hat{\\gamma_i}}{||w||}\\tag{7}\\\\\n\\gamma=\\frac{\\hat{\\gamma}}{||w||}\\tag{8}\n\\end{align*}</script><p><strong>注</strong>：如果$||w||=1$，那么函数间隔和几何间隔相等。如果超平面参数$w$和$b$成比例地改变，超平面没有改变，函数间隔按此比例改变，而几何间隔不变。</p>\n<h1 id=\"二、线性可分支持向量机\"><a href=\"#二、线性可分支持向量机\" class=\"headerlink\" title=\"二、线性可分支持向量机\"></a>二、线性可分支持向量机</h1><p>　　支持向量机学习的基本思想是求解能够<strong>正确划分训练数据集</strong>并且<strong>几何间隔最大</strong>的分离超平面。<br>　　对<strong>线性可分</strong>的训练数据集，线性可分分离超平面有无穷多个，但几何间隔最大的分离超平面是唯一的。这里的间隔最大化又称为<strong>硬间隔最大化</strong>。<br>　　此时，学习到的线性分类器，称为<strong>线性可分支持向量机</strong>或<strong>硬间隔支持向量机</strong>。<br>注：几何间隔最大化的直观解释：对训练数据集找到的几何间隔最大化的超平面意味着以充分大的确信程度对训练数据进行分类。也就是说，不仅将正负实例分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力。</p>\n<h2 id=\"2-1-原始最优化问题\"><a href=\"#2-1-原始最优化问题\" class=\"headerlink\" title=\"2.1 原始最优化问题\"></a>2.1 原始最优化问题</h2><p>　　（1）求最大间隔分离超平面的问题，可以表示为下面的约束最优化问题：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{w,b}\\; &\\gamma \\tag{9}\\\\\ns.t.\\; & y_i(\\frac{w}{||w||}\\cdot x_i+\\frac{b}{||w||})\\geq\\gamma,\\;  i=1,2,...,m\\tag{10}\n\\end{align*}</script><p>注：即我们希望最大化超平面$(w,b)$关于训练数据集的几何间隔$\\gamma$，约束条件表示的是超平面$(w,b)$关于每个训练样本点的几何间隔至少是$\\gamma$。<br>　　（2）根据函数间隔与几何间隔的关系式(8)，约束问题可以等价于：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{w,b}\\; &\\frac{\\hat{\\gamma}}{||w||}\\tag{11}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq\\hat{\\gamma},\\; i=1,2,...,m\\tag{12}\n\\end{align*}</script><p>　　（3）由于式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解（见注解），因此可以取$\\hat{\\gamma}=1$。将$\\hat{\\gamma}=1$代入式(11~12)的最优化问题，且最大化$\\frac{1}{||w||}$和最小化$\\frac{1}{2}||w||^2$是等价的，于是就得到下面的线性可分支持向量机学习的最优化问题：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{w,b}\\; &\\frac{1}{2}||w||^2 \\tag{13}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)-1\\geq0,\\, i=1,2,...,m\\tag{14}\n\\end{align*}</script><p>　　这是一个凸优化问题中的凸二次规划问题。<br>　　如果求出了约束条件最优化问题式(13)~(14)的解<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>，那么就可以得到最大间隔分离超平面<script type=\"math/tex\">w^*\\cdot x+b^*=0</script>及分类决策函数<script type=\"math/tex\">f(x)=sign(w^* \\cdot x+b^*)</script>，即线性可分支持向量机模型。<br><strong>注</strong>：式(12)中函数间隔$\\hat{\\gamma}$的取值不影响优化问题的解。假设将$w$和$b$按比例改变为$\\lambda w$和$\\lambda b$，这时函数间隔成为$\\lambda \\hat{\\gamma}$。函数间隔的这一改变既对式(12)的不等数约束没有影响，又对式(11)的目标函数的优化没有影响，也就是说，它产生一个等价的最优化问题。</p>\n<h2 id=\"2-2-支持向量和间隔边界\"><a href=\"#2-2-支持向量和间隔边界\" class=\"headerlink\" title=\"2.2 支持向量和间隔边界\"></a>2.2 支持向量和间隔边界</h2><p>　　在线性可分的情况下，<strong>训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量</strong>。支持向量是使约束条件式(14)等号成立的点，即</p>\n<script type=\"math/tex; mode=display\">y_i(w\\cdot x_i+ b)-1=0\\tag{15}</script><p>　　对$y_i=+1$的正例点，支持向量在超平面</p>\n<script type=\"math/tex; mode=display\">H_1:w \\cdot x+b=1\\tag{16}</script><p>　　对$y_i=-1$的负例点，支持向量在超平面</p>\n<script type=\"math/tex; mode=display\">H_2:w \\cdot x+b=-1\\tag{17}</script><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/SVM/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%92%8C%E9%97%B4%E9%9A%94%E8%BE%B9%E7%95%8C.JPG\" width=\"50%\" height=\"50%\"><br>　　　　　　　　　　　　　　　　　图1，支持向量和间隔边界<br>　　如图1，在$H_1$和$H_2$上的点就是<strong>支持向量</strong>，$H_1$和$H_2$称为<strong>间隔边界</strong>，$H_1$与$H_2$之间的距离称为<strong>间隔</strong>(margin)。<br>注1：$H_1$与$H_2$平行，并且没有实例点落在它们中间。在$H_1$与$H_2$之间形成一条长带，<strong>分离超平面与它们平行且位于它们中央</strong>。长带的宽度，即$H_1$与$H_2$之间的距离称为间隔。因为$H_1$和$H_2$的函数间隔为1，故各自与分离超平面的几何间隔为$\\frac{1}{||w||}$，即<strong>间隔为$\\frac{2}{||w||}$。</strong><br>注2：在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。如果移动支持向量改变所求的解；但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的。<strong>由于支持向量在确定分离超平面中起着决定性作用，所以将这种分类模型称为支持向量机</strong>。支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定。</p>\n<h2 id=\"2-3-对偶最优化问题\"><a href=\"#2-3-对偶最优化问题\" class=\"headerlink\" title=\"2.3 对偶最优化问题\"></a>2.3 对偶最优化问题</h2><p>　　为了求解线性可分支持向量机的最优化问题（式(13)~(14)），将它作为<strong>原始最优化问题</strong>，应用拉格朗日对偶性，通过求解<strong>对偶问题</strong>(dual problem)得到<strong>原始问题</strong>(primal problem)的最优解，这就是线性可分支持向量机的<strong>对偶算法</strong>。这样做的优点，<strong>一是对偶问题往往更容易求解，二是自然引入核函数，进而推广到非线性分类问题</strong>。<br>　　（1）构建拉格朗日函数<br>　　对每一个不等式约束，引进拉格朗日乘子$\\alpha_i\\geq0,\\ i=1,2,..,m$，定义拉格朗日函数：</p>\n<script type=\"math/tex; mode=display\">L(w,b,\\alpha)=\\frac{1}{2}||w||^2+\\sum_{i=1}^{m}\\alpha_i(1-y_i(w\\cdot x_i+b))\\tag{18}</script><p>　　式中，$\\alpha=(\\alpha_1,\\alpha_2,…,\\alpha_m)^T$为拉格朗日乘子向量。<br>　　（2）对偶问题<br>　　根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：</p>\n<script type=\"math/tex; mode=display\">\\max_\\alpha\\, \\min_{w,b}L(w,b,\\alpha)</script><p>　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\alpha)$对$w,b$的极小，再求对$\\alpha$的极大。<br>　　（3）对偶问题——求$\\min\\limits_{w,b}L(w,b,\\alpha)$<br>　　将拉格朗日函数$L(w,b,\\alpha)$分别对$w,b$求偏导数并令其等于0，</p>\n<script type=\"math/tex; mode=display\">\\nabla_wL(w,b,\\alpha)=w-\\sum_{i=1}^{m}\\alpha_i y_i x_i=0\\\\\n\\nabla_bL(w,b,\\alpha)=-\\sum_{i=1}^{m}\\alpha_i y_i=0</script><p>　　得，</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_i y_i x_i\\tag{19}\\\\\n\\sum_{i=1}^{m}\\alpha_i y_i=0\\tag{20}\n\\end{align*}</script><p>　　将式(19)代入拉格朗日函数（式(18)），并利用式(20),即得</p>\n<script type=\"math/tex; mode=display\">\\min_{w,b}L(w,b,\\alpha)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i</script><p>　　（4）对偶问题——求$\\min_{w,b}L(w,b,\\alpha)$对$\\alpha$的极大，即是对偶问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{21}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\n\\end{align*}</script><p>　　（5）将上式(21)的目标函数由求极大转换成为求极小，就得到下面与之等价的<strong>对偶最优化问题</strong>：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{22}\\\\\ns.t.\\; &\\sum_{i=1}^m\\alpha_iy_i=0\\tag{23}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{24}\n\\end{align*}</script><p>　　考虑原始最优问题(式(13)~(14))和对偶最优化问题(式(22)~(24))，原始问题满足<strong>定理C.2(见书中，此处略)</strong>的条件，故存在$w^<em>$,$\\alpha^</em>$，$w^<em>$是原问题的解，$\\alpha^</em>$是对偶问题的解。<strong>这意味着求解原始问题(式(13)~(14))可以转换为求解对偶问题(式(22)~(24))</strong>。<br>　　依据定理C.3(见书中，此处略)，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">\\alpha^*</script>分别是原始问题和对偶问题的解的充要条件是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">\\alpha^*</script>满足KKT条件</strong>。</p>\n<h2 id=\"2-4-KKT条件\"><a href=\"#2-4-KKT条件\" class=\"headerlink\" title=\"2.4 KKT条件\"></a>2.4 KKT条件</h2><p>原问题可行：　　<br>$y_i(w^<em>\\cdot x_i+b^</em>)-1\\geq0,\\; i=1,2,…,m \\tag{25}$<br>互补松弛条件(complementary slackness):<br>$\\alpha_i^<em>(y_i(w^</em>\\cdot x_i+b^<em>)-1)=0,\\; i=1,2,…,m \\tag{26}$<br>对偶可行：<br>$\\alpha_i^</em>\\geq0,\\; i=1,2,…,m \\tag{27}$<br>对偶内在优化：<br>$\\nabla_wL(w^<em>,b^</em>,\\alpha^<em>)=w^</em>-\\sum_{i=1}^{m}\\alpha_i^<em>y_ix_i=0 \\tag{28}$<br>$\\nabla_bL(w^</em>,b^<em>,\\alpha^</em>)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{29}$</p>\n<h2 id=\"2-5-对偶问题最优解与原始问题最优解的对应关系\"><a href=\"#2-5-对偶问题最优解与原始问题最优解的对应关系\" class=\"headerlink\" title=\"2.5 对偶问题最优解与原始问题最优解的对应关系\"></a>2.5 对偶问题最优解与原始问题最优解的对应关系</h2><p>　　设$\\alpha=(\\alpha_1,\\alpha_2,…,\\alpha_m)^T$是对偶最优化问题(式(22)~(24))的解，则存在下标$j$，使得$\\alpha_j&gt;0$，并可按下式求得原始最优化问题(式(13)~(14))的解$w^<em>$,$b^</em>$：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i \\tag{30}\\\\\nb^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_i(x_i\\cdot x_j) \\tag{31}\n\\end{align*}</script><p><strong>注1</strong>：$w^<em>$从KKT条件中式(28)中直接得出。<br><strong>注2</strong>：$b^</em>$的得出：从KKT条件知道，至少有一个$\\alpha_j^<em>&gt;0$（反证法，假设$\\alpha^</em>=0$，由式(28)得$w^<em>=0$，而$w^</em>=0$不是原始最优化问题(式(13)~(14))的解，矛盾）。结合KKT中互补松弛条件(式(26))，对此$j$有：<br>$y_j(w^<em> \\cdot x_j + b^</em>)-1=0 \\tag{32}$<br>将$w^<em>$的解(式(30))代入式(32)并注意到$y_j^2=1$，即得<br>$b^</em>=y_j-\\sum_{i=1}^{m}\\alpha_i^<em>y_i(x_i\\cdot x_j) \\tag{31}$<br>　　<br>　　求得解$w^</em>$，$b^<em>$后，<em>*分离超平面</em></em>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{33}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{34}\n\\end{align*}</script><p>　　<strong>分类决策函数</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{35}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{36}\n\\end{align*}</script><p>　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。<strong>式(36)称为线性可分支持向量机的对偶形式</strong>。<br>　　综上，对于给定的线性可分训练数据集，可以首先求对偶问题（式(22)~(24)）的解$\\alpha^<em>$；再利用式(30)和式(31)求得原始问题的解$w^</em>$和$b^<em>$；从而得到分离超平面及分类决策函数。这种算法称为<em>*线性可分支持向量机的对偶学习算法</em></em>，是线性可分支持向量机的基本算法。</p>\n<h2 id=\"2-6-支持向量\"><a href=\"#2-6-支持向量\" class=\"headerlink\" title=\"2.6 支持向量\"></a>2.6 支持向量</h2><p>在线性可分支持向量机中，由式(30)和式(31)可知，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">b^*</script>只依赖于训练数据中对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的样本点<script type=\"math/tex\">(x_i,y_i)</script></strong>，而其他样本点对<script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">b^*</script>没有影响。<strong>将训练数据中对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的实例点<script type=\"math/tex\">x_i \\in R^n</script>称为支持向量</strong>。<br>支持向量一定在间隔边界上。由KKT互补松弛条件(式(26))可知，对应于于<script type=\"math/tex\">\\alpha_i^*>0</script>的实例<script type=\"math/tex\">x_i</script>，有</p>\n<script type=\"math/tex; mode=display\">y_i(w^*\\cdot x_i+b^*)-1=0</script><p>或</p>\n<script type=\"math/tex; mode=display\">w^*\\cdot x_i+b^*=\\pm1</script><p>即$x_i$一定在间隔边界上。这里的支持向量的定义与前面给出的支持向量的定义是一致的。</p>\n<h1 id=\"三、线性支持向量机\"><a href=\"#三、线性支持向量机\" class=\"headerlink\" title=\"三、线性支持向量机\"></a>三、线性支持向量机</h1><h2 id=\"2-1-原始最优化问题-1\"><a href=\"#2-1-原始最优化问题-1\" class=\"headerlink\" title=\"2.1 原始最优化问题\"></a>2.1 原始最优化问题</h2><p><strong>线性不可分的线性支持向量机的原始问题</strong>如下：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{w,b,\\xi}\\; & \\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i \\tag{37}\\\\\ns.t.\\; & y_i(w\\cdot x_i+b)\\geq1-\\xi_i, \\; i=1,2,...,m\\tag{38}\\\\\n& \\xi_i\\geq0,\\; i=1,2,...,m\\tag{39}\n\\end{align*}</script><p><strong>注1</strong>：线性不可分意味着某些样本点$(x_i,y_i)$不能满足函数间隔大于等于1的约束条件（式(14)）。为了解决这个问题，可以对每个样本点$(x_i,y_i)$引进一个松弛变量$\\xi_i\\geq0$，使函数间隔加上松弛变量大于等于1。这样约束条件变为式(38)。<br><strong>注2</strong>：同时，对每一个松弛变量$\\xi_i$，支付一个代价$\\xi_i$。目标函数由原来的$\\frac{1}{2}||w||^2$变成式(37)。这里，$C&gt;0$称为惩罚参数，一般由应用问题决定，$C$值大时对误分类的惩罚增大，$C$值小时对误分类的惩罚减小。最小化目标函数式(37)包含两层含义：使$\\frac{1}{2}||w||^2$尽量小即间隔尽量大，同时使误分类点的个数尽量小，$C$是调和二者的系数。<br>　　有了上面的思路，可以和训练数据集线性可分时一样来考虑训练数据集线性不可分时的线性支持向量机学习问题。相应于硬间隔最大化，它称为<strong>软间隔最大化</strong>。<br>　　原问题式(37)~式(39)是一个凸二次规划问题，因而关于$(w,b,\\xi)$的解是存在的。<br>　　设原问题式(37)~式(39)的解是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>，于是可以得到分离超平面<script type=\"math/tex\">w^* \\cdot x + b^* =0</script>及分类决策函数<script type=\"math/tex\">f(x)=sign(w^* \\cdot x + b^*)</script>。成这样的模型为训练样本线性不可分时的线性支持向量机，简称<strong>线性支持向量机</strong>。</p>\n<h2 id=\"2-2-对偶最优化问题\"><a href=\"#2-2-对偶最优化问题\" class=\"headerlink\" title=\"2.2 对偶最优化问题\"></a>2.2 对偶最优化问题</h2><p>（1）构建拉格朗日函数<br>　　原始最优化问题（式(37)~(39)）的拉格朗日函数是</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\xi,\\alpha,\\mu)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{m}\\xi_i-\\sum_{i=1}^{m}\\alpha_i(y_i(w\\cdot x_i+b)-1+\\xi_i)-\\sum_{i=1}^{m}\\mu_i\\xi_i\n\\tag{40}</script><p>　　其中，$\\alpha_i\\geq0,\\mu_i\\geq0$.<br>（2）对偶问题<br>　　对偶问题是拉格朗日函数的极大极小问题：</p>\n<script type=\"math/tex; mode=display\">\\max_\\alpha\\; \\min_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)</script><p>　　所以，为了得到对偶问题的解，需要先求$L(w,b,\\xi,\\alpha,\\mu)$对$w,b,\\xi$的极小，再求对$\\alpha$的极大。<br>（3）对偶问题——求$\\min\\limits_{w,b,\\xi}\\,L(w,b,\\xi,\\alpha,\\mu)$<br>　　通过</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\nabla_wL(w,b,\\xi,\\alpha,\\mu)=w-\\sum_{i=1}^{m}\\alpha_i y_ix_i=0\\\\\n\\nabla_bL(w,b,\\xi,\\alpha,\\mu)=-\\sum_{i=1}^{m}\\alpha_i y_i=0\\\\\n\\nabla_{\\xi}L(w,b,\\xi,\\alpha,\\mu)=C-\\alpha_i-\\mu_i=0\n\\end{align*}</script><p>　　得</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw=\\sum_{i=1}^{m}\\alpha_iy_ix_i\\tag{41}\\\\\n\\sum_{i=1}^{m}\\alpha_iy_i=0\\tag{42}\\\\\nC-\\alpha_i-\\mu_i=0\\tag{43}\n\\end{align*}</script><p>　　将式(41)到式(43)代入式(40)，得</p>\n<script type=\"math/tex; mode=display\">\\min_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)=-\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i</script><p>（4）对偶问题——求$\\min\\limits_{w,b,\\xi}L(w,b,\\xi,\\alpha,\\mu)$对$\\alpha$的极大，即得对偶问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\max_{\\alpha}\\; & -\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)+\\sum_{i=1}^{m}\\alpha_i\\tag{44}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{45}\\\\\n& C-\\alpha_i-\\mu_i=0\\tag{46}\\\\\n& \\alpha_i\\geq0,\\; i=1,2,...m\\tag{47}\\\\\n& \\mu_i\\geq0,\\; i=1,2,...,m\\tag{48}\n\\end{align*}</script><p>　　将对偶最优化问题式(44)~式(48)进行变换：利用等式约束式(46)消去$\\mu_i$，从而只留下变量$\\alpha_i$，并将约束式(46)~式(48)写成</p>\n<script type=\"math/tex; mode=display\">0\\leq\\alpha_i\\leq C\\tag{49}</script><p>（5）再将对目标函数求极大极小转为求极小，于是得到<strong>对偶问题</strong>(50)~(52).</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_j(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{50}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{51}\\\\\n& 0\\leq \\alpha_i\\leq C,\\;i=1,2,...m\\tag{52}\\\\\n\\end{align*}</script><p>　　综上，原始最优化问题(式(37)～式(39))的对偶最优化问题为式(50)~式(51)。可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数。<br>　　有定理可证，<strong>求解原始问题(式(37)～式(39))可以转换为求解对偶问题式(50)~式(52)</strong>。<br>　　有定理可证，<strong><script type=\"math/tex\">w^*</script>和<script type=\"math/tex\">\\alpha^*</script>分别是原始问题和对偶问题的解的充要条件是<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">\\alpha^*</script>满足KKT条件</strong>。</p>\n<h2 id=\"2-3-KKT条件\"><a href=\"#2-3-KKT条件\" class=\"headerlink\" title=\"2.3 KKT条件\"></a>2.3 KKT条件</h2><p>原问题可行：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\ny_i(w^*\\cdot x_i+ & b^*)-1+\\xi_i^*\\geq0 \\tag{53} \\\\\n& \\xi_i^*\\geq0 \\tag{54}\n\\end{align*}</script><p>互补松弛条件(complementary slackness):</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\alpha_i^*(y_i(w^*\\cdot x_i & + b^*)-1 +\\xi_i^*)=0 \\tag{55}\\\\\n& \\mu_i^*\\xi_i^*=0\\tag{56}\n\\end{align*}</script><p>对偶问题可行：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\alpha_i^*\\geq0 \\tag{57}\\\\\n\\mu_i^*\\geq0 \\tag{58}\n\\end{align*}</script><p>对偶内在优化：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\nabla_wL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=w^*-\\sum_{i=1}^{m}\\alpha_i^*y_ix_i=0 \\tag{59}\\\\\n\\nabla_bL(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=-\\sum_{i=1}^{m}\\alpha_i^*y_i=0 \\tag{60}\\\\\n\\nabla_{\\xi}L(w^*,b^*,\\xi^*,\\alpha^*,\\mu^*)=C-\\alpha_i^*-\\mu_i^*=0 \\tag{61}\n\\end{align*}</script><h2 id=\"2-4-对偶问题最优解与原始问题最优解的对应关系\"><a href=\"#2-4-对偶问题最优解与原始问题最优解的对应关系\" class=\"headerlink\" title=\"2.4 对偶问题最优解与原始问题最优解的对应关系\"></a>2.4 对偶问题最优解与原始问题最优解的对应关系</h2><p>　　设<script type=\"math/tex\">\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)</script>是对偶问题（式(50)~式(52)）的一个解，若存在<script type=\"math/tex\">\\alpha^*</script>的一个分量<script type=\"math/tex\">\\alpha_j^*</script>，<script type=\"math/tex\">0<\\alpha_j^* < C</script>，则原始问题式（(37)～式(39)）的解<script type=\"math/tex\">w^*,b^*</script>可按下式求得：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*=\\sum_{i=1}^{m}\\alpha_i^*y_ix_i\\tag{62}\\\\\nb^*=y_j-\\sum_{i=1}^{m}y_i\\alpha_i^*(x_i\\cdot x_j)\\tag{63}\n\\end{align*}</script><p><strong>注1</strong>：<script type=\"math/tex\">w^*</script>从KKT条件中式(59)中直接得出。<br><strong>注2</strong>：<script type=\"math/tex\">b^*</script>的得出：从KKT条件知道，至少有一个<script type=\"math/tex\">0<\\alpha_j^* < C</script>（反证法，假设<script type=\"math/tex\">\\alpha^*=0</script>，由式(59)得<script type=\"math/tex\">w^*=0</script>，而<script type=\"math/tex\">w^*=0</script>不是原始最优化问题(式(37)～式(39)的解，矛盾）。结合KKT中互补松弛条件(式(55)~式(56))，对此$j$有：</p>\n<script type=\"math/tex; mode=display\">y_j(w^* \\cdot x_j + b^*)-1=0 \\tag{64}</script><p>将<script type=\"math/tex\">w^*</script>的解(式(62))代入式(64)并注意到<script type=\"math/tex\">y_j^2=1</script>，即得式(63)。（结合式(61)和(56)，此时的<script type=\"math/tex\">\\xi_j^*=0</script>）<br>　　求得解<script type=\"math/tex\">w^*</script>，<script type=\"math/tex\">b^*</script>后，<strong>分离超平面</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nw^*\\cdot x+b^*=0 \\tag{65}\\\\\n\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*=0 \\tag{66}\n\\end{align*}</script><p>　　<strong>分类决策函数</strong>可写成：</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\nf(x)=sign(w^* \\cdot x+b^*) \\tag{67}\\\\\nf(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i (x \\cdot x_i)+b^*) \\tag{68}\n\\end{align*}</script><p>　　这就是说，分类决策函数只依赖于输入$x$和训练样本输入的内积。<strong>式(68)称为线性支持向量机的对偶形式</strong>。</p>\n<h2 id=\"2-5-支持向量\"><a href=\"#2-5-支持向量\" class=\"headerlink\" title=\"2.5 支持向量\"></a>2.5 支持向量</h2><p>　　<strong>软间隔的支持向量</strong>：在线性不可分的情况下，将对偶问题（式(50)~式(52)）的解<script type=\"math/tex\">\\alpha^*=(\\alpha_1^*,\\alpha_2^*,...,\\alpha_m^*)</script>中<strong>对应于<script type=\"math/tex\">\\alpha_i^*>0</script>的样本点<script type=\"math/tex\">(x_i,y_i)</script>的实例<script type=\"math/tex\">x_i</script>称为支持向量。</strong><br>　　结合互补松弛条件（式(55)~式(56)）及式(61)，得</p>\n<script type=\"math/tex; mode=display\">\n\\alpha_i^*(y_i(w^*\\cdot x_i+b^*)-1+\\xi_i^*)=0, i=1,2,...,m\\\\\n(C-\\alpha_i^*)\\xi_i^*=0</script><p>　　软间隔的支持向量$x_i$<strong>或者在间隔边界上，或者在间隔边界与分离超平面之间，或者在分离超平面误分一侧。</strong></p>\n<ul>\n<li><script type=\"math/tex\">\\alpha_i^*=0</script>时：非支持向量，<script type=\"math/tex\">\\xi_i=0</script>，没犯错，远离间隔边界或在间隔边界上；</li>\n<li><script type=\"math/tex\">0<\\alpha_i^*<C</script>时：支持向量，<script type=\"math/tex\">\\xi_i=0</script>，支持向量<script type=\"math/tex\">x_i</script>在在间隔边界上，决定了<script type=\"math/tex\">b^*</script>；</li>\n<li><script type=\"math/tex\">\\alpha_i^*=C</script>时：支持向量，<script type=\"math/tex\">\\xi_i \\neq 0</script>,<script type=\"math/tex\">\\xi_i>0</script>，<script type=\"math/tex\">\\xi_i</script>记录了违反间隔边界的数量或大小<ul>\n<li><script type=\"math/tex\">0<\\xi_i < 1</script>：分类正确,<script type=\"math/tex\">x_i</script>落在间隔边界与分离超平面之间；</li>\n<li><script type=\"math/tex\">\\xi_i = 1</script>：<script type=\"math/tex\">w^*\\cdot x_i+b^*=0</script>,<script type=\"math/tex\">x_i</script>落在分离超平面上；</li>\n<li><script type=\"math/tex\">\\xi_i >1</script>：样本点分类错误，<script type=\"math/tex\">x_i</script>落在分离超平面误分一侧。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"四、非线性支持向量机\"><a href=\"#四、非线性支持向量机\" class=\"headerlink\" title=\"四、非线性支持向量机\"></a>四、非线性支持向量机</h1><p>　　对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，通常分类问题是非线性的，这时可以使用非线性支持向量机，其主要特点是利用核技巧。<br>　　用线性分类方法求解非线性分类问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练数据中学习分类模型。核技巧就属于这样的方法。</p>\n<h2 id=\"4-1-核函数的定义\"><a href=\"#4-1-核函数的定义\" class=\"headerlink\" title=\"4.1 核函数的定义\"></a>4.1 核函数的定义</h2><p>　　假设$X$是输入空间，$H$是特征空间，如果存在一个从$X$到$H$的映射函数：</p>\n<script type=\"math/tex; mode=display\">\\phi(x):X\\rightarrow H</script><p>　　使得所有$x,z\\in X$,函数$K(x,z)$满足条件：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=\\phi(x)\\cdot \\phi(z)</script><p>　　则称$K(x,z)$为核函数，$\\phi(x)$为映射函数，式中$\\phi(x)\\cdot \\phi(z)$为$\\phi(x)$和$\\phi(z)$的内积。<br>　　<strong>核技巧的想法是：在学习与预测中只定义核函数$K(x,z)$,而不是显示地定义映射函数$\\phi$。通常，直接计算$K(x,z)$比较容易，而通过$\\phi(x)$和$\\phi(z)$计算$K(x,z)$并不容易。</strong>注意，$\\phi$是输入空间$R^n$到特征空间$H$的映射，特征空间$H$一般是高维的，甚至是无穷维的。</p>\n<h2 id=\"4-2-核技巧在支持向量机中的应用\"><a href=\"#4-2-核技巧在支持向量机中的应用\" class=\"headerlink\" title=\"4.2 核技巧在支持向量机中的应用\"></a>4.2 核技巧在支持向量机中的应用</h2><p>　　我们注意到在线性支持向量机的对偶问题中，无论是在目标函数还是在决策函数(分离超平面)都只涉及输入实例与实例之间的内积。<br>　　在对偶问题的目标函数(式(50))中的内积<script type=\"math/tex\">x_i\\cdot x_j</script>可以用核函数<script type=\"math/tex\">K(x_i,x_j)=\\phi(x_i)\\cdot \\phi(x_j)</script>来代替。此时对偶问题的目标函数变为：<br>　　<script type=\"math/tex\">W(\\alpha)=\\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i\\cdot x_j)-\\sum_{i=1}^{m}\\alpha_i \\tag{69}</script><br>　　同样，分类决策函数中的内积也可以用核函数代替，而分类决策函数变为：<br>　　<script type=\"math/tex\">f(x)=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i \\phi(x) \\cdot \\phi(x_i)+b^*) \\\\\n　　=sign(\\sum_{i=1}^{m}\\alpha_i^*y_i K(x \\cdot x_i)+b^*)   \\tag{70}</script><br>　　这等价于经过映射函数$\\phi$将原来的输入空间变换到一个新的特征空间，将输入空间中的内积$x_i \\cdot x_j$变换为特征空间中的内积$\\phi(x_i) \\cdot \\phi(x_j)$，在新的特征空间里从训练样本中学习线性支持向量机。当映射函数是非线性时，学习到的含有核函数的支持向量机是非线性分类模型。<br>　　也就是说，在核函数<script type=\"math/tex\">K(x,z)</script>给定的条件下，可以利用解线性分类问题的方法求解非线性分类问题的支持向量机。学习是在隐式地特征空间进行的，不需要显示地定义特征空间和映射函数。这样的技巧称为核技巧，它是巧妙地利用线性分类学习方法与核函数解决非线性问题的技术。</p>\n<h2 id=\"4-3-常用核函数\"><a href=\"#4-3-常用核函数\" class=\"headerlink\" title=\"4.3 常用核函数\"></a>4.3 常用核函数</h2><p>　　（1）多项式核函数：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=(\\gamma \\cdot x\\cdot z+ \\zeta)^p  \\tag{71}</script><p>　　式中，$\\gamma\\in R$且$\\gamma&gt;0$,$\\zeta\\in R$且$\\zeta\\geq0$<br>　　特殊情况：线性核：$K_1(x,z)=(1 \\cdot x\\cdot z+0)^1$<br>　　（2）高斯核函数：</p>\n<script type=\"math/tex; mode=display\">K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2}) \\tag{72}</script><p>　　或写成$K(x,z)=exp(-\\gamma||x-z||^2)$,$\\gamma&gt;0$<br>　　<strong>注</strong>：正态分布的PDF为：$f(x;\\mu,\\sigma)= \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x-\\mu)^2}{2{\\sigma}^2})$</p>\n<h2 id=\"4-４-非线性支持向量机学习算法\"><a href=\"#4-４-非线性支持向量机学习算法\" class=\"headerlink\" title=\"4.４ 非线性支持向量机学习算法\"></a>4.４ 非线性支持向量机学习算法</h2><p>　　如上所述，利用核技巧，可以将线性分类的学习方法应用到非线性分类问题中去。将线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机对偶形式中的内积换成核函数。<br>　　（1）选取适当的核函数$K(x,z)$和适当的参数$C$，构造并求解最优化问题</p>\n<script type=\"math/tex; mode=display\">\\begin{align*}\n\\min_{\\alpha}\\; & \\frac{1}{2}\\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i\\alpha_jy_iy_jK(x_i,x_j)-\\sum_{i=1}^{m}\\alpha_i\\tag{73}\\\\\ns.t.\\; & \\sum_{i=1}^m\\alpha_iy_i=0\\tag{74}\\\\\n& 0\\leq \\alpha_i\\leq C,\\; i=1,2,...m\\tag{75}\\\\\n\\end{align*}</script><p>　　求得最优解<script type=\"math/tex\">\\alpha^*=(\\alpha^*_1,\\alpha^*_2,...,\\alpha^*_m)</script>.<br>　　(2)选择<script type=\"math/tex\">\\alpha^*</script>的一个正分量<script type=\"math/tex\">0<\\alpha^*_j < C</script>，计算</p>\n<script type=\"math/tex; mode=display\">b^*=y_j-\\sum_{i=1}^{m}\\alpha_i^*y_iK(x_i \\cdot x_j)</script><p>　　(3)构造决策函数：</p>\n<script type=\"math/tex; mode=display\">f(x)=sign(w^*\\cdot x+b^*)=sign(\\sum_{i=1}^{m}\\alpha^*_iy_iK(x\\cdot x_i)+b^*)</script><h1 id=\"五、SMO算法（待补）\"><a href=\"#五、SMO算法（待补）\" class=\"headerlink\" title=\"五、SMO算法（待补）\"></a>五、SMO算法（待补）</h1><p>SMO算法的思想：<br>（1）SMO是一种启发式算法，选择两个变量固定其他变量，针对选择的两个变量构造二次规划问题，二次规划问题可以直接得到解析解；SMO算法将原问题 不断地分解为子问题并对子问题进行求解进而达到求解原问题的目的；<br>（2）之所以选择每次更新两个变量是因为目标函数中的第二个约束，若固定其他的变量，那么最后一个变量也随之确定，因此需要更新两个变量。 </p>\n<h1 id=\"六、SVM优缺点（待补）\"><a href=\"#六、SVM优缺点（待补）\" class=\"headerlink\" title=\"六、SVM优缺点（待补）\"></a>六、SVM优缺点（待补）</h1><p>1.优点<br>（1）可用于线性/非线性分类，也可以用于回归；<br>（2）低泛化误差；<br>（3）容易解释；<br>（4）计算复杂度较低；<br>（5）处理小样本，非线性，高维数问题；<br>2.缺点<br>（1）对参数和核函数的选择比较敏感；<br>（2）原始的SVM只比较擅长处理二分类问题；</p>\n<h1 id=\"七、参考资料\"><a href=\"#七、参考资料\" class=\"headerlink\" title=\"七、参考资料\"></a>七、参考资料</h1><ul>\n<li>李航，统计学习方法</li>\n<li><a href=\"https://www.youtube.com/watch?v=A-GxGCCAIrg&amp;list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2\" target=\"_blank\" rel=\"noopener\">林轩田，机器学习技法</a></li>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\" target=\"_blank\" rel=\"noopener\">Andrew Ng, Machine Learning</a></li>\n<li>周志华，机器学习</li>\n</ul>"},{"title":"深度学习课程(一)神经网络与深度学习","mathjax":true,"top":true,"date":"2017-12-21T07:40:50.000Z","_content":"# **1.深度学习介绍**\n## **用神经网络进行监督学习**\n到目前为止，由神经网络创造的经济价值几乎都是基于一种机器学习方法——监督学习。\n下面是目前主要的几种应用示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.JPG\" width=\"50%\" height=\"50%\">不同的情况，一般使用不同的网络模型：\n- 对于房价预测和在线广告，使用标准的神经网络模型；\n- 对于计算机视觉领域，使用CNN(convolution neural network)；\n- 对于序列数据，如音频(如语音识别)和语言(如机器翻译)，使用RNN(recurrent neural network)。\n- 对于更复杂的应用，如无人驾驶，使用混合的神经网络结构。\n\n<!-- more --> \n\n神经网络类型示例:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B%E4%B8%BE%E4%BE%8B.JPG\" width=\"60%\" height=\"50%\">结构化数据与非结构化数据：\n数据类型一般分为两种：结构化数据和非结构化数据。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%8E%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE.JPG\" width=\"70%\" height=\"50%\">\n\n## **为什么深度学习会兴起？**\n三个要素：数据量、计算能力、算法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%B4%E8%B5%B7.jpg\" width=\"60%\" height=\"50%\">\n\n# **2.神经网络基础**\n## **2.1 将逻辑回归作为一个神经网络**\n### **深度学习符号标准**\n该专项课程，规范了深度学习所用到的所有符号的表示方法：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%861.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%862.JPG\" width=\"50%\" height=\"50%\">\n### **二元分类**\n二元分类(Binary Classification)就是输出`$y \\in \\{0,1\\}$`。\n以一个图像识别问题为例，判断图片中是否有猫存在，0代表不是猫，1代表是猫。\n### **逻辑回归**\n- Given $x$,want $\\hat{y}=P(y=1|x)$，其中$x\\in R^{n_x}$,$0\\leq\\hat{y}\\leq1$\n- 参数：$w\\in R^{n_x}$,$b\\in R$\n- 输出：$\\hat{y}=\\sigma(w^Tx+b)$，其中$\\sigma()$为sigmoid函数，$\\sigma(z)=\\frac{1}{1+e^{-z}}$。\n- 注意：本课程中不采用`$x_0=1,x\\in R^{n_x+1}$`，`$\\hat{y}=\\sigma(\\theta^Tx)$`,`$\\theta=[\\theta_0,\\theta_1,...,\\theta_{n_x}]^T$`的做法。\n\n### **逻辑回归代价函数**\n- Given `$\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}$`, want $\\hat{y}^{(i)}=y^{(i)}$\n- Loss Function: $L(\\hat{y},y)=-(y\\log\\hat{y}+(1-y)\\log(1-\\hat{y}))$\n- Cost Function: $$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})\\\\\n=-\\frac{1}{m} \\sum\\limits_{i=1}^m [y^{(i)}\\log\\hat{y}^{(i)}+(1-y^{(i)})\\log(1-\\hat{y}^{(i)})]$$\n\n### **梯度下降**\n- want to find $w$,$b$ that minimize $J(w,b)$\n- $ w:= w-\\alpha\\frac{\\partial}{\\partial w}J(w,b)$\n- $ b:= b-\\alpha\\frac{\\partial}{\\partial b}J(w,b)$\n\n### **通过计算图求导数**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E5%AF%BC%E6%95%B0.JPG\" width=\"60%\" height=\"50%\">\n### **逻辑回归中的梯度下降法**\n逻辑回归总结:\n- $z=w^Tx+b$\n- $\\hat{y}=a=\\sigma(z)$\n- $L(a,y)=-[y\\log(a)+(1-y)\\log(1-a)]$\n\n逻辑回归求导（通过计算图）:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E5%AF%BC.JPG\" width=\"60%\" height=\"50%\">\n- $d_a=\\frac{d}{d_a}L(a,y)=-\\frac{y}{a}+\\frac{1-y}{1-a}$\n- $d_z=\\frac{d}{d_z}L(a,y)= d_a \\cdot \\frac{d_a}{d_z}=(-\\frac{y}{a}+\\frac{1-y}{1-a}) \\cdot a(1-a)=a-y$\n- $d_{w_1}=\\frac{\\partial L}{\\partial w_1}=d_z \\cdot \\frac{\\partial z}{\\partial w_1}=d_z \\cdot x_1$\n- $d_{w_2}=\\frac{\\partial L}{\\partial w_2}=d_z \\cdot \\frac{\\partial z}{\\partial w_2}=d_z \\cdot x_2$\n- $d_{b}=\\frac{\\partial L}{\\partial b}=d_z \\cdot \\frac{\\partial z}{\\partial b}=d_z$\n\n### **m个样本下的梯度下降**\n因为：$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(a^{(i)},y^{(i)})$\n\n故:\n$$\\frac{\\partial}{\\partial w_1}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_1}L(a^{(i)},y^{(i)}) = \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_1}}^{(i)}=\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1$$\n$$\\frac{\\partial}{\\partial w_2}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_2}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_2}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2$$\n$$\\frac{\\partial}{\\partial b}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial b}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{b}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)}$$\n\n## **2.2 python和向量化**\n### **向量化**\n神经网络编程指南：**无论何时，避免显式的for循环**\n举例：\n```Python\n# 若a,b,c为向量或矩阵\nc = np.dot(a,b)\nb = np.exp(a)\nb = np.log(a)\nb = np.abs(a)\nb = np.maximum(a,0)\nb = a**2\nb = 1/a\n```\n### **向量化逻辑回归**\n- $X_{(n_x*m)}=[x^{(1)},x^{(2)},...,x^{(m)}]$\n- $ Z_{(1*m)}=[z^{(1)},z^{(2)},...,z^{(m)}]=w^T X+ [b,...,b]$\n对应代码：`Z=np.dot(w.T,X)+b #broadcasting`\n- $A=[a^{(1)},a^{(2)},...,a^{(m)}]=[\\sigma(z^{(1)}),\\sigma(z^{(2)}),...,\\sigma(z^{(m)})]=\\sigma(Z)$\n对应代码：`A=sigmoid(Z)`\n\n### **向量化逻辑回归中的梯度计算**\n\n- ${d_{z}}^{(i)}=a^{(i)}-y^{(i)}$\n- 故$$d_{Z_{(1*m)}}=[{d_{z}}^{(1)},{d_{z}}^{(2)},...,{d_{z}}^{(m)}]$$\n- $A=[a^{(1)},a^{(2)},...,a^{(m)}],Y=[y^{(1)},y^{(2)},...,y^{(m)}]$\n- 故$$d_{Z_{(1*m)}}=A-Y=[a^{(1)}-y^{(1)}, a^{(2)}-y^{(2)},..., a^{(m)}-y^{(m)}]$$\n- $$d_b=\\frac{1}{m}\\sum_{i=1}^{m} {d_z}^{(i)}=\\frac{1}{m}np.sum(d_Z)$$\n- $$d_w= \\begin{bmatrix} d_{w_1} \\\\d_{w_2} \\\\ ... \\\\d_{w_{n_x}} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1 \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2 \\\\ ... \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_{n_x} \\end{bmatrix} \\\\\n=\\frac{1}{m} X {d_{Z}}^T \n=\\frac{1}{m}[x^{(1)} ,x^{(2)},...,x^{(m)}] \\begin{bmatrix} {d_{z}}^{(1)} \\\\ {d_{z}}^{(2)}\\\\ ...\\\\{d_{z}}^{(m)}\\end{bmatrix}$$\n\n### **逻辑回归算法流程（伪代码）**\n非向量化：\n```\nJ=0, dw1=0, dw2=0,db=0\nfor i = 1 to m\n\tz(i) = wx(i)+b\n\ta(i) = sigmoid(z(i))\n\tJ += -[y(i)log(a(i))+(1-y(i)）log(1-a(i))\n\tdz(i) = a(i)-y(i)\n\tdw1 += x1(i)dz(i)\n\tdw2 += x2(i)dz(i)\n\tdb += dz(i)\nJ /= m\ndw1 /= m\ndw2 /= m\ndb /= m\n```\n向量化：\n```\nfor iter in range(1000):\n    Z = np.dot(w.T,X) + b\n    A = sigmoid(Z)\n    dZ = A-Y\n    dw = 1/m*np.dot(X,dZ.T)\n    db = 1/m*np.sum(dZ)\n    w = w - alpha*dw\n    b = b - alpha*db\n```\n### **python中的广播**\n广播(broadcasting)是Python使用中的一种技巧，在Python中可以对不同维度的矩阵进行四则混合运算，前提条件是至少有一个维度是相同的。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD1.jpg\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD2.JPG\" width=\"50%\" height=\"50%\">\n\n### **关于python/numpy中的向量说明**\nPython中，如果用下列语句来定义一个向量：\n```\na = np.random.randn(5)\n```\n这条语句生成的$a$的维度是$(5,)$。它既不是行向量也不是列向量，我们把$a$叫做\"rank1 array\"。这种定义会带来一些问题。例如我们对$a$进行转置，还是会得到$a$本身。\n所以，如果我们要定义$(5,1)$的列向量或者$(1,5)$的行向量，最好使用下来标准语句，避免使用\"rank1 array\"。\n```\na = np.random.randn(5,1)\nb = np.random.randn(1,5)\n```\n除此之外，我们还可以使用`assert`语句对向量或数组的维度进行判断，例如：\n```\nassert(a.shape == (5,1))\n```\n`assert`会对内嵌语句进行判断，即判断$a$的维度是不是$(5,1)$的。如果不是，则程序在此处停止。使用`assert`语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。\n另外，还可以使用`reshape`函数对数组设定所需的维度：\n```\na = a.reshape((5,1))\n```\n\n# **3.浅层神经网络**\n## **神经网络表示**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E7%A4%BA.JPG\" width=\"60%\" height=\"50%\">以上图为例，注意以下表示：\n- 输入层（第0层），隐藏层（第1层），输出层（第2层），是一个两层的神经网络。\n- $a^{[1]}$表示第一层的激活函数(输出)值,$a^{[1]}=[a^{[1]}_1,a^{[1]}_2,a^{[1]}_3,a^{[1]}_4]^T$,其维度为`$n^{[1]}*1$`，即`$4*1$`。\n- $W^{[1]}$表示第一层的权重值,其维度为`$n^{[1]}*n^{[0]}$`，即`$4*3$`。(注意)第$l$层的权重$W^{[l]}$的维度为：`$n^{[l]}*n^{[l-1]}$`。\n- $b^{[1]}$表示第一层的偏置值,其维度为`$n^{[1]}*1$`，即`$4*1$`。\n- 预测值$\\hat{y}$即为神经网络最后一层的激活函数值$a^{[2]}$，即$\\hat{y}=a^{[2]}$。\n\n## **计算神经网络的输出**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA1.JPG\" width=\"50%\" height=\"50%\">首先，神经网络中的每一个神经元，都可以看成一个逻辑回归单元，经过两个步骤来计算输出值$a$:\n- $z=w^Tx+b$\n- $a = \\sigma(z)$\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA2.JPG\" width=\"50%\" height=\"50%\">对于神经网络的输出，可向量化为（可通过维度检查进行确认）：\n- $z^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$\n- $a^{[1]}=\\sigma(z^{[1]})$\n- $z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=\\sigma(z^{[2]})$\n\n## **m个样本中的向量化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%A4%9A%E6%A0%B7%E6%9C%AC%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">多个样本的情况下，向量化神经网络输出的方式为：\n- $Z^{[1]}=W^{[1]}X+b^{[1]}$\n- $A^{[1]}=\\sigma(Z^{[1]})$\n- $Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\n- $A^{[2]}=\\sigma(Z^{[2]})$\n- **该向量化方式的核心思想是**：$X$,$Z^{[i]}$及$A^{[i]}$的横向维度表示训练样本，纵向维度表示隐藏单元。形象化示意见图。\n\n## **激活函数**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg\" width=\"50%\" height=\"50%\">\n- `sigmoid`函数和`tanh`函数都有一个问题，就是当$z$很大或很小时，激活函数的梯度接近于0，会拖慢梯度下降算法。\n- 研究表明，当隐藏层使用`tanh`函数几乎总比`sigmoid`函数的表现更好。因为`tanh`函数的激活函数值范在[-1,1]之间，激活函数的平均值接近于0，更方便下一层的学习。\n- 如果是二分类问题，即样本标签$y$为0或1，希望预测值$\\hat{y}$取值为$0\\leq\\hat{y}\\leq1$，则输出层的激活函数可选用`sigmoid`函数，**否则隐藏层和输出层都不使用`sigmoid`函数**。\n- `ReLU(rectified  linear unit)`激活函数在$z$大于零时梯度始终为1，在$z$小于零时梯度始终为0，$z$等于零时的梯度无定义，可以当成1也可以当成0，实际应用中并不影响（因为在程序中值为0.000...的可能性很小）。**当前隐藏层的默认激活函数选择为`ReLU`**。\n- `ReLU`激活函数能够保证$z$大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度（虽然左半边函数的导数等于0，但有足够多的隐藏单元使$z$大于0，因此大部分样本都会训练地很快）。\n- `ReLU`激活函数的缺点为当$z$小于零时，导数为0，这个缺点在实际应用中没什么影响。为了弥补这个缺点，出现了`Leaky ReLU`激活函数，能够保证$z$小于零时梯度不为0，不过实际中使用的频率不高。\n\n## **为什么需要非线性激活函数**\n以上的四种激活函数都是非线性的。不可使用线性的激活函数，原因如下。\n假设所有的激活函数都是线性的，那么，浅层神经网络的各层输出为：\n- $z^{[1]}=w^{[1]}x+b^{[1]}$\n- $a^{[1]}=g^{[1]}(z^{[1]})=z^{[1]}$\n- $z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=g^{[2]}(z^{[2]})=z^{[2]}$\n\n对$a^{[2]}$进行化简:\n$$a^{[2]}=z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}\\\\\n=w^{[2]}(w^{[1]}x+b^{[1]})+b^{[2]}\\\\\n=(w^{[2]}w^{[1]})x+(w^{[2]}b^{[1]}+b^{[2]})\\\\\n=w^{'}+b^{'}$$\n- 经过推导发现$a^{[2]}$仍是输入变量$x$的线性组合。这表明，即便是包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入$x$的线性模型。\n- 因此，**隐藏层的激活函数必须要是非线性的。线性隐藏层没有任何作用，层数再多也不行**。\n- 只有一种情况可以使用线性激活函数，即对于回归问题，当输出$\\hat{y}$是一个实数时，**输出层的激活函数可以使用线性函数**。如果输出$\\hat{y}$是非负数，则可以使用`ReLU`激活函数。具体情况，具体分析。\n\n## **激活函数的导数**\nsigmoid函数的导数：\n- $g(z)=\\frac{1}{1+e^{(-z)}}$\n- $g'(z)=\\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$\n\ntanh函数的导数：\n- $g(z)=\\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}$\n- $g'(z)=\\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$\n\nReLU函数的导数：\n- $g(z)=max(0,z)$\n- $$g'(z)=\\begin{cases} 0, & z<0\\\\  1, & z\\geq0 \\end{cases}$$\n\nLeaky ReLU函数的导数：\n- $g(z)=max(0.01z,z)$\n- $$g'(z)=\\begin{cases} 0.01, & z<0\\\\ 1, & z\\geq0 \\end{cases}$$\n\n## **神经网络的梯度下降法**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"50%\" height=\"50%\">单样本神经网络正向传播过程为：\n- $z^{[1]}=W^{[1]}x+b^{[1]}$\n- $a^{[1]}=g(z^{[1]})$\n- $z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=g(z^{[2]})$\n- 其中，$g(\\cdot)$表示激活函数。\n\n单样本神经网络反向传播过程（即链式法则求导过程）：\n- $da^{[2]}=-\\frac{y}{a}+\\frac{1-y}{1-a}$（不同损失函数，结果不同，可不给出具体形式）\n- $dz^{[2]}=a^{[2]}-y$（不同损失函数，结果不同，可不给出具体形式，一般只用$d_z$，不用$d_a$）\n- $dW^{[2]}=dz^{[2]}a^{[1]T}$\n- $db^{[2]}=dz^{[2]}$\n- $da^{[1]}=W^{[2]T}dz^{[2]}$\n- $dz^{[1]}=W^{[2]T}dz^{[2]}\\ast g^{[1]'}(z^{[1]})$\n- $dW^{[1]}=dz^{[1]}x^T$\n- $db^{[1]}=dz^{[1]}$\n- 其中，$*$为逐元素相乘。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"50%\" height=\"50%\">$m$个样本神经网络正向传播过程为：\n- $Z^{[1]}=W^{[1]}X+b^{[1]}$\n- $A^{[1]}=g(Z^{[1]})$\n- $Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\n- $A^{[2]}=g(Z^{[2]})$\n- 其中，$g(\\cdot)$表示激活函数。\n\n$m$个样本神经网络反向传播过程（即$m$个单样本的梯度求和）：\n- $dZ^{[2]}=A^{[2]}-Y$\n- $dW^{[2]}=\\frac1mdZ^{[2]}A^{[1]T}$\n- $db^{[2]}=\\frac1mnp.sum(dZ^{[2]},axis=1,keepdims=True)$\n- $dZ^{[1]}=W^{[2]T}dZ^{[2]}\\ast g^{[1]'}(Z^{[1]})$\n- $dW^{[1]}=\\frac1mdZ^{[1]}X^T$\n- $db^{[1]}=\\frac1mnp.sum(dZ^{[1]},axis=1,keepdims=True)$\n- 其中，$*$为逐元素相乘。\n\n该节的一个重要参考：[神经网络反向传播的数学原理](https://zhuanlan.zhihu.com/p/22473137)\n\n## **随机初始化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">\n神经网络模型中的参数权重$W$不能全部初始化为零。\n举例说明，如图，如果权重$W^{[1]}$和$W^{[2]}$都初始化为零，即：\n$$W^{[1]}= \\left[ \\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix} \\right]$$\n$$W^{[2]}= \\left[ \\begin{matrix} 0 & 0 \\end{matrix} \\right]$$\n\n- 这样使得$a_1^{[1]}=a_2^{[1]}$。进一步可得$dz_1^{[1]}=dz_2^{[1]}$ ，以及$dW_1^{[1]}=dW_2^{[1]}$。\n- 因此，每次迭代更新：$W^{[1]} = W^{[1]}-dW^{[1]}$。 $W^{[1]}$每一行都相等，即$W_1^{[1]}$和$W_2^{[1]}$都会相等。无论经过多少次迭代，隐藏层的神经元总是对称的。这样隐藏层设置多个神经元就没有任何意义了。\n- 参数$b$全部初始化为零，不会产生对称失效问题。\n- 解决方法：将$W$进行随机初始化($b$可初始化为零)来打破对称(break symmetry)。\n\nPython中可以使用如下语句进行$W$和$b$的随机初始化：\n```\nW_1 = np.random.randn(2,2)*0.01\nb_1 = np.zeros((2,1))\nW_2 = np.random.randn(1,2)*0.01\nb_2 = 0\n```\n- 在对$W^{[1]}$进行随机初始化时，乘以0.01的目的是尽量使得权重$W$初始化为比较小的值。\n- 之所以让$W$比较小，是因为如果使用`sigmoid`函数或者`tanh`函数作为激活函数时，若$W$较大，则训练的开始阶段$z$就比较大，由`sigmoid`函数或者`tanh`函数的曲线可以看出，当$|z|$过大时，其梯度近似为0，会使得训练过程十分缓慢。\n- 当然，如果未使用`sigmoid`激活函数或者`tanh`激活函数，该情况可能不明显。但是如果对于二分类问题，输出层是`sigmoid`函数，则对应的权重$W$最好初始化到比较小的值。\n\n# **4.深层神经网络**\n## **深层神经网络**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"70%\" height=\"50%\">深层神经网络其实就是包含更多隐藏层的神经网络。如上图所示，分别列举了逻辑回归、1个隐藏层的神经网络、2个隐藏层的神经网络和5个隐藏层的神经网络它们的模型结构。\n## **深层网络中的前向传播**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD.JPG\" width=\"50%\" height=\"50%\">以上面讲过的4层神经网络为例，推导一下深层神经网络的正向传播过程。\n单个样本下，深层神经网络的正向传播过程：\n- $l=1$：$z^{[1]}=W^{[1]}x+b^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$，$a^{[1]}=g^{[1]}(z^{[1]})$\n- $l=2$：$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$，$a^{[2]}=g^{[2]}(z^{[2]})$\n- $l=3$：$z^{[3]}=W^{[3]}a^{[2]}+b^{[3]}$，$a^{[3]}=g^{[3]}(z^{[3]})$\n- $l=4$：$z^{[4]}=W^{[4]}a^{[3]}+b^{[4]}$，$a^{[4]}=g^{[4]}(z^{[4]})$\n\n$m$个样本下，深层神经网络的正向传播过程：\n- $l=1$：$Z^{[1]}=W^{[1]}X+b^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$，$A^{[1]}=g^{[1]}(Z^{[1]})$\n- $l=2$：$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$，$A^{[2]}=g^{[2]}(Z^{[2]})$\n- $l=3$：$Z^{[3]}=W^{[3]}A^{[2]}+b^{[3]}$，$A^{[3]}=g^{[3]}(Z^{[3]})$\n- $l=4$：$Z^{[4]}=W^{[4]}A^{[3]}+b^{[4]}$，$A^{[4]}=g^{[4]}(Z^{[4]})$\n\n综上所述，对于第$l$层，其正向传播过程的$Z^{[l]}$和$A^{[l]}$可以表示为：\n- $Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$\n- $A^{[l]}=g^{[l]}(Z^{[l]})$\n- 其中，$l=1,\\cdots,L$\n\n## **矩阵维度检查**\n对于单个训练样本，输入$x$的维度是:\n- $x:(n^{[0]},1)$。\n\n神经网络的参数$W^{[l]}$和$b^{[l]}$的维度分别是：\n- $W^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $b^{[l]}:\\ (n^{[l]},1)$\n- 其中，$l=1,\\cdots,L$，$n^{[l]}$和$n^{[l-1]}$分别表示第$l$层和$l-1$层中所含神经元的个数。$n^{[0]}=n_x$，表示输入尺寸。\n\n正向传播过程中的$z^{[l]}$和$a^{[l]}$的维度分别是：\n- $z^{[l]}:\\ (n^{[l]},1)$\n- $a^{[l]}:\\ (n^{[l]},1)$\n- $z^{[l]}$和$a^{[l]}$的维度是一样的，且$dz^{[l]}$和$da^{[l]}$的维度均与$z^{[l]}$和$a^{[l]}$的维度一致。\n\n反向传播过程中的$dW^{[l]}$和$db^{[l]}$的维度分别是：\n- $dW^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $db^{[l]}:\\ (n^{[l]},1)$\n- 注意到， $dW^{[l]}$与$W^{[l]}$的维度相同，$db^{[l]}$与$b^{[l]}$的维度相同。\n\n\n\n对于$m$个训练样本，输入矩阵$X$的维度是：\n- $X:(n^{[0]},m)$。\n\n参数$W^{[l]}$和$b^{[l]}$的维度与只有单个样本是一致的：\n- $W^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $b^{[l]}:\\ (n^{[l]},1)$\n- 只不过在运算$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$中，$b^{[l]}$会被当成$(n^{[l]},m)$矩阵进行运算，这是因为python的广播性质，且 $b^{[l]}$每一列向量都是一样的。\n- $dW^{[l]}$和$db^{[l]}$的维度分别与$W^{[l]}$和$b^{[l]}$一致。\n\n但是，$Z^{[l]}$ 和$A^{[l]}$的维度发生了变化：\n- $Z^{[l]}:\\ (n^{[l]},m)$\n- $A^{[l]}:\\ (n^{[l]},m)$\n- $dZ^{[l]}$和$dA^{[l]}$的维度分别与$Z^{[l]}$和$A^{[l]}$一致。\n\n## **为什么使用深层的神经网络**\n- 神经网络层数越深，能够提取到的特征越复杂。\n- 以CNN为例，低层网络提取到简单的局部特征，深层网络提取到复杂的全局特征。层数越深，提取到的特征越复杂。\n- 以RNN为例，也是如此。\n\n## **搭建深层神经网络块**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97.jpg\" width=\"50%\" height=\"50%\">\n上图为能表示出深层神经网络正向传播和反向传播过程的块(block)图。\n如图所示，对于第$l$层来说，正向传播过程中：\n- 输入：$a^{[l-1]}$\n- 输出：$a^{[l]}$\n- 参数：$W^{[l]},b^{[l]}$\n- 缓存变量： $z^{[l]}$\n\n反向传播过程中：\n- 输入：$da^{[l]}$\n- 输出：$da^{[l-1]},dW^{[l]},db^{[l]}$\n- 参数：$W^{[l]},b^{[l]}$\n\n用块图构建出一个深层神经网络的正向传播过程和反向传播过程，如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/l%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97%E5%9B%BE.jpg\" width=\"100%\" height=\"50%\">\n\n## **正向传播和反向传播**\n\n对于单个样本，第$l$层的正向传播：\n- 输入：$a^{[l-1]}$\n- 输出：$a^{[l]}$，缓存变量：$z^{[l]}$\n\n具体表达式如下：\n- $z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}$\n- $a^{[l]}=g^{[l]}(z^{[l]})$\n\n$m$个训练样本，向量化形式为：\n- $Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$\n- $A^{[l]}=g^{[l]}(Z^{[l]})$\n\n对于单个样本，第$l$层的反向传播：\n- 输入：$da^{[l]}$\n- 输出：$da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$。\n\n具体表达式如下：\n- $dz^{[l]}=da^{[l]}\\ast g^{[l]'}(z^{[l]})$\n- $dW^{[l]}=dz^{[l]}\\cdot a^{[l-1]}$\n- $db^{[l]}=dz^{[l]}$\n- $da^{[l-1]}=W^{[l]T}\\cdot dz^{[l]}$\n- 由上述第四个表达式可得$da^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}$，将$da^{[l]}$代入第一个表达式中可以得到：$dz^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}\\ast g^{[l]'}(z^{[l]})$该式非常重要，反映了$dz^{[l+1]}$与$dz^{[l]}$的递推关系。\n\n$m$个训练样本，向量化形式为：\n- $dZ^{[l]}=dA^{[l]}\\ast g^{[l]'}(Z^{[l]})$\n- $dW^{[l]}=\\frac1mdZ^{[l]}\\cdot A^{[l-1]T}$\n- $db^{[l]}=\\frac1mnp.sum(dZ^{[l]},axis=1,keepdims=True)$\n- $dA^{[l-1]}=W^{[l]T}\\cdot dZ^{[l]}$\n- $dZ^{[l]}=W^{[l+1]T}\\cdot dZ^{[l+1]}\\ast g^{[l]'}(Z^{[l]})$\n\n## **参数和超参数**\n对于神经网络中的参数(parameters)和超参数(hyperparameters)的概念：\n- 神经网络中的参数就是我们熟悉的$W^{[l]}$和$b^{[l]}$。\n- 而超参数则是例如学习速率$\\alpha$，训练迭代次数$N$，神经网络层数$L$，各层神经元个数$n^{[l]}$，甚至激活函数$g(z)$的种类等。\n- 之所以**叫做超参数的原因**是它们高于参数，决定了参数$W^{[l]}$和$b^{[l]}$的取值。\n\n\n","source":"_posts/深度学习课程(一)神经网络与深度学习.md","raw":"---\ntitle: 深度学习课程(一)神经网络与深度学习\nmathjax: true\ntop: true\ndate: 2017-12-21 15:40:50\ncategories: \n- 深度学习\ntags:\n---\n# **1.深度学习介绍**\n## **用神经网络进行监督学习**\n到目前为止，由神经网络创造的经济价值几乎都是基于一种机器学习方法——监督学习。\n下面是目前主要的几种应用示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.JPG\" width=\"50%\" height=\"50%\">不同的情况，一般使用不同的网络模型：\n- 对于房价预测和在线广告，使用标准的神经网络模型；\n- 对于计算机视觉领域，使用CNN(convolution neural network)；\n- 对于序列数据，如音频(如语音识别)和语言(如机器翻译)，使用RNN(recurrent neural network)。\n- 对于更复杂的应用，如无人驾驶，使用混合的神经网络结构。\n\n<!-- more --> \n\n神经网络类型示例:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B%E4%B8%BE%E4%BE%8B.JPG\" width=\"60%\" height=\"50%\">结构化数据与非结构化数据：\n数据类型一般分为两种：结构化数据和非结构化数据。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%8E%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE.JPG\" width=\"70%\" height=\"50%\">\n\n## **为什么深度学习会兴起？**\n三个要素：数据量、计算能力、算法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%B4%E8%B5%B7.jpg\" width=\"60%\" height=\"50%\">\n\n# **2.神经网络基础**\n## **2.1 将逻辑回归作为一个神经网络**\n### **深度学习符号标准**\n该专项课程，规范了深度学习所用到的所有符号的表示方法：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%861.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%862.JPG\" width=\"50%\" height=\"50%\">\n### **二元分类**\n二元分类(Binary Classification)就是输出`$y \\in \\{0,1\\}$`。\n以一个图像识别问题为例，判断图片中是否有猫存在，0代表不是猫，1代表是猫。\n### **逻辑回归**\n- Given $x$,want $\\hat{y}=P(y=1|x)$，其中$x\\in R^{n_x}$,$0\\leq\\hat{y}\\leq1$\n- 参数：$w\\in R^{n_x}$,$b\\in R$\n- 输出：$\\hat{y}=\\sigma(w^Tx+b)$，其中$\\sigma()$为sigmoid函数，$\\sigma(z)=\\frac{1}{1+e^{-z}}$。\n- 注意：本课程中不采用`$x_0=1,x\\in R^{n_x+1}$`，`$\\hat{y}=\\sigma(\\theta^Tx)$`,`$\\theta=[\\theta_0,\\theta_1,...,\\theta_{n_x}]^T$`的做法。\n\n### **逻辑回归代价函数**\n- Given `$\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}$`, want $\\hat{y}^{(i)}=y^{(i)}$\n- Loss Function: $L(\\hat{y},y)=-(y\\log\\hat{y}+(1-y)\\log(1-\\hat{y}))$\n- Cost Function: $$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})\\\\\n=-\\frac{1}{m} \\sum\\limits_{i=1}^m [y^{(i)}\\log\\hat{y}^{(i)}+(1-y^{(i)})\\log(1-\\hat{y}^{(i)})]$$\n\n### **梯度下降**\n- want to find $w$,$b$ that minimize $J(w,b)$\n- $ w:= w-\\alpha\\frac{\\partial}{\\partial w}J(w,b)$\n- $ b:= b-\\alpha\\frac{\\partial}{\\partial b}J(w,b)$\n\n### **通过计算图求导数**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E5%AF%BC%E6%95%B0.JPG\" width=\"60%\" height=\"50%\">\n### **逻辑回归中的梯度下降法**\n逻辑回归总结:\n- $z=w^Tx+b$\n- $\\hat{y}=a=\\sigma(z)$\n- $L(a,y)=-[y\\log(a)+(1-y)\\log(1-a)]$\n\n逻辑回归求导（通过计算图）:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E5%AF%BC.JPG\" width=\"60%\" height=\"50%\">\n- $d_a=\\frac{d}{d_a}L(a,y)=-\\frac{y}{a}+\\frac{1-y}{1-a}$\n- $d_z=\\frac{d}{d_z}L(a,y)= d_a \\cdot \\frac{d_a}{d_z}=(-\\frac{y}{a}+\\frac{1-y}{1-a}) \\cdot a(1-a)=a-y$\n- $d_{w_1}=\\frac{\\partial L}{\\partial w_1}=d_z \\cdot \\frac{\\partial z}{\\partial w_1}=d_z \\cdot x_1$\n- $d_{w_2}=\\frac{\\partial L}{\\partial w_2}=d_z \\cdot \\frac{\\partial z}{\\partial w_2}=d_z \\cdot x_2$\n- $d_{b}=\\frac{\\partial L}{\\partial b}=d_z \\cdot \\frac{\\partial z}{\\partial b}=d_z$\n\n### **m个样本下的梯度下降**\n因为：$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(a^{(i)},y^{(i)})$\n\n故:\n$$\\frac{\\partial}{\\partial w_1}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_1}L(a^{(i)},y^{(i)}) = \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_1}}^{(i)}=\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1$$\n$$\\frac{\\partial}{\\partial w_2}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_2}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_2}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2$$\n$$\\frac{\\partial}{\\partial b}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial b}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{b}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)}$$\n\n## **2.2 python和向量化**\n### **向量化**\n神经网络编程指南：**无论何时，避免显式的for循环**\n举例：\n```Python\n# 若a,b,c为向量或矩阵\nc = np.dot(a,b)\nb = np.exp(a)\nb = np.log(a)\nb = np.abs(a)\nb = np.maximum(a,0)\nb = a**2\nb = 1/a\n```\n### **向量化逻辑回归**\n- $X_{(n_x*m)}=[x^{(1)},x^{(2)},...,x^{(m)}]$\n- $ Z_{(1*m)}=[z^{(1)},z^{(2)},...,z^{(m)}]=w^T X+ [b,...,b]$\n对应代码：`Z=np.dot(w.T,X)+b #broadcasting`\n- $A=[a^{(1)},a^{(2)},...,a^{(m)}]=[\\sigma(z^{(1)}),\\sigma(z^{(2)}),...,\\sigma(z^{(m)})]=\\sigma(Z)$\n对应代码：`A=sigmoid(Z)`\n\n### **向量化逻辑回归中的梯度计算**\n\n- ${d_{z}}^{(i)}=a^{(i)}-y^{(i)}$\n- 故$$d_{Z_{(1*m)}}=[{d_{z}}^{(1)},{d_{z}}^{(2)},...,{d_{z}}^{(m)}]$$\n- $A=[a^{(1)},a^{(2)},...,a^{(m)}],Y=[y^{(1)},y^{(2)},...,y^{(m)}]$\n- 故$$d_{Z_{(1*m)}}=A-Y=[a^{(1)}-y^{(1)}, a^{(2)}-y^{(2)},..., a^{(m)}-y^{(m)}]$$\n- $$d_b=\\frac{1}{m}\\sum_{i=1}^{m} {d_z}^{(i)}=\\frac{1}{m}np.sum(d_Z)$$\n- $$d_w= \\begin{bmatrix} d_{w_1} \\\\d_{w_2} \\\\ ... \\\\d_{w_{n_x}} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1 \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2 \\\\ ... \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_{n_x} \\end{bmatrix} \\\\\n=\\frac{1}{m} X {d_{Z}}^T \n=\\frac{1}{m}[x^{(1)} ,x^{(2)},...,x^{(m)}] \\begin{bmatrix} {d_{z}}^{(1)} \\\\ {d_{z}}^{(2)}\\\\ ...\\\\{d_{z}}^{(m)}\\end{bmatrix}$$\n\n### **逻辑回归算法流程（伪代码）**\n非向量化：\n```\nJ=0, dw1=0, dw2=0,db=0\nfor i = 1 to m\n\tz(i) = wx(i)+b\n\ta(i) = sigmoid(z(i))\n\tJ += -[y(i)log(a(i))+(1-y(i)）log(1-a(i))\n\tdz(i) = a(i)-y(i)\n\tdw1 += x1(i)dz(i)\n\tdw2 += x2(i)dz(i)\n\tdb += dz(i)\nJ /= m\ndw1 /= m\ndw2 /= m\ndb /= m\n```\n向量化：\n```\nfor iter in range(1000):\n    Z = np.dot(w.T,X) + b\n    A = sigmoid(Z)\n    dZ = A-Y\n    dw = 1/m*np.dot(X,dZ.T)\n    db = 1/m*np.sum(dZ)\n    w = w - alpha*dw\n    b = b - alpha*db\n```\n### **python中的广播**\n广播(broadcasting)是Python使用中的一种技巧，在Python中可以对不同维度的矩阵进行四则混合运算，前提条件是至少有一个维度是相同的。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD1.jpg\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD2.JPG\" width=\"50%\" height=\"50%\">\n\n### **关于python/numpy中的向量说明**\nPython中，如果用下列语句来定义一个向量：\n```\na = np.random.randn(5)\n```\n这条语句生成的$a$的维度是$(5,)$。它既不是行向量也不是列向量，我们把$a$叫做\"rank1 array\"。这种定义会带来一些问题。例如我们对$a$进行转置，还是会得到$a$本身。\n所以，如果我们要定义$(5,1)$的列向量或者$(1,5)$的行向量，最好使用下来标准语句，避免使用\"rank1 array\"。\n```\na = np.random.randn(5,1)\nb = np.random.randn(1,5)\n```\n除此之外，我们还可以使用`assert`语句对向量或数组的维度进行判断，例如：\n```\nassert(a.shape == (5,1))\n```\n`assert`会对内嵌语句进行判断，即判断$a$的维度是不是$(5,1)$的。如果不是，则程序在此处停止。使用`assert`语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。\n另外，还可以使用`reshape`函数对数组设定所需的维度：\n```\na = a.reshape((5,1))\n```\n\n# **3.浅层神经网络**\n## **神经网络表示**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E7%A4%BA.JPG\" width=\"60%\" height=\"50%\">以上图为例，注意以下表示：\n- 输入层（第0层），隐藏层（第1层），输出层（第2层），是一个两层的神经网络。\n- $a^{[1]}$表示第一层的激活函数(输出)值,$a^{[1]}=[a^{[1]}_1,a^{[1]}_2,a^{[1]}_3,a^{[1]}_4]^T$,其维度为`$n^{[1]}*1$`，即`$4*1$`。\n- $W^{[1]}$表示第一层的权重值,其维度为`$n^{[1]}*n^{[0]}$`，即`$4*3$`。(注意)第$l$层的权重$W^{[l]}$的维度为：`$n^{[l]}*n^{[l-1]}$`。\n- $b^{[1]}$表示第一层的偏置值,其维度为`$n^{[1]}*1$`，即`$4*1$`。\n- 预测值$\\hat{y}$即为神经网络最后一层的激活函数值$a^{[2]}$，即$\\hat{y}=a^{[2]}$。\n\n## **计算神经网络的输出**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA1.JPG\" width=\"50%\" height=\"50%\">首先，神经网络中的每一个神经元，都可以看成一个逻辑回归单元，经过两个步骤来计算输出值$a$:\n- $z=w^Tx+b$\n- $a = \\sigma(z)$\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA2.JPG\" width=\"50%\" height=\"50%\">对于神经网络的输出，可向量化为（可通过维度检查进行确认）：\n- $z^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$\n- $a^{[1]}=\\sigma(z^{[1]})$\n- $z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=\\sigma(z^{[2]})$\n\n## **m个样本中的向量化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%A4%9A%E6%A0%B7%E6%9C%AC%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">多个样本的情况下，向量化神经网络输出的方式为：\n- $Z^{[1]}=W^{[1]}X+b^{[1]}$\n- $A^{[1]}=\\sigma(Z^{[1]})$\n- $Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\n- $A^{[2]}=\\sigma(Z^{[2]})$\n- **该向量化方式的核心思想是**：$X$,$Z^{[i]}$及$A^{[i]}$的横向维度表示训练样本，纵向维度表示隐藏单元。形象化示意见图。\n\n## **激活函数**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg\" width=\"50%\" height=\"50%\">\n- `sigmoid`函数和`tanh`函数都有一个问题，就是当$z$很大或很小时，激活函数的梯度接近于0，会拖慢梯度下降算法。\n- 研究表明，当隐藏层使用`tanh`函数几乎总比`sigmoid`函数的表现更好。因为`tanh`函数的激活函数值范在[-1,1]之间，激活函数的平均值接近于0，更方便下一层的学习。\n- 如果是二分类问题，即样本标签$y$为0或1，希望预测值$\\hat{y}$取值为$0\\leq\\hat{y}\\leq1$，则输出层的激活函数可选用`sigmoid`函数，**否则隐藏层和输出层都不使用`sigmoid`函数**。\n- `ReLU(rectified  linear unit)`激活函数在$z$大于零时梯度始终为1，在$z$小于零时梯度始终为0，$z$等于零时的梯度无定义，可以当成1也可以当成0，实际应用中并不影响（因为在程序中值为0.000...的可能性很小）。**当前隐藏层的默认激活函数选择为`ReLU`**。\n- `ReLU`激活函数能够保证$z$大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度（虽然左半边函数的导数等于0，但有足够多的隐藏单元使$z$大于0，因此大部分样本都会训练地很快）。\n- `ReLU`激活函数的缺点为当$z$小于零时，导数为0，这个缺点在实际应用中没什么影响。为了弥补这个缺点，出现了`Leaky ReLU`激活函数，能够保证$z$小于零时梯度不为0，不过实际中使用的频率不高。\n\n## **为什么需要非线性激活函数**\n以上的四种激活函数都是非线性的。不可使用线性的激活函数，原因如下。\n假设所有的激活函数都是线性的，那么，浅层神经网络的各层输出为：\n- $z^{[1]}=w^{[1]}x+b^{[1]}$\n- $a^{[1]}=g^{[1]}(z^{[1]})=z^{[1]}$\n- $z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=g^{[2]}(z^{[2]})=z^{[2]}$\n\n对$a^{[2]}$进行化简:\n$$a^{[2]}=z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}\\\\\n=w^{[2]}(w^{[1]}x+b^{[1]})+b^{[2]}\\\\\n=(w^{[2]}w^{[1]})x+(w^{[2]}b^{[1]}+b^{[2]})\\\\\n=w^{'}+b^{'}$$\n- 经过推导发现$a^{[2]}$仍是输入变量$x$的线性组合。这表明，即便是包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入$x$的线性模型。\n- 因此，**隐藏层的激活函数必须要是非线性的。线性隐藏层没有任何作用，层数再多也不行**。\n- 只有一种情况可以使用线性激活函数，即对于回归问题，当输出$\\hat{y}$是一个实数时，**输出层的激活函数可以使用线性函数**。如果输出$\\hat{y}$是非负数，则可以使用`ReLU`激活函数。具体情况，具体分析。\n\n## **激活函数的导数**\nsigmoid函数的导数：\n- $g(z)=\\frac{1}{1+e^{(-z)}}$\n- $g'(z)=\\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$\n\ntanh函数的导数：\n- $g(z)=\\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}$\n- $g'(z)=\\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$\n\nReLU函数的导数：\n- $g(z)=max(0,z)$\n- $$g'(z)=\\begin{cases} 0, & z<0\\\\  1, & z\\geq0 \\end{cases}$$\n\nLeaky ReLU函数的导数：\n- $g(z)=max(0.01z,z)$\n- $$g'(z)=\\begin{cases} 0.01, & z<0\\\\ 1, & z\\geq0 \\end{cases}$$\n\n## **神经网络的梯度下降法**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"50%\" height=\"50%\">单样本神经网络正向传播过程为：\n- $z^{[1]}=W^{[1]}x+b^{[1]}$\n- $a^{[1]}=g(z^{[1]})$\n- $z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$\n- $a^{[2]}=g(z^{[2]})$\n- 其中，$g(\\cdot)$表示激活函数。\n\n单样本神经网络反向传播过程（即链式法则求导过程）：\n- $da^{[2]}=-\\frac{y}{a}+\\frac{1-y}{1-a}$（不同损失函数，结果不同，可不给出具体形式）\n- $dz^{[2]}=a^{[2]}-y$（不同损失函数，结果不同，可不给出具体形式，一般只用$d_z$，不用$d_a$）\n- $dW^{[2]}=dz^{[2]}a^{[1]T}$\n- $db^{[2]}=dz^{[2]}$\n- $da^{[1]}=W^{[2]T}dz^{[2]}$\n- $dz^{[1]}=W^{[2]T}dz^{[2]}\\ast g^{[1]'}(z^{[1]})$\n- $dW^{[1]}=dz^{[1]}x^T$\n- $db^{[1]}=dz^{[1]}$\n- 其中，$*$为逐元素相乘。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"50%\" height=\"50%\">$m$个样本神经网络正向传播过程为：\n- $Z^{[1]}=W^{[1]}X+b^{[1]}$\n- $A^{[1]}=g(Z^{[1]})$\n- $Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\n- $A^{[2]}=g(Z^{[2]})$\n- 其中，$g(\\cdot)$表示激活函数。\n\n$m$个样本神经网络反向传播过程（即$m$个单样本的梯度求和）：\n- $dZ^{[2]}=A^{[2]}-Y$\n- $dW^{[2]}=\\frac1mdZ^{[2]}A^{[1]T}$\n- $db^{[2]}=\\frac1mnp.sum(dZ^{[2]},axis=1,keepdims=True)$\n- $dZ^{[1]}=W^{[2]T}dZ^{[2]}\\ast g^{[1]'}(Z^{[1]})$\n- $dW^{[1]}=\\frac1mdZ^{[1]}X^T$\n- $db^{[1]}=\\frac1mnp.sum(dZ^{[1]},axis=1,keepdims=True)$\n- 其中，$*$为逐元素相乘。\n\n该节的一个重要参考：[神经网络反向传播的数学原理](https://zhuanlan.zhihu.com/p/22473137)\n\n## **随机初始化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">\n神经网络模型中的参数权重$W$不能全部初始化为零。\n举例说明，如图，如果权重$W^{[1]}$和$W^{[2]}$都初始化为零，即：\n$$W^{[1]}= \\left[ \\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix} \\right]$$\n$$W^{[2]}= \\left[ \\begin{matrix} 0 & 0 \\end{matrix} \\right]$$\n\n- 这样使得$a_1^{[1]}=a_2^{[1]}$。进一步可得$dz_1^{[1]}=dz_2^{[1]}$ ，以及$dW_1^{[1]}=dW_2^{[1]}$。\n- 因此，每次迭代更新：$W^{[1]} = W^{[1]}-dW^{[1]}$。 $W^{[1]}$每一行都相等，即$W_1^{[1]}$和$W_2^{[1]}$都会相等。无论经过多少次迭代，隐藏层的神经元总是对称的。这样隐藏层设置多个神经元就没有任何意义了。\n- 参数$b$全部初始化为零，不会产生对称失效问题。\n- 解决方法：将$W$进行随机初始化($b$可初始化为零)来打破对称(break symmetry)。\n\nPython中可以使用如下语句进行$W$和$b$的随机初始化：\n```\nW_1 = np.random.randn(2,2)*0.01\nb_1 = np.zeros((2,1))\nW_2 = np.random.randn(1,2)*0.01\nb_2 = 0\n```\n- 在对$W^{[1]}$进行随机初始化时，乘以0.01的目的是尽量使得权重$W$初始化为比较小的值。\n- 之所以让$W$比较小，是因为如果使用`sigmoid`函数或者`tanh`函数作为激活函数时，若$W$较大，则训练的开始阶段$z$就比较大，由`sigmoid`函数或者`tanh`函数的曲线可以看出，当$|z|$过大时，其梯度近似为0，会使得训练过程十分缓慢。\n- 当然，如果未使用`sigmoid`激活函数或者`tanh`激活函数，该情况可能不明显。但是如果对于二分类问题，输出层是`sigmoid`函数，则对应的权重$W$最好初始化到比较小的值。\n\n# **4.深层神经网络**\n## **深层神经网络**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"70%\" height=\"50%\">深层神经网络其实就是包含更多隐藏层的神经网络。如上图所示，分别列举了逻辑回归、1个隐藏层的神经网络、2个隐藏层的神经网络和5个隐藏层的神经网络它们的模型结构。\n## **深层网络中的前向传播**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD.JPG\" width=\"50%\" height=\"50%\">以上面讲过的4层神经网络为例，推导一下深层神经网络的正向传播过程。\n单个样本下，深层神经网络的正向传播过程：\n- $l=1$：$z^{[1]}=W^{[1]}x+b^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$，$a^{[1]}=g^{[1]}(z^{[1]})$\n- $l=2$：$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$，$a^{[2]}=g^{[2]}(z^{[2]})$\n- $l=3$：$z^{[3]}=W^{[3]}a^{[2]}+b^{[3]}$，$a^{[3]}=g^{[3]}(z^{[3]})$\n- $l=4$：$z^{[4]}=W^{[4]}a^{[3]}+b^{[4]}$，$a^{[4]}=g^{[4]}(z^{[4]})$\n\n$m$个样本下，深层神经网络的正向传播过程：\n- $l=1$：$Z^{[1]}=W^{[1]}X+b^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$，$A^{[1]}=g^{[1]}(Z^{[1]})$\n- $l=2$：$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$，$A^{[2]}=g^{[2]}(Z^{[2]})$\n- $l=3$：$Z^{[3]}=W^{[3]}A^{[2]}+b^{[3]}$，$A^{[3]}=g^{[3]}(Z^{[3]})$\n- $l=4$：$Z^{[4]}=W^{[4]}A^{[3]}+b^{[4]}$，$A^{[4]}=g^{[4]}(Z^{[4]})$\n\n综上所述，对于第$l$层，其正向传播过程的$Z^{[l]}$和$A^{[l]}$可以表示为：\n- $Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$\n- $A^{[l]}=g^{[l]}(Z^{[l]})$\n- 其中，$l=1,\\cdots,L$\n\n## **矩阵维度检查**\n对于单个训练样本，输入$x$的维度是:\n- $x:(n^{[0]},1)$。\n\n神经网络的参数$W^{[l]}$和$b^{[l]}$的维度分别是：\n- $W^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $b^{[l]}:\\ (n^{[l]},1)$\n- 其中，$l=1,\\cdots,L$，$n^{[l]}$和$n^{[l-1]}$分别表示第$l$层和$l-1$层中所含神经元的个数。$n^{[0]}=n_x$，表示输入尺寸。\n\n正向传播过程中的$z^{[l]}$和$a^{[l]}$的维度分别是：\n- $z^{[l]}:\\ (n^{[l]},1)$\n- $a^{[l]}:\\ (n^{[l]},1)$\n- $z^{[l]}$和$a^{[l]}$的维度是一样的，且$dz^{[l]}$和$da^{[l]}$的维度均与$z^{[l]}$和$a^{[l]}$的维度一致。\n\n反向传播过程中的$dW^{[l]}$和$db^{[l]}$的维度分别是：\n- $dW^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $db^{[l]}:\\ (n^{[l]},1)$\n- 注意到， $dW^{[l]}$与$W^{[l]}$的维度相同，$db^{[l]}$与$b^{[l]}$的维度相同。\n\n\n\n对于$m$个训练样本，输入矩阵$X$的维度是：\n- $X:(n^{[0]},m)$。\n\n参数$W^{[l]}$和$b^{[l]}$的维度与只有单个样本是一致的：\n- $W^{[l]}:\\ (n^{[l]},n^{[l-1]})$\n- $b^{[l]}:\\ (n^{[l]},1)$\n- 只不过在运算$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$中，$b^{[l]}$会被当成$(n^{[l]},m)$矩阵进行运算，这是因为python的广播性质，且 $b^{[l]}$每一列向量都是一样的。\n- $dW^{[l]}$和$db^{[l]}$的维度分别与$W^{[l]}$和$b^{[l]}$一致。\n\n但是，$Z^{[l]}$ 和$A^{[l]}$的维度发生了变化：\n- $Z^{[l]}:\\ (n^{[l]},m)$\n- $A^{[l]}:\\ (n^{[l]},m)$\n- $dZ^{[l]}$和$dA^{[l]}$的维度分别与$Z^{[l]}$和$A^{[l]}$一致。\n\n## **为什么使用深层的神经网络**\n- 神经网络层数越深，能够提取到的特征越复杂。\n- 以CNN为例，低层网络提取到简单的局部特征，深层网络提取到复杂的全局特征。层数越深，提取到的特征越复杂。\n- 以RNN为例，也是如此。\n\n## **搭建深层神经网络块**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97.jpg\" width=\"50%\" height=\"50%\">\n上图为能表示出深层神经网络正向传播和反向传播过程的块(block)图。\n如图所示，对于第$l$层来说，正向传播过程中：\n- 输入：$a^{[l-1]}$\n- 输出：$a^{[l]}$\n- 参数：$W^{[l]},b^{[l]}$\n- 缓存变量： $z^{[l]}$\n\n反向传播过程中：\n- 输入：$da^{[l]}$\n- 输出：$da^{[l-1]},dW^{[l]},db^{[l]}$\n- 参数：$W^{[l]},b^{[l]}$\n\n用块图构建出一个深层神经网络的正向传播过程和反向传播过程，如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/l%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97%E5%9B%BE.jpg\" width=\"100%\" height=\"50%\">\n\n## **正向传播和反向传播**\n\n对于单个样本，第$l$层的正向传播：\n- 输入：$a^{[l-1]}$\n- 输出：$a^{[l]}$，缓存变量：$z^{[l]}$\n\n具体表达式如下：\n- $z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}$\n- $a^{[l]}=g^{[l]}(z^{[l]})$\n\n$m$个训练样本，向量化形式为：\n- $Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$\n- $A^{[l]}=g^{[l]}(Z^{[l]})$\n\n对于单个样本，第$l$层的反向传播：\n- 输入：$da^{[l]}$\n- 输出：$da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$。\n\n具体表达式如下：\n- $dz^{[l]}=da^{[l]}\\ast g^{[l]'}(z^{[l]})$\n- $dW^{[l]}=dz^{[l]}\\cdot a^{[l-1]}$\n- $db^{[l]}=dz^{[l]}$\n- $da^{[l-1]}=W^{[l]T}\\cdot dz^{[l]}$\n- 由上述第四个表达式可得$da^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}$，将$da^{[l]}$代入第一个表达式中可以得到：$dz^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}\\ast g^{[l]'}(z^{[l]})$该式非常重要，反映了$dz^{[l+1]}$与$dz^{[l]}$的递推关系。\n\n$m$个训练样本，向量化形式为：\n- $dZ^{[l]}=dA^{[l]}\\ast g^{[l]'}(Z^{[l]})$\n- $dW^{[l]}=\\frac1mdZ^{[l]}\\cdot A^{[l-1]T}$\n- $db^{[l]}=\\frac1mnp.sum(dZ^{[l]},axis=1,keepdims=True)$\n- $dA^{[l-1]}=W^{[l]T}\\cdot dZ^{[l]}$\n- $dZ^{[l]}=W^{[l+1]T}\\cdot dZ^{[l+1]}\\ast g^{[l]'}(Z^{[l]})$\n\n## **参数和超参数**\n对于神经网络中的参数(parameters)和超参数(hyperparameters)的概念：\n- 神经网络中的参数就是我们熟悉的$W^{[l]}$和$b^{[l]}$。\n- 而超参数则是例如学习速率$\\alpha$，训练迭代次数$N$，神经网络层数$L$，各层神经元个数$n^{[l]}$，甚至激活函数$g(z)$的种类等。\n- 之所以**叫做超参数的原因**是它们高于参数，决定了参数$W^{[l]}$和$b^{[l]}$的取值。\n\n\n","slug":"深度学习课程(一)神经网络与深度学习","published":1,"updated":"2018-01-31T13:41:09.671Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w2q005uqslpy6wjd7po","content":"<h1 id=\"1-深度学习介绍\"><a href=\"#1-深度学习介绍\" class=\"headerlink\" title=\"1.深度学习介绍\"></a><strong>1.深度学习介绍</strong></h1><h2 id=\"用神经网络进行监督学习\"><a href=\"#用神经网络进行监督学习\" class=\"headerlink\" title=\"用神经网络进行监督学习\"></a><strong>用神经网络进行监督学习</strong></h2><p>到目前为止，由神经网络创造的经济价值几乎都是基于一种机器学习方法——监督学习。<br>下面是目前主要的几种应用示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.JPG\" width=\"50%\" height=\"50%\">不同的情况，一般使用不同的网络模型：</p>\n<ul>\n<li>对于房价预测和在线广告，使用标准的神经网络模型；</li>\n<li>对于计算机视觉领域，使用CNN(convolution neural network)；</li>\n<li>对于序列数据，如音频(如语音识别)和语言(如机器翻译)，使用RNN(recurrent neural network)。</li>\n<li>对于更复杂的应用，如无人驾驶，使用混合的神经网络结构。</li>\n</ul>\n<a id=\"more\"></a> \n<p>神经网络类型示例:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B%E4%B8%BE%E4%BE%8B.JPG\" width=\"60%\" height=\"50%\">结构化数据与非结构化数据：<br>数据类型一般分为两种：结构化数据和非结构化数据。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%8E%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE.JPG\" width=\"70%\" height=\"50%\"></p>\n<h2 id=\"为什么深度学习会兴起？\"><a href=\"#为什么深度学习会兴起？\" class=\"headerlink\" title=\"为什么深度学习会兴起？\"></a><strong>为什么深度学习会兴起？</strong></h2><p>三个要素：数据量、计算能力、算法<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%B4%E8%B5%B7.jpg\" width=\"60%\" height=\"50%\"></p>\n<h1 id=\"2-神经网络基础\"><a href=\"#2-神经网络基础\" class=\"headerlink\" title=\"2.神经网络基础\"></a><strong>2.神经网络基础</strong></h1><h2 id=\"2-1-将逻辑回归作为一个神经网络\"><a href=\"#2-1-将逻辑回归作为一个神经网络\" class=\"headerlink\" title=\"2.1 将逻辑回归作为一个神经网络\"></a><strong>2.1 将逻辑回归作为一个神经网络</strong></h2><h3 id=\"深度学习符号标准\"><a href=\"#深度学习符号标准\" class=\"headerlink\" title=\"深度学习符号标准\"></a><strong>深度学习符号标准</strong></h3><p>该专项课程，规范了深度学习所用到的所有符号的表示方法：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%861.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%862.JPG\" width=\"50%\" height=\"50%\"></p>\n<h3 id=\"二元分类\"><a href=\"#二元分类\" class=\"headerlink\" title=\"二元分类\"></a><strong>二元分类</strong></h3><p>二元分类(Binary Classification)就是输出<script type=\"math/tex\">y \\in \\{0,1\\}</script>。<br>以一个图像识别问题为例，判断图片中是否有猫存在，0代表不是猫，1代表是猫。</p>\n<h3 id=\"逻辑回归\"><a href=\"#逻辑回归\" class=\"headerlink\" title=\"逻辑回归\"></a><strong>逻辑回归</strong></h3><ul>\n<li>Given $x$,want $\\hat{y}=P(y=1|x)$，其中$x\\in R^{n_x}$,$0\\leq\\hat{y}\\leq1$</li>\n<li>参数：$w\\in R^{n_x}$,$b\\in R$</li>\n<li>输出：$\\hat{y}=\\sigma(w^Tx+b)$，其中$\\sigma()$为sigmoid函数，$\\sigma(z)=\\frac{1}{1+e^{-z}}$。</li>\n<li>注意：本课程中不采用<script type=\"math/tex\">x_0=1,x\\in R^{n_x+1}</script>，<script type=\"math/tex\">\\hat{y}=\\sigma(\\theta^Tx)</script>,<script type=\"math/tex\">\\theta=[\\theta_0,\\theta_1,...,\\theta_{n_x}]^T</script>的做法。</li>\n</ul>\n<h3 id=\"逻辑回归代价函数\"><a href=\"#逻辑回归代价函数\" class=\"headerlink\" title=\"逻辑回归代价函数\"></a><strong>逻辑回归代价函数</strong></h3><ul>\n<li>Given <script type=\"math/tex\">\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}</script>, want $\\hat{y}^{(i)}=y^{(i)}$</li>\n<li>Loss Function: $L(\\hat{y},y)=-(y\\log\\hat{y}+(1-y)\\log(1-\\hat{y}))$</li>\n<li>Cost Function: <script type=\"math/tex\">J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})\\\\\n=-\\frac{1}{m} \\sum\\limits_{i=1}^m [y^{(i)}\\log\\hat{y}^{(i)}+(1-y^{(i)})\\log(1-\\hat{y}^{(i)})]</script></li>\n</ul>\n<h3 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a><strong>梯度下降</strong></h3><ul>\n<li>want to find $w$,$b$ that minimize $J(w,b)$</li>\n<li>$ w:= w-\\alpha\\frac{\\partial}{\\partial w}J(w,b)$</li>\n<li>$ b:= b-\\alpha\\frac{\\partial}{\\partial b}J(w,b)$</li>\n</ul>\n<h3 id=\"通过计算图求导数\"><a href=\"#通过计算图求导数\" class=\"headerlink\" title=\"通过计算图求导数\"></a><strong>通过计算图求导数</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E5%AF%BC%E6%95%B0.JPG\" width=\"60%\" height=\"50%\"></p>\n<h3 id=\"逻辑回归中的梯度下降法\"><a href=\"#逻辑回归中的梯度下降法\" class=\"headerlink\" title=\"逻辑回归中的梯度下降法\"></a><strong>逻辑回归中的梯度下降法</strong></h3><p>逻辑回归总结:</p>\n<ul>\n<li>$z=w^Tx+b$</li>\n<li>$\\hat{y}=a=\\sigma(z)$</li>\n<li>$L(a,y)=-[y\\log(a)+(1-y)\\log(1-a)]$</li>\n</ul>\n<p>逻辑回归求导（通过计算图）:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E5%AF%BC.JPG\" width=\"60%\" height=\"50%\"></p>\n<ul>\n<li>$d_a=\\frac{d}{d_a}L(a,y)=-\\frac{y}{a}+\\frac{1-y}{1-a}$</li>\n<li>$d_z=\\frac{d}{d_z}L(a,y)= d_a \\cdot \\frac{d_a}{d_z}=(-\\frac{y}{a}+\\frac{1-y}{1-a}) \\cdot a(1-a)=a-y$</li>\n<li>$d_{w_1}=\\frac{\\partial L}{\\partial w_1}=d_z \\cdot \\frac{\\partial z}{\\partial w_1}=d_z \\cdot x_1$</li>\n<li>$d_{w_2}=\\frac{\\partial L}{\\partial w_2}=d_z \\cdot \\frac{\\partial z}{\\partial w_2}=d_z \\cdot x_2$</li>\n<li>$d_{b}=\\frac{\\partial L}{\\partial b}=d_z \\cdot \\frac{\\partial z}{\\partial b}=d_z$</li>\n</ul>\n<h3 id=\"m个样本下的梯度下降\"><a href=\"#m个样本下的梯度下降\" class=\"headerlink\" title=\"m个样本下的梯度下降\"></a><strong>m个样本下的梯度下降</strong></h3><p>因为：$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(a^{(i)},y^{(i)})$</p>\n<p>故:</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial w_1}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_1}L(a^{(i)},y^{(i)}) = \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_1}}^{(i)}=\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1</script><script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial w_2}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_2}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_2}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2</script><script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial b}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial b}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{b}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)}</script><h2 id=\"2-2-python和向量化\"><a href=\"#2-2-python和向量化\" class=\"headerlink\" title=\"2.2 python和向量化\"></a><strong>2.2 python和向量化</strong></h2><h3 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a><strong>向量化</strong></h3><p>神经网络编程指南：<strong>无论何时，避免显式的for循环</strong><br>举例：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 若a,b,c为向量或矩阵</span></span><br><span class=\"line\">c = np.dot(a,b)</span><br><span class=\"line\">b = np.exp(a)</span><br><span class=\"line\">b = np.log(a)</span><br><span class=\"line\">b = np.abs(a)</span><br><span class=\"line\">b = np.maximum(a,<span class=\"number\">0</span>)</span><br><span class=\"line\">b = a**<span class=\"number\">2</span></span><br><span class=\"line\">b = <span class=\"number\">1</span>/a</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"向量化逻辑回归\"><a href=\"#向量化逻辑回归\" class=\"headerlink\" title=\"向量化逻辑回归\"></a><strong>向量化逻辑回归</strong></h3><ul>\n<li>$X_{(n_x*m)}=[x^{(1)},x^{(2)},…,x^{(m)}]$</li>\n<li>$ Z_{(1*m)}=[z^{(1)},z^{(2)},…,z^{(m)}]=w^T X+ [b,…,b]$<br>对应代码：<code>Z=np.dot(w.T,X)+b #broadcasting</code></li>\n<li>$A=[a^{(1)},a^{(2)},…,a^{(m)}]=[\\sigma(z^{(1)}),\\sigma(z^{(2)}),…,\\sigma(z^{(m)})]=\\sigma(Z)$<br>对应代码：<code>A=sigmoid(Z)</code></li>\n</ul>\n<h3 id=\"向量化逻辑回归中的梯度计算\"><a href=\"#向量化逻辑回归中的梯度计算\" class=\"headerlink\" title=\"向量化逻辑回归中的梯度计算\"></a><strong>向量化逻辑回归中的梯度计算</strong></h3><ul>\n<li>${d_{z}}^{(i)}=a^{(i)}-y^{(i)}$</li>\n<li>故<script type=\"math/tex\">d_{Z_{(1*m)}}=[{d_{z}}^{(1)},{d_{z}}^{(2)},...,{d_{z}}^{(m)}]</script></li>\n<li>$A=[a^{(1)},a^{(2)},…,a^{(m)}],Y=[y^{(1)},y^{(2)},…,y^{(m)}]$</li>\n<li>故<script type=\"math/tex\">d_{Z_{(1*m)}}=A-Y=[a^{(1)}-y^{(1)}, a^{(2)}-y^{(2)},..., a^{(m)}-y^{(m)}]</script></li>\n<li><script type=\"math/tex; mode=display\">d_b=\\frac{1}{m}\\sum_{i=1}^{m} {d_z}^{(i)}=\\frac{1}{m}np.sum(d_Z)</script></li>\n<li><script type=\"math/tex; mode=display\">d_w= \\begin{bmatrix} d_{w_1} \\\\d_{w_2} \\\\ ... \\\\d_{w_{n_x}} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1 \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2 \\\\ ... \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_{n_x} \\end{bmatrix} \\\\\n=\\frac{1}{m} X {d_{Z}}^T \n=\\frac{1}{m}[x^{(1)} ,x^{(2)},...,x^{(m)}] \\begin{bmatrix} {d_{z}}^{(1)} \\\\ {d_{z}}^{(2)}\\\\ ...\\\\{d_{z}}^{(m)}\\end{bmatrix}</script></li>\n</ul>\n<h3 id=\"逻辑回归算法流程（伪代码）\"><a href=\"#逻辑回归算法流程（伪代码）\" class=\"headerlink\" title=\"逻辑回归算法流程（伪代码）\"></a><strong>逻辑回归算法流程（伪代码）</strong></h3><p>非向量化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">J=0, dw1=0, dw2=0,db=0</span><br><span class=\"line\">for i = 1 to m</span><br><span class=\"line\">truez(i) = wx(i)+b</span><br><span class=\"line\">truea(i) = sigmoid(z(i))</span><br><span class=\"line\">trueJ += -[y(i)log(a(i))+(1-y(i)）log(1-a(i))</span><br><span class=\"line\">truedz(i) = a(i)-y(i)</span><br><span class=\"line\">truedw1 += x1(i)dz(i)</span><br><span class=\"line\">truedw2 += x2(i)dz(i)</span><br><span class=\"line\">truedb += dz(i)</span><br><span class=\"line\">J /= m</span><br><span class=\"line\">dw1 /= m</span><br><span class=\"line\">dw2 /= m</span><br><span class=\"line\">db /= m</span><br></pre></td></tr></table></figure></p>\n<p>向量化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for iter in range(1000):</span><br><span class=\"line\">    Z = np.dot(w.T,X) + b</span><br><span class=\"line\">    A = sigmoid(Z)</span><br><span class=\"line\">    dZ = A-Y</span><br><span class=\"line\">    dw = 1/m*np.dot(X,dZ.T)</span><br><span class=\"line\">    db = 1/m*np.sum(dZ)</span><br><span class=\"line\">    w = w - alpha*dw</span><br><span class=\"line\">    b = b - alpha*db</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"python中的广播\"><a href=\"#python中的广播\" class=\"headerlink\" title=\"python中的广播\"></a><strong>python中的广播</strong></h3><p>广播(broadcasting)是Python使用中的一种技巧，在Python中可以对不同维度的矩阵进行四则混合运算，前提条件是至少有一个维度是相同的。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD1.jpg\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD2.JPG\" width=\"50%\" height=\"50%\"></p>\n<h3 id=\"关于python-numpy中的向量说明\"><a href=\"#关于python-numpy中的向量说明\" class=\"headerlink\" title=\"关于python/numpy中的向量说明\"></a><strong>关于python/numpy中的向量说明</strong></h3><p>Python中，如果用下列语句来定义一个向量：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.random.randn(5)</span><br></pre></td></tr></table></figure></p>\n<p>这条语句生成的$a$的维度是$(5,)$。它既不是行向量也不是列向量，我们把$a$叫做”rank1 array”。这种定义会带来一些问题。例如我们对$a$进行转置，还是会得到$a$本身。<br>所以，如果我们要定义$(5,1)$的列向量或者$(1,5)$的行向量，最好使用下来标准语句，避免使用”rank1 array”。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.random.randn(5,1)</span><br><span class=\"line\">b = np.random.randn(1,5)</span><br></pre></td></tr></table></figure></p>\n<p>除此之外，我们还可以使用<code>assert</code>语句对向量或数组的维度进行判断，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">assert(a.shape == (5,1))</span><br></pre></td></tr></table></figure></p>\n<p><code>assert</code>会对内嵌语句进行判断，即判断$a$的维度是不是$(5,1)$的。如果不是，则程序在此处停止。使用<code>assert</code>语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。<br>另外，还可以使用<code>reshape</code>函数对数组设定所需的维度：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = a.reshape((5,1))</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"3-浅层神经网络\"><a href=\"#3-浅层神经网络\" class=\"headerlink\" title=\"3.浅层神经网络\"></a><strong>3.浅层神经网络</strong></h1><h2 id=\"神经网络表示\"><a href=\"#神经网络表示\" class=\"headerlink\" title=\"神经网络表示\"></a><strong>神经网络表示</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E7%A4%BA.JPG\" width=\"60%\" height=\"50%\">以上图为例，注意以下表示：</p>\n<ul>\n<li>输入层（第0层），隐藏层（第1层），输出层（第2层），是一个两层的神经网络。</li>\n<li>$a^{[1]}$表示第一层的激活函数(输出)值,$a^{[1]}=[a^{[1]}_1,a^{[1]}_2,a^{[1]}_3,a^{[1]}_4]^T$,其维度为<script type=\"math/tex\">n^{[1]}*1</script>，即<script type=\"math/tex\">4*1</script>。</li>\n<li>$W^{[1]}$表示第一层的权重值,其维度为<script type=\"math/tex\">n^{[1]}*n^{[0]}</script>，即<script type=\"math/tex\">4*3</script>。(注意)第$l$层的权重$W^{[l]}$的维度为：<script type=\"math/tex\">n^{[l]}*n^{[l-1]}</script>。</li>\n<li>$b^{[1]}$表示第一层的偏置值,其维度为<script type=\"math/tex\">n^{[1]}*1</script>，即<script type=\"math/tex\">4*1</script>。</li>\n<li>预测值$\\hat{y}$即为神经网络最后一层的激活函数值$a^{[2]}$，即$\\hat{y}=a^{[2]}$。</li>\n</ul>\n<h2 id=\"计算神经网络的输出\"><a href=\"#计算神经网络的输出\" class=\"headerlink\" title=\"计算神经网络的输出\"></a><strong>计算神经网络的输出</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA1.JPG\" width=\"50%\" height=\"50%\">首先，神经网络中的每一个神经元，都可以看成一个逻辑回归单元，经过两个步骤来计算输出值$a$:</p>\n<ul>\n<li>$z=w^Tx+b$</li>\n<li>$a = \\sigma(z)$</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA2.JPG\" width=\"50%\" height=\"50%\">对于神经网络的输出，可向量化为（可通过维度检查进行确认）：</p>\n<ul>\n<li>$z^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$</li>\n<li>$a^{[1]}=\\sigma(z^{[1]})$</li>\n<li>$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=\\sigma(z^{[2]})$</li>\n</ul>\n<h2 id=\"m个样本中的向量化\"><a href=\"#m个样本中的向量化\" class=\"headerlink\" title=\"m个样本中的向量化\"></a><strong>m个样本中的向量化</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%A4%9A%E6%A0%B7%E6%9C%AC%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">多个样本的情况下，向量化神经网络输出的方式为：</p>\n<ul>\n<li>$Z^{[1]}=W^{[1]}X+b^{[1]}$</li>\n<li>$A^{[1]}=\\sigma(Z^{[1]})$</li>\n<li>$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$</li>\n<li>$A^{[2]}=\\sigma(Z^{[2]})$</li>\n<li><strong>该向量化方式的核心思想是</strong>：$X$,$Z^{[i]}$及$A^{[i]}$的横向维度表示训练样本，纵向维度表示隐藏单元。形象化示意见图。</li>\n</ul>\n<h2 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a><strong>激活函数</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg\" width=\"50%\" height=\"50%\"></p>\n<ul>\n<li><code>sigmoid</code>函数和<code>tanh</code>函数都有一个问题，就是当$z$很大或很小时，激活函数的梯度接近于0，会拖慢梯度下降算法。</li>\n<li>研究表明，当隐藏层使用<code>tanh</code>函数几乎总比<code>sigmoid</code>函数的表现更好。因为<code>tanh</code>函数的激活函数值范在[-1,1]之间，激活函数的平均值接近于0，更方便下一层的学习。</li>\n<li>如果是二分类问题，即样本标签$y$为0或1，希望预测值$\\hat{y}$取值为$0\\leq\\hat{y}\\leq1$，则输出层的激活函数可选用<code>sigmoid</code>函数，<strong>否则隐藏层和输出层都不使用<code>sigmoid</code>函数</strong>。</li>\n<li><code>ReLU(rectified  linear unit)</code>激活函数在$z$大于零时梯度始终为1，在$z$小于零时梯度始终为0，$z$等于零时的梯度无定义，可以当成1也可以当成0，实际应用中并不影响（因为在程序中值为0.000…的可能性很小）。<strong>当前隐藏层的默认激活函数选择为<code>ReLU</code></strong>。</li>\n<li><code>ReLU</code>激活函数能够保证$z$大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度（虽然左半边函数的导数等于0，但有足够多的隐藏单元使$z$大于0，因此大部分样本都会训练地很快）。</li>\n<li><code>ReLU</code>激活函数的缺点为当$z$小于零时，导数为0，这个缺点在实际应用中没什么影响。为了弥补这个缺点，出现了<code>Leaky ReLU</code>激活函数，能够保证$z$小于零时梯度不为0，不过实际中使用的频率不高。</li>\n</ul>\n<h2 id=\"为什么需要非线性激活函数\"><a href=\"#为什么需要非线性激活函数\" class=\"headerlink\" title=\"为什么需要非线性激活函数\"></a><strong>为什么需要非线性激活函数</strong></h2><p>以上的四种激活函数都是非线性的。不可使用线性的激活函数，原因如下。<br>假设所有的激活函数都是线性的，那么，浅层神经网络的各层输出为：</p>\n<ul>\n<li>$z^{[1]}=w^{[1]}x+b^{[1]}$</li>\n<li>$a^{[1]}=g^{[1]}(z^{[1]})=z^{[1]}$</li>\n<li>$z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=g^{[2]}(z^{[2]})=z^{[2]}$</li>\n</ul>\n<p>对$a^{[2]}$进行化简:</p>\n<script type=\"math/tex; mode=display\">a^{[2]}=z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}\\\\\n=w^{[2]}(w^{[1]}x+b^{[1]})+b^{[2]}\\\\\n=(w^{[2]}w^{[1]})x+(w^{[2]}b^{[1]}+b^{[2]})\\\\\n=w^{'}+b^{'}</script><ul>\n<li>经过推导发现$a^{[2]}$仍是输入变量$x$的线性组合。这表明，即便是包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入$x$的线性模型。</li>\n<li>因此，<strong>隐藏层的激活函数必须要是非线性的。线性隐藏层没有任何作用，层数再多也不行</strong>。</li>\n<li>只有一种情况可以使用线性激活函数，即对于回归问题，当输出$\\hat{y}$是一个实数时，<strong>输出层的激活函数可以使用线性函数</strong>。如果输出$\\hat{y}$是非负数，则可以使用<code>ReLU</code>激活函数。具体情况，具体分析。</li>\n</ul>\n<h2 id=\"激活函数的导数\"><a href=\"#激活函数的导数\" class=\"headerlink\" title=\"激活函数的导数\"></a><strong>激活函数的导数</strong></h2><p>sigmoid函数的导数：</p>\n<ul>\n<li>$g(z)=\\frac{1}{1+e^{(-z)}}$</li>\n<li>$g’(z)=\\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$</li>\n</ul>\n<p>tanh函数的导数：</p>\n<ul>\n<li>$g(z)=\\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}$</li>\n<li>$g’(z)=\\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$</li>\n</ul>\n<p>ReLU函数的导数：</p>\n<ul>\n<li>$g(z)=max(0,z)$</li>\n<li><script type=\"math/tex; mode=display\">g'(z)=\\begin{cases} 0, & z<0\\\\  1, & z\\geq0 \\end{cases}</script></li>\n</ul>\n<p>Leaky ReLU函数的导数：</p>\n<ul>\n<li>$g(z)=max(0.01z,z)$</li>\n<li><script type=\"math/tex; mode=display\">g'(z)=\\begin{cases} 0.01, & z<0\\\\ 1, & z\\geq0 \\end{cases}</script></li>\n</ul>\n<h2 id=\"神经网络的梯度下降法\"><a href=\"#神经网络的梯度下降法\" class=\"headerlink\" title=\"神经网络的梯度下降法\"></a><strong>神经网络的梯度下降法</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"50%\" height=\"50%\">单样本神经网络正向传播过程为：</p>\n<ul>\n<li>$z^{[1]}=W^{[1]}x+b^{[1]}$</li>\n<li>$a^{[1]}=g(z^{[1]})$</li>\n<li>$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=g(z^{[2]})$</li>\n<li>其中，$g(\\cdot)$表示激活函数。</li>\n</ul>\n<p>单样本神经网络反向传播过程（即链式法则求导过程）：</p>\n<ul>\n<li>$da^{[2]}=-\\frac{y}{a}+\\frac{1-y}{1-a}$（不同损失函数，结果不同，可不给出具体形式）</li>\n<li>$dz^{[2]}=a^{[2]}-y$（不同损失函数，结果不同，可不给出具体形式，一般只用$d_z$，不用$d_a$）</li>\n<li>$dW^{[2]}=dz^{[2]}a^{[1]T}$</li>\n<li>$db^{[2]}=dz^{[2]}$</li>\n<li>$da^{[1]}=W^{[2]T}dz^{[2]}$</li>\n<li>$dz^{[1]}=W^{[2]T}dz^{[2]}\\ast g^{[1]’}(z^{[1]})$</li>\n<li>$dW^{[1]}=dz^{[1]}x^T$</li>\n<li>$db^{[1]}=dz^{[1]}$</li>\n<li>其中，$*$为逐元素相乘。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"50%\" height=\"50%\">$m$个样本神经网络正向传播过程为：</p>\n<ul>\n<li>$Z^{[1]}=W^{[1]}X+b^{[1]}$</li>\n<li>$A^{[1]}=g(Z^{[1]})$</li>\n<li>$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$</li>\n<li>$A^{[2]}=g(Z^{[2]})$</li>\n<li>其中，$g(\\cdot)$表示激活函数。</li>\n</ul>\n<p>$m$个样本神经网络反向传播过程（即$m$个单样本的梯度求和）：</p>\n<ul>\n<li>$dZ^{[2]}=A^{[2]}-Y$</li>\n<li>$dW^{[2]}=\\frac1mdZ^{[2]}A^{[1]T}$</li>\n<li>$db^{[2]}=\\frac1mnp.sum(dZ^{[2]},axis=1,keepdims=True)$</li>\n<li>$dZ^{[1]}=W^{[2]T}dZ^{[2]}\\ast g^{[1]’}(Z^{[1]})$</li>\n<li>$dW^{[1]}=\\frac1mdZ^{[1]}X^T$</li>\n<li>$db^{[1]}=\\frac1mnp.sum(dZ^{[1]},axis=1,keepdims=True)$</li>\n<li>其中，$*$为逐元素相乘。</li>\n</ul>\n<p>该节的一个重要参考：<a href=\"https://zhuanlan.zhihu.com/p/22473137\" target=\"_blank\" rel=\"noopener\">神经网络反向传播的数学原理</a></p>\n<h2 id=\"随机初始化\"><a href=\"#随机初始化\" class=\"headerlink\" title=\"随机初始化\"></a><strong>随机初始化</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.jpg\" width=\"50%\" height=\"50%\"><br>神经网络模型中的参数权重$W$不能全部初始化为零。<br>举例说明，如图，如果权重$W^{[1]}$和$W^{[2]}$都初始化为零，即：</p>\n<script type=\"math/tex; mode=display\">W^{[1]}= \\left[ \\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix} \\right]</script><script type=\"math/tex; mode=display\">W^{[2]}= \\left[ \\begin{matrix} 0 & 0 \\end{matrix} \\right]</script><ul>\n<li>这样使得$a_1^{[1]}=a_2^{[1]}$。进一步可得$dz_1^{[1]}=dz_2^{[1]}$ ，以及$dW_1^{[1]}=dW_2^{[1]}$。</li>\n<li>因此，每次迭代更新：$W^{[1]} = W^{[1]}-dW^{[1]}$。 $W^{[1]}$每一行都相等，即$W_1^{[1]}$和$W_2^{[1]}$都会相等。无论经过多少次迭代，隐藏层的神经元总是对称的。这样隐藏层设置多个神经元就没有任何意义了。</li>\n<li>参数$b$全部初始化为零，不会产生对称失效问题。</li>\n<li>解决方法：将$W$进行随机初始化($b$可初始化为零)来打破对称(break symmetry)。</li>\n</ul>\n<p>Python中可以使用如下语句进行$W$和$b$的随机初始化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W_1 = np.random.randn(2,2)*0.01</span><br><span class=\"line\">b_1 = np.zeros((2,1))</span><br><span class=\"line\">W_2 = np.random.randn(1,2)*0.01</span><br><span class=\"line\">b_2 = 0</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>在对$W^{[1]}$进行随机初始化时，乘以0.01的目的是尽量使得权重$W$初始化为比较小的值。</li>\n<li>之所以让$W$比较小，是因为如果使用<code>sigmoid</code>函数或者<code>tanh</code>函数作为激活函数时，若$W$较大，则训练的开始阶段$z$就比较大，由<code>sigmoid</code>函数或者<code>tanh</code>函数的曲线可以看出，当$|z|$过大时，其梯度近似为0，会使得训练过程十分缓慢。</li>\n<li>当然，如果未使用<code>sigmoid</code>激活函数或者<code>tanh</code>激活函数，该情况可能不明显。但是如果对于二分类问题，输出层是<code>sigmoid</code>函数，则对应的权重$W$最好初始化到比较小的值。</li>\n</ul>\n<h1 id=\"4-深层神经网络\"><a href=\"#4-深层神经网络\" class=\"headerlink\" title=\"4.深层神经网络\"></a><strong>4.深层神经网络</strong></h1><h2 id=\"深层神经网络\"><a href=\"#深层神经网络\" class=\"headerlink\" title=\"深层神经网络\"></a><strong>深层神经网络</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"70%\" height=\"50%\">深层神经网络其实就是包含更多隐藏层的神经网络。如上图所示，分别列举了逻辑回归、1个隐藏层的神经网络、2个隐藏层的神经网络和5个隐藏层的神经网络它们的模型结构。</p>\n<h2 id=\"深层网络中的前向传播\"><a href=\"#深层网络中的前向传播\" class=\"headerlink\" title=\"深层网络中的前向传播\"></a><strong>深层网络中的前向传播</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD.JPG\" width=\"50%\" height=\"50%\">以上面讲过的4层神经网络为例，推导一下深层神经网络的正向传播过程。<br>单个样本下，深层神经网络的正向传播过程：</p>\n<ul>\n<li>$l=1$：$z^{[1]}=W^{[1]}x+b^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$，$a^{[1]}=g^{[1]}(z^{[1]})$</li>\n<li>$l=2$：$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$，$a^{[2]}=g^{[2]}(z^{[2]})$</li>\n<li>$l=3$：$z^{[3]}=W^{[3]}a^{[2]}+b^{[3]}$，$a^{[3]}=g^{[3]}(z^{[3]})$</li>\n<li>$l=4$：$z^{[4]}=W^{[4]}a^{[3]}+b^{[4]}$，$a^{[4]}=g^{[4]}(z^{[4]})$</li>\n</ul>\n<p>$m$个样本下，深层神经网络的正向传播过程：</p>\n<ul>\n<li>$l=1$：$Z^{[1]}=W^{[1]}X+b^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$，$A^{[1]}=g^{[1]}(Z^{[1]})$</li>\n<li>$l=2$：$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$，$A^{[2]}=g^{[2]}(Z^{[2]})$</li>\n<li>$l=3$：$Z^{[3]}=W^{[3]}A^{[2]}+b^{[3]}$，$A^{[3]}=g^{[3]}(Z^{[3]})$</li>\n<li>$l=4$：$Z^{[4]}=W^{[4]}A^{[3]}+b^{[4]}$，$A^{[4]}=g^{[4]}(Z^{[4]})$</li>\n</ul>\n<p>综上所述，对于第$l$层，其正向传播过程的$Z^{[l]}$和$A^{[l]}$可以表示为：</p>\n<ul>\n<li>$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$</li>\n<li>$A^{[l]}=g^{[l]}(Z^{[l]})$</li>\n<li>其中，$l=1,\\cdots,L$</li>\n</ul>\n<h2 id=\"矩阵维度检查\"><a href=\"#矩阵维度检查\" class=\"headerlink\" title=\"矩阵维度检查\"></a><strong>矩阵维度检查</strong></h2><p>对于单个训练样本，输入$x$的维度是:</p>\n<ul>\n<li>$x:(n^{[0]},1)$。</li>\n</ul>\n<p>神经网络的参数$W^{[l]}$和$b^{[l]}$的维度分别是：</p>\n<ul>\n<li>$W^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$b^{[l]}:\\ (n^{[l]},1)$</li>\n<li>其中，$l=1,\\cdots,L$，$n^{[l]}$和$n^{[l-1]}$分别表示第$l$层和$l-1$层中所含神经元的个数。$n^{[0]}=n_x$，表示输入尺寸。</li>\n</ul>\n<p>正向传播过程中的$z^{[l]}$和$a^{[l]}$的维度分别是：</p>\n<ul>\n<li>$z^{[l]}:\\ (n^{[l]},1)$</li>\n<li>$a^{[l]}:\\ (n^{[l]},1)$</li>\n<li>$z^{[l]}$和$a^{[l]}$的维度是一样的，且$dz^{[l]}$和$da^{[l]}$的维度均与$z^{[l]}$和$a^{[l]}$的维度一致。</li>\n</ul>\n<p>反向传播过程中的$dW^{[l]}$和$db^{[l]}$的维度分别是：</p>\n<ul>\n<li>$dW^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$db^{[l]}:\\ (n^{[l]},1)$</li>\n<li>注意到， $dW^{[l]}$与$W^{[l]}$的维度相同，$db^{[l]}$与$b^{[l]}$的维度相同。</li>\n</ul>\n<p>对于$m$个训练样本，输入矩阵$X$的维度是：</p>\n<ul>\n<li>$X:(n^{[0]},m)$。</li>\n</ul>\n<p>参数$W^{[l]}$和$b^{[l]}$的维度与只有单个样本是一致的：</p>\n<ul>\n<li>$W^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$b^{[l]}:\\ (n^{[l]},1)$</li>\n<li>只不过在运算$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$中，$b^{[l]}$会被当成$(n^{[l]},m)$矩阵进行运算，这是因为python的广播性质，且 $b^{[l]}$每一列向量都是一样的。</li>\n<li>$dW^{[l]}$和$db^{[l]}$的维度分别与$W^{[l]}$和$b^{[l]}$一致。</li>\n</ul>\n<p>但是，$Z^{[l]}$ 和$A^{[l]}$的维度发生了变化：</p>\n<ul>\n<li>$Z^{[l]}:\\ (n^{[l]},m)$</li>\n<li>$A^{[l]}:\\ (n^{[l]},m)$</li>\n<li>$dZ^{[l]}$和$dA^{[l]}$的维度分别与$Z^{[l]}$和$A^{[l]}$一致。</li>\n</ul>\n<h2 id=\"为什么使用深层的神经网络\"><a href=\"#为什么使用深层的神经网络\" class=\"headerlink\" title=\"为什么使用深层的神经网络\"></a><strong>为什么使用深层的神经网络</strong></h2><ul>\n<li>神经网络层数越深，能够提取到的特征越复杂。</li>\n<li>以CNN为例，低层网络提取到简单的局部特征，深层网络提取到复杂的全局特征。层数越深，提取到的特征越复杂。</li>\n<li>以RNN为例，也是如此。</li>\n</ul>\n<h2 id=\"搭建深层神经网络块\"><a href=\"#搭建深层神经网络块\" class=\"headerlink\" title=\"搭建深层神经网络块\"></a><strong>搭建深层神经网络块</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97.jpg\" width=\"50%\" height=\"50%\"><br>上图为能表示出深层神经网络正向传播和反向传播过程的块(block)图。<br>如图所示，对于第$l$层来说，正向传播过程中：</p>\n<ul>\n<li>输入：$a^{[l-1]}$</li>\n<li>输出：$a^{[l]}$</li>\n<li>参数：$W^{[l]},b^{[l]}$</li>\n<li>缓存变量： $z^{[l]}$</li>\n</ul>\n<p>反向传播过程中：</p>\n<ul>\n<li>输入：$da^{[l]}$</li>\n<li>输出：$da^{[l-1]},dW^{[l]},db^{[l]}$</li>\n<li>参数：$W^{[l]},b^{[l]}$</li>\n</ul>\n<p>用块图构建出一个深层神经网络的正向传播过程和反向传播过程，如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/l%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97%E5%9B%BE.jpg\" width=\"100%\" height=\"50%\"></p>\n<h2 id=\"正向传播和反向传播\"><a href=\"#正向传播和反向传播\" class=\"headerlink\" title=\"正向传播和反向传播\"></a><strong>正向传播和反向传播</strong></h2><p>对于单个样本，第$l$层的正向传播：</p>\n<ul>\n<li>输入：$a^{[l-1]}$</li>\n<li>输出：$a^{[l]}$，缓存变量：$z^{[l]}$</li>\n</ul>\n<p>具体表达式如下：</p>\n<ul>\n<li>$z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}$</li>\n<li>$a^{[l]}=g^{[l]}(z^{[l]})$</li>\n</ul>\n<p>$m$个训练样本，向量化形式为：</p>\n<ul>\n<li>$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$</li>\n<li>$A^{[l]}=g^{[l]}(Z^{[l]})$</li>\n</ul>\n<p>对于单个样本，第$l$层的反向传播：</p>\n<ul>\n<li>输入：$da^{[l]}$</li>\n<li>输出：$da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$。</li>\n</ul>\n<p>具体表达式如下：</p>\n<ul>\n<li>$dz^{[l]}=da^{[l]}\\ast g^{[l]’}(z^{[l]})$</li>\n<li>$dW^{[l]}=dz^{[l]}\\cdot a^{[l-1]}$</li>\n<li>$db^{[l]}=dz^{[l]}$</li>\n<li>$da^{[l-1]}=W^{[l]T}\\cdot dz^{[l]}$</li>\n<li>由上述第四个表达式可得$da^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}$，将$da^{[l]}$代入第一个表达式中可以得到：$dz^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}\\ast g^{[l]’}(z^{[l]})$该式非常重要，反映了$dz^{[l+1]}$与$dz^{[l]}$的递推关系。</li>\n</ul>\n<p>$m$个训练样本，向量化形式为：</p>\n<ul>\n<li>$dZ^{[l]}=dA^{[l]}\\ast g^{[l]’}(Z^{[l]})$</li>\n<li>$dW^{[l]}=\\frac1mdZ^{[l]}\\cdot A^{[l-1]T}$</li>\n<li>$db^{[l]}=\\frac1mnp.sum(dZ^{[l]},axis=1,keepdims=True)$</li>\n<li>$dA^{[l-1]}=W^{[l]T}\\cdot dZ^{[l]}$</li>\n<li>$dZ^{[l]}=W^{[l+1]T}\\cdot dZ^{[l+1]}\\ast g^{[l]’}(Z^{[l]})$</li>\n</ul>\n<h2 id=\"参数和超参数\"><a href=\"#参数和超参数\" class=\"headerlink\" title=\"参数和超参数\"></a><strong>参数和超参数</strong></h2><p>对于神经网络中的参数(parameters)和超参数(hyperparameters)的概念：</p>\n<ul>\n<li>神经网络中的参数就是我们熟悉的$W^{[l]}$和$b^{[l]}$。</li>\n<li>而超参数则是例如学习速率$\\alpha$，训练迭代次数$N$，神经网络层数$L$，各层神经元个数$n^{[l]}$，甚至激活函数$g(z)$的种类等。</li>\n<li>之所以<strong>叫做超参数的原因</strong>是它们高于参数，决定了参数$W^{[l]}$和$b^{[l]}$的取值。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-深度学习介绍\"><a href=\"#1-深度学习介绍\" class=\"headerlink\" title=\"1.深度学习介绍\"></a><strong>1.深度学习介绍</strong></h1><h2 id=\"用神经网络进行监督学习\"><a href=\"#用神经网络进行监督学习\" class=\"headerlink\" title=\"用神经网络进行监督学习\"></a><strong>用神经网络进行监督学习</strong></h2><p>到目前为止，由神经网络创造的经济价值几乎都是基于一种机器学习方法——监督学习。<br>下面是目前主要的几种应用示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.JPG\" width=\"50%\" height=\"50%\">不同的情况，一般使用不同的网络模型：</p>\n<ul>\n<li>对于房价预测和在线广告，使用标准的神经网络模型；</li>\n<li>对于计算机视觉领域，使用CNN(convolution neural network)；</li>\n<li>对于序列数据，如音频(如语音识别)和语言(如机器翻译)，使用RNN(recurrent neural network)。</li>\n<li>对于更复杂的应用，如无人驾驶，使用混合的神经网络结构。</li>\n</ul>","more":"<p>神经网络类型示例:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B%E4%B8%BE%E4%BE%8B.JPG\" width=\"60%\" height=\"50%\">结构化数据与非结构化数据：<br>数据类型一般分为两种：结构化数据和非结构化数据。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%8E%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE.JPG\" width=\"70%\" height=\"50%\"></p>\n<h2 id=\"为什么深度学习会兴起？\"><a href=\"#为什么深度学习会兴起？\" class=\"headerlink\" title=\"为什么深度学习会兴起？\"></a><strong>为什么深度学习会兴起？</strong></h2><p>三个要素：数据量、计算能力、算法<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%B4%E8%B5%B7.jpg\" width=\"60%\" height=\"50%\"></p>\n<h1 id=\"2-神经网络基础\"><a href=\"#2-神经网络基础\" class=\"headerlink\" title=\"2.神经网络基础\"></a><strong>2.神经网络基础</strong></h1><h2 id=\"2-1-将逻辑回归作为一个神经网络\"><a href=\"#2-1-将逻辑回归作为一个神经网络\" class=\"headerlink\" title=\"2.1 将逻辑回归作为一个神经网络\"></a><strong>2.1 将逻辑回归作为一个神经网络</strong></h2><h3 id=\"深度学习符号标准\"><a href=\"#深度学习符号标准\" class=\"headerlink\" title=\"深度学习符号标准\"></a><strong>深度学习符号标准</strong></h3><p>该专项课程，规范了深度学习所用到的所有符号的表示方法：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%861.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%AC%A6%E5%8F%B7%E6%A0%87%E5%87%862.JPG\" width=\"50%\" height=\"50%\"></p>\n<h3 id=\"二元分类\"><a href=\"#二元分类\" class=\"headerlink\" title=\"二元分类\"></a><strong>二元分类</strong></h3><p>二元分类(Binary Classification)就是输出<script type=\"math/tex\">y \\in \\{0,1\\}</script>。<br>以一个图像识别问题为例，判断图片中是否有猫存在，0代表不是猫，1代表是猫。</p>\n<h3 id=\"逻辑回归\"><a href=\"#逻辑回归\" class=\"headerlink\" title=\"逻辑回归\"></a><strong>逻辑回归</strong></h3><ul>\n<li>Given $x$,want $\\hat{y}=P(y=1|x)$，其中$x\\in R^{n_x}$,$0\\leq\\hat{y}\\leq1$</li>\n<li>参数：$w\\in R^{n_x}$,$b\\in R$</li>\n<li>输出：$\\hat{y}=\\sigma(w^Tx+b)$，其中$\\sigma()$为sigmoid函数，$\\sigma(z)=\\frac{1}{1+e^{-z}}$。</li>\n<li>注意：本课程中不采用<script type=\"math/tex\">x_0=1,x\\in R^{n_x+1}</script>，<script type=\"math/tex\">\\hat{y}=\\sigma(\\theta^Tx)</script>,<script type=\"math/tex\">\\theta=[\\theta_0,\\theta_1,...,\\theta_{n_x}]^T</script>的做法。</li>\n</ul>\n<h3 id=\"逻辑回归代价函数\"><a href=\"#逻辑回归代价函数\" class=\"headerlink\" title=\"逻辑回归代价函数\"></a><strong>逻辑回归代价函数</strong></h3><ul>\n<li>Given <script type=\"math/tex\">\\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\\}</script>, want $\\hat{y}^{(i)}=y^{(i)}$</li>\n<li>Loss Function: $L(\\hat{y},y)=-(y\\log\\hat{y}+(1-y)\\log(1-\\hat{y}))$</li>\n<li>Cost Function: <script type=\"math/tex\">J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})\\\\\n=-\\frac{1}{m} \\sum\\limits_{i=1}^m [y^{(i)}\\log\\hat{y}^{(i)}+(1-y^{(i)})\\log(1-\\hat{y}^{(i)})]</script></li>\n</ul>\n<h3 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a><strong>梯度下降</strong></h3><ul>\n<li>want to find $w$,$b$ that minimize $J(w,b)$</li>\n<li>$ w:= w-\\alpha\\frac{\\partial}{\\partial w}J(w,b)$</li>\n<li>$ b:= b-\\alpha\\frac{\\partial}{\\partial b}J(w,b)$</li>\n</ul>\n<h3 id=\"通过计算图求导数\"><a href=\"#通过计算图求导数\" class=\"headerlink\" title=\"通过计算图求导数\"></a><strong>通过计算图求导数</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E5%9B%BE%E6%B1%82%E5%AF%BC%E6%95%B0.JPG\" width=\"60%\" height=\"50%\"></p>\n<h3 id=\"逻辑回归中的梯度下降法\"><a href=\"#逻辑回归中的梯度下降法\" class=\"headerlink\" title=\"逻辑回归中的梯度下降法\"></a><strong>逻辑回归中的梯度下降法</strong></h3><p>逻辑回归总结:</p>\n<ul>\n<li>$z=w^Tx+b$</li>\n<li>$\\hat{y}=a=\\sigma(z)$</li>\n<li>$L(a,y)=-[y\\log(a)+(1-y)\\log(1-a)]$</li>\n</ul>\n<p>逻辑回归求导（通过计算图）:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E5%AF%BC.JPG\" width=\"60%\" height=\"50%\"></p>\n<ul>\n<li>$d_a=\\frac{d}{d_a}L(a,y)=-\\frac{y}{a}+\\frac{1-y}{1-a}$</li>\n<li>$d_z=\\frac{d}{d_z}L(a,y)= d_a \\cdot \\frac{d_a}{d_z}=(-\\frac{y}{a}+\\frac{1-y}{1-a}) \\cdot a(1-a)=a-y$</li>\n<li>$d_{w_1}=\\frac{\\partial L}{\\partial w_1}=d_z \\cdot \\frac{\\partial z}{\\partial w_1}=d_z \\cdot x_1$</li>\n<li>$d_{w_2}=\\frac{\\partial L}{\\partial w_2}=d_z \\cdot \\frac{\\partial z}{\\partial w_2}=d_z \\cdot x_2$</li>\n<li>$d_{b}=\\frac{\\partial L}{\\partial b}=d_z \\cdot \\frac{\\partial z}{\\partial b}=d_z$</li>\n</ul>\n<h3 id=\"m个样本下的梯度下降\"><a href=\"#m个样本下的梯度下降\" class=\"headerlink\" title=\"m个样本下的梯度下降\"></a><strong>m个样本下的梯度下降</strong></h3><p>因为：$J(w,b)= \\frac{1}{m} \\sum\\limits_{i=1}^m L(a^{(i)},y^{(i)})$</p>\n<p>故:</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial w_1}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_1}L(a^{(i)},y^{(i)}) = \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_1}}^{(i)}=\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1</script><script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial w_2}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial w_2}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{w_2}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2</script><script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial b}J(w,b)=\\frac{1}{m} \\sum\\limits_{i=1}^m \\frac{\\partial}{\\partial b}L(a^{(i)},y^{(i)})= \\frac{1}{m} \\sum\\limits_{i=1}^m {d_{b}}^{(i)} =\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)}</script><h2 id=\"2-2-python和向量化\"><a href=\"#2-2-python和向量化\" class=\"headerlink\" title=\"2.2 python和向量化\"></a><strong>2.2 python和向量化</strong></h2><h3 id=\"向量化\"><a href=\"#向量化\" class=\"headerlink\" title=\"向量化\"></a><strong>向量化</strong></h3><p>神经网络编程指南：<strong>无论何时，避免显式的for循环</strong><br>举例：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 若a,b,c为向量或矩阵</span></span><br><span class=\"line\">c = np.dot(a,b)</span><br><span class=\"line\">b = np.exp(a)</span><br><span class=\"line\">b = np.log(a)</span><br><span class=\"line\">b = np.abs(a)</span><br><span class=\"line\">b = np.maximum(a,<span class=\"number\">0</span>)</span><br><span class=\"line\">b = a**<span class=\"number\">2</span></span><br><span class=\"line\">b = <span class=\"number\">1</span>/a</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"向量化逻辑回归\"><a href=\"#向量化逻辑回归\" class=\"headerlink\" title=\"向量化逻辑回归\"></a><strong>向量化逻辑回归</strong></h3><ul>\n<li>$X_{(n_x*m)}=[x^{(1)},x^{(2)},…,x^{(m)}]$</li>\n<li>$ Z_{(1*m)}=[z^{(1)},z^{(2)},…,z^{(m)}]=w^T X+ [b,…,b]$<br>对应代码：<code>Z=np.dot(w.T,X)+b #broadcasting</code></li>\n<li>$A=[a^{(1)},a^{(2)},…,a^{(m)}]=[\\sigma(z^{(1)}),\\sigma(z^{(2)}),…,\\sigma(z^{(m)})]=\\sigma(Z)$<br>对应代码：<code>A=sigmoid(Z)</code></li>\n</ul>\n<h3 id=\"向量化逻辑回归中的梯度计算\"><a href=\"#向量化逻辑回归中的梯度计算\" class=\"headerlink\" title=\"向量化逻辑回归中的梯度计算\"></a><strong>向量化逻辑回归中的梯度计算</strong></h3><ul>\n<li>${d_{z}}^{(i)}=a^{(i)}-y^{(i)}$</li>\n<li>故<script type=\"math/tex\">d_{Z_{(1*m)}}=[{d_{z}}^{(1)},{d_{z}}^{(2)},...,{d_{z}}^{(m)}]</script></li>\n<li>$A=[a^{(1)},a^{(2)},…,a^{(m)}],Y=[y^{(1)},y^{(2)},…,y^{(m)}]$</li>\n<li>故<script type=\"math/tex\">d_{Z_{(1*m)}}=A-Y=[a^{(1)}-y^{(1)}, a^{(2)}-y^{(2)},..., a^{(m)}-y^{(m)}]</script></li>\n<li><script type=\"math/tex; mode=display\">d_b=\\frac{1}{m}\\sum_{i=1}^{m} {d_z}^{(i)}=\\frac{1}{m}np.sum(d_Z)</script></li>\n<li><script type=\"math/tex; mode=display\">d_w= \\begin{bmatrix} d_{w_1} \\\\d_{w_2} \\\\ ... \\\\d_{w_{n_x}} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_1 \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_2 \\\\ ... \\\\\\frac{1}{m} \\sum\\limits_{i=1}^m {d_z}^{(i)} x^{(i)}_{n_x} \\end{bmatrix} \\\\\n=\\frac{1}{m} X {d_{Z}}^T \n=\\frac{1}{m}[x^{(1)} ,x^{(2)},...,x^{(m)}] \\begin{bmatrix} {d_{z}}^{(1)} \\\\ {d_{z}}^{(2)}\\\\ ...\\\\{d_{z}}^{(m)}\\end{bmatrix}</script></li>\n</ul>\n<h3 id=\"逻辑回归算法流程（伪代码）\"><a href=\"#逻辑回归算法流程（伪代码）\" class=\"headerlink\" title=\"逻辑回归算法流程（伪代码）\"></a><strong>逻辑回归算法流程（伪代码）</strong></h3><p>非向量化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">J=0, dw1=0, dw2=0,db=0</span><br><span class=\"line\">for i = 1 to m</span><br><span class=\"line\">truez(i) = wx(i)+b</span><br><span class=\"line\">truea(i) = sigmoid(z(i))</span><br><span class=\"line\">trueJ += -[y(i)log(a(i))+(1-y(i)）log(1-a(i))</span><br><span class=\"line\">truedz(i) = a(i)-y(i)</span><br><span class=\"line\">truedw1 += x1(i)dz(i)</span><br><span class=\"line\">truedw2 += x2(i)dz(i)</span><br><span class=\"line\">truedb += dz(i)</span><br><span class=\"line\">J /= m</span><br><span class=\"line\">dw1 /= m</span><br><span class=\"line\">dw2 /= m</span><br><span class=\"line\">db /= m</span><br></pre></td></tr></table></figure></p>\n<p>向量化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for iter in range(1000):</span><br><span class=\"line\">    Z = np.dot(w.T,X) + b</span><br><span class=\"line\">    A = sigmoid(Z)</span><br><span class=\"line\">    dZ = A-Y</span><br><span class=\"line\">    dw = 1/m*np.dot(X,dZ.T)</span><br><span class=\"line\">    db = 1/m*np.sum(dZ)</span><br><span class=\"line\">    w = w - alpha*dw</span><br><span class=\"line\">    b = b - alpha*db</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"python中的广播\"><a href=\"#python中的广播\" class=\"headerlink\" title=\"python中的广播\"></a><strong>python中的广播</strong></h3><p>广播(broadcasting)是Python使用中的一种技巧，在Python中可以对不同维度的矩阵进行四则混合运算，前提条件是至少有一个维度是相同的。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD1.jpg\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/python%E5%B9%BF%E6%92%AD2.JPG\" width=\"50%\" height=\"50%\"></p>\n<h3 id=\"关于python-numpy中的向量说明\"><a href=\"#关于python-numpy中的向量说明\" class=\"headerlink\" title=\"关于python/numpy中的向量说明\"></a><strong>关于python/numpy中的向量说明</strong></h3><p>Python中，如果用下列语句来定义一个向量：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.random.randn(5)</span><br></pre></td></tr></table></figure></p>\n<p>这条语句生成的$a$的维度是$(5,)$。它既不是行向量也不是列向量，我们把$a$叫做”rank1 array”。这种定义会带来一些问题。例如我们对$a$进行转置，还是会得到$a$本身。<br>所以，如果我们要定义$(5,1)$的列向量或者$(1,5)$的行向量，最好使用下来标准语句，避免使用”rank1 array”。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.random.randn(5,1)</span><br><span class=\"line\">b = np.random.randn(1,5)</span><br></pre></td></tr></table></figure></p>\n<p>除此之外，我们还可以使用<code>assert</code>语句对向量或数组的维度进行判断，例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">assert(a.shape == (5,1))</span><br></pre></td></tr></table></figure></p>\n<p><code>assert</code>会对内嵌语句进行判断，即判断$a$的维度是不是$(5,1)$的。如果不是，则程序在此处停止。使用<code>assert</code>语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。<br>另外，还可以使用<code>reshape</code>函数对数组设定所需的维度：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = a.reshape((5,1))</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"3-浅层神经网络\"><a href=\"#3-浅层神经网络\" class=\"headerlink\" title=\"3.浅层神经网络\"></a><strong>3.浅层神经网络</strong></h1><h2 id=\"神经网络表示\"><a href=\"#神经网络表示\" class=\"headerlink\" title=\"神经网络表示\"></a><strong>神经网络表示</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E7%A4%BA.JPG\" width=\"60%\" height=\"50%\">以上图为例，注意以下表示：</p>\n<ul>\n<li>输入层（第0层），隐藏层（第1层），输出层（第2层），是一个两层的神经网络。</li>\n<li>$a^{[1]}$表示第一层的激活函数(输出)值,$a^{[1]}=[a^{[1]}_1,a^{[1]}_2,a^{[1]}_3,a^{[1]}_4]^T$,其维度为<script type=\"math/tex\">n^{[1]}*1</script>，即<script type=\"math/tex\">4*1</script>。</li>\n<li>$W^{[1]}$表示第一层的权重值,其维度为<script type=\"math/tex\">n^{[1]}*n^{[0]}</script>，即<script type=\"math/tex\">4*3</script>。(注意)第$l$层的权重$W^{[l]}$的维度为：<script type=\"math/tex\">n^{[l]}*n^{[l-1]}</script>。</li>\n<li>$b^{[1]}$表示第一层的偏置值,其维度为<script type=\"math/tex\">n^{[1]}*1</script>，即<script type=\"math/tex\">4*1</script>。</li>\n<li>预测值$\\hat{y}$即为神经网络最后一层的激活函数值$a^{[2]}$，即$\\hat{y}=a^{[2]}$。</li>\n</ul>\n<h2 id=\"计算神经网络的输出\"><a href=\"#计算神经网络的输出\" class=\"headerlink\" title=\"计算神经网络的输出\"></a><strong>计算神经网络的输出</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA1.JPG\" width=\"50%\" height=\"50%\">首先，神经网络中的每一个神经元，都可以看成一个逻辑回归单元，经过两个步骤来计算输出值$a$:</p>\n<ul>\n<li>$z=w^Tx+b$</li>\n<li>$a = \\sigma(z)$</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BE%93%E5%87%BA2.JPG\" width=\"50%\" height=\"50%\">对于神经网络的输出，可向量化为（可通过维度检查进行确认）：</p>\n<ul>\n<li>$z^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$</li>\n<li>$a^{[1]}=\\sigma(z^{[1]})$</li>\n<li>$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=\\sigma(z^{[2]})$</li>\n</ul>\n<h2 id=\"m个样本中的向量化\"><a href=\"#m个样本中的向量化\" class=\"headerlink\" title=\"m个样本中的向量化\"></a><strong>m个样本中的向量化</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%A4%9A%E6%A0%B7%E6%9C%AC%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96.jpg\" width=\"50%\" height=\"50%\">多个样本的情况下，向量化神经网络输出的方式为：</p>\n<ul>\n<li>$Z^{[1]}=W^{[1]}X+b^{[1]}$</li>\n<li>$A^{[1]}=\\sigma(Z^{[1]})$</li>\n<li>$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$</li>\n<li>$A^{[2]}=\\sigma(Z^{[2]})$</li>\n<li><strong>该向量化方式的核心思想是</strong>：$X$,$Z^{[i]}$及$A^{[i]}$的横向维度表示训练样本，纵向维度表示隐藏单元。形象化示意见图。</li>\n</ul>\n<h2 id=\"激活函数\"><a href=\"#激活函数\" class=\"headerlink\" title=\"激活函数\"></a><strong>激活函数</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg\" width=\"50%\" height=\"50%\"></p>\n<ul>\n<li><code>sigmoid</code>函数和<code>tanh</code>函数都有一个问题，就是当$z$很大或很小时，激活函数的梯度接近于0，会拖慢梯度下降算法。</li>\n<li>研究表明，当隐藏层使用<code>tanh</code>函数几乎总比<code>sigmoid</code>函数的表现更好。因为<code>tanh</code>函数的激活函数值范在[-1,1]之间，激活函数的平均值接近于0，更方便下一层的学习。</li>\n<li>如果是二分类问题，即样本标签$y$为0或1，希望预测值$\\hat{y}$取值为$0\\leq\\hat{y}\\leq1$，则输出层的激活函数可选用<code>sigmoid</code>函数，<strong>否则隐藏层和输出层都不使用<code>sigmoid</code>函数</strong>。</li>\n<li><code>ReLU(rectified  linear unit)</code>激活函数在$z$大于零时梯度始终为1，在$z$小于零时梯度始终为0，$z$等于零时的梯度无定义，可以当成1也可以当成0，实际应用中并不影响（因为在程序中值为0.000…的可能性很小）。<strong>当前隐藏层的默认激活函数选择为<code>ReLU</code></strong>。</li>\n<li><code>ReLU</code>激活函数能够保证$z$大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度（虽然左半边函数的导数等于0，但有足够多的隐藏单元使$z$大于0，因此大部分样本都会训练地很快）。</li>\n<li><code>ReLU</code>激活函数的缺点为当$z$小于零时，导数为0，这个缺点在实际应用中没什么影响。为了弥补这个缺点，出现了<code>Leaky ReLU</code>激活函数，能够保证$z$小于零时梯度不为0，不过实际中使用的频率不高。</li>\n</ul>\n<h2 id=\"为什么需要非线性激活函数\"><a href=\"#为什么需要非线性激活函数\" class=\"headerlink\" title=\"为什么需要非线性激活函数\"></a><strong>为什么需要非线性激活函数</strong></h2><p>以上的四种激活函数都是非线性的。不可使用线性的激活函数，原因如下。<br>假设所有的激活函数都是线性的，那么，浅层神经网络的各层输出为：</p>\n<ul>\n<li>$z^{[1]}=w^{[1]}x+b^{[1]}$</li>\n<li>$a^{[1]}=g^{[1]}(z^{[1]})=z^{[1]}$</li>\n<li>$z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=g^{[2]}(z^{[2]})=z^{[2]}$</li>\n</ul>\n<p>对$a^{[2]}$进行化简:</p>\n<script type=\"math/tex; mode=display\">a^{[2]}=z^{[2]}=w^{[2]}a^{[1]}+b^{[2]}\\\\\n=w^{[2]}(w^{[1]}x+b^{[1]})+b^{[2]}\\\\\n=(w^{[2]}w^{[1]})x+(w^{[2]}b^{[1]}+b^{[2]})\\\\\n=w^{'}+b^{'}</script><ul>\n<li>经过推导发现$a^{[2]}$仍是输入变量$x$的线性组合。这表明，即便是包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入$x$的线性模型。</li>\n<li>因此，<strong>隐藏层的激活函数必须要是非线性的。线性隐藏层没有任何作用，层数再多也不行</strong>。</li>\n<li>只有一种情况可以使用线性激活函数，即对于回归问题，当输出$\\hat{y}$是一个实数时，<strong>输出层的激活函数可以使用线性函数</strong>。如果输出$\\hat{y}$是非负数，则可以使用<code>ReLU</code>激活函数。具体情况，具体分析。</li>\n</ul>\n<h2 id=\"激活函数的导数\"><a href=\"#激活函数的导数\" class=\"headerlink\" title=\"激活函数的导数\"></a><strong>激活函数的导数</strong></h2><p>sigmoid函数的导数：</p>\n<ul>\n<li>$g(z)=\\frac{1}{1+e^{(-z)}}$</li>\n<li>$g’(z)=\\frac{d}{dz}g(z)=g(z)(1-g(z))=a(1-a)$</li>\n</ul>\n<p>tanh函数的导数：</p>\n<ul>\n<li>$g(z)=\\frac{e^{(z)}-e^{(-z)}}{e^{(z)}+e^{(-z)}}$</li>\n<li>$g’(z)=\\frac{d}{dz}g(z)=1-(g(z))^2=1-a^2$</li>\n</ul>\n<p>ReLU函数的导数：</p>\n<ul>\n<li>$g(z)=max(0,z)$</li>\n<li><script type=\"math/tex; mode=display\">g'(z)=\\begin{cases} 0, & z<0\\\\  1, & z\\geq0 \\end{cases}</script></li>\n</ul>\n<p>Leaky ReLU函数的导数：</p>\n<ul>\n<li>$g(z)=max(0.01z,z)$</li>\n<li><script type=\"math/tex; mode=display\">g'(z)=\\begin{cases} 0.01, & z<0\\\\ 1, & z\\geq0 \\end{cases}</script></li>\n</ul>\n<h2 id=\"神经网络的梯度下降法\"><a href=\"#神经网络的梯度下降法\" class=\"headerlink\" title=\"神经网络的梯度下降法\"></a><strong>神经网络的梯度下降法</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"50%\" height=\"50%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"50%\" height=\"50%\">单样本神经网络正向传播过程为：</p>\n<ul>\n<li>$z^{[1]}=W^{[1]}x+b^{[1]}$</li>\n<li>$a^{[1]}=g(z^{[1]})$</li>\n<li>$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$</li>\n<li>$a^{[2]}=g(z^{[2]})$</li>\n<li>其中，$g(\\cdot)$表示激活函数。</li>\n</ul>\n<p>单样本神经网络反向传播过程（即链式法则求导过程）：</p>\n<ul>\n<li>$da^{[2]}=-\\frac{y}{a}+\\frac{1-y}{1-a}$（不同损失函数，结果不同，可不给出具体形式）</li>\n<li>$dz^{[2]}=a^{[2]}-y$（不同损失函数，结果不同，可不给出具体形式，一般只用$d_z$，不用$d_a$）</li>\n<li>$dW^{[2]}=dz^{[2]}a^{[1]T}$</li>\n<li>$db^{[2]}=dz^{[2]}$</li>\n<li>$da^{[1]}=W^{[2]T}dz^{[2]}$</li>\n<li>$dz^{[1]}=W^{[2]T}dz^{[2]}\\ast g^{[1]’}(z^{[1]})$</li>\n<li>$dW^{[1]}=dz^{[1]}x^T$</li>\n<li>$db^{[1]}=dz^{[1]}$</li>\n<li>其中，$*$为逐元素相乘。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"50%\" height=\"50%\">$m$个样本神经网络正向传播过程为：</p>\n<ul>\n<li>$Z^{[1]}=W^{[1]}X+b^{[1]}$</li>\n<li>$A^{[1]}=g(Z^{[1]})$</li>\n<li>$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$</li>\n<li>$A^{[2]}=g(Z^{[2]})$</li>\n<li>其中，$g(\\cdot)$表示激活函数。</li>\n</ul>\n<p>$m$个样本神经网络反向传播过程（即$m$个单样本的梯度求和）：</p>\n<ul>\n<li>$dZ^{[2]}=A^{[2]}-Y$</li>\n<li>$dW^{[2]}=\\frac1mdZ^{[2]}A^{[1]T}$</li>\n<li>$db^{[2]}=\\frac1mnp.sum(dZ^{[2]},axis=1,keepdims=True)$</li>\n<li>$dZ^{[1]}=W^{[2]T}dZ^{[2]}\\ast g^{[1]’}(Z^{[1]})$</li>\n<li>$dW^{[1]}=\\frac1mdZ^{[1]}X^T$</li>\n<li>$db^{[1]}=\\frac1mnp.sum(dZ^{[1]},axis=1,keepdims=True)$</li>\n<li>其中，$*$为逐元素相乘。</li>\n</ul>\n<p>该节的一个重要参考：<a href=\"https://zhuanlan.zhihu.com/p/22473137\" target=\"_blank\" rel=\"noopener\">神经网络反向传播的数学原理</a></p>\n<h2 id=\"随机初始化\"><a href=\"#随机初始化\" class=\"headerlink\" title=\"随机初始化\"></a><strong>随机初始化</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.jpg\" width=\"50%\" height=\"50%\"><br>神经网络模型中的参数权重$W$不能全部初始化为零。<br>举例说明，如图，如果权重$W^{[1]}$和$W^{[2]}$都初始化为零，即：</p>\n<script type=\"math/tex; mode=display\">W^{[1]}= \\left[ \\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix} \\right]</script><script type=\"math/tex; mode=display\">W^{[2]}= \\left[ \\begin{matrix} 0 & 0 \\end{matrix} \\right]</script><ul>\n<li>这样使得$a_1^{[1]}=a_2^{[1]}$。进一步可得$dz_1^{[1]}=dz_2^{[1]}$ ，以及$dW_1^{[1]}=dW_2^{[1]}$。</li>\n<li>因此，每次迭代更新：$W^{[1]} = W^{[1]}-dW^{[1]}$。 $W^{[1]}$每一行都相等，即$W_1^{[1]}$和$W_2^{[1]}$都会相等。无论经过多少次迭代，隐藏层的神经元总是对称的。这样隐藏层设置多个神经元就没有任何意义了。</li>\n<li>参数$b$全部初始化为零，不会产生对称失效问题。</li>\n<li>解决方法：将$W$进行随机初始化($b$可初始化为零)来打破对称(break symmetry)。</li>\n</ul>\n<p>Python中可以使用如下语句进行$W$和$b$的随机初始化：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">W_1 = np.random.randn(2,2)*0.01</span><br><span class=\"line\">b_1 = np.zeros((2,1))</span><br><span class=\"line\">W_2 = np.random.randn(1,2)*0.01</span><br><span class=\"line\">b_2 = 0</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>在对$W^{[1]}$进行随机初始化时，乘以0.01的目的是尽量使得权重$W$初始化为比较小的值。</li>\n<li>之所以让$W$比较小，是因为如果使用<code>sigmoid</code>函数或者<code>tanh</code>函数作为激活函数时，若$W$较大，则训练的开始阶段$z$就比较大，由<code>sigmoid</code>函数或者<code>tanh</code>函数的曲线可以看出，当$|z|$过大时，其梯度近似为0，会使得训练过程十分缓慢。</li>\n<li>当然，如果未使用<code>sigmoid</code>激活函数或者<code>tanh</code>激活函数，该情况可能不明显。但是如果对于二分类问题，输出层是<code>sigmoid</code>函数，则对应的权重$W$最好初始化到比较小的值。</li>\n</ul>\n<h1 id=\"4-深层神经网络\"><a href=\"#4-深层神经网络\" class=\"headerlink\" title=\"4.深层神经网络\"></a><strong>4.深层神经网络</strong></h1><h2 id=\"深层神经网络\"><a href=\"#深层神经网络\" class=\"headerlink\" title=\"深层神经网络\"></a><strong>深层神经网络</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"70%\" height=\"50%\">深层神经网络其实就是包含更多隐藏层的神经网络。如上图所示，分别列举了逻辑回归、1个隐藏层的神经网络、2个隐藏层的神经网络和5个隐藏层的神经网络它们的模型结构。</p>\n<h2 id=\"深层网络中的前向传播\"><a href=\"#深层网络中的前向传播\" class=\"headerlink\" title=\"深层网络中的前向传播\"></a><strong>深层网络中的前向传播</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD.JPG\" width=\"50%\" height=\"50%\">以上面讲过的4层神经网络为例，推导一下深层神经网络的正向传播过程。<br>单个样本下，深层神经网络的正向传播过程：</p>\n<ul>\n<li>$l=1$：$z^{[1]}=W^{[1]}x+b^{[1]}=W^{[1]}a^{[0]}+b^{[1]}$，$a^{[1]}=g^{[1]}(z^{[1]})$</li>\n<li>$l=2$：$z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}$，$a^{[2]}=g^{[2]}(z^{[2]})$</li>\n<li>$l=3$：$z^{[3]}=W^{[3]}a^{[2]}+b^{[3]}$，$a^{[3]}=g^{[3]}(z^{[3]})$</li>\n<li>$l=4$：$z^{[4]}=W^{[4]}a^{[3]}+b^{[4]}$，$a^{[4]}=g^{[4]}(z^{[4]})$</li>\n</ul>\n<p>$m$个样本下，深层神经网络的正向传播过程：</p>\n<ul>\n<li>$l=1$：$Z^{[1]}=W^{[1]}X+b^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$，$A^{[1]}=g^{[1]}(Z^{[1]})$</li>\n<li>$l=2$：$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$，$A^{[2]}=g^{[2]}(Z^{[2]})$</li>\n<li>$l=3$：$Z^{[3]}=W^{[3]}A^{[2]}+b^{[3]}$，$A^{[3]}=g^{[3]}(Z^{[3]})$</li>\n<li>$l=4$：$Z^{[4]}=W^{[4]}A^{[3]}+b^{[4]}$，$A^{[4]}=g^{[4]}(Z^{[4]})$</li>\n</ul>\n<p>综上所述，对于第$l$层，其正向传播过程的$Z^{[l]}$和$A^{[l]}$可以表示为：</p>\n<ul>\n<li>$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$</li>\n<li>$A^{[l]}=g^{[l]}(Z^{[l]})$</li>\n<li>其中，$l=1,\\cdots,L$</li>\n</ul>\n<h2 id=\"矩阵维度检查\"><a href=\"#矩阵维度检查\" class=\"headerlink\" title=\"矩阵维度检查\"></a><strong>矩阵维度检查</strong></h2><p>对于单个训练样本，输入$x$的维度是:</p>\n<ul>\n<li>$x:(n^{[0]},1)$。</li>\n</ul>\n<p>神经网络的参数$W^{[l]}$和$b^{[l]}$的维度分别是：</p>\n<ul>\n<li>$W^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$b^{[l]}:\\ (n^{[l]},1)$</li>\n<li>其中，$l=1,\\cdots,L$，$n^{[l]}$和$n^{[l-1]}$分别表示第$l$层和$l-1$层中所含神经元的个数。$n^{[0]}=n_x$，表示输入尺寸。</li>\n</ul>\n<p>正向传播过程中的$z^{[l]}$和$a^{[l]}$的维度分别是：</p>\n<ul>\n<li>$z^{[l]}:\\ (n^{[l]},1)$</li>\n<li>$a^{[l]}:\\ (n^{[l]},1)$</li>\n<li>$z^{[l]}$和$a^{[l]}$的维度是一样的，且$dz^{[l]}$和$da^{[l]}$的维度均与$z^{[l]}$和$a^{[l]}$的维度一致。</li>\n</ul>\n<p>反向传播过程中的$dW^{[l]}$和$db^{[l]}$的维度分别是：</p>\n<ul>\n<li>$dW^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$db^{[l]}:\\ (n^{[l]},1)$</li>\n<li>注意到， $dW^{[l]}$与$W^{[l]}$的维度相同，$db^{[l]}$与$b^{[l]}$的维度相同。</li>\n</ul>\n<p>对于$m$个训练样本，输入矩阵$X$的维度是：</p>\n<ul>\n<li>$X:(n^{[0]},m)$。</li>\n</ul>\n<p>参数$W^{[l]}$和$b^{[l]}$的维度与只有单个样本是一致的：</p>\n<ul>\n<li>$W^{[l]}:\\ (n^{[l]},n^{[l-1]})$</li>\n<li>$b^{[l]}:\\ (n^{[l]},1)$</li>\n<li>只不过在运算$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$中，$b^{[l]}$会被当成$(n^{[l]},m)$矩阵进行运算，这是因为python的广播性质，且 $b^{[l]}$每一列向量都是一样的。</li>\n<li>$dW^{[l]}$和$db^{[l]}$的维度分别与$W^{[l]}$和$b^{[l]}$一致。</li>\n</ul>\n<p>但是，$Z^{[l]}$ 和$A^{[l]}$的维度发生了变化：</p>\n<ul>\n<li>$Z^{[l]}:\\ (n^{[l]},m)$</li>\n<li>$A^{[l]}:\\ (n^{[l]},m)$</li>\n<li>$dZ^{[l]}$和$dA^{[l]}$的维度分别与$Z^{[l]}$和$A^{[l]}$一致。</li>\n</ul>\n<h2 id=\"为什么使用深层的神经网络\"><a href=\"#为什么使用深层的神经网络\" class=\"headerlink\" title=\"为什么使用深层的神经网络\"></a><strong>为什么使用深层的神经网络</strong></h2><ul>\n<li>神经网络层数越深，能够提取到的特征越复杂。</li>\n<li>以CNN为例，低层网络提取到简单的局部特征，深层网络提取到复杂的全局特征。层数越深，提取到的特征越复杂。</li>\n<li>以RNN为例，也是如此。</li>\n</ul>\n<h2 id=\"搭建深层神经网络块\"><a href=\"#搭建深层神经网络块\" class=\"headerlink\" title=\"搭建深层神经网络块\"></a><strong>搭建深层神经网络块</strong></h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97.jpg\" width=\"50%\" height=\"50%\"><br>上图为能表示出深层神经网络正向传播和反向传播过程的块(block)图。<br>如图所示，对于第$l$层来说，正向传播过程中：</p>\n<ul>\n<li>输入：$a^{[l-1]}$</li>\n<li>输出：$a^{[l]}$</li>\n<li>参数：$W^{[l]},b^{[l]}$</li>\n<li>缓存变量： $z^{[l]}$</li>\n</ul>\n<p>反向传播过程中：</p>\n<ul>\n<li>输入：$da^{[l]}$</li>\n<li>输出：$da^{[l-1]},dW^{[l]},db^{[l]}$</li>\n<li>参数：$W^{[l]},b^{[l]}$</li>\n</ul>\n<p>用块图构建出一个深层神经网络的正向传播过程和反向传播过程，如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/l%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9D%97%E5%9B%BE.jpg\" width=\"100%\" height=\"50%\"></p>\n<h2 id=\"正向传播和反向传播\"><a href=\"#正向传播和反向传播\" class=\"headerlink\" title=\"正向传播和反向传播\"></a><strong>正向传播和反向传播</strong></h2><p>对于单个样本，第$l$层的正向传播：</p>\n<ul>\n<li>输入：$a^{[l-1]}$</li>\n<li>输出：$a^{[l]}$，缓存变量：$z^{[l]}$</li>\n</ul>\n<p>具体表达式如下：</p>\n<ul>\n<li>$z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]}$</li>\n<li>$a^{[l]}=g^{[l]}(z^{[l]})$</li>\n</ul>\n<p>$m$个训练样本，向量化形式为：</p>\n<ul>\n<li>$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$</li>\n<li>$A^{[l]}=g^{[l]}(Z^{[l]})$</li>\n</ul>\n<p>对于单个样本，第$l$层的反向传播：</p>\n<ul>\n<li>输入：$da^{[l]}$</li>\n<li>输出：$da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$。</li>\n</ul>\n<p>具体表达式如下：</p>\n<ul>\n<li>$dz^{[l]}=da^{[l]}\\ast g^{[l]’}(z^{[l]})$</li>\n<li>$dW^{[l]}=dz^{[l]}\\cdot a^{[l-1]}$</li>\n<li>$db^{[l]}=dz^{[l]}$</li>\n<li>$da^{[l-1]}=W^{[l]T}\\cdot dz^{[l]}$</li>\n<li>由上述第四个表达式可得$da^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}$，将$da^{[l]}$代入第一个表达式中可以得到：$dz^{[l]}=W^{[l+1]T}\\cdot dz^{[l+1]}\\ast g^{[l]’}(z^{[l]})$该式非常重要，反映了$dz^{[l+1]}$与$dz^{[l]}$的递推关系。</li>\n</ul>\n<p>$m$个训练样本，向量化形式为：</p>\n<ul>\n<li>$dZ^{[l]}=dA^{[l]}\\ast g^{[l]’}(Z^{[l]})$</li>\n<li>$dW^{[l]}=\\frac1mdZ^{[l]}\\cdot A^{[l-1]T}$</li>\n<li>$db^{[l]}=\\frac1mnp.sum(dZ^{[l]},axis=1,keepdims=True)$</li>\n<li>$dA^{[l-1]}=W^{[l]T}\\cdot dZ^{[l]}$</li>\n<li>$dZ^{[l]}=W^{[l+1]T}\\cdot dZ^{[l+1]}\\ast g^{[l]’}(Z^{[l]})$</li>\n</ul>\n<h2 id=\"参数和超参数\"><a href=\"#参数和超参数\" class=\"headerlink\" title=\"参数和超参数\"></a><strong>参数和超参数</strong></h2><p>对于神经网络中的参数(parameters)和超参数(hyperparameters)的概念：</p>\n<ul>\n<li>神经网络中的参数就是我们熟悉的$W^{[l]}$和$b^{[l]}$。</li>\n<li>而超参数则是例如学习速率$\\alpha$，训练迭代次数$N$，神经网络层数$L$，各层神经元个数$n^{[l]}$，甚至激活函数$g(z)$的种类等。</li>\n<li>之所以<strong>叫做超参数的原因</strong>是它们高于参数，决定了参数$W^{[l]}$和$b^{[l]}$的取值。</li>\n</ul>"},{"title":"深度学习课程(三)构建机器学习项目","mathjax":true,"date":"2018-01-08T01:17:50.000Z","_content":"# 1.机器学习策略(1)\n## 1.1 机器学习策略介绍\n### 为什么需要机器学习策略\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5.JPG\" width=\"80%\" height=\"80%\">\n- 当试图优化一个深度学习系统时，通常有很多想法可以尝试。如图，比如我们在做一个猫的分类器时，经过一段时间的工作，系统的准确率达到了90%。但对于应用程序来说，表现还不够好，我们可能有许多想法来改进这个系统，想法如图所示。\n- 如果做出了错误的选择，不仅耗费时间而且可能收效甚微。如盲目的选择收集更多数据，花费6个月时间收集数据，但最终对系统的改进很小。\n- 机器学习策略就是分析机器学习问题的方法，指引我们朝着最有希望的想法的方向去尝试。\n \n<!-- more --> \n \n### 正交化\n学会诊断出限制系统性能的瓶颈在哪里，然后找到一组**特定的旋钮(方法)**，从而改善系统**特定方面的性能**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%961.JPG\" width=\"80%\" height=\"80%\">\n- 如图，以电视机屏幕调节为例，每个旋钮对应一个功能(如长度调整、宽度调整、梯度调整等)，每一旋钮解决特定问题，是正交的，可很好的调节电视机屏幕。\n- 如图，以驾驶汽车为例，方向盘、油门及刹车，这三种正交化的操作，可以很好的控制汽车。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%962.JPG\" width=\"80%\" height=\"80%\">\n- 要做好一个监督学习系统，需要调节系统的旋钮，去确保四件事情：\n- 1.使得代价函数很好地拟合训练集。\n  - 旋钮：更大的网络，使用Adam等优化算法。\n- 2.使得代价函数很好地拟合开发集。\n  - 旋钮：正则化，采用更大的训练集。\n  - 解释：在训练集上表现好，而开发集表现不好，则是在训练集上过拟合。\n- 3.使得代价函数很好地拟合测试集。\n  - 旋钮：采用更大的开发集。\n  - 解释：在开发集上表现好，而测试集表现不好，则是在开发集上过拟合。\n- 4.在现实世界中取得好的表现。\n  - 旋钮：调整开发/测试集，使用新的代价函数。\n  - 解释：在开发/测试集上表现好，在现实中表现不好，要么是开发/测试集设置有问题，要么是代价函数设置有问题。\n- 概括来说，系统的每一旋钮只会针对性的解决一个问题，是正交的。\n- 此外，提前终止(early stopping)在模型功能调试中并不推荐使用。因为提前终止提升验证集性能的同时降低了训练集的性能。也就是说提前终止同时影响两件事情，不具有正交性。\n\n## 1.2 设置你的目标\n### 单一数字评价指标\n无论是在调节超参数，还是尝试不同的算法，设置一个单一数字评价指标，可以提高决策效率。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87_1.JPG\" width=\"100%\" height=\"100%\">\n- 之前讲过，应用机器学习是一个经验性的过程：想法-代码-实验，循环迭代。\n- 如图，对于分类器A和B，若采用两个评价指标：查准率(precision)和查全率(recall)时，将难以决策分类器A和B的好坏。\n- 此情况下，采用F1得分(F1 score)作为单一数字评价指标，则可快速选出最好的分类器。\n- 很多机器学习团队的做法：明确的开发集结合单一数字评价指标，可以加速上述迭代过程。\n\n注：\n- <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87.jpg\" width=\"50%\" height=\"50%\">\n- 查准率(precision)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87.JPG\" width=\"80%\" height=\"50%\">\n - 假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。\n- 查全率(recall)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%85%A8%E7%8E%87.JPG\" width=\"80%\" height=\"50%\">\n - 假设在是否为猫的分类问题中，查全率代表：所有真实为猫的图片中，预测正确的概率。\n- F1得分(F1 score)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/f1score.JPG\" width=\"30%\" height=\"30%\">\n - F1得分是查准率和查全率的调和平均。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\">\n- 另一例，对于不同算法，以每一算法在不同地区表现的平均数作为单一数字评价指标，可以快速选出表现最好的算法。\n\n### 满足和优化指标\n有时候，要把所有的性能指标都综合在一起，组成单实数评价指标(single real number evaluation metric)是比较困难的。解决办法是，把某些性能作为**优化指标(Optimizing metic)**，寻求最优化值；而某些性能作为**满意指标(Satisficing metic)**，只要满足阈值就行了。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%BB%A1%E8%B6%B3%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E6%A0%87.JPG\" width=\"90%\" height=\"90%\"> \n- 如图，分类器的性能：准确率和运行时间。若将准确率和运行时间组合成一个整体评价指标，如：$$cost=accuracy  -  0.5 \\cdot running\\ time$$\n- 可将准确率作为优化指标，将运行时间作为满意指标。即最大限度的提高准确率($maximize\\ accuracy$)，但算法必须满足运行时间的要求，即达到一定阈值即可(如$running \\ time \\leq 100ms$)。这是一个相对合理地权衡准确率和运行时间的方式。\n- 更一般地说，若有$N$个指标，有时将1个指标作为最优指标，其他$N-1$个作为满意指标。\n\n第二个例子：谷歌/亚马逊/百度的语音助手的唤醒/触发词，关心的指标有两个：\n- 一是对于触发词检测系统的准确率(说出触发词，有多大概率唤醒设备)。\n- 二是假阳性(false positive)的数量(没有说出触发词，设备被随机唤醒的概率)。\n- 组合这两种评估指标的合理方式是：准确率作为优化指标，最大化准确率。假阳性数量作为满意指标，小于一定阈值即可，如24小时之内少于1次。\n \n### 训练/开发/测试集划分\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%92%E5%88%863.JPG\" width=\"80%\" height=\"80%\">  开发/测试集划分准则：\n- 首先，**开发集和测试集需要来自同一分布**。\n- 然后，选择这样的开发集和测试集：**能够反映未来会得到的数据，并且你认为是很重要的，必须得到好结果的数据**。\n- **设立开发集以及评价指标，就等同于定义了你要瞄准的目标。测试集和开发集属于同一分布，相当于瞄准的是同一目标(靶心)，否则相当于设置了另一个目标(靶心)。而训练集的设置，影响的是逼近这个目标有多快**。\n \n### 开发集和测试集的大小\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F2.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F3.JPG\" width=\"80%\" height=\"80%\">\n旧的划分数据的方式：\n- 当没有测试集时：训练集分70%，开发集分30%。\n- 当有开发集时：训练集分60%，开发集分20%，测试集分20%。\n- 此划分方法适用于机器学习早期，即适用于数据量小的情况(如100，1000，10000个样本)。\n\n现代机器学习划分数据的方式（有着非常大的数据集，如有一百万个样本）：\n- 训练集分98%，开发集分1%，测试集分1%。\n- 开发集和测试集各有10000个例子，足够了。\n- 深度学习算法对数据的胃口很大，给训练集划分更多的数据，去喂饱模型。\n\n开发集的大小设置准则：\n- 令开发集足够大，能够检测不同算法/模型的区别，选择出更好的算法/模型即可。\n\n测试集的大小设置准则：\n- 令测试集足够大，能够以高置信度评价系统的整体性能即可。\n\n另外：\n- 虽然不建议这样做，但如果不需要给出对算法/模型的无偏估计，那不设置测试集，只划分训练/开发集也是可以的。\n\n### 什么时候改变开发/测试集和评价指标\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%871.JPG\" width=\"80%\" height=\"80%\"> 如果当前的评价指标无法给出更好算法的正确排名，那就需要花时间定义一个新的评价指标：\n- 如图所示，目前的评价指标是错误率。\n- 虽然算法A的错误率低于算法B的错误率，但算法A会将色情图片分类为猫的图片。这时若将色情图片当作猫的图片推送给用户，那这是极其糟糕的错误。因此，算法A虽然错误率低，但其实是一个很糟糕的算法，相比而言，算法B应该更好。\n- 因此，当前的评价指标错误率，无法给出更好算法的正确排名，应重新定义一个新的评价指标。\n- 如定义新的评价指标为$$Error: \\frac{1}{\\sum_{i=1}^{m_{dev}} w^{(i)}}\\sum_{i=1}^{m_{dev}} w^{(i)}1\\{\\hat y^{(i)} \\neq y^{(i)}\\}$$\n- 其中，$$w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}$$\n- 注：使用此种加权函数的方式，需手动遍历开发集和测试集，将色情图片标注出来。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"> 上一课件中，处理猫类图片反色情问题的方式，实际上是正交化一种体现：\n- 第一步，只讨论了如何去定义一个评价分类器的指标。这相当于设定一个目标(靶心)。\n- 第二步，单独去考虑如何提升系统在这个指标上的表现。这相当于如何瞄准/命中这个目标(靶心)。\n- 对于第二步，为了提高系统在新的评价指标上的评分，如修改神经网络需优化的代价函数为：$$J=\\frac{1}{\\sum_{i=1}^m w^{(i)}}\\sum_{i=1}^mw^{(i)}L(\\hat y^{(i)},y^{(i)})$$\n- 其中，$$w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%873.JPG\" width=\"80%\" height=\"80%\"> 如图，另一例：\n- 开发/测试集是专业且正规的猫的图片，实际应用中用户上传的图片是随意且模糊的。\n- 当在评价指标和开发/测试集上做的很好，但在实际应用中做的不好时，应该改变评价指标以及开发/测试集。\n- 可以看出，上图中的开发/测试集设置有误，没有反映出你的算法需要处理好的且在未来会遇到的数据。\n\n最后的建议：\n- 有一个评价指标和开发集，可以让你更快的做出决策，到底哪个算法更好，从而加快迭代速度。\n- 因此，即使无法定义出一个很完美的评价指标和开发集，直接快速设置出来，然后使用它们来驱动迭代速度。\n- 在这之后，如果发现它们不够好，马上做出改变。\n\n## 1.3 相比于人类的表现\n### 为什么是人类的表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 在过去的几年里，许多机器团队一直在讨论如何比较机器学习系统和人类的表现：\n- 图中，机器学习系统以较快地速度接近人类表现，甚至超过它。\n- 超过人类表现之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，称之为贝叶斯最优误差(bayes optimal error)。\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 当机器学习系统的表现比人类的差时，有一些工具可以用来提高性能，而一旦超越了人类的表现，这些工具就不那么好用了：\n- 让人类帮助标注数据。\n - 解释：这样就可以有更多的数据可以喂给模型。\n- 通过人工错误分析。\n - 解释：下周讲解。只要人类的表现比其他任何算法都要好，就可以让人类去查看算法做错的例子，并尝试了解为什么人能做对，算法做错。\n- 进行更好的偏差/方差分析。\n - 解释：下节讲解。\n- 注：只要你的算法比人类的表现糟糕，上述三条策略可以改善算法，而一旦你的算法做的比人类好，上述三条策略就很难利用了。\n\n### 可避免偏差\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8F%AF%E9%81%BF%E5%85%8D%E5%81%8F%E5%B7%AE.JPG\" width=\"90%\" height=\"90%\"> 我们希望算法在训练集上表现好，但实际上不想算法在训练集上表现得太好。当知道人类的表现后，可以准确的告诉你算法在训练集上的表现到底该有多好。\n如图中的猫分类器为例：\n- 在第二们课程里关于偏差和方差的讨论中，我们主要假设一些任务的贝叶斯误差几乎接近于0。\n- 在对于某些人类擅长的任务：如计算机视觉任务，人类水平误差虽高于贝叶斯误差(理论上限)，但可认为近似等于贝叶斯误差。\n- 在确定人类水平(近似贝叶斯误差)后，就定义了我们认为什么样的水平是可以实现的：\n - **将人类水平误差和训练误差之间的差值**称为**可避免偏差(avoidable bias)**，或可避免偏差的度量。\n - **将训练误差和开发集误差之间的差值**称为**方差**，或方差的度量。\n - **根据可避免偏差和方差的相对大小，决定专注于减少偏差的策略还是减少方差的策略**。\n - 若将贝叶斯误差定为1%，而训练误差为8%，我们认为可以将它降低到1%，那么将专注于减小偏差；\n - 若将贝叶斯误差定为7.5%，而训练误差为8%，可避免误差为0.5%，没什么改进空间，不能再继续减少训练误差了，防止过拟合。而训练误差和开发集误差相差2%，那么将专注于减少方差。\n\n### 理解人类的表现\n应该这样看待人来水平表现：人类的表现是贝叶斯误差的替代或估计。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\">\n- 如图所示，应将人类水平定义为一个专家团队的表现，即错误率为0.5%。0.5%是贝叶斯误差的最佳估计。\n - 解释：因为要将人类水平表现看作是贝叶斯误差的替代或近似，故选取表现最好的一组，所以此处便可认为：$Bayes\\ error \\leq 0.05%$\n- 在上一节，通过人类水平表现来分析偏差和方差时，也是这样看待人类水平表现的，即作为贝叶斯误差的替代。\n- 在实际应用中，针对具体的应用情况，如果认为达到某个标准，就已经实用了，也可选用其他标准来作为人类水平表现。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\">\n- 在系统表现，未达到人类水平表现之前，不管如何定义人类水平表现(1%/0/7%/0.5%)，都不影响减小偏差策略还是减小方差策略的确定。\n - 如图中左侧两例。\n- 在系统接近人类表现之后，系统的提升变得很难，因为如果贝叶斯误差估计的不准确，将难以发现到底是方差问题还是偏差问题：\n - 如上图最右侧，只有将贝叶斯误差定义为0.5%(一个专家团队的表现)，才能发现可避免偏差0.2%，方差0.1%，从而决定该采用减小偏差策略；\n - 若将贝叶斯误差定义为0.7%，则可避免偏差为0%，方差为0.1%，则会采用减小方差的策略。、\n - 当你只知道贝叶斯误差是单个医生的表现即1%时，你甚至无法知道该不该继续去拟合训练集。\n - 因此，当系统接近人类表现时，很难更进一步。因为很难准确的估计贝叶斯误差，难以确定是偏差还是方差问题。\n\n另外：\n- 对于计算机视觉任务，比如猫识别问题，人类的表现近乎完美，所以贝叶斯误差也接近完美，那么将贝叶斯误差设为0，没什么问题。\n- 但如果数据有很大的噪声，对于背景很嘈杂的语音识别问题，有时几乎不可能听清说什么。对于这样的问题，更好的定义贝叶斯误差很重要，可以帮助我们更好的估计可避免误差和方差，这样才能更好的做出决策，选择减少偏差策略还是减少方差策略。\n\n### 超越人的表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\">\n- 如图左侧，当贝叶斯误差为0.5%，则可避免偏差为0.1%，方差为0.2%，则选择减小方差策略。\n- 如图右侧，当贝叶斯误差为0.5%，训练误差为0.3%，则不知道是训练误差过拟合了0.2%，还是贝叶斯误差实际上是0.1%/0.2%/0.3%，无法知道。此例中没有足够的信息，来判断应该选择减小偏差还是减小方差，这样取得进展的效率就会降低。\n- 在这个例子中，一旦超过了0.5%这个阈值，优化算法的方向便不那么明确了，因为现有的一些指明明确方向的工具失效了（但并不意味着不能继续提升，还是可以继续提升）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 图中列举出了显著超越人类水平表现的机器学习应用：\n- 首先是对于结构化数据：\n - 在线广告（估计某个用户点击某个广告的可能性）\n - 产品推荐（推荐电影或书籍之类）\n - 物流预测(logistics)（预测运输时间）\n - 贷款批准\n - 原因：计算机擅长访问大量数据，识别出数据中的统计规律。\n- 人类擅长自然感知(natural perception)任务，但也有一些机器学习应用超越了人类水平表现：\n - 语音识别\n - 某些图像识别任务\n - 某些医疗方面任务，如阅读ECG、皮肤癌诊断、放射科读图任务\n\n### 改善你的模型表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 要让一个监督学习算法足够好，需要完成以下两件事：\n- 首先，很好的拟合训练集（即让可避免误差很低）。\n- 然后，在开发/测试集上的泛化很好（即让方差较低）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在正交化的精神下，有单独的旋钮，去处理偏差问题或方差问题：\n- 减少可避免偏差：\n - 使用更大的模型\n - 训练更长的时间，或使用更好的优化算法(如Momentum,RMSprop,Adam)\n - 尝试其他的神经网络架构(如RNN，CNN，有时会有好的效果，不确定)，或进行超参数搜索\n- 减少方差：\n - 搜集更多训练数据（训练更多数据，可以帮助系统泛化到看不到的开发集）\n - 正则化(如L2正则化，Dropout，数据增强)\n - 尝试其他的神经网络架构或进行超参数搜索\n \n# 2.机器学习策略(2)\n## 2.1 错误分析 \n### 进行错误分析\n如果你希望让学习算法胜任人类能做的任务，但你的学习算法还没有达到人类的表现。那么，**人工检查算法所犯下的错误，可以让你了解接下来该做什么**。这个过程称为**错误分析(error analysis)**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%901.JPG\" width=\"80%\" height=\"80%\">\n- 假设猫分类器在开发集上取得了90%的准确率，即10%的误差。\n- 注意到把一些狗分类成猫，问题是：是否需要开始做一个项目专门处理狗的问题？\n- 解决方法：错误分析：\n - 首先，从开发集中找出约100个错误分类的样本。\n - 然后，人工统计出多少个是狗。\n- 如果有5%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是9.5%(10%减少5%)的错误率。不值得专门花费大量时间。\n- 如果有50%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是5%(10%减少50%)的错误率。值得花费时间解决狗的问题。\n- 另外，尽管是人工统计，但检查100个开发集错误分类样本，只需要5-10分钟的时间，便可以给我们指出最有希望的方向。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%902.JPG\" width=\"80%\" height=\"80%\"> 并行评估多个想法：\n- 如图，针对如何改进猫的分类器，你有以下几个想法：狗的误分类问题，大型猫科动物的误分类问题，以及改善系统在模糊图片上的表现。\n- 进行错误分析：\n - 首先，建立一个电子表格，每一列是你的一个想法，每一行是一个开发集上的误分类样本。此外，最后一栏记录你对每个误分类样本的注释。\n - 然后，人工统计从开发集选出的每一个误分类样本，记录在电子表格中。\n - 最后，统计出每一列(即每一个想法)所对应的误分类样本的比例，针对不同比例，确定改进猫分类器的方向。\n - 另外，当你在人工统计时，又有了新的想法，比如发现由于Instagram滤镜的问题经常导致误分类，则可将该想法作为新的一列加入电子表格中。\n\n总结：\n- 进行错误分析：\n - 首先应该从开发集找一组错误分类的例子。\n - 观察错误分类的例子（假阳性和假阴性），统计出属于不同错误类型的错误样本数量。\n - 在这个过程中，你可能会得到启发归纳出新的错误类型，那就在中途新建一个错误类型。\n - 最后，通过统计不同错误类型包含的样本的比例，决定哪个问题需要优先解决，或者给你构思新优化方向的灵感。\n \n### 清理错误标记的数据\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE1.JPG\" width=\"80%\" height=\"80%\"> 首先，对于训练集中标记出错的样本：\n- 深度学习算法对训练集中的随机错误是相当鲁棒的：\n - 只要标记出错的样本，是由于随机错误(即标记人员不小心标错)，不管也没问题，不用花费太多时间去修正它们，只要训练集足够大。\n - 但如果标记出错的样本，是由于系统性错误(如标记人员一直把白色的狗标记成猫)，分类器训练后，将会一直把白色的狗标记成猫。这种情况肯定需要修正。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE2.JPG\" width=\"80%\" height=\"80%\"> 然后，对于开发/测试集中标记出错的数据：\n- 若担心在开发/测试集上标记出错的例子带来的影响，建议在进行错误分析时，增加一列，记录标签出错的样本，然后统计其比例。\n- 若这些标记错误严重影响了你在开发集上评估算法的能力，那就需要花时间修正错误标记的数据，具体来说，通过查看三个数字：\n - 整体开发集错误率\n - 由错误标记样本导致的错误率\n - 其他原因导致的错误率\n - 例1：如图左侧，整体开发集错误率为10%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为9.4%，修正错误标记样本是低优先级的方向。\n - 例2：如图右侧，整体开发集错误率为2%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为1.4%，由错误标记样本导致的错误率占了整体开发集错误率的很大比重，值得花费时间去修正错误标记的数据。\n - 例3：开发集的目的是为了帮助你从分类器A和B中选择更好的一个。\n 算法A的整体开发集错误率为2.1%，算法B的整体开发集错误率为1.9%，而其中由错误标记样本导致的错误率为0.6%，无法再信任开发集，因为它无法正确告诉你分类器A是否真的比分类器B好。此情况必须去修正开发集里的错误标签了。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE3.JPG\" width=\"80%\" height=\"80%\"> 如果决定要修正开发集数据里的错误标签(人工逐个检查并修正)，那么有一些指南：\n- 施加同样的处理手段给开发集和测试集，以保证它们依然来自同一分布。\n- 考虑同时检测算法判断正确和判断错误的例子。\n - 不容易去做，因为如果算法准确率很高，如98%，那检查98%的数据的标签，要花费很长时间，所以通常不总是这么做，但也是需要考虑的。\n- 训练集和开发/测试集有可能来自稍微不同的分布。\n - 如果你决定修改开发/测试集(通常比训练集小很多)，而有可能不修改训练集(深度学习算法对随机错误很鲁棒且训练集很大，也不想花费大量时间去修正)，而这样是可以的。后面会进一步讲解。\n\n最后的建议：\n- 在构建实际的系统时，通常需要更多的人工错误分析和更多的人类见解。\n- 有些深度学习研究员不愿意去亲自看这100或几百个例子，来统计错误数量，这是我(吴恩达)经常亲自去做的，可能花费十几分钟或几个小时，但可以帮我找到需要优先处理的任务。\n \n### 快速构建你的第一个系统，然后迭代\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%84%B6%E5%90%8E%E8%BF%AD%E4%BB%A3.JPG\" width=\"80%\" height=\"80%\"> 如图，如果要建立一个新的语音识别系统，你可以走很多方向或有很多可以优先考虑的事情，来改善语音识别系统，如图所示。\n- 建议：如果你正在开发新的机器学习应用，那么应该快速建立你的第一个系统，然后迭代：\n - 快速设立开发/测试集以及评价指标 \n - 快速构建初始的系统\n - 使用偏差/方差分析以及错误分析去确定下一步优先做什么\n\n最后的总结：\n- 如果你在这个应用领域有很多经验，这个建议的适用程度要低一些。或当这个领域有很多可以借鉴的学术文献和你要处理扽问题几乎完全相同，这个建议的适用程度也要低一些。例如，在人脸识别领域就有很多学术文献，如果你尝试建立一个人脸识别器，那么就可以从现有的大量学术文献作为基础出发，一开始就建立比较复杂的系统。\n- 但如果你第一次处理某个新问题，还是遵循以上建议。\n\n## 2.2 不匹配的训练集和验证/测试集\n### 在不同分布上进行训练和测试\n深度学习算法对训练数据的胃口很大，当你收集到足够多的带标签的数据构成训练集时，算法效果最好。这导致很多团队用尽一切办法收集数据，然后把它们放进训练集中，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集及测试集不同的分布。在深度学习时代，越来越多的团队，都用来自和开发集及测试集不同分布的数据来训练。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%951.JPG\" width=\"50%\" height=\"50%\"> \n- 假设你在开发一个手机应用，有两个数据来源：一个是你真正关心的数据分居，来自应用上传的数据。 \n - 一个是你真正关心的数据分居，来自应用上传的数据。如图右侧，或随意或模糊。约10,000张。\n - 另一个数据源是通过爬虫，从网页中下载的数据。如图左侧，专业且高分辨率。约200,000张。\n- 你真正关心的是：你的最终系统处理来自应用程序的图片分布时，效果好不好。\n- 选项1：如图，将两组数据组合在一起，共210,000张，然后随机分配到训练集、开发集和测试集中，训练集占205,000张，开发/测试集个占2,500张：\n - 好处：训练集和开发集及测试集来自同一分布，这样更易于管理。\n - 巨大的坏处：开发/测试集中有大量数据($200k/210k*2500 \\approx 2381$)来自网页下载，不是你真正关心的数据分布。只有约119张来自用户手机上传。\n - 设置开发集的目的是告诉团队瞄准的目标(靶心)。此做法相当设置了错误的目标。不建议使用该做法。\n- **选项2**：如图，**训练集由网页下载的200,000张图片加上用户手机上传的5000张图片，共205,000张。开发集和测试集都是手机上传图片，各2,500张**。\n - 好处：**开发集和测试集都是用户手机上传的照片，是你真正关心的数据分布**。现在你瞄准的目标就是你想要处理的目标。\n - 坏处：**训练集和开发/测试集的分布不一样**，**但事实证明，这样分配数据集，在长期能给你带来更好的系统性能**。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 如图，以语音激活后视镜应用为例：：\n- 有两个数据来源：\n - 一个是从其他语音识别应用中收集到的数据。约500,000条。\n - 一个是语音激活后视镜的数据(用户要查询导航信息，可能包含更多街道地址)。约20,000条。\n- 设置训练集、开发集和测试集，如图：\n - 训练集包含其他语音识别应用中的500k条语音，开发/测试集各包含10k条语音激活后视镜的语音。\n - 或训练集包含其他语音识别应用中的500k条语音加上语音激活后视镜的语音的10k条语音，开发/测试集各包含5k条语音激活后视镜的语音。\n\n### 不匹配的数据分布的偏差和方差\n估计学习算法的偏差和方差，可以帮助你确定接下来优先该进行的方向。但是**当你的训练集和开发/测试集来自不同分布时，分析偏差和方差的方法需要改变**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 以猫分类器为例：\n- 人类的表现几乎完美，所以贝叶斯误差几乎为0%。\n- 训练集误差为1%，开发集误差为10%。\n- **若训练集和开发集来自同一分布，在这种情况下，可以说存在很大的方差问题**。\n- **但如果训练集和开发集不是来自同一分布，那就无法确定地下结论**。也许分类器已经在开发集上做的很好，因为训练集中都是专业且高分辨率的图片，很容易进行分类，而开发集中是难以精确分类的图片。即有可能分类器不存在方差问题。\n- 问题在于：从训练误差到开发集误差，改变了两件事情：第一，算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。因为同时改变了两件事，**无法确定导致训练误差和开发集误差的差值9%的原因，有多少是由于没见过开发集导致，即方差问题。有多少是由于开发集来自不同分布**。\n- 解决方法：**划分出训练-开发集(training-dev set)**。\n - 训练-开发集：与训练集同分布，但不用于训练。\n - 具体划分示意，如图所示。\n- 接来下，分析四个指标：**人类水平表现(贝叶斯误差)、训练集误差、训练-开发集误差和开发集误差**。\n- 例1：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为9%，开发集误差为10%。\n - 贝叶斯误差和训练集误差之间的差值为可避免偏差，值为1%。训练集误差和训练-开发集的误差的差值为方差，值为8%。训练-开发集误差和开发集误差之间的差值为数据不匹配，值为1%。\n - 因此，存在方差问题。\n\n- 例2：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为1.5%，开发集误差为10%。\n - 可避免偏差为1%，方差为0.5%，数据不匹配为8.5%。\n - 因此，存在数据不匹配问题。\n\n- 例3：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为12%。\n - 可避免偏差为10%，方差为1%，数据不匹配为1%。\n - 因此，存在偏差问题。\n\n- 例4：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为20%。\n - 可避免偏差为10%，方差为1%，数据不匹配为9%。\n - 因此，存在偏差问题和数据不匹配问题。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"100%\" height=\"100%\"> **总结训练集和开发/测试集来自不同分布时，分析偏差和方差问题的方法**：\n- 贝叶斯误差和训练集误差之间的差值为**可避免偏差**，或可避免误差的度量。\n- 训练集误差和训练-开发集的误差的差值为**方差**，或方差的度量。\n- 训练-开发集误差和开发集误差之间的差值为**数据不匹配**，或数据不匹配的度量。\n- 开发集误差和测试集误差之间的差值为**对开发集的过拟合程度**，或对开发集的过拟合程度的度量。\n- 举例一个特殊的例子：\n - 贝叶斯误差为4%，训练集误差7%，训练-开发集误差为10%，开发集误差为6%，测试集误差为6%。\n - 这种情况是合理的，说明训练集的难度比开发/测试集的难度要高很多。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"90%\" height=\"90%\"> 以语音激活后视镜为例：\n- 第一列为其他通用语音应用中的数据，第二列为语音激活后视镜的数据。\n- 只不过强调了：\n - 算法只在训练集上训练过，而训练-开发集，开发/测试集，算法都没有训练过。\n - 训练集和训练-开发集来自同一分布(通用语音应用中的数据)。开发/测试集来自另一分布(语音激活后视镜的数据)。\n\n### 处理数据不匹配\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D1.JPG\" width=\"100%\" height=\"100%\"> **如果发现有严重的数据不匹配问题**：\n- 进行人工错误分析，去尝试理解训练集和开发/测试集的区别。\n - 如在语音激活后视镜应用中：进行错误分析后，发现开发集中以汽车噪音为背景的语音片段误判很多。或很多请求街道号码的语音片段误判很多。\n- 让训练集更像开发集，收集更多类似开发/测试集的数据。\n - 如可以模拟车辆背景噪声数据，或刻意的收集人类说数字的音频数据，然后添加进训练集。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D2.JPG\" width=\"100%\" height=\"100%\"> 人工数据合成：\n- 例子如图：将人类说话的音频和汽车噪声的音频进行人工合成，合成为车内说话的音频数据。\n- 人工数据合成可以快速制造出更多的训练数据。但要注意，人工数据合成存在一个潜在问题：\n - 假设你录制了10,000个小时的安静背景下的音频数据，录制了1个小时的汽车噪音数据，然后将汽车噪音重复播放10,000次叠加到安静背景下的音频数据。人类听起来，这些合成的音频数据没问题。但学习算法会对这1小时的汽车噪音过拟合。你收集得到的1小时汽车噪音背景下的音频数据只是所有存在的汽车噪音的一个很小的子集，从整个空间的很小的一个子集出发，去合成数据，神经网络可能最后会对这1个小时的汽车噪音过拟合。\n - 更好的做法是收集10,000个小时的汽车噪音，而不是重复播放1小时的汽车噪音10,000次。在不考虑成本的情况下，这种做法会使得学习算法取得更好的性能。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D3.JPG\" width=\"90%\" height=\"90%\"> 人工数据合成的另一例：\n- 若对于汽车检测任务，用人工数据合成时，如果只是基于20种车的人工数据合成。20辆车只是所有可能出现的车辆的很小的子集。人眼看不出来，神经网络可能对这20种车过拟合。\n\n\n最后的总结：\n- 如果你认为存在数据不匹配问题，建议进行错误分析，查看训练集和开发集，尝试了解这个两个数据分布到底有什么不同，然后看看是否有办法收集更多像开发集的训练数据进行训练。\n- 其中一种办法是人工数据合成，人工数据合成确实有效，在语音识别系统中，已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现。但当你使用人工数据合成时，一定要谨慎，要记住你有可能只是从所有可能性的空间选择了很小的一部分去模拟数据。\n\n## 2.3 从多个任务中学习\n### 迁移学习\n深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。例如，你已经训练好一个可以识别猫的神经网络，然后可以用这些已学到的知识或部分知识去帮助你更好地阅读X射线扫描图。这就是所谓的**迁移学习**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 迁移学习举例：\n- 例1：已经训练好一个图像识别的神经网络，然后将图像识别中学习到的知识应用/迁移到放射诊断任务中：\n - 删去原神经网络中的最后一层及其权重，新建最后一层神经网络并随机初始化权重，即$W^{[l]}$，$b^{[l]}$ 。\n - 在新的放射诊断数据集上训练神经网络。如果放射诊断数据集较小，就只训练新的最后一层网络的参数$W^{[l]}$，$b^{[l]}$并保持原网络其他参数不变。如果放射诊断数据集很大，可以重新训练网络中的所有参数(以之前网络训练好的参数作为初始参数)。\n - 如果选择重新训练网络中的所有参数，那么图像识别任务的训练阶段称为**预训练(pre-training)**。然后在放射诊断数据上重新训练参数的过程，称为**微调(fine tuning)**。\n- 有效的原因：在图像识别任务中，很多低层次的特征，比如边缘检测、曲线检测等结构信息知识，可能帮助放射诊断任务。\n- 例2：已经训练好一个语音识别的神经网络，然后迁移到唤醒/触发词检测系统中：\n - 删去原神经网络的最后一层，在末端建立新的几层。\n - 若唤醒/触发词检测的数据量较小，则在唤醒/触发词检测数据集中，只训练新建的几层。若唤醒/触发词检测的数据量较大，可重新训练神经网络的所有参数。\n - 在语音识别任务中，预先学到的很多人类声音的特征，人类语言的组成部分等知识，可以帮助你建立一个很好的唤醒词检测器。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> 什么时候迁移学习是有意义的：\n- 任务A和任务B有一样的输入x。\n - 在上节的例1中，任务A和任务B的输入都是图像。\n - 在上节的例2中，任务A和任务B的输入都是音频。\n- 任务A拥有的数据量要比任务B大得多。\n - 在上节的例1中，任务A中图像识别有着大量的数据集，如1000,000张。而任务B中放射诊断数据集图像只有100张。\n - 在上节的例2中，任务A中语音识别数据集中有10,000小时的音频。而任务B唤醒词检测任务中只有1小时的音频。\n- 任务A中的低层次特征可以帮助任务B的学习。\n \n### 多任务学习\n在迁移学习中，你的步骤是串行的：先从任务A中学习，然后迁移到任务B。在多任务学习中，你是同时开始学习的，试图让神经网络同时做几件事情，然后希望这里的每个任务都能帮助到其他所有任务。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以开发无人驾驶汽车为例：\n- 无人驾驶汽车需要同时检测不同的物体，如行人、车辆、停车标志及交通灯。\n- 此时输入为图像$x^{(i)}$,输出$y^{(i)}$为：$$y^{(i)}= \\left[ \\begin{matrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{matrix} \\right]$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 神经网络结构，如图：\n- 神经网络的最后一层有四个结点，分别代表是否存在行人、车辆、停车标志及交通灯。即$\\hat{y}$的维度为$(4,1)$\n- 代价函数为：$$\\frac1m\\sum_{i=1}^m\\sum_{j=1}^4L(\\hat y_j^{(i)},y_j^{(i)})$$\n - 其中，$L(\\hat y_j^{(i)},y_j^{(i)})$是单个结点的损失，采用常用的逻辑损失，$$L(\\hat y_j^{(i)},y_j^{(i)})=-y_j^{(i)}log\\ \\hat y_j^{(i)}-(1-y_j^{(i)})log\\ (1-\\hat y_j^{(i)})$$\n- 多任务学习**与softmax回归的主要区别**在于：softmax将单个标签分给单个样本。而多任务学习中，一张图片有多个(4个)标签（从代价函数中的形式中也可以看出来）。\n- 另外，多任务学习也可以用于处理图像中只有部分物体被标记的情况。\n - 如某个样本只标记有行人和车辆，但没有标记是否有停车标志和交通灯，即样本标签形式为$$y^{(i)}= \\left[ \\begin{matrix} 1\\\\ 1\\\\ ?\\\\ ? \\end{matrix} \\right]$$\n - 即便是这样的数据集，你也可以上面训练算法同时做四个任务。在训练时，数据中缺失的标签所对应的结点，不参加代价函数的求和即可。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A03.JPG\" width=\"90%\" height=\"90%\"> 多任务学习什么时候有意义：\n- 如果你训练的一组任务可以公用低层次特征。\n- 如果每个任务的数据量很接近(这个准则没有那么绝对，并不一定是对的)。\n - 例如，你有一百个任务，每个任务的数据集大小为1000，那么进行多任务学习，训练集大小将达100,000。\n- 可以训练一个足够大的神经网络同时做好所有任务。\n - 有研究表明：只要你可以训练一个足够大的神经网络进行多任务学习，几乎都比单独训练多个神经网络来单独完成各个任务的性能要好。\n \n最后的总结：\n- 多任务学习能让你训练一个神经网络来同时进行多个任务，可以给你比单独完成各个任务更高的性能。\n- 多任务学习使用到的频率要比迁移学习使用到的频率低得多。\n - 其中一个例外是计算机视觉中的目标检测。人们经常训练一个神经网络，同时检测许多不同的物体，这比训练单独的神经网络来检测物体要好。\n  \n## 2.4 端到端的深度学习\n### 什么是端到端的深度学习\n深度学习中最令人兴奋最新发展之一就是端到端的深度学习的兴起。什么是端到端的深度学习，简而言之，以前有一些数据处理系统，它们需要多个阶段的处理。而端到端的深度学习就是将所有这些多个阶段用单个神经网络替代它。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以语音识别为例：\n- 输入$x$是一段音频(audio clip)，输出$y$是这段音频的听写文本(transcript)。\n- 传统上，语音识别需要很多阶段的处理，首先你会提取一些手工设计的音频特征(如MFCC)，通过机器学习算法在音频片段中找到音位(声音的基本单位)，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本。\n- 端到端的深度学习是，训练一个巨大的神经网络，输入是音频，输出直接是听写文本。\n- **端到端的深度学习的挑战之一是：需要大量数据才能让系统表现好**。\n - 若你只有3,000个小时的数据去训练语音识别系统，那么传统的流水线(pipeline)的效果很好。\n - 若你拥有非常大的数据集，如10,000小时甚至100,000小时的数据，那么端到端的学习方法就表现的很好了。\n - 如果你数据量适中，那么可以用折中的方法，如输入音频，然后让过特征提取，直接尝试从神经网络输出音位，然后其他阶段继续采用传统方法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 以门禁人脸识别系统为例，如图：\n- 端到端的学习方法：将相机拍摄到的图片作为输入，然后直接学习图像$x$到人类身份$y$的函数映射。\n - 但事实证明，这不是最好的方法，因为人可以从很多不同的方向接近门禁(即人类可能以不同大小出现在照片的不同位置)。在实际构建这些门禁系统时，不是将原始图片喂给神经网络，然后尝试去找出人类的身份。\n- 迄今为止最好的做法，是一个多步方法。首先，找出照片中人脸的位置，检测到人脸后，然后放大人脸图像的那部分，并剪裁图像，使得人脸居中显示。然后，再将人脸图片喂给神经网络，让网络去学习或估计人类的身份。\n- 两步方法更好的原因：\n - 你解决的两个问题，每个都更简单。\n - 两个子任务的训练数据都很多。对于任务1，人脸检测的数据很多，$x$是图片，$y$是人脸位置。对于任务2，人脸识别的数据也很多。**相比之下，直接输入门禁系统拍摄照片$x$，输出人类身份$y$的数据集很少**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.JPG\" width=\"100%\" height=\"100%\"> \n- 以机器翻译(machine translation)为例：\n - 传统上，机器翻译系统也有很复杂的流水线：英语，文本，文本分析等等。\n - 而如今，**端到端的机器翻译表现的很好，因为可以收集大量的数据对$(x,y)$，即英文句子对用的法文翻译**。\n- 以孩子手部的$x$光线图片，来估计年龄：\n - 非端到端的学习方法：输入图片，分割出每一块骨头，弄清每一块骨头的长度，然后查找儿童手中骨头的平均长度，然后用它来估计孩子的年龄。\n - 端到端：**通过图片直接估计孩子的年龄。那么需要大量数据去训练，在今天，还没有足够数据**。\n\n最后的总结：\n- 端到端学习是可行的，它可以表现得非常好，并简化系统，让你不需要构建那么多的手工设计的单独部件。\n- 但它也不是万能之计，并不是在所有任务中都有效。\n\n### 是否使用端到端的深度学习\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> **端到端的深度学习的优缺点**：\n优点：\n- 让数据说话。\n - 解释：如果有足够多的数据$(x,y)$，那么不管从$x$到$y$的最合适的函数映射是什么，一个足够大的神经网络能自己找到。而不是在如语音识别中，强制算法以“音位“为单位思考，也许让算法自己从大量数据中洞察到更好的表示方法更好。\n- 需要更少的手工设计组件。\n - 解释：简化系统，节省时间。\n \n缺点：\n- 需要大量的数据$(x,y)$。\n- 排除了潜在的有用的手工设计的组件。\n - 解释：**学习算法有两个主要的知识来源，一是数据，二是手工设计的组件或特征**。当有大量数据时，手工设计的东西就不太重要了。但**当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的最好途径**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> \n如果你在构建一个新的机器学习系统，而你在尝试决定是否使用端到端的深度学习，那么问题的关键是：**你有足够的数据能够直接学习到从$x$映射到$y$的足够复杂的函数吗？**\n- 如果输入手的$x$射线图片，分割出骨头位置，不需要太多的数据就可以完成这个任务。\n- 如果输入人的图片，检测出人脸的位置，不需要太多的数据就可以完成这个任务。\n- 但如果输入手的$x$射线图片，直接估计出孩子的年龄，这种复杂的映射函数，就需要大量的数据。\n\n如图下半部分，以无人驾驶汽车为例：\n- 需要完成的任务：输入雷达图片，检测车辆和行人，规划路线，控制方向盘/油门/刹车。\n- 解决方法：用深度学习方法进行检测车辆和行人；用运动规划(motion planning)软件解决路径规划；用控制算法决定如何控制方向盘/油门/刹车。\n- 这个例子表明了：\n - 你想用机器学习或深度学习来学习一些单独的组件。\n - 当你用监督学习时，应该仔细地选择你想要学习的$x$到$y$的映射，取决于哪些任务你可以收集到数据。\n- 相比之下，若考虑使用端到端的深度学习：即输入图像$x$，直接得出方向盘角度等。\n - 就目前能收集到的数据以及目前神经网络可以学习到的事物类型而言，这实际上不是最有前景的方向。这种纯粹的端到端的学习方法，其前景不如上述分步进行的方法。\n\n\n\n\n\n\n\n\n","source":"_posts/深度学习课程(三)构建机器学习项目.md","raw":"---\ntitle: 深度学习课程(三)构建机器学习项目\nmathjax: true\ndate: 2018-1-8 9:17:50\ncategories: \n- 深度学习\ntags:\n---\n# 1.机器学习策略(1)\n## 1.1 机器学习策略介绍\n### 为什么需要机器学习策略\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5.JPG\" width=\"80%\" height=\"80%\">\n- 当试图优化一个深度学习系统时，通常有很多想法可以尝试。如图，比如我们在做一个猫的分类器时，经过一段时间的工作，系统的准确率达到了90%。但对于应用程序来说，表现还不够好，我们可能有许多想法来改进这个系统，想法如图所示。\n- 如果做出了错误的选择，不仅耗费时间而且可能收效甚微。如盲目的选择收集更多数据，花费6个月时间收集数据，但最终对系统的改进很小。\n- 机器学习策略就是分析机器学习问题的方法，指引我们朝着最有希望的想法的方向去尝试。\n \n<!-- more --> \n \n### 正交化\n学会诊断出限制系统性能的瓶颈在哪里，然后找到一组**特定的旋钮(方法)**，从而改善系统**特定方面的性能**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%961.JPG\" width=\"80%\" height=\"80%\">\n- 如图，以电视机屏幕调节为例，每个旋钮对应一个功能(如长度调整、宽度调整、梯度调整等)，每一旋钮解决特定问题，是正交的，可很好的调节电视机屏幕。\n- 如图，以驾驶汽车为例，方向盘、油门及刹车，这三种正交化的操作，可以很好的控制汽车。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%962.JPG\" width=\"80%\" height=\"80%\">\n- 要做好一个监督学习系统，需要调节系统的旋钮，去确保四件事情：\n- 1.使得代价函数很好地拟合训练集。\n  - 旋钮：更大的网络，使用Adam等优化算法。\n- 2.使得代价函数很好地拟合开发集。\n  - 旋钮：正则化，采用更大的训练集。\n  - 解释：在训练集上表现好，而开发集表现不好，则是在训练集上过拟合。\n- 3.使得代价函数很好地拟合测试集。\n  - 旋钮：采用更大的开发集。\n  - 解释：在开发集上表现好，而测试集表现不好，则是在开发集上过拟合。\n- 4.在现实世界中取得好的表现。\n  - 旋钮：调整开发/测试集，使用新的代价函数。\n  - 解释：在开发/测试集上表现好，在现实中表现不好，要么是开发/测试集设置有问题，要么是代价函数设置有问题。\n- 概括来说，系统的每一旋钮只会针对性的解决一个问题，是正交的。\n- 此外，提前终止(early stopping)在模型功能调试中并不推荐使用。因为提前终止提升验证集性能的同时降低了训练集的性能。也就是说提前终止同时影响两件事情，不具有正交性。\n\n## 1.2 设置你的目标\n### 单一数字评价指标\n无论是在调节超参数，还是尝试不同的算法，设置一个单一数字评价指标，可以提高决策效率。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87_1.JPG\" width=\"100%\" height=\"100%\">\n- 之前讲过，应用机器学习是一个经验性的过程：想法-代码-实验，循环迭代。\n- 如图，对于分类器A和B，若采用两个评价指标：查准率(precision)和查全率(recall)时，将难以决策分类器A和B的好坏。\n- 此情况下，采用F1得分(F1 score)作为单一数字评价指标，则可快速选出最好的分类器。\n- 很多机器学习团队的做法：明确的开发集结合单一数字评价指标，可以加速上述迭代过程。\n\n注：\n- <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87.jpg\" width=\"50%\" height=\"50%\">\n- 查准率(precision)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87.JPG\" width=\"80%\" height=\"50%\">\n - 假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。\n- 查全率(recall)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%85%A8%E7%8E%87.JPG\" width=\"80%\" height=\"50%\">\n - 假设在是否为猫的分类问题中，查全率代表：所有真实为猫的图片中，预测正确的概率。\n- F1得分(F1 score)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/f1score.JPG\" width=\"30%\" height=\"30%\">\n - F1得分是查准率和查全率的调和平均。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\">\n- 另一例，对于不同算法，以每一算法在不同地区表现的平均数作为单一数字评价指标，可以快速选出表现最好的算法。\n\n### 满足和优化指标\n有时候，要把所有的性能指标都综合在一起，组成单实数评价指标(single real number evaluation metric)是比较困难的。解决办法是，把某些性能作为**优化指标(Optimizing metic)**，寻求最优化值；而某些性能作为**满意指标(Satisficing metic)**，只要满足阈值就行了。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%BB%A1%E8%B6%B3%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E6%A0%87.JPG\" width=\"90%\" height=\"90%\"> \n- 如图，分类器的性能：准确率和运行时间。若将准确率和运行时间组合成一个整体评价指标，如：$$cost=accuracy  -  0.5 \\cdot running\\ time$$\n- 可将准确率作为优化指标，将运行时间作为满意指标。即最大限度的提高准确率($maximize\\ accuracy$)，但算法必须满足运行时间的要求，即达到一定阈值即可(如$running \\ time \\leq 100ms$)。这是一个相对合理地权衡准确率和运行时间的方式。\n- 更一般地说，若有$N$个指标，有时将1个指标作为最优指标，其他$N-1$个作为满意指标。\n\n第二个例子：谷歌/亚马逊/百度的语音助手的唤醒/触发词，关心的指标有两个：\n- 一是对于触发词检测系统的准确率(说出触发词，有多大概率唤醒设备)。\n- 二是假阳性(false positive)的数量(没有说出触发词，设备被随机唤醒的概率)。\n- 组合这两种评估指标的合理方式是：准确率作为优化指标，最大化准确率。假阳性数量作为满意指标，小于一定阈值即可，如24小时之内少于1次。\n \n### 训练/开发/测试集划分\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%92%E5%88%863.JPG\" width=\"80%\" height=\"80%\">  开发/测试集划分准则：\n- 首先，**开发集和测试集需要来自同一分布**。\n- 然后，选择这样的开发集和测试集：**能够反映未来会得到的数据，并且你认为是很重要的，必须得到好结果的数据**。\n- **设立开发集以及评价指标，就等同于定义了你要瞄准的目标。测试集和开发集属于同一分布，相当于瞄准的是同一目标(靶心)，否则相当于设置了另一个目标(靶心)。而训练集的设置，影响的是逼近这个目标有多快**。\n \n### 开发集和测试集的大小\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F2.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F3.JPG\" width=\"80%\" height=\"80%\">\n旧的划分数据的方式：\n- 当没有测试集时：训练集分70%，开发集分30%。\n- 当有开发集时：训练集分60%，开发集分20%，测试集分20%。\n- 此划分方法适用于机器学习早期，即适用于数据量小的情况(如100，1000，10000个样本)。\n\n现代机器学习划分数据的方式（有着非常大的数据集，如有一百万个样本）：\n- 训练集分98%，开发集分1%，测试集分1%。\n- 开发集和测试集各有10000个例子，足够了。\n- 深度学习算法对数据的胃口很大，给训练集划分更多的数据，去喂饱模型。\n\n开发集的大小设置准则：\n- 令开发集足够大，能够检测不同算法/模型的区别，选择出更好的算法/模型即可。\n\n测试集的大小设置准则：\n- 令测试集足够大，能够以高置信度评价系统的整体性能即可。\n\n另外：\n- 虽然不建议这样做，但如果不需要给出对算法/模型的无偏估计，那不设置测试集，只划分训练/开发集也是可以的。\n\n### 什么时候改变开发/测试集和评价指标\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%871.JPG\" width=\"80%\" height=\"80%\"> 如果当前的评价指标无法给出更好算法的正确排名，那就需要花时间定义一个新的评价指标：\n- 如图所示，目前的评价指标是错误率。\n- 虽然算法A的错误率低于算法B的错误率，但算法A会将色情图片分类为猫的图片。这时若将色情图片当作猫的图片推送给用户，那这是极其糟糕的错误。因此，算法A虽然错误率低，但其实是一个很糟糕的算法，相比而言，算法B应该更好。\n- 因此，当前的评价指标错误率，无法给出更好算法的正确排名，应重新定义一个新的评价指标。\n- 如定义新的评价指标为$$Error: \\frac{1}{\\sum_{i=1}^{m_{dev}} w^{(i)}}\\sum_{i=1}^{m_{dev}} w^{(i)}1\\{\\hat y^{(i)} \\neq y^{(i)}\\}$$\n- 其中，$$w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}$$\n- 注：使用此种加权函数的方式，需手动遍历开发集和测试集，将色情图片标注出来。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"> 上一课件中，处理猫类图片反色情问题的方式，实际上是正交化一种体现：\n- 第一步，只讨论了如何去定义一个评价分类器的指标。这相当于设定一个目标(靶心)。\n- 第二步，单独去考虑如何提升系统在这个指标上的表现。这相当于如何瞄准/命中这个目标(靶心)。\n- 对于第二步，为了提高系统在新的评价指标上的评分，如修改神经网络需优化的代价函数为：$$J=\\frac{1}{\\sum_{i=1}^m w^{(i)}}\\sum_{i=1}^mw^{(i)}L(\\hat y^{(i)},y^{(i)})$$\n- 其中，$$w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%873.JPG\" width=\"80%\" height=\"80%\"> 如图，另一例：\n- 开发/测试集是专业且正规的猫的图片，实际应用中用户上传的图片是随意且模糊的。\n- 当在评价指标和开发/测试集上做的很好，但在实际应用中做的不好时，应该改变评价指标以及开发/测试集。\n- 可以看出，上图中的开发/测试集设置有误，没有反映出你的算法需要处理好的且在未来会遇到的数据。\n\n最后的建议：\n- 有一个评价指标和开发集，可以让你更快的做出决策，到底哪个算法更好，从而加快迭代速度。\n- 因此，即使无法定义出一个很完美的评价指标和开发集，直接快速设置出来，然后使用它们来驱动迭代速度。\n- 在这之后，如果发现它们不够好，马上做出改变。\n\n## 1.3 相比于人类的表现\n### 为什么是人类的表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 在过去的几年里，许多机器团队一直在讨论如何比较机器学习系统和人类的表现：\n- 图中，机器学习系统以较快地速度接近人类表现，甚至超过它。\n- 超过人类表现之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，称之为贝叶斯最优误差(bayes optimal error)。\n\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 当机器学习系统的表现比人类的差时，有一些工具可以用来提高性能，而一旦超越了人类的表现，这些工具就不那么好用了：\n- 让人类帮助标注数据。\n - 解释：这样就可以有更多的数据可以喂给模型。\n- 通过人工错误分析。\n - 解释：下周讲解。只要人类的表现比其他任何算法都要好，就可以让人类去查看算法做错的例子，并尝试了解为什么人能做对，算法做错。\n- 进行更好的偏差/方差分析。\n - 解释：下节讲解。\n- 注：只要你的算法比人类的表现糟糕，上述三条策略可以改善算法，而一旦你的算法做的比人类好，上述三条策略就很难利用了。\n\n### 可避免偏差\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8F%AF%E9%81%BF%E5%85%8D%E5%81%8F%E5%B7%AE.JPG\" width=\"90%\" height=\"90%\"> 我们希望算法在训练集上表现好，但实际上不想算法在训练集上表现得太好。当知道人类的表现后，可以准确的告诉你算法在训练集上的表现到底该有多好。\n如图中的猫分类器为例：\n- 在第二们课程里关于偏差和方差的讨论中，我们主要假设一些任务的贝叶斯误差几乎接近于0。\n- 在对于某些人类擅长的任务：如计算机视觉任务，人类水平误差虽高于贝叶斯误差(理论上限)，但可认为近似等于贝叶斯误差。\n- 在确定人类水平(近似贝叶斯误差)后，就定义了我们认为什么样的水平是可以实现的：\n - **将人类水平误差和训练误差之间的差值**称为**可避免偏差(avoidable bias)**，或可避免偏差的度量。\n - **将训练误差和开发集误差之间的差值**称为**方差**，或方差的度量。\n - **根据可避免偏差和方差的相对大小，决定专注于减少偏差的策略还是减少方差的策略**。\n - 若将贝叶斯误差定为1%，而训练误差为8%，我们认为可以将它降低到1%，那么将专注于减小偏差；\n - 若将贝叶斯误差定为7.5%，而训练误差为8%，可避免误差为0.5%，没什么改进空间，不能再继续减少训练误差了，防止过拟合。而训练误差和开发集误差相差2%，那么将专注于减少方差。\n\n### 理解人类的表现\n应该这样看待人来水平表现：人类的表现是贝叶斯误差的替代或估计。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\">\n- 如图所示，应将人类水平定义为一个专家团队的表现，即错误率为0.5%。0.5%是贝叶斯误差的最佳估计。\n - 解释：因为要将人类水平表现看作是贝叶斯误差的替代或近似，故选取表现最好的一组，所以此处便可认为：$Bayes\\ error \\leq 0.05%$\n- 在上一节，通过人类水平表现来分析偏差和方差时，也是这样看待人类水平表现的，即作为贝叶斯误差的替代。\n- 在实际应用中，针对具体的应用情况，如果认为达到某个标准，就已经实用了，也可选用其他标准来作为人类水平表现。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\">\n- 在系统表现，未达到人类水平表现之前，不管如何定义人类水平表现(1%/0/7%/0.5%)，都不影响减小偏差策略还是减小方差策略的确定。\n - 如图中左侧两例。\n- 在系统接近人类表现之后，系统的提升变得很难，因为如果贝叶斯误差估计的不准确，将难以发现到底是方差问题还是偏差问题：\n - 如上图最右侧，只有将贝叶斯误差定义为0.5%(一个专家团队的表现)，才能发现可避免偏差0.2%，方差0.1%，从而决定该采用减小偏差策略；\n - 若将贝叶斯误差定义为0.7%，则可避免偏差为0%，方差为0.1%，则会采用减小方差的策略。、\n - 当你只知道贝叶斯误差是单个医生的表现即1%时，你甚至无法知道该不该继续去拟合训练集。\n - 因此，当系统接近人类表现时，很难更进一步。因为很难准确的估计贝叶斯误差，难以确定是偏差还是方差问题。\n\n另外：\n- 对于计算机视觉任务，比如猫识别问题，人类的表现近乎完美，所以贝叶斯误差也接近完美，那么将贝叶斯误差设为0，没什么问题。\n- 但如果数据有很大的噪声，对于背景很嘈杂的语音识别问题，有时几乎不可能听清说什么。对于这样的问题，更好的定义贝叶斯误差很重要，可以帮助我们更好的估计可避免误差和方差，这样才能更好的做出决策，选择减少偏差策略还是减少方差策略。\n\n### 超越人的表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\">\n- 如图左侧，当贝叶斯误差为0.5%，则可避免偏差为0.1%，方差为0.2%，则选择减小方差策略。\n- 如图右侧，当贝叶斯误差为0.5%，训练误差为0.3%，则不知道是训练误差过拟合了0.2%，还是贝叶斯误差实际上是0.1%/0.2%/0.3%，无法知道。此例中没有足够的信息，来判断应该选择减小偏差还是减小方差，这样取得进展的效率就会降低。\n- 在这个例子中，一旦超过了0.5%这个阈值，优化算法的方向便不那么明确了，因为现有的一些指明明确方向的工具失效了（但并不意味着不能继续提升，还是可以继续提升）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 图中列举出了显著超越人类水平表现的机器学习应用：\n- 首先是对于结构化数据：\n - 在线广告（估计某个用户点击某个广告的可能性）\n - 产品推荐（推荐电影或书籍之类）\n - 物流预测(logistics)（预测运输时间）\n - 贷款批准\n - 原因：计算机擅长访问大量数据，识别出数据中的统计规律。\n- 人类擅长自然感知(natural perception)任务，但也有一些机器学习应用超越了人类水平表现：\n - 语音识别\n - 某些图像识别任务\n - 某些医疗方面任务，如阅读ECG、皮肤癌诊断、放射科读图任务\n\n### 改善你的模型表现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 要让一个监督学习算法足够好，需要完成以下两件事：\n- 首先，很好的拟合训练集（即让可避免误差很低）。\n- 然后，在开发/测试集上的泛化很好（即让方差较低）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在正交化的精神下，有单独的旋钮，去处理偏差问题或方差问题：\n- 减少可避免偏差：\n - 使用更大的模型\n - 训练更长的时间，或使用更好的优化算法(如Momentum,RMSprop,Adam)\n - 尝试其他的神经网络架构(如RNN，CNN，有时会有好的效果，不确定)，或进行超参数搜索\n- 减少方差：\n - 搜集更多训练数据（训练更多数据，可以帮助系统泛化到看不到的开发集）\n - 正则化(如L2正则化，Dropout，数据增强)\n - 尝试其他的神经网络架构或进行超参数搜索\n \n# 2.机器学习策略(2)\n## 2.1 错误分析 \n### 进行错误分析\n如果你希望让学习算法胜任人类能做的任务，但你的学习算法还没有达到人类的表现。那么，**人工检查算法所犯下的错误，可以让你了解接下来该做什么**。这个过程称为**错误分析(error analysis)**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%901.JPG\" width=\"80%\" height=\"80%\">\n- 假设猫分类器在开发集上取得了90%的准确率，即10%的误差。\n- 注意到把一些狗分类成猫，问题是：是否需要开始做一个项目专门处理狗的问题？\n- 解决方法：错误分析：\n - 首先，从开发集中找出约100个错误分类的样本。\n - 然后，人工统计出多少个是狗。\n- 如果有5%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是9.5%(10%减少5%)的错误率。不值得专门花费大量时间。\n- 如果有50%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是5%(10%减少50%)的错误率。值得花费时间解决狗的问题。\n- 另外，尽管是人工统计，但检查100个开发集错误分类样本，只需要5-10分钟的时间，便可以给我们指出最有希望的方向。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%902.JPG\" width=\"80%\" height=\"80%\"> 并行评估多个想法：\n- 如图，针对如何改进猫的分类器，你有以下几个想法：狗的误分类问题，大型猫科动物的误分类问题，以及改善系统在模糊图片上的表现。\n- 进行错误分析：\n - 首先，建立一个电子表格，每一列是你的一个想法，每一行是一个开发集上的误分类样本。此外，最后一栏记录你对每个误分类样本的注释。\n - 然后，人工统计从开发集选出的每一个误分类样本，记录在电子表格中。\n - 最后，统计出每一列(即每一个想法)所对应的误分类样本的比例，针对不同比例，确定改进猫分类器的方向。\n - 另外，当你在人工统计时，又有了新的想法，比如发现由于Instagram滤镜的问题经常导致误分类，则可将该想法作为新的一列加入电子表格中。\n\n总结：\n- 进行错误分析：\n - 首先应该从开发集找一组错误分类的例子。\n - 观察错误分类的例子（假阳性和假阴性），统计出属于不同错误类型的错误样本数量。\n - 在这个过程中，你可能会得到启发归纳出新的错误类型，那就在中途新建一个错误类型。\n - 最后，通过统计不同错误类型包含的样本的比例，决定哪个问题需要优先解决，或者给你构思新优化方向的灵感。\n \n### 清理错误标记的数据\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE1.JPG\" width=\"80%\" height=\"80%\"> 首先，对于训练集中标记出错的样本：\n- 深度学习算法对训练集中的随机错误是相当鲁棒的：\n - 只要标记出错的样本，是由于随机错误(即标记人员不小心标错)，不管也没问题，不用花费太多时间去修正它们，只要训练集足够大。\n - 但如果标记出错的样本，是由于系统性错误(如标记人员一直把白色的狗标记成猫)，分类器训练后，将会一直把白色的狗标记成猫。这种情况肯定需要修正。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE2.JPG\" width=\"80%\" height=\"80%\"> 然后，对于开发/测试集中标记出错的数据：\n- 若担心在开发/测试集上标记出错的例子带来的影响，建议在进行错误分析时，增加一列，记录标签出错的样本，然后统计其比例。\n- 若这些标记错误严重影响了你在开发集上评估算法的能力，那就需要花时间修正错误标记的数据，具体来说，通过查看三个数字：\n - 整体开发集错误率\n - 由错误标记样本导致的错误率\n - 其他原因导致的错误率\n - 例1：如图左侧，整体开发集错误率为10%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为9.4%，修正错误标记样本是低优先级的方向。\n - 例2：如图右侧，整体开发集错误率为2%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为1.4%，由错误标记样本导致的错误率占了整体开发集错误率的很大比重，值得花费时间去修正错误标记的数据。\n - 例3：开发集的目的是为了帮助你从分类器A和B中选择更好的一个。\n 算法A的整体开发集错误率为2.1%，算法B的整体开发集错误率为1.9%，而其中由错误标记样本导致的错误率为0.6%，无法再信任开发集，因为它无法正确告诉你分类器A是否真的比分类器B好。此情况必须去修正开发集里的错误标签了。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE3.JPG\" width=\"80%\" height=\"80%\"> 如果决定要修正开发集数据里的错误标签(人工逐个检查并修正)，那么有一些指南：\n- 施加同样的处理手段给开发集和测试集，以保证它们依然来自同一分布。\n- 考虑同时检测算法判断正确和判断错误的例子。\n - 不容易去做，因为如果算法准确率很高，如98%，那检查98%的数据的标签，要花费很长时间，所以通常不总是这么做，但也是需要考虑的。\n- 训练集和开发/测试集有可能来自稍微不同的分布。\n - 如果你决定修改开发/测试集(通常比训练集小很多)，而有可能不修改训练集(深度学习算法对随机错误很鲁棒且训练集很大，也不想花费大量时间去修正)，而这样是可以的。后面会进一步讲解。\n\n最后的建议：\n- 在构建实际的系统时，通常需要更多的人工错误分析和更多的人类见解。\n- 有些深度学习研究员不愿意去亲自看这100或几百个例子，来统计错误数量，这是我(吴恩达)经常亲自去做的，可能花费十几分钟或几个小时，但可以帮我找到需要优先处理的任务。\n \n### 快速构建你的第一个系统，然后迭代\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%84%B6%E5%90%8E%E8%BF%AD%E4%BB%A3.JPG\" width=\"80%\" height=\"80%\"> 如图，如果要建立一个新的语音识别系统，你可以走很多方向或有很多可以优先考虑的事情，来改善语音识别系统，如图所示。\n- 建议：如果你正在开发新的机器学习应用，那么应该快速建立你的第一个系统，然后迭代：\n - 快速设立开发/测试集以及评价指标 \n - 快速构建初始的系统\n - 使用偏差/方差分析以及错误分析去确定下一步优先做什么\n\n最后的总结：\n- 如果你在这个应用领域有很多经验，这个建议的适用程度要低一些。或当这个领域有很多可以借鉴的学术文献和你要处理扽问题几乎完全相同，这个建议的适用程度也要低一些。例如，在人脸识别领域就有很多学术文献，如果你尝试建立一个人脸识别器，那么就可以从现有的大量学术文献作为基础出发，一开始就建立比较复杂的系统。\n- 但如果你第一次处理某个新问题，还是遵循以上建议。\n\n## 2.2 不匹配的训练集和验证/测试集\n### 在不同分布上进行训练和测试\n深度学习算法对训练数据的胃口很大，当你收集到足够多的带标签的数据构成训练集时，算法效果最好。这导致很多团队用尽一切办法收集数据，然后把它们放进训练集中，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集及测试集不同的分布。在深度学习时代，越来越多的团队，都用来自和开发集及测试集不同分布的数据来训练。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%951.JPG\" width=\"50%\" height=\"50%\"> \n- 假设你在开发一个手机应用，有两个数据来源：一个是你真正关心的数据分居，来自应用上传的数据。 \n - 一个是你真正关心的数据分居，来自应用上传的数据。如图右侧，或随意或模糊。约10,000张。\n - 另一个数据源是通过爬虫，从网页中下载的数据。如图左侧，专业且高分辨率。约200,000张。\n- 你真正关心的是：你的最终系统处理来自应用程序的图片分布时，效果好不好。\n- 选项1：如图，将两组数据组合在一起，共210,000张，然后随机分配到训练集、开发集和测试集中，训练集占205,000张，开发/测试集个占2,500张：\n - 好处：训练集和开发集及测试集来自同一分布，这样更易于管理。\n - 巨大的坏处：开发/测试集中有大量数据($200k/210k*2500 \\approx 2381$)来自网页下载，不是你真正关心的数据分布。只有约119张来自用户手机上传。\n - 设置开发集的目的是告诉团队瞄准的目标(靶心)。此做法相当设置了错误的目标。不建议使用该做法。\n- **选项2**：如图，**训练集由网页下载的200,000张图片加上用户手机上传的5000张图片，共205,000张。开发集和测试集都是手机上传图片，各2,500张**。\n - 好处：**开发集和测试集都是用户手机上传的照片，是你真正关心的数据分布**。现在你瞄准的目标就是你想要处理的目标。\n - 坏处：**训练集和开发/测试集的分布不一样**，**但事实证明，这样分配数据集，在长期能给你带来更好的系统性能**。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 如图，以语音激活后视镜应用为例：：\n- 有两个数据来源：\n - 一个是从其他语音识别应用中收集到的数据。约500,000条。\n - 一个是语音激活后视镜的数据(用户要查询导航信息，可能包含更多街道地址)。约20,000条。\n- 设置训练集、开发集和测试集，如图：\n - 训练集包含其他语音识别应用中的500k条语音，开发/测试集各包含10k条语音激活后视镜的语音。\n - 或训练集包含其他语音识别应用中的500k条语音加上语音激活后视镜的语音的10k条语音，开发/测试集各包含5k条语音激活后视镜的语音。\n\n### 不匹配的数据分布的偏差和方差\n估计学习算法的偏差和方差，可以帮助你确定接下来优先该进行的方向。但是**当你的训练集和开发/测试集来自不同分布时，分析偏差和方差的方法需要改变**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 以猫分类器为例：\n- 人类的表现几乎完美，所以贝叶斯误差几乎为0%。\n- 训练集误差为1%，开发集误差为10%。\n- **若训练集和开发集来自同一分布，在这种情况下，可以说存在很大的方差问题**。\n- **但如果训练集和开发集不是来自同一分布，那就无法确定地下结论**。也许分类器已经在开发集上做的很好，因为训练集中都是专业且高分辨率的图片，很容易进行分类，而开发集中是难以精确分类的图片。即有可能分类器不存在方差问题。\n- 问题在于：从训练误差到开发集误差，改变了两件事情：第一，算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。因为同时改变了两件事，**无法确定导致训练误差和开发集误差的差值9%的原因，有多少是由于没见过开发集导致，即方差问题。有多少是由于开发集来自不同分布**。\n- 解决方法：**划分出训练-开发集(training-dev set)**。\n - 训练-开发集：与训练集同分布，但不用于训练。\n - 具体划分示意，如图所示。\n- 接来下，分析四个指标：**人类水平表现(贝叶斯误差)、训练集误差、训练-开发集误差和开发集误差**。\n- 例1：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为9%，开发集误差为10%。\n - 贝叶斯误差和训练集误差之间的差值为可避免偏差，值为1%。训练集误差和训练-开发集的误差的差值为方差，值为8%。训练-开发集误差和开发集误差之间的差值为数据不匹配，值为1%。\n - 因此，存在方差问题。\n\n- 例2：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为1.5%，开发集误差为10%。\n - 可避免偏差为1%，方差为0.5%，数据不匹配为8.5%。\n - 因此，存在数据不匹配问题。\n\n- 例3：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为12%。\n - 可避免偏差为10%，方差为1%，数据不匹配为1%。\n - 因此，存在偏差问题。\n\n- 例4：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为20%。\n - 可避免偏差为10%，方差为1%，数据不匹配为9%。\n - 因此，存在偏差问题和数据不匹配问题。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"100%\" height=\"100%\"> **总结训练集和开发/测试集来自不同分布时，分析偏差和方差问题的方法**：\n- 贝叶斯误差和训练集误差之间的差值为**可避免偏差**，或可避免误差的度量。\n- 训练集误差和训练-开发集的误差的差值为**方差**，或方差的度量。\n- 训练-开发集误差和开发集误差之间的差值为**数据不匹配**，或数据不匹配的度量。\n- 开发集误差和测试集误差之间的差值为**对开发集的过拟合程度**，或对开发集的过拟合程度的度量。\n- 举例一个特殊的例子：\n - 贝叶斯误差为4%，训练集误差7%，训练-开发集误差为10%，开发集误差为6%，测试集误差为6%。\n - 这种情况是合理的，说明训练集的难度比开发/测试集的难度要高很多。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"90%\" height=\"90%\"> 以语音激活后视镜为例：\n- 第一列为其他通用语音应用中的数据，第二列为语音激活后视镜的数据。\n- 只不过强调了：\n - 算法只在训练集上训练过，而训练-开发集，开发/测试集，算法都没有训练过。\n - 训练集和训练-开发集来自同一分布(通用语音应用中的数据)。开发/测试集来自另一分布(语音激活后视镜的数据)。\n\n### 处理数据不匹配\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D1.JPG\" width=\"100%\" height=\"100%\"> **如果发现有严重的数据不匹配问题**：\n- 进行人工错误分析，去尝试理解训练集和开发/测试集的区别。\n - 如在语音激活后视镜应用中：进行错误分析后，发现开发集中以汽车噪音为背景的语音片段误判很多。或很多请求街道号码的语音片段误判很多。\n- 让训练集更像开发集，收集更多类似开发/测试集的数据。\n - 如可以模拟车辆背景噪声数据，或刻意的收集人类说数字的音频数据，然后添加进训练集。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D2.JPG\" width=\"100%\" height=\"100%\"> 人工数据合成：\n- 例子如图：将人类说话的音频和汽车噪声的音频进行人工合成，合成为车内说话的音频数据。\n- 人工数据合成可以快速制造出更多的训练数据。但要注意，人工数据合成存在一个潜在问题：\n - 假设你录制了10,000个小时的安静背景下的音频数据，录制了1个小时的汽车噪音数据，然后将汽车噪音重复播放10,000次叠加到安静背景下的音频数据。人类听起来，这些合成的音频数据没问题。但学习算法会对这1小时的汽车噪音过拟合。你收集得到的1小时汽车噪音背景下的音频数据只是所有存在的汽车噪音的一个很小的子集，从整个空间的很小的一个子集出发，去合成数据，神经网络可能最后会对这1个小时的汽车噪音过拟合。\n - 更好的做法是收集10,000个小时的汽车噪音，而不是重复播放1小时的汽车噪音10,000次。在不考虑成本的情况下，这种做法会使得学习算法取得更好的性能。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D3.JPG\" width=\"90%\" height=\"90%\"> 人工数据合成的另一例：\n- 若对于汽车检测任务，用人工数据合成时，如果只是基于20种车的人工数据合成。20辆车只是所有可能出现的车辆的很小的子集。人眼看不出来，神经网络可能对这20种车过拟合。\n\n\n最后的总结：\n- 如果你认为存在数据不匹配问题，建议进行错误分析，查看训练集和开发集，尝试了解这个两个数据分布到底有什么不同，然后看看是否有办法收集更多像开发集的训练数据进行训练。\n- 其中一种办法是人工数据合成，人工数据合成确实有效，在语音识别系统中，已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现。但当你使用人工数据合成时，一定要谨慎，要记住你有可能只是从所有可能性的空间选择了很小的一部分去模拟数据。\n\n## 2.3 从多个任务中学习\n### 迁移学习\n深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。例如，你已经训练好一个可以识别猫的神经网络，然后可以用这些已学到的知识或部分知识去帮助你更好地阅读X射线扫描图。这就是所谓的**迁移学习**。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 迁移学习举例：\n- 例1：已经训练好一个图像识别的神经网络，然后将图像识别中学习到的知识应用/迁移到放射诊断任务中：\n - 删去原神经网络中的最后一层及其权重，新建最后一层神经网络并随机初始化权重，即$W^{[l]}$，$b^{[l]}$ 。\n - 在新的放射诊断数据集上训练神经网络。如果放射诊断数据集较小，就只训练新的最后一层网络的参数$W^{[l]}$，$b^{[l]}$并保持原网络其他参数不变。如果放射诊断数据集很大，可以重新训练网络中的所有参数(以之前网络训练好的参数作为初始参数)。\n - 如果选择重新训练网络中的所有参数，那么图像识别任务的训练阶段称为**预训练(pre-training)**。然后在放射诊断数据上重新训练参数的过程，称为**微调(fine tuning)**。\n- 有效的原因：在图像识别任务中，很多低层次的特征，比如边缘检测、曲线检测等结构信息知识，可能帮助放射诊断任务。\n- 例2：已经训练好一个语音识别的神经网络，然后迁移到唤醒/触发词检测系统中：\n - 删去原神经网络的最后一层，在末端建立新的几层。\n - 若唤醒/触发词检测的数据量较小，则在唤醒/触发词检测数据集中，只训练新建的几层。若唤醒/触发词检测的数据量较大，可重新训练神经网络的所有参数。\n - 在语音识别任务中，预先学到的很多人类声音的特征，人类语言的组成部分等知识，可以帮助你建立一个很好的唤醒词检测器。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> 什么时候迁移学习是有意义的：\n- 任务A和任务B有一样的输入x。\n - 在上节的例1中，任务A和任务B的输入都是图像。\n - 在上节的例2中，任务A和任务B的输入都是音频。\n- 任务A拥有的数据量要比任务B大得多。\n - 在上节的例1中，任务A中图像识别有着大量的数据集，如1000,000张。而任务B中放射诊断数据集图像只有100张。\n - 在上节的例2中，任务A中语音识别数据集中有10,000小时的音频。而任务B唤醒词检测任务中只有1小时的音频。\n- 任务A中的低层次特征可以帮助任务B的学习。\n \n### 多任务学习\n在迁移学习中，你的步骤是串行的：先从任务A中学习，然后迁移到任务B。在多任务学习中，你是同时开始学习的，试图让神经网络同时做几件事情，然后希望这里的每个任务都能帮助到其他所有任务。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以开发无人驾驶汽车为例：\n- 无人驾驶汽车需要同时检测不同的物体，如行人、车辆、停车标志及交通灯。\n- 此时输入为图像$x^{(i)}$,输出$y^{(i)}$为：$$y^{(i)}= \\left[ \\begin{matrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{matrix} \\right]$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 神经网络结构，如图：\n- 神经网络的最后一层有四个结点，分别代表是否存在行人、车辆、停车标志及交通灯。即$\\hat{y}$的维度为$(4,1)$\n- 代价函数为：$$\\frac1m\\sum_{i=1}^m\\sum_{j=1}^4L(\\hat y_j^{(i)},y_j^{(i)})$$\n - 其中，$L(\\hat y_j^{(i)},y_j^{(i)})$是单个结点的损失，采用常用的逻辑损失，$$L(\\hat y_j^{(i)},y_j^{(i)})=-y_j^{(i)}log\\ \\hat y_j^{(i)}-(1-y_j^{(i)})log\\ (1-\\hat y_j^{(i)})$$\n- 多任务学习**与softmax回归的主要区别**在于：softmax将单个标签分给单个样本。而多任务学习中，一张图片有多个(4个)标签（从代价函数中的形式中也可以看出来）。\n- 另外，多任务学习也可以用于处理图像中只有部分物体被标记的情况。\n - 如某个样本只标记有行人和车辆，但没有标记是否有停车标志和交通灯，即样本标签形式为$$y^{(i)}= \\left[ \\begin{matrix} 1\\\\ 1\\\\ ?\\\\ ? \\end{matrix} \\right]$$\n - 即便是这样的数据集，你也可以上面训练算法同时做四个任务。在训练时，数据中缺失的标签所对应的结点，不参加代价函数的求和即可。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A03.JPG\" width=\"90%\" height=\"90%\"> 多任务学习什么时候有意义：\n- 如果你训练的一组任务可以公用低层次特征。\n- 如果每个任务的数据量很接近(这个准则没有那么绝对，并不一定是对的)。\n - 例如，你有一百个任务，每个任务的数据集大小为1000，那么进行多任务学习，训练集大小将达100,000。\n- 可以训练一个足够大的神经网络同时做好所有任务。\n - 有研究表明：只要你可以训练一个足够大的神经网络进行多任务学习，几乎都比单独训练多个神经网络来单独完成各个任务的性能要好。\n \n最后的总结：\n- 多任务学习能让你训练一个神经网络来同时进行多个任务，可以给你比单独完成各个任务更高的性能。\n- 多任务学习使用到的频率要比迁移学习使用到的频率低得多。\n - 其中一个例外是计算机视觉中的目标检测。人们经常训练一个神经网络，同时检测许多不同的物体，这比训练单独的神经网络来检测物体要好。\n  \n## 2.4 端到端的深度学习\n### 什么是端到端的深度学习\n深度学习中最令人兴奋最新发展之一就是端到端的深度学习的兴起。什么是端到端的深度学习，简而言之，以前有一些数据处理系统，它们需要多个阶段的处理。而端到端的深度学习就是将所有这些多个阶段用单个神经网络替代它。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以语音识别为例：\n- 输入$x$是一段音频(audio clip)，输出$y$是这段音频的听写文本(transcript)。\n- 传统上，语音识别需要很多阶段的处理，首先你会提取一些手工设计的音频特征(如MFCC)，通过机器学习算法在音频片段中找到音位(声音的基本单位)，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本。\n- 端到端的深度学习是，训练一个巨大的神经网络，输入是音频，输出直接是听写文本。\n- **端到端的深度学习的挑战之一是：需要大量数据才能让系统表现好**。\n - 若你只有3,000个小时的数据去训练语音识别系统，那么传统的流水线(pipeline)的效果很好。\n - 若你拥有非常大的数据集，如10,000小时甚至100,000小时的数据，那么端到端的学习方法就表现的很好了。\n - 如果你数据量适中，那么可以用折中的方法，如输入音频，然后让过特征提取，直接尝试从神经网络输出音位，然后其他阶段继续采用传统方法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 以门禁人脸识别系统为例，如图：\n- 端到端的学习方法：将相机拍摄到的图片作为输入，然后直接学习图像$x$到人类身份$y$的函数映射。\n - 但事实证明，这不是最好的方法，因为人可以从很多不同的方向接近门禁(即人类可能以不同大小出现在照片的不同位置)。在实际构建这些门禁系统时，不是将原始图片喂给神经网络，然后尝试去找出人类的身份。\n- 迄今为止最好的做法，是一个多步方法。首先，找出照片中人脸的位置，检测到人脸后，然后放大人脸图像的那部分，并剪裁图像，使得人脸居中显示。然后，再将人脸图片喂给神经网络，让网络去学习或估计人类的身份。\n- 两步方法更好的原因：\n - 你解决的两个问题，每个都更简单。\n - 两个子任务的训练数据都很多。对于任务1，人脸检测的数据很多，$x$是图片，$y$是人脸位置。对于任务2，人脸识别的数据也很多。**相比之下，直接输入门禁系统拍摄照片$x$，输出人类身份$y$的数据集很少**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.JPG\" width=\"100%\" height=\"100%\"> \n- 以机器翻译(machine translation)为例：\n - 传统上，机器翻译系统也有很复杂的流水线：英语，文本，文本分析等等。\n - 而如今，**端到端的机器翻译表现的很好，因为可以收集大量的数据对$(x,y)$，即英文句子对用的法文翻译**。\n- 以孩子手部的$x$光线图片，来估计年龄：\n - 非端到端的学习方法：输入图片，分割出每一块骨头，弄清每一块骨头的长度，然后查找儿童手中骨头的平均长度，然后用它来估计孩子的年龄。\n - 端到端：**通过图片直接估计孩子的年龄。那么需要大量数据去训练，在今天，还没有足够数据**。\n\n最后的总结：\n- 端到端学习是可行的，它可以表现得非常好，并简化系统，让你不需要构建那么多的手工设计的单独部件。\n- 但它也不是万能之计，并不是在所有任务中都有效。\n\n### 是否使用端到端的深度学习\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> **端到端的深度学习的优缺点**：\n优点：\n- 让数据说话。\n - 解释：如果有足够多的数据$(x,y)$，那么不管从$x$到$y$的最合适的函数映射是什么，一个足够大的神经网络能自己找到。而不是在如语音识别中，强制算法以“音位“为单位思考，也许让算法自己从大量数据中洞察到更好的表示方法更好。\n- 需要更少的手工设计组件。\n - 解释：简化系统，节省时间。\n \n缺点：\n- 需要大量的数据$(x,y)$。\n- 排除了潜在的有用的手工设计的组件。\n - 解释：**学习算法有两个主要的知识来源，一是数据，二是手工设计的组件或特征**。当有大量数据时，手工设计的东西就不太重要了。但**当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的最好途径**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> \n如果你在构建一个新的机器学习系统，而你在尝试决定是否使用端到端的深度学习，那么问题的关键是：**你有足够的数据能够直接学习到从$x$映射到$y$的足够复杂的函数吗？**\n- 如果输入手的$x$射线图片，分割出骨头位置，不需要太多的数据就可以完成这个任务。\n- 如果输入人的图片，检测出人脸的位置，不需要太多的数据就可以完成这个任务。\n- 但如果输入手的$x$射线图片，直接估计出孩子的年龄，这种复杂的映射函数，就需要大量的数据。\n\n如图下半部分，以无人驾驶汽车为例：\n- 需要完成的任务：输入雷达图片，检测车辆和行人，规划路线，控制方向盘/油门/刹车。\n- 解决方法：用深度学习方法进行检测车辆和行人；用运动规划(motion planning)软件解决路径规划；用控制算法决定如何控制方向盘/油门/刹车。\n- 这个例子表明了：\n - 你想用机器学习或深度学习来学习一些单独的组件。\n - 当你用监督学习时，应该仔细地选择你想要学习的$x$到$y$的映射，取决于哪些任务你可以收集到数据。\n- 相比之下，若考虑使用端到端的深度学习：即输入图像$x$，直接得出方向盘角度等。\n - 就目前能收集到的数据以及目前神经网络可以学习到的事物类型而言，这实际上不是最有前景的方向。这种纯粹的端到端的学习方法，其前景不如上述分步进行的方法。\n\n\n\n\n\n\n\n\n","slug":"深度学习课程(三)构建机器学习项目","published":1,"updated":"2018-01-30T09:28:45.962Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w430068qslps4orsy6w","content":"<h1 id=\"1-机器学习策略-1\"><a href=\"#1-机器学习策略-1\" class=\"headerlink\" title=\"1.机器学习策略(1)\"></a>1.机器学习策略(1)</h1><h2 id=\"1-1-机器学习策略介绍\"><a href=\"#1-1-机器学习策略介绍\" class=\"headerlink\" title=\"1.1 机器学习策略介绍\"></a>1.1 机器学习策略介绍</h2><h3 id=\"为什么需要机器学习策略\"><a href=\"#为什么需要机器学习策略\" class=\"headerlink\" title=\"为什么需要机器学习策略\"></a>为什么需要机器学习策略</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>当试图优化一个深度学习系统时，通常有很多想法可以尝试。如图，比如我们在做一个猫的分类器时，经过一段时间的工作，系统的准确率达到了90%。但对于应用程序来说，表现还不够好，我们可能有许多想法来改进这个系统，想法如图所示。</li>\n<li>如果做出了错误的选择，不仅耗费时间而且可能收效甚微。如盲目的选择收集更多数据，花费6个月时间收集数据，但最终对系统的改进很小。</li>\n<li>机器学习策略就是分析机器学习问题的方法，指引我们朝着最有希望的想法的方向去尝试。</li>\n</ul>\n<a id=\"more\"></a> \n<h3 id=\"正交化\"><a href=\"#正交化\" class=\"headerlink\" title=\"正交化\"></a>正交化</h3><p>学会诊断出限制系统性能的瓶颈在哪里，然后找到一组<strong>特定的旋钮(方法)</strong>，从而改善系统<strong>特定方面的性能</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图，以电视机屏幕调节为例，每个旋钮对应一个功能(如长度调整、宽度调整、梯度调整等)，每一旋钮解决特定问题，是正交的，可很好的调节电视机屏幕。</li>\n<li>如图，以驾驶汽车为例，方向盘、油门及刹车，这三种正交化的操作，可以很好的控制汽车。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"></li>\n<li>要做好一个监督学习系统，需要调节系统的旋钮，去确保四件事情：</li>\n<li>1.使得代价函数很好地拟合训练集。<ul>\n<li>旋钮：更大的网络，使用Adam等优化算法。</li>\n</ul>\n</li>\n<li>2.使得代价函数很好地拟合开发集。<ul>\n<li>旋钮：正则化，采用更大的训练集。</li>\n<li>解释：在训练集上表现好，而开发集表现不好，则是在训练集上过拟合。</li>\n</ul>\n</li>\n<li>3.使得代价函数很好地拟合测试集。<ul>\n<li>旋钮：采用更大的开发集。</li>\n<li>解释：在开发集上表现好，而测试集表现不好，则是在开发集上过拟合。</li>\n</ul>\n</li>\n<li>4.在现实世界中取得好的表现。<ul>\n<li>旋钮：调整开发/测试集，使用新的代价函数。</li>\n<li>解释：在开发/测试集上表现好，在现实中表现不好，要么是开发/测试集设置有问题，要么是代价函数设置有问题。</li>\n</ul>\n</li>\n<li>概括来说，系统的每一旋钮只会针对性的解决一个问题，是正交的。</li>\n<li>此外，提前终止(early stopping)在模型功能调试中并不推荐使用。因为提前终止提升验证集性能的同时降低了训练集的性能。也就是说提前终止同时影响两件事情，不具有正交性。</li>\n</ul>\n<h2 id=\"1-2-设置你的目标\"><a href=\"#1-2-设置你的目标\" class=\"headerlink\" title=\"1.2 设置你的目标\"></a>1.2 设置你的目标</h2><h3 id=\"单一数字评价指标\"><a href=\"#单一数字评价指标\" class=\"headerlink\" title=\"单一数字评价指标\"></a>单一数字评价指标</h3><p>无论是在调节超参数，还是尝试不同的算法，设置一个单一数字评价指标，可以提高决策效率。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87_1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>之前讲过，应用机器学习是一个经验性的过程：想法-代码-实验，循环迭代。</li>\n<li>如图，对于分类器A和B，若采用两个评价指标：查准率(precision)和查全率(recall)时，将难以决策分类器A和B的好坏。</li>\n<li>此情况下，采用F1得分(F1 score)作为单一数字评价指标，则可快速选出最好的分类器。</li>\n<li>很多机器学习团队的做法：明确的开发集结合单一数字评价指标，可以加速上述迭代过程。</li>\n</ul>\n<p>注：</p>\n<ul>\n<li><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87.jpg\" width=\"50%\" height=\"50%\"></li>\n<li>查准率(precision)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87.JPG\" width=\"80%\" height=\"50%\"><ul>\n<li>假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。</li>\n</ul>\n</li>\n<li>查全率(recall)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%85%A8%E7%8E%87.JPG\" width=\"80%\" height=\"50%\"><ul>\n<li>假设在是否为猫的分类问题中，查全率代表：所有真实为猫的图片中，预测正确的概率。</li>\n</ul>\n</li>\n<li>F1得分(F1 score)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/f1score.JPG\" width=\"30%\" height=\"30%\"><ul>\n<li>F1得分是查准率和查全率的调和平均。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>另一例，对于不同算法，以每一算法在不同地区表现的平均数作为单一数字评价指标，可以快速选出表现最好的算法。</li>\n</ul>\n<h3 id=\"满足和优化指标\"><a href=\"#满足和优化指标\" class=\"headerlink\" title=\"满足和优化指标\"></a>满足和优化指标</h3><p>有时候，要把所有的性能指标都综合在一起，组成单实数评价指标(single real number evaluation metric)是比较困难的。解决办法是，把某些性能作为<strong>优化指标(Optimizing metic)</strong>，寻求最优化值；而某些性能作为<strong>满意指标(Satisficing metic)</strong>，只要满足阈值就行了。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%BB%A1%E8%B6%B3%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E6%A0%87.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>如图，分类器的性能：准确率和运行时间。若将准确率和运行时间组合成一个整体评价指标，如：<script type=\"math/tex\">cost=accuracy  -  0.5 \\cdot running\\ time</script></li>\n<li>可将准确率作为优化指标，将运行时间作为满意指标。即最大限度的提高准确率($maximize\\ accuracy$)，但算法必须满足运行时间的要求，即达到一定阈值即可(如$running \\ time \\leq 100ms$)。这是一个相对合理地权衡准确率和运行时间的方式。</li>\n<li>更一般地说，若有$N$个指标，有时将1个指标作为最优指标，其他$N-1$个作为满意指标。</li>\n</ul>\n<p>第二个例子：谷歌/亚马逊/百度的语音助手的唤醒/触发词，关心的指标有两个：</p>\n<ul>\n<li>一是对于触发词检测系统的准确率(说出触发词，有多大概率唤醒设备)。</li>\n<li>二是假阳性(false positive)的数量(没有说出触发词，设备被随机唤醒的概率)。</li>\n<li>组合这两种评估指标的合理方式是：准确率作为优化指标，最大化准确率。假阳性数量作为满意指标，小于一定阈值即可，如24小时之内少于1次。</li>\n</ul>\n<h3 id=\"训练-开发-测试集划分\"><a href=\"#训练-开发-测试集划分\" class=\"headerlink\" title=\"训练/开发/测试集划分\"></a>训练/开发/测试集划分</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%92%E5%88%863.JPG\" width=\"80%\" height=\"80%\">  开发/测试集划分准则：</p>\n<ul>\n<li>首先，<strong>开发集和测试集需要来自同一分布</strong>。</li>\n<li>然后，选择这样的开发集和测试集：<strong>能够反映未来会得到的数据，并且你认为是很重要的，必须得到好结果的数据</strong>。</li>\n<li><strong>设立开发集以及评价指标，就等同于定义了你要瞄准的目标。测试集和开发集属于同一分布，相当于瞄准的是同一目标(靶心)，否则相当于设置了另一个目标(靶心)。而训练集的设置，影响的是逼近这个目标有多快</strong>。</li>\n</ul>\n<h3 id=\"开发集和测试集的大小\"><a href=\"#开发集和测试集的大小\" class=\"headerlink\" title=\"开发集和测试集的大小\"></a>开发集和测试集的大小</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F2.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F3.JPG\" width=\"80%\" height=\"80%\"><br>旧的划分数据的方式：</p>\n<ul>\n<li>当没有测试集时：训练集分70%，开发集分30%。</li>\n<li>当有开发集时：训练集分60%，开发集分20%，测试集分20%。</li>\n<li>此划分方法适用于机器学习早期，即适用于数据量小的情况(如100，1000，10000个样本)。</li>\n</ul>\n<p>现代机器学习划分数据的方式（有着非常大的数据集，如有一百万个样本）：</p>\n<ul>\n<li>训练集分98%，开发集分1%，测试集分1%。</li>\n<li>开发集和测试集各有10000个例子，足够了。</li>\n<li>深度学习算法对数据的胃口很大，给训练集划分更多的数据，去喂饱模型。</li>\n</ul>\n<p>开发集的大小设置准则：</p>\n<ul>\n<li>令开发集足够大，能够检测不同算法/模型的区别，选择出更好的算法/模型即可。</li>\n</ul>\n<p>测试集的大小设置准则：</p>\n<ul>\n<li>令测试集足够大，能够以高置信度评价系统的整体性能即可。</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>虽然不建议这样做，但如果不需要给出对算法/模型的无偏估计，那不设置测试集，只划分训练/开发集也是可以的。</li>\n</ul>\n<h3 id=\"什么时候改变开发-测试集和评价指标\"><a href=\"#什么时候改变开发-测试集和评价指标\" class=\"headerlink\" title=\"什么时候改变开发/测试集和评价指标\"></a>什么时候改变开发/测试集和评价指标</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%871.JPG\" width=\"80%\" height=\"80%\"> 如果当前的评价指标无法给出更好算法的正确排名，那就需要花时间定义一个新的评价指标：</p>\n<ul>\n<li>如图所示，目前的评价指标是错误率。</li>\n<li>虽然算法A的错误率低于算法B的错误率，但算法A会将色情图片分类为猫的图片。这时若将色情图片当作猫的图片推送给用户，那这是极其糟糕的错误。因此，算法A虽然错误率低，但其实是一个很糟糕的算法，相比而言，算法B应该更好。</li>\n<li>因此，当前的评价指标错误率，无法给出更好算法的正确排名，应重新定义一个新的评价指标。</li>\n<li>如定义新的评价指标为<script type=\"math/tex\">Error: \\frac{1}{\\sum_{i=1}^{m_{dev}} w^{(i)}}\\sum_{i=1}^{m_{dev}} w^{(i)}1\\{\\hat y^{(i)} \\neq y^{(i)}\\}</script></li>\n<li>其中，<script type=\"math/tex\">w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}</script></li>\n<li>注：使用此种加权函数的方式，需手动遍历开发集和测试集，将色情图片标注出来。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"> 上一课件中，处理猫类图片反色情问题的方式，实际上是正交化一种体现：</p>\n<ul>\n<li>第一步，只讨论了如何去定义一个评价分类器的指标。这相当于设定一个目标(靶心)。</li>\n<li>第二步，单独去考虑如何提升系统在这个指标上的表现。这相当于如何瞄准/命中这个目标(靶心)。</li>\n<li>对于第二步，为了提高系统在新的评价指标上的评分，如修改神经网络需优化的代价函数为：<script type=\"math/tex\">J=\\frac{1}{\\sum_{i=1}^m w^{(i)}}\\sum_{i=1}^mw^{(i)}L(\\hat y^{(i)},y^{(i)})</script></li>\n<li>其中，<script type=\"math/tex\">w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}</script></li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%873.JPG\" width=\"80%\" height=\"80%\"> 如图，另一例：</p>\n<ul>\n<li>开发/测试集是专业且正规的猫的图片，实际应用中用户上传的图片是随意且模糊的。</li>\n<li>当在评价指标和开发/测试集上做的很好，但在实际应用中做的不好时，应该改变评价指标以及开发/测试集。</li>\n<li>可以看出，上图中的开发/测试集设置有误，没有反映出你的算法需要处理好的且在未来会遇到的数据。</li>\n</ul>\n<p>最后的建议：</p>\n<ul>\n<li>有一个评价指标和开发集，可以让你更快的做出决策，到底哪个算法更好，从而加快迭代速度。</li>\n<li>因此，即使无法定义出一个很完美的评价指标和开发集，直接快速设置出来，然后使用它们来驱动迭代速度。</li>\n<li>在这之后，如果发现它们不够好，马上做出改变。</li>\n</ul>\n<h2 id=\"1-3-相比于人类的表现\"><a href=\"#1-3-相比于人类的表现\" class=\"headerlink\" title=\"1.3 相比于人类的表现\"></a>1.3 相比于人类的表现</h2><h3 id=\"为什么是人类的表现\"><a href=\"#为什么是人类的表现\" class=\"headerlink\" title=\"为什么是人类的表现\"></a>为什么是人类的表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 在过去的几年里，许多机器团队一直在讨论如何比较机器学习系统和人类的表现：</p>\n<ul>\n<li>图中，机器学习系统以较快地速度接近人类表现，甚至超过它。</li>\n<li>超过人类表现之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，称之为贝叶斯最优误差(bayes optimal error)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 当机器学习系统的表现比人类的差时，有一些工具可以用来提高性能，而一旦超越了人类的表现，这些工具就不那么好用了：</p>\n<ul>\n<li>让人类帮助标注数据。<ul>\n<li>解释：这样就可以有更多的数据可以喂给模型。</li>\n</ul>\n</li>\n<li>通过人工错误分析。<ul>\n<li>解释：下周讲解。只要人类的表现比其他任何算法都要好，就可以让人类去查看算法做错的例子，并尝试了解为什么人能做对，算法做错。</li>\n</ul>\n</li>\n<li>进行更好的偏差/方差分析。<ul>\n<li>解释：下节讲解。</li>\n</ul>\n</li>\n<li>注：只要你的算法比人类的表现糟糕，上述三条策略可以改善算法，而一旦你的算法做的比人类好，上述三条策略就很难利用了。</li>\n</ul>\n<h3 id=\"可避免偏差\"><a href=\"#可避免偏差\" class=\"headerlink\" title=\"可避免偏差\"></a>可避免偏差</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8F%AF%E9%81%BF%E5%85%8D%E5%81%8F%E5%B7%AE.JPG\" width=\"90%\" height=\"90%\"> 我们希望算法在训练集上表现好，但实际上不想算法在训练集上表现得太好。当知道人类的表现后，可以准确的告诉你算法在训练集上的表现到底该有多好。<br>如图中的猫分类器为例：</p>\n<ul>\n<li>在第二们课程里关于偏差和方差的讨论中，我们主要假设一些任务的贝叶斯误差几乎接近于0。</li>\n<li>在对于某些人类擅长的任务：如计算机视觉任务，人类水平误差虽高于贝叶斯误差(理论上限)，但可认为近似等于贝叶斯误差。</li>\n<li>在确定人类水平(近似贝叶斯误差)后，就定义了我们认为什么样的水平是可以实现的：<ul>\n<li><strong>将人类水平误差和训练误差之间的差值</strong>称为<strong>可避免偏差(avoidable bias)</strong>，或可避免偏差的度量。</li>\n<li><strong>将训练误差和开发集误差之间的差值</strong>称为<strong>方差</strong>，或方差的度量。</li>\n<li><strong>根据可避免偏差和方差的相对大小，决定专注于减少偏差的策略还是减少方差的策略</strong>。</li>\n<li>若将贝叶斯误差定为1%，而训练误差为8%，我们认为可以将它降低到1%，那么将专注于减小偏差；</li>\n<li>若将贝叶斯误差定为7.5%，而训练误差为8%，可避免误差为0.5%，没什么改进空间，不能再继续减少训练误差了，防止过拟合。而训练误差和开发集误差相差2%，那么将专注于减少方差。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"理解人类的表现\"><a href=\"#理解人类的表现\" class=\"headerlink\" title=\"理解人类的表现\"></a>理解人类的表现</h3><p>应该这样看待人来水平表现：人类的表现是贝叶斯误差的替代或估计。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图所示，应将人类水平定义为一个专家团队的表现，即错误率为0.5%。0.5%是贝叶斯误差的最佳估计。<ul>\n<li>解释：因为要将人类水平表现看作是贝叶斯误差的替代或近似，故选取表现最好的一组，所以此处便可认为：$Bayes\\ error \\leq 0.05%$</li>\n</ul>\n</li>\n<li>在上一节，通过人类水平表现来分析偏差和方差时，也是这样看待人类水平表现的，即作为贝叶斯误差的替代。</li>\n<li>在实际应用中，针对具体的应用情况，如果认为达到某个标准，就已经实用了，也可选用其他标准来作为人类水平表现。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>在系统表现，未达到人类水平表现之前，不管如何定义人类水平表现(1%/0/7%/0.5%)，都不影响减小偏差策略还是减小方差策略的确定。<ul>\n<li>如图中左侧两例。</li>\n</ul>\n</li>\n<li>在系统接近人类表现之后，系统的提升变得很难，因为如果贝叶斯误差估计的不准确，将难以发现到底是方差问题还是偏差问题：<ul>\n<li>如上图最右侧，只有将贝叶斯误差定义为0.5%(一个专家团队的表现)，才能发现可避免偏差0.2%，方差0.1%，从而决定该采用减小偏差策略；</li>\n<li>若将贝叶斯误差定义为0.7%，则可避免偏差为0%，方差为0.1%，则会采用减小方差的策略。、</li>\n<li>当你只知道贝叶斯误差是单个医生的表现即1%时，你甚至无法知道该不该继续去拟合训练集。</li>\n<li>因此，当系统接近人类表现时，很难更进一步。因为很难准确的估计贝叶斯误差，难以确定是偏差还是方差问题。</li>\n</ul>\n</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>对于计算机视觉任务，比如猫识别问题，人类的表现近乎完美，所以贝叶斯误差也接近完美，那么将贝叶斯误差设为0，没什么问题。</li>\n<li>但如果数据有很大的噪声，对于背景很嘈杂的语音识别问题，有时几乎不可能听清说什么。对于这样的问题，更好的定义贝叶斯误差很重要，可以帮助我们更好的估计可避免误差和方差，这样才能更好的做出决策，选择减少偏差策略还是减少方差策略。</li>\n</ul>\n<h3 id=\"超越人的表现\"><a href=\"#超越人的表现\" class=\"headerlink\" title=\"超越人的表现\"></a>超越人的表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图左侧，当贝叶斯误差为0.5%，则可避免偏差为0.1%，方差为0.2%，则选择减小方差策略。</li>\n<li>如图右侧，当贝叶斯误差为0.5%，训练误差为0.3%，则不知道是训练误差过拟合了0.2%，还是贝叶斯误差实际上是0.1%/0.2%/0.3%，无法知道。此例中没有足够的信息，来判断应该选择减小偏差还是减小方差，这样取得进展的效率就会降低。</li>\n<li>在这个例子中，一旦超过了0.5%这个阈值，优化算法的方向便不那么明确了，因为现有的一些指明明确方向的工具失效了（但并不意味着不能继续提升，还是可以继续提升）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 图中列举出了显著超越人类水平表现的机器学习应用：</p>\n<ul>\n<li>首先是对于结构化数据：<ul>\n<li>在线广告（估计某个用户点击某个广告的可能性）</li>\n<li>产品推荐（推荐电影或书籍之类）</li>\n<li>物流预测(logistics)（预测运输时间）</li>\n<li>贷款批准</li>\n<li>原因：计算机擅长访问大量数据，识别出数据中的统计规律。</li>\n</ul>\n</li>\n<li>人类擅长自然感知(natural perception)任务，但也有一些机器学习应用超越了人类水平表现：<ul>\n<li>语音识别</li>\n<li>某些图像识别任务</li>\n<li>某些医疗方面任务，如阅读ECG、皮肤癌诊断、放射科读图任务</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"改善你的模型表现\"><a href=\"#改善你的模型表现\" class=\"headerlink\" title=\"改善你的模型表现\"></a>改善你的模型表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 要让一个监督学习算法足够好，需要完成以下两件事：</p>\n<ul>\n<li>首先，很好的拟合训练集（即让可避免误差很低）。</li>\n<li>然后，在开发/测试集上的泛化很好（即让方差较低）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在正交化的精神下，有单独的旋钮，去处理偏差问题或方差问题：</p>\n<ul>\n<li>减少可避免偏差：<ul>\n<li>使用更大的模型</li>\n<li>训练更长的时间，或使用更好的优化算法(如Momentum,RMSprop,Adam)</li>\n<li>尝试其他的神经网络架构(如RNN，CNN，有时会有好的效果，不确定)，或进行超参数搜索</li>\n</ul>\n</li>\n<li>减少方差：<ul>\n<li>搜集更多训练数据（训练更多数据，可以帮助系统泛化到看不到的开发集）</li>\n<li>正则化(如L2正则化，Dropout，数据增强)</li>\n<li>尝试其他的神经网络架构或进行超参数搜索</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-机器学习策略-2\"><a href=\"#2-机器学习策略-2\" class=\"headerlink\" title=\"2.机器学习策略(2)\"></a>2.机器学习策略(2)</h1><h2 id=\"2-1-错误分析\"><a href=\"#2-1-错误分析\" class=\"headerlink\" title=\"2.1 错误分析\"></a>2.1 错误分析</h2><h3 id=\"进行错误分析\"><a href=\"#进行错误分析\" class=\"headerlink\" title=\"进行错误分析\"></a>进行错误分析</h3><p>如果你希望让学习算法胜任人类能做的任务，但你的学习算法还没有达到人类的表现。那么，<strong>人工检查算法所犯下的错误，可以让你了解接下来该做什么</strong>。这个过程称为<strong>错误分析(error analysis)</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%901.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设猫分类器在开发集上取得了90%的准确率，即10%的误差。</li>\n<li>注意到把一些狗分类成猫，问题是：是否需要开始做一个项目专门处理狗的问题？</li>\n<li>解决方法：错误分析：<ul>\n<li>首先，从开发集中找出约100个错误分类的样本。</li>\n<li>然后，人工统计出多少个是狗。</li>\n</ul>\n</li>\n<li>如果有5%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是9.5%(10%减少5%)的错误率。不值得专门花费大量时间。</li>\n<li>如果有50%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是5%(10%减少50%)的错误率。值得花费时间解决狗的问题。</li>\n<li>另外，尽管是人工统计，但检查100个开发集错误分类样本，只需要5-10分钟的时间，便可以给我们指出最有希望的方向。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%902.JPG\" width=\"80%\" height=\"80%\"> 并行评估多个想法：</p>\n<ul>\n<li>如图，针对如何改进猫的分类器，你有以下几个想法：狗的误分类问题，大型猫科动物的误分类问题，以及改善系统在模糊图片上的表现。</li>\n<li>进行错误分析：<ul>\n<li>首先，建立一个电子表格，每一列是你的一个想法，每一行是一个开发集上的误分类样本。此外，最后一栏记录你对每个误分类样本的注释。</li>\n<li>然后，人工统计从开发集选出的每一个误分类样本，记录在电子表格中。</li>\n<li>最后，统计出每一列(即每一个想法)所对应的误分类样本的比例，针对不同比例，确定改进猫分类器的方向。</li>\n<li>另外，当你在人工统计时，又有了新的想法，比如发现由于Instagram滤镜的问题经常导致误分类，则可将该想法作为新的一列加入电子表格中。</li>\n</ul>\n</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>进行错误分析：<ul>\n<li>首先应该从开发集找一组错误分类的例子。</li>\n<li>观察错误分类的例子（假阳性和假阴性），统计出属于不同错误类型的错误样本数量。</li>\n<li>在这个过程中，你可能会得到启发归纳出新的错误类型，那就在中途新建一个错误类型。</li>\n<li>最后，通过统计不同错误类型包含的样本的比例，决定哪个问题需要优先解决，或者给你构思新优化方向的灵感。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"清理错误标记的数据\"><a href=\"#清理错误标记的数据\" class=\"headerlink\" title=\"清理错误标记的数据\"></a>清理错误标记的数据</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE1.JPG\" width=\"80%\" height=\"80%\"> 首先，对于训练集中标记出错的样本：</p>\n<ul>\n<li>深度学习算法对训练集中的随机错误是相当鲁棒的：<ul>\n<li>只要标记出错的样本，是由于随机错误(即标记人员不小心标错)，不管也没问题，不用花费太多时间去修正它们，只要训练集足够大。</li>\n<li>但如果标记出错的样本，是由于系统性错误(如标记人员一直把白色的狗标记成猫)，分类器训练后，将会一直把白色的狗标记成猫。这种情况肯定需要修正。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE2.JPG\" width=\"80%\" height=\"80%\"> 然后，对于开发/测试集中标记出错的数据：</p>\n<ul>\n<li>若担心在开发/测试集上标记出错的例子带来的影响，建议在进行错误分析时，增加一列，记录标签出错的样本，然后统计其比例。</li>\n<li>若这些标记错误严重影响了你在开发集上评估算法的能力，那就需要花时间修正错误标记的数据，具体来说，通过查看三个数字：<ul>\n<li>整体开发集错误率</li>\n<li>由错误标记样本导致的错误率</li>\n<li>其他原因导致的错误率</li>\n<li>例1：如图左侧，整体开发集错误率为10%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为9.4%，修正错误标记样本是低优先级的方向。</li>\n<li>例2：如图右侧，整体开发集错误率为2%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为1.4%，由错误标记样本导致的错误率占了整体开发集错误率的很大比重，值得花费时间去修正错误标记的数据。</li>\n<li>例3：开发集的目的是为了帮助你从分类器A和B中选择更好的一个。<br>算法A的整体开发集错误率为2.1%，算法B的整体开发集错误率为1.9%，而其中由错误标记样本导致的错误率为0.6%，无法再信任开发集，因为它无法正确告诉你分类器A是否真的比分类器B好。此情况必须去修正开发集里的错误标签了。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE3.JPG\" width=\"80%\" height=\"80%\"> 如果决定要修正开发集数据里的错误标签(人工逐个检查并修正)，那么有一些指南：</p>\n<ul>\n<li>施加同样的处理手段给开发集和测试集，以保证它们依然来自同一分布。</li>\n<li>考虑同时检测算法判断正确和判断错误的例子。<ul>\n<li>不容易去做，因为如果算法准确率很高，如98%，那检查98%的数据的标签，要花费很长时间，所以通常不总是这么做，但也是需要考虑的。</li>\n</ul>\n</li>\n<li>训练集和开发/测试集有可能来自稍微不同的分布。<ul>\n<li>如果你决定修改开发/测试集(通常比训练集小很多)，而有可能不修改训练集(深度学习算法对随机错误很鲁棒且训练集很大，也不想花费大量时间去修正)，而这样是可以的。后面会进一步讲解。</li>\n</ul>\n</li>\n</ul>\n<p>最后的建议：</p>\n<ul>\n<li>在构建实际的系统时，通常需要更多的人工错误分析和更多的人类见解。</li>\n<li>有些深度学习研究员不愿意去亲自看这100或几百个例子，来统计错误数量，这是我(吴恩达)经常亲自去做的，可能花费十几分钟或几个小时，但可以帮我找到需要优先处理的任务。</li>\n</ul>\n<h3 id=\"快速构建你的第一个系统，然后迭代\"><a href=\"#快速构建你的第一个系统，然后迭代\" class=\"headerlink\" title=\"快速构建你的第一个系统，然后迭代\"></a>快速构建你的第一个系统，然后迭代</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%84%B6%E5%90%8E%E8%BF%AD%E4%BB%A3.JPG\" width=\"80%\" height=\"80%\"> 如图，如果要建立一个新的语音识别系统，你可以走很多方向或有很多可以优先考虑的事情，来改善语音识别系统，如图所示。</p>\n<ul>\n<li>建议：如果你正在开发新的机器学习应用，那么应该快速建立你的第一个系统，然后迭代：<ul>\n<li>快速设立开发/测试集以及评价指标 </li>\n<li>快速构建初始的系统</li>\n<li>使用偏差/方差分析以及错误分析去确定下一步优先做什么</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>如果你在这个应用领域有很多经验，这个建议的适用程度要低一些。或当这个领域有很多可以借鉴的学术文献和你要处理扽问题几乎完全相同，这个建议的适用程度也要低一些。例如，在人脸识别领域就有很多学术文献，如果你尝试建立一个人脸识别器，那么就可以从现有的大量学术文献作为基础出发，一开始就建立比较复杂的系统。</li>\n<li>但如果你第一次处理某个新问题，还是遵循以上建议。</li>\n</ul>\n<h2 id=\"2-2-不匹配的训练集和验证-测试集\"><a href=\"#2-2-不匹配的训练集和验证-测试集\" class=\"headerlink\" title=\"2.2 不匹配的训练集和验证/测试集\"></a>2.2 不匹配的训练集和验证/测试集</h2><h3 id=\"在不同分布上进行训练和测试\"><a href=\"#在不同分布上进行训练和测试\" class=\"headerlink\" title=\"在不同分布上进行训练和测试\"></a>在不同分布上进行训练和测试</h3><p>深度学习算法对训练数据的胃口很大，当你收集到足够多的带标签的数据构成训练集时，算法效果最好。这导致很多团队用尽一切办法收集数据，然后把它们放进训练集中，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集及测试集不同的分布。在深度学习时代，越来越多的团队，都用来自和开发集及测试集不同分布的数据来训练。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%951.JPG\" width=\"50%\" height=\"50%\"> </p>\n<ul>\n<li>假设你在开发一个手机应用，有两个数据来源：一个是你真正关心的数据分居，来自应用上传的数据。 <ul>\n<li>一个是你真正关心的数据分居，来自应用上传的数据。如图右侧，或随意或模糊。约10,000张。</li>\n<li>另一个数据源是通过爬虫，从网页中下载的数据。如图左侧，专业且高分辨率。约200,000张。</li>\n</ul>\n</li>\n<li>你真正关心的是：你的最终系统处理来自应用程序的图片分布时，效果好不好。</li>\n<li>选项1：如图，将两组数据组合在一起，共210,000张，然后随机分配到训练集、开发集和测试集中，训练集占205,000张，开发/测试集个占2,500张：<ul>\n<li>好处：训练集和开发集及测试集来自同一分布，这样更易于管理。</li>\n<li>巨大的坏处：开发/测试集中有大量数据($200k/210k*2500 \\approx 2381$)来自网页下载，不是你真正关心的数据分布。只有约119张来自用户手机上传。</li>\n<li>设置开发集的目的是告诉团队瞄准的目标(靶心)。此做法相当设置了错误的目标。不建议使用该做法。</li>\n</ul>\n</li>\n<li><strong>选项2</strong>：如图，<strong>训练集由网页下载的200,000张图片加上用户手机上传的5000张图片，共205,000张。开发集和测试集都是手机上传图片，各2,500张</strong>。<ul>\n<li>好处：<strong>开发集和测试集都是用户手机上传的照片，是你真正关心的数据分布</strong>。现在你瞄准的目标就是你想要处理的目标。</li>\n<li>坏处：<strong>训练集和开发/测试集的分布不一样</strong>，<strong>但事实证明，这样分配数据集，在长期能给你带来更好的系统性能</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 如图，以语音激活后视镜应用为例：：</p>\n<ul>\n<li>有两个数据来源：<ul>\n<li>一个是从其他语音识别应用中收集到的数据。约500,000条。</li>\n<li>一个是语音激活后视镜的数据(用户要查询导航信息，可能包含更多街道地址)。约20,000条。</li>\n</ul>\n</li>\n<li>设置训练集、开发集和测试集，如图：<ul>\n<li>训练集包含其他语音识别应用中的500k条语音，开发/测试集各包含10k条语音激活后视镜的语音。</li>\n<li>或训练集包含其他语音识别应用中的500k条语音加上语音激活后视镜的语音的10k条语音，开发/测试集各包含5k条语音激活后视镜的语音。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"不匹配的数据分布的偏差和方差\"><a href=\"#不匹配的数据分布的偏差和方差\" class=\"headerlink\" title=\"不匹配的数据分布的偏差和方差\"></a>不匹配的数据分布的偏差和方差</h3><p>估计学习算法的偏差和方差，可以帮助你确定接下来优先该进行的方向。但是<strong>当你的训练集和开发/测试集来自不同分布时，分析偏差和方差的方法需要改变</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 以猫分类器为例：</p>\n<ul>\n<li>人类的表现几乎完美，所以贝叶斯误差几乎为0%。</li>\n<li>训练集误差为1%，开发集误差为10%。</li>\n<li><strong>若训练集和开发集来自同一分布，在这种情况下，可以说存在很大的方差问题</strong>。</li>\n<li><strong>但如果训练集和开发集不是来自同一分布，那就无法确定地下结论</strong>。也许分类器已经在开发集上做的很好，因为训练集中都是专业且高分辨率的图片，很容易进行分类，而开发集中是难以精确分类的图片。即有可能分类器不存在方差问题。</li>\n<li>问题在于：从训练误差到开发集误差，改变了两件事情：第一，算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。因为同时改变了两件事，<strong>无法确定导致训练误差和开发集误差的差值9%的原因，有多少是由于没见过开发集导致，即方差问题。有多少是由于开发集来自不同分布</strong>。</li>\n<li>解决方法：<strong>划分出训练-开发集(training-dev set)</strong>。<ul>\n<li>训练-开发集：与训练集同分布，但不用于训练。</li>\n<li>具体划分示意，如图所示。</li>\n</ul>\n</li>\n<li>接来下，分析四个指标：<strong>人类水平表现(贝叶斯误差)、训练集误差、训练-开发集误差和开发集误差</strong>。</li>\n<li><p>例1：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为9%，开发集误差为10%。</p>\n<ul>\n<li>贝叶斯误差和训练集误差之间的差值为可避免偏差，值为1%。训练集误差和训练-开发集的误差的差值为方差，值为8%。训练-开发集误差和开发集误差之间的差值为数据不匹配，值为1%。</li>\n<li>因此，存在方差问题。</li>\n</ul>\n</li>\n<li><p>例2：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为1.5%，开发集误差为10%。</p>\n<ul>\n<li>可避免偏差为1%，方差为0.5%，数据不匹配为8.5%。</li>\n<li>因此，存在数据不匹配问题。</li>\n</ul>\n</li>\n<li><p>例3：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为12%。</p>\n<ul>\n<li>可避免偏差为10%，方差为1%，数据不匹配为1%。</li>\n<li>因此，存在偏差问题。</li>\n</ul>\n</li>\n<li><p>例4：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为20%。</p>\n<ul>\n<li>可避免偏差为10%，方差为1%，数据不匹配为9%。</li>\n<li>因此，存在偏差问题和数据不匹配问题。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"100%\" height=\"100%\"> <strong>总结训练集和开发/测试集来自不同分布时，分析偏差和方差问题的方法</strong>：</p>\n<ul>\n<li>贝叶斯误差和训练集误差之间的差值为<strong>可避免偏差</strong>，或可避免误差的度量。</li>\n<li>训练集误差和训练-开发集的误差的差值为<strong>方差</strong>，或方差的度量。</li>\n<li>训练-开发集误差和开发集误差之间的差值为<strong>数据不匹配</strong>，或数据不匹配的度量。</li>\n<li>开发集误差和测试集误差之间的差值为<strong>对开发集的过拟合程度</strong>，或对开发集的过拟合程度的度量。</li>\n<li>举例一个特殊的例子：<ul>\n<li>贝叶斯误差为4%，训练集误差7%，训练-开发集误差为10%，开发集误差为6%，测试集误差为6%。</li>\n<li>这种情况是合理的，说明训练集的难度比开发/测试集的难度要高很多。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"90%\" height=\"90%\"> 以语音激活后视镜为例：</p>\n<ul>\n<li>第一列为其他通用语音应用中的数据，第二列为语音激活后视镜的数据。</li>\n<li>只不过强调了：<ul>\n<li>算法只在训练集上训练过，而训练-开发集，开发/测试集，算法都没有训练过。</li>\n<li>训练集和训练-开发集来自同一分布(通用语音应用中的数据)。开发/测试集来自另一分布(语音激活后视镜的数据)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"处理数据不匹配\"><a href=\"#处理数据不匹配\" class=\"headerlink\" title=\"处理数据不匹配\"></a>处理数据不匹配</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D1.JPG\" width=\"100%\" height=\"100%\"> <strong>如果发现有严重的数据不匹配问题</strong>：</p>\n<ul>\n<li>进行人工错误分析，去尝试理解训练集和开发/测试集的区别。<ul>\n<li>如在语音激活后视镜应用中：进行错误分析后，发现开发集中以汽车噪音为背景的语音片段误判很多。或很多请求街道号码的语音片段误判很多。</li>\n</ul>\n</li>\n<li>让训练集更像开发集，收集更多类似开发/测试集的数据。<ul>\n<li>如可以模拟车辆背景噪声数据，或刻意的收集人类说数字的音频数据，然后添加进训练集。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D2.JPG\" width=\"100%\" height=\"100%\"> 人工数据合成：</p>\n<ul>\n<li>例子如图：将人类说话的音频和汽车噪声的音频进行人工合成，合成为车内说话的音频数据。</li>\n<li>人工数据合成可以快速制造出更多的训练数据。但要注意，人工数据合成存在一个潜在问题：<ul>\n<li>假设你录制了10,000个小时的安静背景下的音频数据，录制了1个小时的汽车噪音数据，然后将汽车噪音重复播放10,000次叠加到安静背景下的音频数据。人类听起来，这些合成的音频数据没问题。但学习算法会对这1小时的汽车噪音过拟合。你收集得到的1小时汽车噪音背景下的音频数据只是所有存在的汽车噪音的一个很小的子集，从整个空间的很小的一个子集出发，去合成数据，神经网络可能最后会对这1个小时的汽车噪音过拟合。</li>\n<li>更好的做法是收集10,000个小时的汽车噪音，而不是重复播放1小时的汽车噪音10,000次。在不考虑成本的情况下，这种做法会使得学习算法取得更好的性能。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D3.JPG\" width=\"90%\" height=\"90%\"> 人工数据合成的另一例：</p>\n<ul>\n<li>若对于汽车检测任务，用人工数据合成时，如果只是基于20种车的人工数据合成。20辆车只是所有可能出现的车辆的很小的子集。人眼看不出来，神经网络可能对这20种车过拟合。</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>如果你认为存在数据不匹配问题，建议进行错误分析，查看训练集和开发集，尝试了解这个两个数据分布到底有什么不同，然后看看是否有办法收集更多像开发集的训练数据进行训练。</li>\n<li>其中一种办法是人工数据合成，人工数据合成确实有效，在语音识别系统中，已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现。但当你使用人工数据合成时，一定要谨慎，要记住你有可能只是从所有可能性的空间选择了很小的一部分去模拟数据。</li>\n</ul>\n<h2 id=\"2-3-从多个任务中学习\"><a href=\"#2-3-从多个任务中学习\" class=\"headerlink\" title=\"2.3 从多个任务中学习\"></a>2.3 从多个任务中学习</h2><h3 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h3><p>深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。例如，你已经训练好一个可以识别猫的神经网络，然后可以用这些已学到的知识或部分知识去帮助你更好地阅读X射线扫描图。这就是所谓的<strong>迁移学习</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 迁移学习举例：</p>\n<ul>\n<li>例1：已经训练好一个图像识别的神经网络，然后将图像识别中学习到的知识应用/迁移到放射诊断任务中：<ul>\n<li>删去原神经网络中的最后一层及其权重，新建最后一层神经网络并随机初始化权重，即$W^{[l]}$，$b^{[l]}$ 。</li>\n<li>在新的放射诊断数据集上训练神经网络。如果放射诊断数据集较小，就只训练新的最后一层网络的参数$W^{[l]}$，$b^{[l]}$并保持原网络其他参数不变。如果放射诊断数据集很大，可以重新训练网络中的所有参数(以之前网络训练好的参数作为初始参数)。</li>\n<li>如果选择重新训练网络中的所有参数，那么图像识别任务的训练阶段称为<strong>预训练(pre-training)</strong>。然后在放射诊断数据上重新训练参数的过程，称为<strong>微调(fine tuning)</strong>。</li>\n</ul>\n</li>\n<li>有效的原因：在图像识别任务中，很多低层次的特征，比如边缘检测、曲线检测等结构信息知识，可能帮助放射诊断任务。</li>\n<li>例2：已经训练好一个语音识别的神经网络，然后迁移到唤醒/触发词检测系统中：<ul>\n<li>删去原神经网络的最后一层，在末端建立新的几层。</li>\n<li>若唤醒/触发词检测的数据量较小，则在唤醒/触发词检测数据集中，只训练新建的几层。若唤醒/触发词检测的数据量较大，可重新训练神经网络的所有参数。</li>\n<li>在语音识别任务中，预先学到的很多人类声音的特征，人类语言的组成部分等知识，可以帮助你建立一个很好的唤醒词检测器。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> 什么时候迁移学习是有意义的：</p>\n<ul>\n<li>任务A和任务B有一样的输入x。<ul>\n<li>在上节的例1中，任务A和任务B的输入都是图像。</li>\n<li>在上节的例2中，任务A和任务B的输入都是音频。</li>\n</ul>\n</li>\n<li>任务A拥有的数据量要比任务B大得多。<ul>\n<li>在上节的例1中，任务A中图像识别有着大量的数据集，如1000,000张。而任务B中放射诊断数据集图像只有100张。</li>\n<li>在上节的例2中，任务A中语音识别数据集中有10,000小时的音频。而任务B唤醒词检测任务中只有1小时的音频。</li>\n</ul>\n</li>\n<li>任务A中的低层次特征可以帮助任务B的学习。</li>\n</ul>\n<h3 id=\"多任务学习\"><a href=\"#多任务学习\" class=\"headerlink\" title=\"多任务学习\"></a>多任务学习</h3><p>在迁移学习中，你的步骤是串行的：先从任务A中学习，然后迁移到任务B。在多任务学习中，你是同时开始学习的，试图让神经网络同时做几件事情，然后希望这里的每个任务都能帮助到其他所有任务。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以开发无人驾驶汽车为例：</p>\n<ul>\n<li>无人驾驶汽车需要同时检测不同的物体，如行人、车辆、停车标志及交通灯。</li>\n<li>此时输入为图像$x^{(i)}$,输出$y^{(i)}$为：<script type=\"math/tex\">y^{(i)}= \\left[ \\begin{matrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{matrix} \\right]</script></li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 神经网络结构，如图：</p>\n<ul>\n<li>神经网络的最后一层有四个结点，分别代表是否存在行人、车辆、停车标志及交通灯。即$\\hat{y}$的维度为$(4,1)$</li>\n<li>代价函数为：<script type=\"math/tex\">\\frac1m\\sum_{i=1}^m\\sum_{j=1}^4L(\\hat y_j^{(i)},y_j^{(i)})</script><ul>\n<li>其中，$L(\\hat y_j^{(i)},y_j^{(i)})$是单个结点的损失，采用常用的逻辑损失，<script type=\"math/tex\">L(\\hat y_j^{(i)},y_j^{(i)})=-y_j^{(i)}log\\ \\hat y_j^{(i)}-(1-y_j^{(i)})log\\ (1-\\hat y_j^{(i)})</script></li>\n</ul>\n</li>\n<li>多任务学习<strong>与softmax回归的主要区别</strong>在于：softmax将单个标签分给单个样本。而多任务学习中，一张图片有多个(4个)标签（从代价函数中的形式中也可以看出来）。</li>\n<li>另外，多任务学习也可以用于处理图像中只有部分物体被标记的情况。<ul>\n<li>如某个样本只标记有行人和车辆，但没有标记是否有停车标志和交通灯，即样本标签形式为<script type=\"math/tex\">y^{(i)}= \\left[ \\begin{matrix} 1\\\\ 1\\\\ ?\\\\ ? \\end{matrix} \\right]</script></li>\n<li>即便是这样的数据集，你也可以上面训练算法同时做四个任务。在训练时，数据中缺失的标签所对应的结点，不参加代价函数的求和即可。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A03.JPG\" width=\"90%\" height=\"90%\"> 多任务学习什么时候有意义：</p>\n<ul>\n<li>如果你训练的一组任务可以公用低层次特征。</li>\n<li>如果每个任务的数据量很接近(这个准则没有那么绝对，并不一定是对的)。<ul>\n<li>例如，你有一百个任务，每个任务的数据集大小为1000，那么进行多任务学习，训练集大小将达100,000。</li>\n</ul>\n</li>\n<li>可以训练一个足够大的神经网络同时做好所有任务。<ul>\n<li>有研究表明：只要你可以训练一个足够大的神经网络进行多任务学习，几乎都比单独训练多个神经网络来单独完成各个任务的性能要好。</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>多任务学习能让你训练一个神经网络来同时进行多个任务，可以给你比单独完成各个任务更高的性能。</li>\n<li>多任务学习使用到的频率要比迁移学习使用到的频率低得多。<ul>\n<li>其中一个例外是计算机视觉中的目标检测。人们经常训练一个神经网络，同时检测许多不同的物体，这比训练单独的神经网络来检测物体要好。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-4-端到端的深度学习\"><a href=\"#2-4-端到端的深度学习\" class=\"headerlink\" title=\"2.4 端到端的深度学习\"></a>2.4 端到端的深度学习</h2><h3 id=\"什么是端到端的深度学习\"><a href=\"#什么是端到端的深度学习\" class=\"headerlink\" title=\"什么是端到端的深度学习\"></a>什么是端到端的深度学习</h3><p>深度学习中最令人兴奋最新发展之一就是端到端的深度学习的兴起。什么是端到端的深度学习，简而言之，以前有一些数据处理系统，它们需要多个阶段的处理。而端到端的深度学习就是将所有这些多个阶段用单个神经网络替代它。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以语音识别为例：</p>\n<ul>\n<li>输入$x$是一段音频(audio clip)，输出$y$是这段音频的听写文本(transcript)。</li>\n<li>传统上，语音识别需要很多阶段的处理，首先你会提取一些手工设计的音频特征(如MFCC)，通过机器学习算法在音频片段中找到音位(声音的基本单位)，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本。</li>\n<li>端到端的深度学习是，训练一个巨大的神经网络，输入是音频，输出直接是听写文本。</li>\n<li><strong>端到端的深度学习的挑战之一是：需要大量数据才能让系统表现好</strong>。<ul>\n<li>若你只有3,000个小时的数据去训练语音识别系统，那么传统的流水线(pipeline)的效果很好。</li>\n<li>若你拥有非常大的数据集，如10,000小时甚至100,000小时的数据，那么端到端的学习方法就表现的很好了。</li>\n<li>如果你数据量适中，那么可以用折中的方法，如输入音频，然后让过特征提取，直接尝试从神经网络输出音位，然后其他阶段继续采用传统方法。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 以门禁人脸识别系统为例，如图：</p>\n<ul>\n<li>端到端的学习方法：将相机拍摄到的图片作为输入，然后直接学习图像$x$到人类身份$y$的函数映射。<ul>\n<li>但事实证明，这不是最好的方法，因为人可以从很多不同的方向接近门禁(即人类可能以不同大小出现在照片的不同位置)。在实际构建这些门禁系统时，不是将原始图片喂给神经网络，然后尝试去找出人类的身份。</li>\n</ul>\n</li>\n<li>迄今为止最好的做法，是一个多步方法。首先，找出照片中人脸的位置，检测到人脸后，然后放大人脸图像的那部分，并剪裁图像，使得人脸居中显示。然后，再将人脸图片喂给神经网络，让网络去学习或估计人类的身份。</li>\n<li>两步方法更好的原因：<ul>\n<li>你解决的两个问题，每个都更简单。</li>\n<li>两个子任务的训练数据都很多。对于任务1，人脸检测的数据很多，$x$是图片，$y$是人脸位置。对于任务2，人脸识别的数据也很多。<strong>相比之下，直接输入门禁系统拍摄照片$x$，输出人类身份$y$的数据集很少</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.JPG\" width=\"100%\" height=\"100%\"> </p>\n<ul>\n<li>以机器翻译(machine translation)为例：<ul>\n<li>传统上，机器翻译系统也有很复杂的流水线：英语，文本，文本分析等等。</li>\n<li>而如今，<strong>端到端的机器翻译表现的很好，因为可以收集大量的数据对$(x,y)$，即英文句子对用的法文翻译</strong>。</li>\n</ul>\n</li>\n<li>以孩子手部的$x$光线图片，来估计年龄：<ul>\n<li>非端到端的学习方法：输入图片，分割出每一块骨头，弄清每一块骨头的长度，然后查找儿童手中骨头的平均长度，然后用它来估计孩子的年龄。</li>\n<li>端到端：<strong>通过图片直接估计孩子的年龄。那么需要大量数据去训练，在今天，还没有足够数据</strong>。</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>端到端学习是可行的，它可以表现得非常好，并简化系统，让你不需要构建那么多的手工设计的单独部件。</li>\n<li>但它也不是万能之计，并不是在所有任务中都有效。</li>\n</ul>\n<h3 id=\"是否使用端到端的深度学习\"><a href=\"#是否使用端到端的深度学习\" class=\"headerlink\" title=\"是否使用端到端的深度学习\"></a>是否使用端到端的深度学习</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> <strong>端到端的深度学习的优缺点</strong>：<br>优点：</p>\n<ul>\n<li>让数据说话。<ul>\n<li>解释：如果有足够多的数据$(x,y)$，那么不管从$x$到$y$的最合适的函数映射是什么，一个足够大的神经网络能自己找到。而不是在如语音识别中，强制算法以“音位“为单位思考，也许让算法自己从大量数据中洞察到更好的表示方法更好。</li>\n</ul>\n</li>\n<li>需要更少的手工设计组件。<ul>\n<li>解释：简化系统，节省时间。</li>\n</ul>\n</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>需要大量的数据$(x,y)$。</li>\n<li>排除了潜在的有用的手工设计的组件。<ul>\n<li>解释：<strong>学习算法有两个主要的知识来源，一是数据，二是手工设计的组件或特征</strong>。当有大量数据时，手工设计的东西就不太重要了。但<strong>当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的最好途径</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"><br>如果你在构建一个新的机器学习系统，而你在尝试决定是否使用端到端的深度学习，那么问题的关键是：<strong>你有足够的数据能够直接学习到从$x$映射到$y$的足够复杂的函数吗？</strong></p>\n<ul>\n<li>如果输入手的$x$射线图片，分割出骨头位置，不需要太多的数据就可以完成这个任务。</li>\n<li>如果输入人的图片，检测出人脸的位置，不需要太多的数据就可以完成这个任务。</li>\n<li>但如果输入手的$x$射线图片，直接估计出孩子的年龄，这种复杂的映射函数，就需要大量的数据。</li>\n</ul>\n<p>如图下半部分，以无人驾驶汽车为例：</p>\n<ul>\n<li>需要完成的任务：输入雷达图片，检测车辆和行人，规划路线，控制方向盘/油门/刹车。</li>\n<li>解决方法：用深度学习方法进行检测车辆和行人；用运动规划(motion planning)软件解决路径规划；用控制算法决定如何控制方向盘/油门/刹车。</li>\n<li>这个例子表明了：<ul>\n<li>你想用机器学习或深度学习来学习一些单独的组件。</li>\n<li>当你用监督学习时，应该仔细地选择你想要学习的$x$到$y$的映射，取决于哪些任务你可以收集到数据。</li>\n</ul>\n</li>\n<li>相比之下，若考虑使用端到端的深度学习：即输入图像$x$，直接得出方向盘角度等。<ul>\n<li>就目前能收集到的数据以及目前神经网络可以学习到的事物类型而言，这实际上不是最有前景的方向。这种纯粹的端到端的学习方法，其前景不如上述分步进行的方法。</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-机器学习策略-1\"><a href=\"#1-机器学习策略-1\" class=\"headerlink\" title=\"1.机器学习策略(1)\"></a>1.机器学习策略(1)</h1><h2 id=\"1-1-机器学习策略介绍\"><a href=\"#1-1-机器学习策略介绍\" class=\"headerlink\" title=\"1.1 机器学习策略介绍\"></a>1.1 机器学习策略介绍</h2><h3 id=\"为什么需要机器学习策略\"><a href=\"#为什么需要机器学习策略\" class=\"headerlink\" title=\"为什么需要机器学习策略\"></a>为什么需要机器学习策略</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>当试图优化一个深度学习系统时，通常有很多想法可以尝试。如图，比如我们在做一个猫的分类器时，经过一段时间的工作，系统的准确率达到了90%。但对于应用程序来说，表现还不够好，我们可能有许多想法来改进这个系统，想法如图所示。</li>\n<li>如果做出了错误的选择，不仅耗费时间而且可能收效甚微。如盲目的选择收集更多数据，花费6个月时间收集数据，但最终对系统的改进很小。</li>\n<li>机器学习策略就是分析机器学习问题的方法，指引我们朝着最有希望的想法的方向去尝试。</li>\n</ul>","more":"<h3 id=\"正交化\"><a href=\"#正交化\" class=\"headerlink\" title=\"正交化\"></a>正交化</h3><p>学会诊断出限制系统性能的瓶颈在哪里，然后找到一组<strong>特定的旋钮(方法)</strong>，从而改善系统<strong>特定方面的性能</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图，以电视机屏幕调节为例，每个旋钮对应一个功能(如长度调整、宽度调整、梯度调整等)，每一旋钮解决特定问题，是正交的，可很好的调节电视机屏幕。</li>\n<li>如图，以驾驶汽车为例，方向盘、油门及刹车，这三种正交化的操作，可以很好的控制汽车。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%AD%A3%E4%BA%A4%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"></li>\n<li>要做好一个监督学习系统，需要调节系统的旋钮，去确保四件事情：</li>\n<li>1.使得代价函数很好地拟合训练集。<ul>\n<li>旋钮：更大的网络，使用Adam等优化算法。</li>\n</ul>\n</li>\n<li>2.使得代价函数很好地拟合开发集。<ul>\n<li>旋钮：正则化，采用更大的训练集。</li>\n<li>解释：在训练集上表现好，而开发集表现不好，则是在训练集上过拟合。</li>\n</ul>\n</li>\n<li>3.使得代价函数很好地拟合测试集。<ul>\n<li>旋钮：采用更大的开发集。</li>\n<li>解释：在开发集上表现好，而测试集表现不好，则是在开发集上过拟合。</li>\n</ul>\n</li>\n<li>4.在现实世界中取得好的表现。<ul>\n<li>旋钮：调整开发/测试集，使用新的代价函数。</li>\n<li>解释：在开发/测试集上表现好，在现实中表现不好，要么是开发/测试集设置有问题，要么是代价函数设置有问题。</li>\n</ul>\n</li>\n<li>概括来说，系统的每一旋钮只会针对性的解决一个问题，是正交的。</li>\n<li>此外，提前终止(early stopping)在模型功能调试中并不推荐使用。因为提前终止提升验证集性能的同时降低了训练集的性能。也就是说提前终止同时影响两件事情，不具有正交性。</li>\n</ul>\n<h2 id=\"1-2-设置你的目标\"><a href=\"#1-2-设置你的目标\" class=\"headerlink\" title=\"1.2 设置你的目标\"></a>1.2 设置你的目标</h2><h3 id=\"单一数字评价指标\"><a href=\"#单一数字评价指标\" class=\"headerlink\" title=\"单一数字评价指标\"></a>单一数字评价指标</h3><p>无论是在调节超参数，还是尝试不同的算法，设置一个单一数字评价指标，可以提高决策效率。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87_1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>之前讲过，应用机器学习是一个经验性的过程：想法-代码-实验，循环迭代。</li>\n<li>如图，对于分类器A和B，若采用两个评价指标：查准率(precision)和查全率(recall)时，将难以决策分类器A和B的好坏。</li>\n<li>此情况下，采用F1得分(F1 score)作为单一数字评价指标，则可快速选出最好的分类器。</li>\n<li>很多机器学习团队的做法：明确的开发集结合单一数字评价指标，可以加速上述迭代过程。</li>\n</ul>\n<p>注：</p>\n<ul>\n<li><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87.jpg\" width=\"50%\" height=\"50%\"></li>\n<li>查准率(precision)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%87%86%E7%8E%87.JPG\" width=\"80%\" height=\"50%\"><ul>\n<li>假设在是否为猫的分类问题中，查准率代表：所有模型预测为猫的图片中，确实为猫的概率。</li>\n</ul>\n</li>\n<li>查全率(recall)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%9F%A5%E5%85%A8%E7%8E%87.JPG\" width=\"80%\" height=\"50%\"><ul>\n<li>假设在是否为猫的分类问题中，查全率代表：所有真实为猫的图片中，预测正确的概率。</li>\n</ul>\n</li>\n<li>F1得分(F1 score)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/f1score.JPG\" width=\"30%\" height=\"30%\"><ul>\n<li>F1得分是查准率和查全率的调和平均。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8D%95%E4%B8%80%E6%95%B0%E5%AD%97%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>另一例，对于不同算法，以每一算法在不同地区表现的平均数作为单一数字评价指标，可以快速选出表现最好的算法。</li>\n</ul>\n<h3 id=\"满足和优化指标\"><a href=\"#满足和优化指标\" class=\"headerlink\" title=\"满足和优化指标\"></a>满足和优化指标</h3><p>有时候，要把所有的性能指标都综合在一起，组成单实数评价指标(single real number evaluation metric)是比较困难的。解决办法是，把某些性能作为<strong>优化指标(Optimizing metic)</strong>，寻求最优化值；而某些性能作为<strong>满意指标(Satisficing metic)</strong>，只要满足阈值就行了。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%BB%A1%E8%B6%B3%E5%92%8C%E4%BC%98%E5%8C%96%E6%8C%87%E6%A0%87.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>如图，分类器的性能：准确率和运行时间。若将准确率和运行时间组合成一个整体评价指标，如：<script type=\"math/tex\">cost=accuracy  -  0.5 \\cdot running\\ time</script></li>\n<li>可将准确率作为优化指标，将运行时间作为满意指标。即最大限度的提高准确率($maximize\\ accuracy$)，但算法必须满足运行时间的要求，即达到一定阈值即可(如$running \\ time \\leq 100ms$)。这是一个相对合理地权衡准确率和运行时间的方式。</li>\n<li>更一般地说，若有$N$个指标，有时将1个指标作为最优指标，其他$N-1$个作为满意指标。</li>\n</ul>\n<p>第二个例子：谷歌/亚马逊/百度的语音助手的唤醒/触发词，关心的指标有两个：</p>\n<ul>\n<li>一是对于触发词检测系统的准确率(说出触发词，有多大概率唤醒设备)。</li>\n<li>二是假阳性(false positive)的数量(没有说出触发词，设备被随机唤醒的概率)。</li>\n<li>组合这两种评估指标的合理方式是：准确率作为优化指标，最大化准确率。假阳性数量作为满意指标，小于一定阈值即可，如24小时之内少于1次。</li>\n</ul>\n<h3 id=\"训练-开发-测试集划分\"><a href=\"#训练-开发-测试集划分\" class=\"headerlink\" title=\"训练/开发/测试集划分\"></a>训练/开发/测试集划分</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%92%E5%88%863.JPG\" width=\"80%\" height=\"80%\">  开发/测试集划分准则：</p>\n<ul>\n<li>首先，<strong>开发集和测试集需要来自同一分布</strong>。</li>\n<li>然后，选择这样的开发集和测试集：<strong>能够反映未来会得到的数据，并且你认为是很重要的，必须得到好结果的数据</strong>。</li>\n<li><strong>设立开发集以及评价指标，就等同于定义了你要瞄准的目标。测试集和开发集属于同一分布，相当于瞄准的是同一目标(靶心)，否则相当于设置了另一个目标(靶心)。而训练集的设置，影响的是逼近这个目标有多快</strong>。</li>\n</ul>\n<h3 id=\"开发集和测试集的大小\"><a href=\"#开发集和测试集的大小\" class=\"headerlink\" title=\"开发集和测试集的大小\"></a>开发集和测试集的大小</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F2.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BC%80%E5%8F%91%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%A4%A7%E5%B0%8F3.JPG\" width=\"80%\" height=\"80%\"><br>旧的划分数据的方式：</p>\n<ul>\n<li>当没有测试集时：训练集分70%，开发集分30%。</li>\n<li>当有开发集时：训练集分60%，开发集分20%，测试集分20%。</li>\n<li>此划分方法适用于机器学习早期，即适用于数据量小的情况(如100，1000，10000个样本)。</li>\n</ul>\n<p>现代机器学习划分数据的方式（有着非常大的数据集，如有一百万个样本）：</p>\n<ul>\n<li>训练集分98%，开发集分1%，测试集分1%。</li>\n<li>开发集和测试集各有10000个例子，足够了。</li>\n<li>深度学习算法对数据的胃口很大，给训练集划分更多的数据，去喂饱模型。</li>\n</ul>\n<p>开发集的大小设置准则：</p>\n<ul>\n<li>令开发集足够大，能够检测不同算法/模型的区别，选择出更好的算法/模型即可。</li>\n</ul>\n<p>测试集的大小设置准则：</p>\n<ul>\n<li>令测试集足够大，能够以高置信度评价系统的整体性能即可。</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>虽然不建议这样做，但如果不需要给出对算法/模型的无偏估计，那不设置测试集，只划分训练/开发集也是可以的。</li>\n</ul>\n<h3 id=\"什么时候改变开发-测试集和评价指标\"><a href=\"#什么时候改变开发-测试集和评价指标\" class=\"headerlink\" title=\"什么时候改变开发/测试集和评价指标\"></a>什么时候改变开发/测试集和评价指标</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%871.JPG\" width=\"80%\" height=\"80%\"> 如果当前的评价指标无法给出更好算法的正确排名，那就需要花时间定义一个新的评价指标：</p>\n<ul>\n<li>如图所示，目前的评价指标是错误率。</li>\n<li>虽然算法A的错误率低于算法B的错误率，但算法A会将色情图片分类为猫的图片。这时若将色情图片当作猫的图片推送给用户，那这是极其糟糕的错误。因此，算法A虽然错误率低，但其实是一个很糟糕的算法，相比而言，算法B应该更好。</li>\n<li>因此，当前的评价指标错误率，无法给出更好算法的正确排名，应重新定义一个新的评价指标。</li>\n<li>如定义新的评价指标为<script type=\"math/tex\">Error: \\frac{1}{\\sum_{i=1}^{m_{dev}} w^{(i)}}\\sum_{i=1}^{m_{dev}} w^{(i)}1\\{\\hat y^{(i)} \\neq y^{(i)}\\}</script></li>\n<li>其中，<script type=\"math/tex\">w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}</script></li>\n<li>注：使用此种加权函数的方式，需手动遍历开发集和测试集，将色情图片标注出来。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%872.JPG\" width=\"80%\" height=\"80%\"> 上一课件中，处理猫类图片反色情问题的方式，实际上是正交化一种体现：</p>\n<ul>\n<li>第一步，只讨论了如何去定义一个评价分类器的指标。这相当于设定一个目标(靶心)。</li>\n<li>第二步，单独去考虑如何提升系统在这个指标上的表现。这相当于如何瞄准/命中这个目标(靶心)。</li>\n<li>对于第二步，为了提高系统在新的评价指标上的评分，如修改神经网络需优化的代价函数为：<script type=\"math/tex\">J=\\frac{1}{\\sum_{i=1}^m w^{(i)}}\\sum_{i=1}^mw^{(i)}L(\\hat y^{(i)},y^{(i)})</script></li>\n<li>其中，<script type=\"math/tex\">w^{(i)}=\\begin{cases} 1, & x^{(i)}\\ is\\ non-porn\\\\ 10, & x^{(i)}\\ is\\ porn \\end{cases}</script></li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%8F%98%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%873.JPG\" width=\"80%\" height=\"80%\"> 如图，另一例：</p>\n<ul>\n<li>开发/测试集是专业且正规的猫的图片，实际应用中用户上传的图片是随意且模糊的。</li>\n<li>当在评价指标和开发/测试集上做的很好，但在实际应用中做的不好时，应该改变评价指标以及开发/测试集。</li>\n<li>可以看出，上图中的开发/测试集设置有误，没有反映出你的算法需要处理好的且在未来会遇到的数据。</li>\n</ul>\n<p>最后的建议：</p>\n<ul>\n<li>有一个评价指标和开发集，可以让你更快的做出决策，到底哪个算法更好，从而加快迭代速度。</li>\n<li>因此，即使无法定义出一个很完美的评价指标和开发集，直接快速设置出来，然后使用它们来驱动迭代速度。</li>\n<li>在这之后，如果发现它们不够好，马上做出改变。</li>\n</ul>\n<h2 id=\"1-3-相比于人类的表现\"><a href=\"#1-3-相比于人类的表现\" class=\"headerlink\" title=\"1.3 相比于人类的表现\"></a>1.3 相比于人类的表现</h2><h3 id=\"为什么是人类的表现\"><a href=\"#为什么是人类的表现\" class=\"headerlink\" title=\"为什么是人类的表现\"></a>为什么是人类的表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 在过去的几年里，许多机器团队一直在讨论如何比较机器学习系统和人类的表现：</p>\n<ul>\n<li>图中，机器学习系统以较快地速度接近人类表现，甚至超过它。</li>\n<li>超过人类表现之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，称之为贝叶斯最优误差(bayes optimal error)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 当机器学习系统的表现比人类的差时，有一些工具可以用来提高性能，而一旦超越了人类的表现，这些工具就不那么好用了：</p>\n<ul>\n<li>让人类帮助标注数据。<ul>\n<li>解释：这样就可以有更多的数据可以喂给模型。</li>\n</ul>\n</li>\n<li>通过人工错误分析。<ul>\n<li>解释：下周讲解。只要人类的表现比其他任何算法都要好，就可以让人类去查看算法做错的例子，并尝试了解为什么人能做对，算法做错。</li>\n</ul>\n</li>\n<li>进行更好的偏差/方差分析。<ul>\n<li>解释：下节讲解。</li>\n</ul>\n</li>\n<li>注：只要你的算法比人类的表现糟糕，上述三条策略可以改善算法，而一旦你的算法做的比人类好，上述三条策略就很难利用了。</li>\n</ul>\n<h3 id=\"可避免偏差\"><a href=\"#可避免偏差\" class=\"headerlink\" title=\"可避免偏差\"></a>可避免偏差</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%8F%AF%E9%81%BF%E5%85%8D%E5%81%8F%E5%B7%AE.JPG\" width=\"90%\" height=\"90%\"> 我们希望算法在训练集上表现好，但实际上不想算法在训练集上表现得太好。当知道人类的表现后，可以准确的告诉你算法在训练集上的表现到底该有多好。<br>如图中的猫分类器为例：</p>\n<ul>\n<li>在第二们课程里关于偏差和方差的讨论中，我们主要假设一些任务的贝叶斯误差几乎接近于0。</li>\n<li>在对于某些人类擅长的任务：如计算机视觉任务，人类水平误差虽高于贝叶斯误差(理论上限)，但可认为近似等于贝叶斯误差。</li>\n<li>在确定人类水平(近似贝叶斯误差)后，就定义了我们认为什么样的水平是可以实现的：<ul>\n<li><strong>将人类水平误差和训练误差之间的差值</strong>称为<strong>可避免偏差(avoidable bias)</strong>，或可避免偏差的度量。</li>\n<li><strong>将训练误差和开发集误差之间的差值</strong>称为<strong>方差</strong>，或方差的度量。</li>\n<li><strong>根据可避免偏差和方差的相对大小，决定专注于减少偏差的策略还是减少方差的策略</strong>。</li>\n<li>若将贝叶斯误差定为1%，而训练误差为8%，我们认为可以将它降低到1%，那么将专注于减小偏差；</li>\n<li>若将贝叶斯误差定为7.5%，而训练误差为8%，可避免误差为0.5%，没什么改进空间，不能再继续减少训练误差了，防止过拟合。而训练误差和开发集误差相差2%，那么将专注于减少方差。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"理解人类的表现\"><a href=\"#理解人类的表现\" class=\"headerlink\" title=\"理解人类的表现\"></a>理解人类的表现</h3><p>应该这样看待人来水平表现：人类的表现是贝叶斯误差的替代或估计。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图所示，应将人类水平定义为一个专家团队的表现，即错误率为0.5%。0.5%是贝叶斯误差的最佳估计。<ul>\n<li>解释：因为要将人类水平表现看作是贝叶斯误差的替代或近似，故选取表现最好的一组，所以此处便可认为：$Bayes\\ error \\leq 0.05%$</li>\n</ul>\n</li>\n<li>在上一节，通过人类水平表现来分析偏差和方差时，也是这样看待人类水平表现的，即作为贝叶斯误差的替代。</li>\n<li>在实际应用中，针对具体的应用情况，如果认为达到某个标准，就已经实用了，也可选用其他标准来作为人类水平表现。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E7%90%86%E8%A7%A3%E4%BA%BA%E7%B1%BB%E6%B0%B4%E5%B9%B3%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>在系统表现，未达到人类水平表现之前，不管如何定义人类水平表现(1%/0/7%/0.5%)，都不影响减小偏差策略还是减小方差策略的确定。<ul>\n<li>如图中左侧两例。</li>\n</ul>\n</li>\n<li>在系统接近人类表现之后，系统的提升变得很难，因为如果贝叶斯误差估计的不准确，将难以发现到底是方差问题还是偏差问题：<ul>\n<li>如上图最右侧，只有将贝叶斯误差定义为0.5%(一个专家团队的表现)，才能发现可避免偏差0.2%，方差0.1%，从而决定该采用减小偏差策略；</li>\n<li>若将贝叶斯误差定义为0.7%，则可避免偏差为0%，方差为0.1%，则会采用减小方差的策略。、</li>\n<li>当你只知道贝叶斯误差是单个医生的表现即1%时，你甚至无法知道该不该继续去拟合训练集。</li>\n<li>因此，当系统接近人类表现时，很难更进一步。因为很难准确的估计贝叶斯误差，难以确定是偏差还是方差问题。</li>\n</ul>\n</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>对于计算机视觉任务，比如猫识别问题，人类的表现近乎完美，所以贝叶斯误差也接近完美，那么将贝叶斯误差设为0，没什么问题。</li>\n<li>但如果数据有很大的噪声，对于背景很嘈杂的语音识别问题，有时几乎不可能听清说什么。对于这样的问题，更好的定义贝叶斯误差很重要，可以帮助我们更好的估计可避免误差和方差，这样才能更好的做出决策，选择减少偏差策略还是减少方差策略。</li>\n</ul>\n<h3 id=\"超越人的表现\"><a href=\"#超越人的表现\" class=\"headerlink\" title=\"超越人的表现\"></a>超越人的表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图左侧，当贝叶斯误差为0.5%，则可避免偏差为0.1%，方差为0.2%，则选择减小方差策略。</li>\n<li>如图右侧，当贝叶斯误差为0.5%，训练误差为0.3%，则不知道是训练误差过拟合了0.2%，还是贝叶斯误差实际上是0.1%/0.2%/0.3%，无法知道。此例中没有足够的信息，来判断应该选择减小偏差还是减小方差，这样取得进展的效率就会降低。</li>\n<li>在这个例子中，一旦超过了0.5%这个阈值，优化算法的方向便不那么明确了，因为现有的一些指明明确方向的工具失效了（但并不意味着不能继续提升，还是可以继续提升）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%B6%85%E8%B6%8A%E4%BA%BA%E7%B1%BB%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 图中列举出了显著超越人类水平表现的机器学习应用：</p>\n<ul>\n<li>首先是对于结构化数据：<ul>\n<li>在线广告（估计某个用户点击某个广告的可能性）</li>\n<li>产品推荐（推荐电影或书籍之类）</li>\n<li>物流预测(logistics)（预测运输时间）</li>\n<li>贷款批准</li>\n<li>原因：计算机擅长访问大量数据，识别出数据中的统计规律。</li>\n</ul>\n</li>\n<li>人类擅长自然感知(natural perception)任务，但也有一些机器学习应用超越了人类水平表现：<ul>\n<li>语音识别</li>\n<li>某些图像识别任务</li>\n<li>某些医疗方面任务，如阅读ECG、皮肤癌诊断、放射科读图任务</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"改善你的模型表现\"><a href=\"#改善你的模型表现\" class=\"headerlink\" title=\"改善你的模型表现\"></a>改善你的模型表现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 要让一个监督学习算法足够好，需要完成以下两件事：</p>\n<ul>\n<li>首先，很好的拟合训练集（即让可避免误差很低）。</li>\n<li>然后，在开发/测试集上的泛化很好（即让方差较低）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%94%B9%E5%96%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在正交化的精神下，有单独的旋钮，去处理偏差问题或方差问题：</p>\n<ul>\n<li>减少可避免偏差：<ul>\n<li>使用更大的模型</li>\n<li>训练更长的时间，或使用更好的优化算法(如Momentum,RMSprop,Adam)</li>\n<li>尝试其他的神经网络架构(如RNN，CNN，有时会有好的效果，不确定)，或进行超参数搜索</li>\n</ul>\n</li>\n<li>减少方差：<ul>\n<li>搜集更多训练数据（训练更多数据，可以帮助系统泛化到看不到的开发集）</li>\n<li>正则化(如L2正则化，Dropout，数据增强)</li>\n<li>尝试其他的神经网络架构或进行超参数搜索</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-机器学习策略-2\"><a href=\"#2-机器学习策略-2\" class=\"headerlink\" title=\"2.机器学习策略(2)\"></a>2.机器学习策略(2)</h1><h2 id=\"2-1-错误分析\"><a href=\"#2-1-错误分析\" class=\"headerlink\" title=\"2.1 错误分析\"></a>2.1 错误分析</h2><h3 id=\"进行错误分析\"><a href=\"#进行错误分析\" class=\"headerlink\" title=\"进行错误分析\"></a>进行错误分析</h3><p>如果你希望让学习算法胜任人类能做的任务，但你的学习算法还没有达到人类的表现。那么，<strong>人工检查算法所犯下的错误，可以让你了解接下来该做什么</strong>。这个过程称为<strong>错误分析(error analysis)</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%901.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设猫分类器在开发集上取得了90%的准确率，即10%的误差。</li>\n<li>注意到把一些狗分类成猫，问题是：是否需要开始做一个项目专门处理狗的问题？</li>\n<li>解决方法：错误分析：<ul>\n<li>首先，从开发集中找出约100个错误分类的样本。</li>\n<li>然后，人工统计出多少个是狗。</li>\n</ul>\n</li>\n<li>如果有5%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是9.5%(10%减少5%)的错误率。不值得专门花费大量时间。</li>\n<li>如果有50%的错误分类样本是狗，那么解决狗的问题后，算法的性能上限(ceiling)是5%(10%减少50%)的错误率。值得花费时间解决狗的问题。</li>\n<li>另外，尽管是人工统计，但检查100个开发集错误分类样本，只需要5-10分钟的时间，便可以给我们指出最有希望的方向。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%9B%E8%A1%8C%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%902.JPG\" width=\"80%\" height=\"80%\"> 并行评估多个想法：</p>\n<ul>\n<li>如图，针对如何改进猫的分类器，你有以下几个想法：狗的误分类问题，大型猫科动物的误分类问题，以及改善系统在模糊图片上的表现。</li>\n<li>进行错误分析：<ul>\n<li>首先，建立一个电子表格，每一列是你的一个想法，每一行是一个开发集上的误分类样本。此外，最后一栏记录你对每个误分类样本的注释。</li>\n<li>然后，人工统计从开发集选出的每一个误分类样本，记录在电子表格中。</li>\n<li>最后，统计出每一列(即每一个想法)所对应的误分类样本的比例，针对不同比例，确定改进猫分类器的方向。</li>\n<li>另外，当你在人工统计时，又有了新的想法，比如发现由于Instagram滤镜的问题经常导致误分类，则可将该想法作为新的一列加入电子表格中。</li>\n</ul>\n</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>进行错误分析：<ul>\n<li>首先应该从开发集找一组错误分类的例子。</li>\n<li>观察错误分类的例子（假阳性和假阴性），统计出属于不同错误类型的错误样本数量。</li>\n<li>在这个过程中，你可能会得到启发归纳出新的错误类型，那就在中途新建一个错误类型。</li>\n<li>最后，通过统计不同错误类型包含的样本的比例，决定哪个问题需要优先解决，或者给你构思新优化方向的灵感。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"清理错误标记的数据\"><a href=\"#清理错误标记的数据\" class=\"headerlink\" title=\"清理错误标记的数据\"></a>清理错误标记的数据</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE1.JPG\" width=\"80%\" height=\"80%\"> 首先，对于训练集中标记出错的样本：</p>\n<ul>\n<li>深度学习算法对训练集中的随机错误是相当鲁棒的：<ul>\n<li>只要标记出错的样本，是由于随机错误(即标记人员不小心标错)，不管也没问题，不用花费太多时间去修正它们，只要训练集足够大。</li>\n<li>但如果标记出错的样本，是由于系统性错误(如标记人员一直把白色的狗标记成猫)，分类器训练后，将会一直把白色的狗标记成猫。这种情况肯定需要修正。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE2.JPG\" width=\"80%\" height=\"80%\"> 然后，对于开发/测试集中标记出错的数据：</p>\n<ul>\n<li>若担心在开发/测试集上标记出错的例子带来的影响，建议在进行错误分析时，增加一列，记录标签出错的样本，然后统计其比例。</li>\n<li>若这些标记错误严重影响了你在开发集上评估算法的能力，那就需要花时间修正错误标记的数据，具体来说，通过查看三个数字：<ul>\n<li>整体开发集错误率</li>\n<li>由错误标记样本导致的错误率</li>\n<li>其他原因导致的错误率</li>\n<li>例1：如图左侧，整体开发集错误率为10%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为9.4%，修正错误标记样本是低优先级的方向。</li>\n<li>例2：如图右侧，整体开发集错误率为2%，由错误标记样本导致的错误率为0.6%，其他原因导致的错误率为1.4%，由错误标记样本导致的错误率占了整体开发集错误率的很大比重，值得花费时间去修正错误标记的数据。</li>\n<li>例3：开发集的目的是为了帮助你从分类器A和B中选择更好的一个。<br>算法A的整体开发集错误率为2.1%，算法B的整体开发集错误率为1.9%，而其中由错误标记样本导致的错误率为0.6%，无法再信任开发集，因为它无法正确告诉你分类器A是否真的比分类器B好。此情况必须去修正开发集里的错误标签了。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%B8%85%E7%90%86%E9%94%99%E8%AF%AF%E6%A0%87%E8%AE%B0%E7%9A%84%E6%95%B0%E6%8D%AE3.JPG\" width=\"80%\" height=\"80%\"> 如果决定要修正开发集数据里的错误标签(人工逐个检查并修正)，那么有一些指南：</p>\n<ul>\n<li>施加同样的处理手段给开发集和测试集，以保证它们依然来自同一分布。</li>\n<li>考虑同时检测算法判断正确和判断错误的例子。<ul>\n<li>不容易去做，因为如果算法准确率很高，如98%，那检查98%的数据的标签，要花费很长时间，所以通常不总是这么做，但也是需要考虑的。</li>\n</ul>\n</li>\n<li>训练集和开发/测试集有可能来自稍微不同的分布。<ul>\n<li>如果你决定修改开发/测试集(通常比训练集小很多)，而有可能不修改训练集(深度学习算法对随机错误很鲁棒且训练集很大，也不想花费大量时间去修正)，而这样是可以的。后面会进一步讲解。</li>\n</ul>\n</li>\n</ul>\n<p>最后的建议：</p>\n<ul>\n<li>在构建实际的系统时，通常需要更多的人工错误分析和更多的人类见解。</li>\n<li>有些深度学习研究员不愿意去亲自看这100或几百个例子，来统计错误数量，这是我(吴恩达)经常亲自去做的，可能花费十几分钟或几个小时，但可以帮我找到需要优先处理的任务。</li>\n</ul>\n<h3 id=\"快速构建你的第一个系统，然后迭代\"><a href=\"#快速构建你的第一个系统，然后迭代\" class=\"headerlink\" title=\"快速构建你的第一个系统，然后迭代\"></a>快速构建你的第一个系统，然后迭代</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%84%B6%E5%90%8E%E8%BF%AD%E4%BB%A3.JPG\" width=\"80%\" height=\"80%\"> 如图，如果要建立一个新的语音识别系统，你可以走很多方向或有很多可以优先考虑的事情，来改善语音识别系统，如图所示。</p>\n<ul>\n<li>建议：如果你正在开发新的机器学习应用，那么应该快速建立你的第一个系统，然后迭代：<ul>\n<li>快速设立开发/测试集以及评价指标 </li>\n<li>快速构建初始的系统</li>\n<li>使用偏差/方差分析以及错误分析去确定下一步优先做什么</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>如果你在这个应用领域有很多经验，这个建议的适用程度要低一些。或当这个领域有很多可以借鉴的学术文献和你要处理扽问题几乎完全相同，这个建议的适用程度也要低一些。例如，在人脸识别领域就有很多学术文献，如果你尝试建立一个人脸识别器，那么就可以从现有的大量学术文献作为基础出发，一开始就建立比较复杂的系统。</li>\n<li>但如果你第一次处理某个新问题，还是遵循以上建议。</li>\n</ul>\n<h2 id=\"2-2-不匹配的训练集和验证-测试集\"><a href=\"#2-2-不匹配的训练集和验证-测试集\" class=\"headerlink\" title=\"2.2 不匹配的训练集和验证/测试集\"></a>2.2 不匹配的训练集和验证/测试集</h2><h3 id=\"在不同分布上进行训练和测试\"><a href=\"#在不同分布上进行训练和测试\" class=\"headerlink\" title=\"在不同分布上进行训练和测试\"></a>在不同分布上进行训练和测试</h3><p>深度学习算法对训练数据的胃口很大，当你收集到足够多的带标签的数据构成训练集时，算法效果最好。这导致很多团队用尽一切办法收集数据，然后把它们放进训练集中，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集及测试集不同的分布。在深度学习时代，越来越多的团队，都用来自和开发集及测试集不同分布的数据来训练。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%951.JPG\" width=\"50%\" height=\"50%\"> </p>\n<ul>\n<li>假设你在开发一个手机应用，有两个数据来源：一个是你真正关心的数据分居，来自应用上传的数据。 <ul>\n<li>一个是你真正关心的数据分居，来自应用上传的数据。如图右侧，或随意或模糊。约10,000张。</li>\n<li>另一个数据源是通过爬虫，从网页中下载的数据。如图左侧，专业且高分辨率。约200,000张。</li>\n</ul>\n</li>\n<li>你真正关心的是：你的最终系统处理来自应用程序的图片分布时，效果好不好。</li>\n<li>选项1：如图，将两组数据组合在一起，共210,000张，然后随机分配到训练集、开发集和测试集中，训练集占205,000张，开发/测试集个占2,500张：<ul>\n<li>好处：训练集和开发集及测试集来自同一分布，这样更易于管理。</li>\n<li>巨大的坏处：开发/测试集中有大量数据($200k/210k*2500 \\approx 2381$)来自网页下载，不是你真正关心的数据分布。只有约119张来自用户手机上传。</li>\n<li>设置开发集的目的是告诉团队瞄准的目标(靶心)。此做法相当设置了错误的目标。不建议使用该做法。</li>\n</ul>\n</li>\n<li><strong>选项2</strong>：如图，<strong>训练集由网页下载的200,000张图片加上用户手机上传的5000张图片，共205,000张。开发集和测试集都是手机上传图片，各2,500张</strong>。<ul>\n<li>好处：<strong>开发集和测试集都是用户手机上传的照片，是你真正关心的数据分布</strong>。现在你瞄准的目标就是你想要处理的目标。</li>\n<li>坏处：<strong>训练集和开发/测试集的分布不一样</strong>，<strong>但事实证明，这样分配数据集，在长期能给你带来更好的系统性能</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%9C%A8%E4%B8%8D%E5%90%8C%E5%88%86%E5%B8%83%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E6%88%96%E6%B5%8B%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 如图，以语音激活后视镜应用为例：：</p>\n<ul>\n<li>有两个数据来源：<ul>\n<li>一个是从其他语音识别应用中收集到的数据。约500,000条。</li>\n<li>一个是语音激活后视镜的数据(用户要查询导航信息，可能包含更多街道地址)。约20,000条。</li>\n</ul>\n</li>\n<li>设置训练集、开发集和测试集，如图：<ul>\n<li>训练集包含其他语音识别应用中的500k条语音，开发/测试集各包含10k条语音激活后视镜的语音。</li>\n<li>或训练集包含其他语音识别应用中的500k条语音加上语音激活后视镜的语音的10k条语音，开发/测试集各包含5k条语音激活后视镜的语音。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"不匹配的数据分布的偏差和方差\"><a href=\"#不匹配的数据分布的偏差和方差\" class=\"headerlink\" title=\"不匹配的数据分布的偏差和方差\"></a>不匹配的数据分布的偏差和方差</h3><p>估计学习算法的偏差和方差，可以帮助你确定接下来优先该进行的方向。但是<strong>当你的训练集和开发/测试集来自不同分布时，分析偏差和方差的方法需要改变</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 以猫分类器为例：</p>\n<ul>\n<li>人类的表现几乎完美，所以贝叶斯误差几乎为0%。</li>\n<li>训练集误差为1%，开发集误差为10%。</li>\n<li><strong>若训练集和开发集来自同一分布，在这种情况下，可以说存在很大的方差问题</strong>。</li>\n<li><strong>但如果训练集和开发集不是来自同一分布，那就无法确定地下结论</strong>。也许分类器已经在开发集上做的很好，因为训练集中都是专业且高分辨率的图片，很容易进行分类，而开发集中是难以精确分类的图片。即有可能分类器不存在方差问题。</li>\n<li>问题在于：从训练误差到开发集误差，改变了两件事情：第一，算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。因为同时改变了两件事，<strong>无法确定导致训练误差和开发集误差的差值9%的原因，有多少是由于没见过开发集导致，即方差问题。有多少是由于开发集来自不同分布</strong>。</li>\n<li>解决方法：<strong>划分出训练-开发集(training-dev set)</strong>。<ul>\n<li>训练-开发集：与训练集同分布，但不用于训练。</li>\n<li>具体划分示意，如图所示。</li>\n</ul>\n</li>\n<li>接来下，分析四个指标：<strong>人类水平表现(贝叶斯误差)、训练集误差、训练-开发集误差和开发集误差</strong>。</li>\n<li><p>例1：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为9%，开发集误差为10%。</p>\n<ul>\n<li>贝叶斯误差和训练集误差之间的差值为可避免偏差，值为1%。训练集误差和训练-开发集的误差的差值为方差，值为8%。训练-开发集误差和开发集误差之间的差值为数据不匹配，值为1%。</li>\n<li>因此，存在方差问题。</li>\n</ul>\n</li>\n<li><p>例2：贝叶斯误差为0%，训练集误差1%，训练-开发集误差为1.5%，开发集误差为10%。</p>\n<ul>\n<li>可避免偏差为1%，方差为0.5%，数据不匹配为8.5%。</li>\n<li>因此，存在数据不匹配问题。</li>\n</ul>\n</li>\n<li><p>例3：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为12%。</p>\n<ul>\n<li>可避免偏差为10%，方差为1%，数据不匹配为1%。</li>\n<li>因此，存在偏差问题。</li>\n</ul>\n</li>\n<li><p>例4：贝叶斯误差为0%，训练集误差10%，训练-开发集误差为11%，开发集误差为20%。</p>\n<ul>\n<li>可避免偏差为10%，方差为1%，数据不匹配为9%。</li>\n<li>因此，存在偏差问题和数据不匹配问题。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"100%\" height=\"100%\"> <strong>总结训练集和开发/测试集来自不同分布时，分析偏差和方差问题的方法</strong>：</p>\n<ul>\n<li>贝叶斯误差和训练集误差之间的差值为<strong>可避免偏差</strong>，或可避免误差的度量。</li>\n<li>训练集误差和训练-开发集的误差的差值为<strong>方差</strong>，或方差的度量。</li>\n<li>训练-开发集误差和开发集误差之间的差值为<strong>数据不匹配</strong>，或数据不匹配的度量。</li>\n<li>开发集误差和测试集误差之间的差值为<strong>对开发集的过拟合程度</strong>，或对开发集的过拟合程度的度量。</li>\n<li>举例一个特殊的例子：<ul>\n<li>贝叶斯误差为4%，训练集误差7%，训练-开发集误差为10%，开发集误差为6%，测试集误差为6%。</li>\n<li>这种情况是合理的，说明训练集的难度比开发/测试集的难度要高很多。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%B8%8D%E5%8C%B9%E9%85%8D%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"90%\" height=\"90%\"> 以语音激活后视镜为例：</p>\n<ul>\n<li>第一列为其他通用语音应用中的数据，第二列为语音激活后视镜的数据。</li>\n<li>只不过强调了：<ul>\n<li>算法只在训练集上训练过，而训练-开发集，开发/测试集，算法都没有训练过。</li>\n<li>训练集和训练-开发集来自同一分布(通用语音应用中的数据)。开发/测试集来自另一分布(语音激活后视镜的数据)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"处理数据不匹配\"><a href=\"#处理数据不匹配\" class=\"headerlink\" title=\"处理数据不匹配\"></a>处理数据不匹配</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D1.JPG\" width=\"100%\" height=\"100%\"> <strong>如果发现有严重的数据不匹配问题</strong>：</p>\n<ul>\n<li>进行人工错误分析，去尝试理解训练集和开发/测试集的区别。<ul>\n<li>如在语音激活后视镜应用中：进行错误分析后，发现开发集中以汽车噪音为背景的语音片段误判很多。或很多请求街道号码的语音片段误判很多。</li>\n</ul>\n</li>\n<li>让训练集更像开发集，收集更多类似开发/测试集的数据。<ul>\n<li>如可以模拟车辆背景噪声数据，或刻意的收集人类说数字的音频数据，然后添加进训练集。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D2.JPG\" width=\"100%\" height=\"100%\"> 人工数据合成：</p>\n<ul>\n<li>例子如图：将人类说话的音频和汽车噪声的音频进行人工合成，合成为车内说话的音频数据。</li>\n<li>人工数据合成可以快速制造出更多的训练数据。但要注意，人工数据合成存在一个潜在问题：<ul>\n<li>假设你录制了10,000个小时的安静背景下的音频数据，录制了1个小时的汽车噪音数据，然后将汽车噪音重复播放10,000次叠加到安静背景下的音频数据。人类听起来，这些合成的音频数据没问题。但学习算法会对这1小时的汽车噪音过拟合。你收集得到的1小时汽车噪音背景下的音频数据只是所有存在的汽车噪音的一个很小的子集，从整个空间的很小的一个子集出发，去合成数据，神经网络可能最后会对这1个小时的汽车噪音过拟合。</li>\n<li>更好的做法是收集10,000个小时的汽车噪音，而不是重复播放1小时的汽车噪音10,000次。在不考虑成本的情况下，这种做法会使得学习算法取得更好的性能。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8C%B9%E9%85%8D3.JPG\" width=\"90%\" height=\"90%\"> 人工数据合成的另一例：</p>\n<ul>\n<li>若对于汽车检测任务，用人工数据合成时，如果只是基于20种车的人工数据合成。20辆车只是所有可能出现的车辆的很小的子集。人眼看不出来，神经网络可能对这20种车过拟合。</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>如果你认为存在数据不匹配问题，建议进行错误分析，查看训练集和开发集，尝试了解这个两个数据分布到底有什么不同，然后看看是否有办法收集更多像开发集的训练数据进行训练。</li>\n<li>其中一种办法是人工数据合成，人工数据合成确实有效，在语音识别系统中，已经看到人工数据合成显著提升了已经非常好的语音识别系统的表现。但当你使用人工数据合成时，一定要谨慎，要记住你有可能只是从所有可能性的空间选择了很小的一部分去模拟数据。</li>\n</ul>\n<h2 id=\"2-3-从多个任务中学习\"><a href=\"#2-3-从多个任务中学习\" class=\"headerlink\" title=\"2.3 从多个任务中学习\"></a>2.3 从多个任务中学习</h2><h3 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h3><p>深度学习中最强大的理念之一就是有时候神经网络可以从一个任务中学习到知识，并将这些知识应用到另一个独立的任务中。例如，你已经训练好一个可以识别猫的神经网络，然后可以用这些已学到的知识或部分知识去帮助你更好地阅读X射线扫描图。这就是所谓的<strong>迁移学习</strong>。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 迁移学习举例：</p>\n<ul>\n<li>例1：已经训练好一个图像识别的神经网络，然后将图像识别中学习到的知识应用/迁移到放射诊断任务中：<ul>\n<li>删去原神经网络中的最后一层及其权重，新建最后一层神经网络并随机初始化权重，即$W^{[l]}$，$b^{[l]}$ 。</li>\n<li>在新的放射诊断数据集上训练神经网络。如果放射诊断数据集较小，就只训练新的最后一层网络的参数$W^{[l]}$，$b^{[l]}$并保持原网络其他参数不变。如果放射诊断数据集很大，可以重新训练网络中的所有参数(以之前网络训练好的参数作为初始参数)。</li>\n<li>如果选择重新训练网络中的所有参数，那么图像识别任务的训练阶段称为<strong>预训练(pre-training)</strong>。然后在放射诊断数据上重新训练参数的过程，称为<strong>微调(fine tuning)</strong>。</li>\n</ul>\n</li>\n<li>有效的原因：在图像识别任务中，很多低层次的特征，比如边缘检测、曲线检测等结构信息知识，可能帮助放射诊断任务。</li>\n<li>例2：已经训练好一个语音识别的神经网络，然后迁移到唤醒/触发词检测系统中：<ul>\n<li>删去原神经网络的最后一层，在末端建立新的几层。</li>\n<li>若唤醒/触发词检测的数据量较小，则在唤醒/触发词检测数据集中，只训练新建的几层。若唤醒/触发词检测的数据量较大，可重新训练神经网络的所有参数。</li>\n<li>在语音识别任务中，预先学到的很多人类声音的特征，人类语言的组成部分等知识，可以帮助你建立一个很好的唤醒词检测器。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"> 什么时候迁移学习是有意义的：</p>\n<ul>\n<li>任务A和任务B有一样的输入x。<ul>\n<li>在上节的例1中，任务A和任务B的输入都是图像。</li>\n<li>在上节的例2中，任务A和任务B的输入都是音频。</li>\n</ul>\n</li>\n<li>任务A拥有的数据量要比任务B大得多。<ul>\n<li>在上节的例1中，任务A中图像识别有着大量的数据集，如1000,000张。而任务B中放射诊断数据集图像只有100张。</li>\n<li>在上节的例2中，任务A中语音识别数据集中有10,000小时的音频。而任务B唤醒词检测任务中只有1小时的音频。</li>\n</ul>\n</li>\n<li>任务A中的低层次特征可以帮助任务B的学习。</li>\n</ul>\n<h3 id=\"多任务学习\"><a href=\"#多任务学习\" class=\"headerlink\" title=\"多任务学习\"></a>多任务学习</h3><p>在迁移学习中，你的步骤是串行的：先从任务A中学习，然后迁移到任务B。在多任务学习中，你是同时开始学习的，试图让神经网络同时做几件事情，然后希望这里的每个任务都能帮助到其他所有任务。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以开发无人驾驶汽车为例：</p>\n<ul>\n<li>无人驾驶汽车需要同时检测不同的物体，如行人、车辆、停车标志及交通灯。</li>\n<li>此时输入为图像$x^{(i)}$,输出$y^{(i)}$为：<script type=\"math/tex\">y^{(i)}= \\left[ \\begin{matrix} 0\\\\ 1\\\\ 1\\\\ 0 \\end{matrix} \\right]</script></li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 神经网络结构，如图：</p>\n<ul>\n<li>神经网络的最后一层有四个结点，分别代表是否存在行人、车辆、停车标志及交通灯。即$\\hat{y}$的维度为$(4,1)$</li>\n<li>代价函数为：<script type=\"math/tex\">\\frac1m\\sum_{i=1}^m\\sum_{j=1}^4L(\\hat y_j^{(i)},y_j^{(i)})</script><ul>\n<li>其中，$L(\\hat y_j^{(i)},y_j^{(i)})$是单个结点的损失，采用常用的逻辑损失，<script type=\"math/tex\">L(\\hat y_j^{(i)},y_j^{(i)})=-y_j^{(i)}log\\ \\hat y_j^{(i)}-(1-y_j^{(i)})log\\ (1-\\hat y_j^{(i)})</script></li>\n</ul>\n</li>\n<li>多任务学习<strong>与softmax回归的主要区别</strong>在于：softmax将单个标签分给单个样本。而多任务学习中，一张图片有多个(4个)标签（从代价函数中的形式中也可以看出来）。</li>\n<li>另外，多任务学习也可以用于处理图像中只有部分物体被标记的情况。<ul>\n<li>如某个样本只标记有行人和车辆，但没有标记是否有停车标志和交通灯，即样本标签形式为<script type=\"math/tex\">y^{(i)}= \\left[ \\begin{matrix} 1\\\\ 1\\\\ ?\\\\ ? \\end{matrix} \\right]</script></li>\n<li>即便是这样的数据集，你也可以上面训练算法同时做四个任务。在训练时，数据中缺失的标签所对应的结点，不参加代价函数的求和即可。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A03.JPG\" width=\"90%\" height=\"90%\"> 多任务学习什么时候有意义：</p>\n<ul>\n<li>如果你训练的一组任务可以公用低层次特征。</li>\n<li>如果每个任务的数据量很接近(这个准则没有那么绝对，并不一定是对的)。<ul>\n<li>例如，你有一百个任务，每个任务的数据集大小为1000，那么进行多任务学习，训练集大小将达100,000。</li>\n</ul>\n</li>\n<li>可以训练一个足够大的神经网络同时做好所有任务。<ul>\n<li>有研究表明：只要你可以训练一个足够大的神经网络进行多任务学习，几乎都比单独训练多个神经网络来单独完成各个任务的性能要好。</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>多任务学习能让你训练一个神经网络来同时进行多个任务，可以给你比单独完成各个任务更高的性能。</li>\n<li>多任务学习使用到的频率要比迁移学习使用到的频率低得多。<ul>\n<li>其中一个例外是计算机视觉中的目标检测。人们经常训练一个神经网络，同时检测许多不同的物体，这比训练单独的神经网络来检测物体要好。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-4-端到端的深度学习\"><a href=\"#2-4-端到端的深度学习\" class=\"headerlink\" title=\"2.4 端到端的深度学习\"></a>2.4 端到端的深度学习</h2><h3 id=\"什么是端到端的深度学习\"><a href=\"#什么是端到端的深度学习\" class=\"headerlink\" title=\"什么是端到端的深度学习\"></a>什么是端到端的深度学习</h3><p>深度学习中最令人兴奋最新发展之一就是端到端的深度学习的兴起。什么是端到端的深度学习，简而言之，以前有一些数据处理系统，它们需要多个阶段的处理。而端到端的深度学习就是将所有这些多个阶段用单个神经网络替代它。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> 以语音识别为例：</p>\n<ul>\n<li>输入$x$是一段音频(audio clip)，输出$y$是这段音频的听写文本(transcript)。</li>\n<li>传统上，语音识别需要很多阶段的处理，首先你会提取一些手工设计的音频特征(如MFCC)，通过机器学习算法在音频片段中找到音位(声音的基本单位)，然后将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本。</li>\n<li>端到端的深度学习是，训练一个巨大的神经网络，输入是音频，输出直接是听写文本。</li>\n<li><strong>端到端的深度学习的挑战之一是：需要大量数据才能让系统表现好</strong>。<ul>\n<li>若你只有3,000个小时的数据去训练语音识别系统，那么传统的流水线(pipeline)的效果很好。</li>\n<li>若你拥有非常大的数据集，如10,000小时甚至100,000小时的数据，那么端到端的学习方法就表现的很好了。</li>\n<li>如果你数据量适中，那么可以用折中的方法，如输入音频，然后让过特征提取，直接尝试从神经网络输出音位，然后其他阶段继续采用传统方法。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"100%\" height=\"100%\"> 以门禁人脸识别系统为例，如图：</p>\n<ul>\n<li>端到端的学习方法：将相机拍摄到的图片作为输入，然后直接学习图像$x$到人类身份$y$的函数映射。<ul>\n<li>但事实证明，这不是最好的方法，因为人可以从很多不同的方向接近门禁(即人类可能以不同大小出现在照片的不同位置)。在实际构建这些门禁系统时，不是将原始图片喂给神经网络，然后尝试去找出人类的身份。</li>\n</ul>\n</li>\n<li>迄今为止最好的做法，是一个多步方法。首先，找出照片中人脸的位置，检测到人脸后，然后放大人脸图像的那部分，并剪裁图像，使得人脸居中显示。然后，再将人脸图片喂给神经网络，让网络去学习或估计人类的身份。</li>\n<li>两步方法更好的原因：<ul>\n<li>你解决的两个问题，每个都更简单。</li>\n<li>两个子任务的训练数据都很多。对于任务1，人脸检测的数据很多，$x$是图片，$y$是人脸位置。对于任务2，人脸识别的数据也很多。<strong>相比之下，直接输入门禁系统拍摄照片$x$，输出人类身份$y$的数据集很少</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E4%BB%80%E4%B9%88%E6%98%AF%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03.JPG\" width=\"100%\" height=\"100%\"> </p>\n<ul>\n<li>以机器翻译(machine translation)为例：<ul>\n<li>传统上，机器翻译系统也有很复杂的流水线：英语，文本，文本分析等等。</li>\n<li>而如今，<strong>端到端的机器翻译表现的很好，因为可以收集大量的数据对$(x,y)$，即英文句子对用的法文翻译</strong>。</li>\n</ul>\n</li>\n<li>以孩子手部的$x$光线图片，来估计年龄：<ul>\n<li>非端到端的学习方法：输入图片，分割出每一块骨头，弄清每一块骨头的长度，然后查找儿童手中骨头的平均长度，然后用它来估计孩子的年龄。</li>\n<li>端到端：<strong>通过图片直接估计孩子的年龄。那么需要大量数据去训练，在今天，还没有足够数据</strong>。</li>\n</ul>\n</li>\n</ul>\n<p>最后的总结：</p>\n<ul>\n<li>端到端学习是可行的，它可以表现得非常好，并简化系统，让你不需要构建那么多的手工设计的单独部件。</li>\n<li>但它也不是万能之计，并不是在所有任务中都有效。</li>\n</ul>\n<h3 id=\"是否使用端到端的深度学习\"><a href=\"#是否使用端到端的深度学习\" class=\"headerlink\" title=\"是否使用端到端的深度学习\"></a>是否使用端到端的深度学习</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01.JPG\" width=\"100%\" height=\"100%\"> <strong>端到端的深度学习的优缺点</strong>：<br>优点：</p>\n<ul>\n<li>让数据说话。<ul>\n<li>解释：如果有足够多的数据$(x,y)$，那么不管从$x$到$y$的最合适的函数映射是什么，一个足够大的神经网络能自己找到。而不是在如语音识别中，强制算法以“音位“为单位思考，也许让算法自己从大量数据中洞察到更好的表示方法更好。</li>\n</ul>\n</li>\n<li>需要更少的手工设计组件。<ul>\n<li>解释：简化系统，节省时间。</li>\n</ul>\n</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>需要大量的数据$(x,y)$。</li>\n<li>排除了潜在的有用的手工设计的组件。<ul>\n<li>解释：<strong>学习算法有两个主要的知识来源，一是数据，二是手工设计的组件或特征</strong>。当有大量数据时，手工设计的东西就不太重要了。但<strong>当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的最好途径</strong>。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B3/%E6%98%AF%E5%90%A6%E4%BD%BF%E7%94%A8%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02.JPG\" width=\"90%\" height=\"90%\"><br>如果你在构建一个新的机器学习系统，而你在尝试决定是否使用端到端的深度学习，那么问题的关键是：<strong>你有足够的数据能够直接学习到从$x$映射到$y$的足够复杂的函数吗？</strong></p>\n<ul>\n<li>如果输入手的$x$射线图片，分割出骨头位置，不需要太多的数据就可以完成这个任务。</li>\n<li>如果输入人的图片，检测出人脸的位置，不需要太多的数据就可以完成这个任务。</li>\n<li>但如果输入手的$x$射线图片，直接估计出孩子的年龄，这种复杂的映射函数，就需要大量的数据。</li>\n</ul>\n<p>如图下半部分，以无人驾驶汽车为例：</p>\n<ul>\n<li>需要完成的任务：输入雷达图片，检测车辆和行人，规划路线，控制方向盘/油门/刹车。</li>\n<li>解决方法：用深度学习方法进行检测车辆和行人；用运动规划(motion planning)软件解决路径规划；用控制算法决定如何控制方向盘/油门/刹车。</li>\n<li>这个例子表明了：<ul>\n<li>你想用机器学习或深度学习来学习一些单独的组件。</li>\n<li>当你用监督学习时，应该仔细地选择你想要学习的$x$到$y$的映射，取决于哪些任务你可以收集到数据。</li>\n</ul>\n</li>\n<li>相比之下，若考虑使用端到端的深度学习：即输入图像$x$，直接得出方向盘角度等。<ul>\n<li>就目前能收集到的数据以及目前神经网络可以学习到的事物类型而言，这实际上不是最有前景的方向。这种纯粹的端到端的学习方法，其前景不如上述分步进行的方法。</li>\n</ul>\n</li>\n</ul>"},{"title":"计算机网络笔记","mathjax":true,"date":"2017-12-28T07:49:50.000Z","_content":"# 1.计算机网络体系结构\n- **协议**：协议是控制两个对等实体（或多个实体）进行通信的规则的集合。网络协议主要由以下三要素组成：语法、语义、同步。\n- **网络体系结构**：网络体系结构是计算机网络的分层、每层的功能以及每层使用到的协议的集合。\n\n<!-- more --> \n\n## 1.1 计算机网络体系结构\n\n- 国际标准化组织（ISO）提出**开放系统互连参考模型OSI/RM**(Open System Interconnection Reference Model)。OSI是一个七层协议体系结构，如图1(a)。\n- 美国国防部提出**TCP/IP体系结构**，TCP/IP是一个四层的体系结构，如图1(b)。\n- OSI的七层体系结构的理论完整，但即复杂又不实用。TCP/IP是事实上的国际标准。\n- 从实质上讲，TCP/IP只有最上面的三层，因为最下面的网络接口层并没有什么具体内容。因此在学习计算机网络的原理时，采用折中的办法，即综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，如图1(c)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"70%\">\n\n## 1.2 各层的主要功能\n（1）**应用层**(application layer)\n\n- 功能：应用层是体系结构中的最高层。应用层的任务是**通过应用进程间的交互来完成特定网络应用**。这里的**进程**就是指**主机中正在运行的程序**。\n- 协议：应用层协议定义的是**应用进程间通信和交互的规则**。对于不同的网络应用需要有不同的应用层协议。应用层协议有：域名系统DNS，支持万维网应用的**HTTP**协议，支持电子邮件的**SMTP**协议，支持文件传送的**FTP**协议等。我们把应用层交互的数据单元成为**报文**(message)。\n\n（2）**运输层**(transport layer)\n\n- 功能：运输层的任务就是负责向**两个主机中进程之间的通信**提供**通用的数据传输**服务。应用进程利用该服务传送应用层报文。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付给上面应用层中的相应的进程。\n- 协议：运输层主要使用两种协议：1.**传输控制协议TCP**——提供面向连接的、可靠的数据服务，数据传输的单位是**报文段**(segment)；2.**用户数据包协议UDP**——提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是**用户数据报**。\n- 重要设备：网关(gateway)。\n\n（3）**网络层**(network layer)\n\n- 功能：（1）网络层负责为分组交换网上的不同**主机**提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成**分组**或**包**进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫做**IP数据报**或简称**数据报**；\n注：无论在哪一层传送的数据单元，都可笼统地用**“分组”**来表示\n（2）网络层的另一个任务是选择合适的路由，使源主机运输层传下来的分组，能够通过网络中的路由器找到目的主机。\n- 协议：（1）互联网是大量的**异构**网络通过**路由器**相互连接起来的。互联网使用的网络协议是无连接的**网际协议IP**(Internet Protocol)和许多种路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**；（2）与IP协议配套使用的还有三个协议：地址解析协议ARP、网际控制报文协议ICMP和网际组管理协议IGMP；（3）路由选择协议。\n- 重要的设备：路由器(router)。\n\n（4）**数据链路层**(data link layer)\n\n- 功能：两台主机之间的数据传输，总是在一段一段的**链路**上传送的，也就是说，在两个相邻结点之间（主机和路由器之间或两个路由器之间）传送数据是直接传送的（点对点）。数据链路层把网络层交下来的IP数据报（或数据报/分组/包）**封装成帧**(framing)发送到链路上，在两个相邻结点间的链路上传送**帧**(frame)，以及把接受到的帧中的数据取出并上交给网络层。\n- 重要设备：网桥(bridge)、交换机（多接口的网桥）。\n\n（5）**物理层**(physical layer)\n\n- 功能：在物理层上所数据的单位是**比特**。物理层的任务就是**透明地传送比特流**。也就是说，发送方发送1(或0)时，接收方应当收到1(或0)而不是0(或1)。因此物理层要考虑用多大的电压代表\"1\"或\"0\"，以及接收方如何识别出发送方所发送的比特，物理层还要确定连接电缆的插头应当有多少根引脚以及各条引脚应如何连接。注意，传递信息所利用的一些物理媒体/传输媒体，如双绞线、同轴电缆、光缆、无线信道等，并不在物理层协议之内而是在物理层协议的下面，有人把物理媒体称为第0层。\n综上，物理层的作用正视要经可能的屏蔽掉传输媒体和通信手段的差异，是物理层之上的数据链路层感觉不到这些差异，使数据链路层只需要考虑如何完成本层的协议和服务。\n- 中间设备：转发器(repeater)\n\n## 1.3 数据在各层之间的传递过程\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE2_%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%90%84%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E9%80%92%E8%BF%87%E7%A8%8B.JPG\" width=\"80%\" height=\"80%\">\n\n- 假定主机1的应用进程$AP_1$向主机2的应用进程$AP_2$传送数据。\n- $AP_1$先将其数据交给本主机的第5层(应用层)。第5层加上必要的控制信息$H_5$就变成了下一层的数据单元。第4层(运输层)收到这个数据单元后，加上本层的控制信息$H_4$，再交给第3层(网络层)，成为第3层的数据单元。依此类推。不过到了第2层(数据链路层)后，控制信息被分成两部分，分别加到本层数据单元的首部($H_2$)和尾部($T_2$)；而第1层(物理层)由于是比特流的传送，所以不再加上控制信息。\n- 当这一串的比特流离开主机1经网络的物理媒体传送到路由器时，就从路由器的第一层一次上升到第三层。每一层都根据控制信息进行必要的操作，然后将控制信息剥去，将该层剩下的数据单元交给更高的一层。当分组上升到第3层时，就根据首部中的目的地址查找路由器中的转发表，找到转发分组的接口，然后往下传送到第2层，加上新的首部和尾部，再到最下面的第1层，然后在物理媒体上把每一个比特发送出去。\n- 当这一串的比特流离开路由器到达目的主机2时，就从主机2的第1层按照上面讲过的方式，一次上升到第5层。最后，把应用进程$AP_1$发送的数据交给目的站的应用进程$AP_2$。\n- 对于用户来说，这个复杂的过程被屏蔽了，以至于感觉应用进程$AP_1$是直接把数据交给了应用进程$AP_2$。同理，任何两个同样的层次（例如两个系统的第4层）之间，也好像如同图2中的水平虚线所示的那样，把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层“之间的通信。之前提到的各层协议，实际上就是在各个对等层之间传递数据时的各项规定。\n\n## 1.4 TCP/IP体系结构\n前面已经说过，TCP/IP的体系结构比较简单，它只有四层。图3给出了用这四层协议表示方法的例子。注意，图中的路由器在转发分组时最高只用到网络层而没有使用运输层和应用层。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE3_TCPIP%E5%9B%9B%E5%B1%82%E5%8D%8F%E8%AE%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n\n还有一种方法，就是分层次画出具体的协议来表示TCP/IP协议族，如图4。它的特点是上下两头大而中间小：应用层和网络接口层都有多种协议，而中间的IP层很小，上层的各种协议都向下汇聚到一个IP协议中。这种像沙漏计时器形状的TCP/IP协议族表明：TCP/IP协议**可以为各式各样的应用提供服务**（所谓的everying over IP），同时TCP/IP协议也**允许IP协议在各式各样的网络构成的互联网上运行**（所谓的 IP over everything）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE4_%E6%B2%99%E6%BC%8F%E8%AE%A1%E6%97%B6%E5%99%A8%E5%BD%A2%E7%8A%B6%E7%9A%84TCP-IP%E5%8D%8F%E8%AE%AE%E6%97%8F.JPG\" width=\"70%\" height=\"70%\">\n\n# 2.网络层\n## 2.1网际协议IP\n互联网由多种异构网络互连而成，参加互联的计算机网络都使用相同的网际协议IP，因此实现互联。\n网际协议IP是TCP/IP体系中两个最重要的协议之一。与IP协议配套使用的还有三个协议：\n\n- 地址解析协议ARP \n- 网际控制报文协议ICMP\n- 网际组管理协议IGMP\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE-%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE%E9%85%8D%E5%A5%97%E5%8D%8F%E8%AE%AE.JPG\" width=\"40%\" height=\"40%\">\n## 2.2 IP地址及其表示方法\n整个的互联就是一个单一的、抽象的网络。IP地址就是给因特网上的每一个主机(或路由器)的每一个接口分配一个在全世界范围内位移的**32位**的标识符。IP地址的结构使我们可以在互联网上很方便地进行寻址。\nIP地址的编制方法经过了三个历史阶段：\n\n- 分类的IP地址。\n- 子网的划分。这是对最基本的编址方法的改进。\n- 构成超网。这是无分类编制方法。\n\n## 2.3 分类的IP地址\n（1）概念\n分类的IP地址就是将IP地址划分为若干个固定类，每一类地址都由两个固定长度的字段组成，记为：` IP地址 ::= {<网络号>,<主机号>}`\n注：第一个字段是**网络号**，它标志主机（或路由器）所连接到的网络。一个网络号在整个互联网内必须是唯一的。第二个字段是**主机号**，它标志该主机（或路由器）。一个主机号在它前面所指明的网络范围内必须是唯一的。故，**一个IP地址在整个互联网范围内是唯一的**。\n图5给出了各种IP地址的网络号字段和主机号字段。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE5-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%86%E7%B1%BB.JPG\" width=\"60%\" height=\"60%\">（2）点分十进制记法\n对主机和路由器来说，IP地址都是32位的二进制代码。为了提高可读性，常采用点分十进制记法。如图6所示。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE6-%E7%82%B9%E5%88%86%E5%8D%81%E8%BF%9B%E5%88%B6%E8%AE%B0%E6%B3%95.JPG\" width=\"90%\" height=\"90%\"> （3）常用的三种类别的IP地址\n图7为IP地址的指派范围：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE7-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E6%8C%87%E6%B4%BE%E8%8C%83%E5%9B%B4.JPG\" width=\"100%\" height=\"100%\"> 注1：(1)A类地址的网络号字段占1个字节，有7位可用（第一位已固定为0），可指派的网络号个数为126(即$2^7-2$)。减2的原因：网络号字段为全0的IP地址和网络号为127(即01111111)保留;(2)A类地址的主机号占3个字节，最大主机数是$2^{24}-2$，即16777214。减2的原因：全0的主机号字段和全1的主机号字段保留;(3)IP地址空间共有$2^{32}$个地址，整个A类网络地址空间共有$2^{31}$个地址。故占整个IP地址空间的50%。\n注2：(1)B类地址的网络号字段有2个字节，有14位可用(前两位固定为10)。无论如何取也不会全0或全1，因此不存在减2。但`128(1000 0000).0.0.0`默认不分配，可指派的最小网络地址是`128.1(0000 0001).0.0`。因此B类地址可指派的网络数为$2^{14}-1$，即16383;(2)B类地址的每一个网络上的最大主机数为$2^{16}-2$，即65534。全0和全1的主机号保留;(3)整个B类地址空间共约$2^{30}$个地址，占整个IP地址空间的25%。\n注3：(1)C类地址的网络号字段有3个字节，有21位可用（前面3为固定为110），C类网络地址`192(1100 0000).0.0.0`也是不指派的，故C类最小网络地址为`192.0.1(0000 0001).0`，故C类地址可指派的网络数为$2^{21}-1$，即2097151个;(2)每一个C类地址的最大主机数是$2^8-2$，即254个;(3)整个C类地址空间共约$2^{29}$个地址，占整个IP地址的12.5%。\n（4）IP地址的重要特点\n- IP地址分两个等级的好处是：\n - 第一，IP地址管理机构在分配IP地址时只分配网络号（第一级），而剩下的主机号（第二级）则由得到该网络号的单位自行分配。\n - 第二，路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目的主机），这样就可以使得路由表中的项目数大幅减少，从而减少了路由表所占的存储空间以及查找路由表的时间。\n- 实际上IP地址是标志一个主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址，其网络号必须是不同的。由于一个路由器至少应当连接到两个网络，因此一个路由器至少应当有两个不同的IP地址。\n- 按照互联网的观点，一个网络是指具有相同网络号的主机的集合。因此，用转发器或网桥连接起来的若干个局域网仍为一个网络，因为这些局域网都有相同的网络号。具有不同网络号的局域网必须使用路由器进行互联。\n\n（5）示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE8-%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%AD%E7%9A%84IP%E5%9C%B0%E5%9D%80.JPG\" width=\"75%\" height=\"75%\"> 图8为三个局域网（LAN_1,LAN_2,LAN_3）通过三个路由器(R_1,R_2,R_3)互连起来所构成的一个互联网。其中局域网LAN_2是由两个网段通过网桥B互连的。图中的小圆圈表示需要有一个IP地址。\n从图中可以注意到：\n- 在同一个局域网上的主机或路由器的IP地址中的网络号必须是一样的。图中所示的网络号是IP地址中的网络号字段的值，也即主机号全为0的网络IP地址。\n- 用网桥（它只在链路层工作）互联的网段仍然是一个局域网，只能有一个网络号。\n- 路由器总是具有两个或两个以上的IP地址。即路由器的每一个接口都有一个不同的网络号的IP地址。\n\n## 2.4 IP地址与硬件地址\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE9-IP%E5%9C%B0%E5%9D%80%E4%B8%8E%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80%E7%9A%84%E5%8C%BA%E5%88%AB.JPG\" width=\"70%\" height=\"70%\"> IP地址放在IP数据报的首部，而硬件地址则放在MAC帧的首部。在网络层和网络层以上使用的是IP地址，而数据链路层及以下使用的是硬件地址。如图9中，当IP数据报放入数据链路层的MAC帧中以后，整个的IP数据报就成为MAC帧的数据，因而在数据链路层看不见数据报的IP地址。\n\n## 2.5 地址解析协议ARP\n地址解析协议ARP为网络层IP地址和数据链路层MAC地址提供动态映射，即`IP地址->MAC地址`。\n\n- ARP使用广播的方式获得物理地址。\n- ARP高速缓存：\n - 每一个主机中都设有一个ARP高速缓存(ARP cache)，里面存放的是最近获得的局域网上各主机和路由器的IP地址到硬件地址的映射表。\n - 所以，当发送分组时，计算机在发送ARP请求之前总是先在ARP缓存中寻找所需的绑定，若有，则无须广播。\n - 可以通过命令 “ arp -a” 来查看本机的ARP缓存中内容。\n\n## 2.6 IP数据报的格式\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE10-IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"80%\" height=\"80%\">\n## 2.7 划分子网\n（1）划分子网\n从1985年起在IP地址中又增加了一个“子网号字段”，使两级的IP地址变成为三级的IP地址。这种做法叫做**划分子网**，或子网寻址或子网路由选择。\n划分子网的基本思路如下：\n\n - 划分子网的方法是**从网络的主机号借用若干位作为子网号**，而主机号也就相应减少了若干位。于是两级IP地址在**本单位内部**就变成了**三级IP地址**：网络号、子网号和主机号，记为\n`IP地址::={<网络号>,<子网号>,<主机号>}`\n - 子网号在网外是不可见的，仅在子网内使用\n - 凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付给目的主机。\n\n（2）子网掩码\n子网掩码：子网号的位数是可变的，为了反映有多少位用于表示子网号，采用子网掩码。\n`  IP地址　::={<网络号>,<子网号>,<主机号>}`\n`子网掩码::={11....11,11....11,00....00}`（即网络号和子网号全1，主机号全0）\n（3）默认子网掩码\nA类网络：`255.0.0.0`\nB类网络：`255.255.0.0`\nC类网络：`255.255.255.0`\n（4）广播地址\n用途：要用广播的方式（一对所有进行通信）发送一个分组时，目的IP地址是一个广播地址。\n特点：主机号部分全1\n（5）例题\n**例题1**：假如在一个B类网络`128.10.0.0`中，我们准备从16位主机号部分里借用3位进行子网划分，求对应的子网掩码 。\n**分析**：因为是B类网络，所以网络号部分是16位，又因为子网号部分是3位，所以子网掩码里就有16+3=19位1，剩下的32-19=13位主机号部分全0。\n**结果**：`11111111 11111111 11100000 00000000`，即`255.255.224.0`\n\n**例题2**：假如一台主机的IP地址是`128.10.32.6`，子网掩码是`255.255.224.0`，那么该主机所在子网的子网地址又是什么呢？\n**分析**：子网地址也是一个特殊的IP地址，就是网络号部分和子网号部分不变，主机号部分全零的地址。用逻辑“与” 操作。\n`子网地址 = 主机IP地址 AND 子网掩码`\n**答案**：子网地址 = `128.10.00100000.6`AND`255.255.11100000.0`=`128. 10.00100000.0`=`128. 10.32.0`\n\n**例题3**：在子网128.10.32.0中，广播地址是多少呢？\n**答案**：把主机号部分(13位)变成全1，`128.10.00111111.11111111`即`128.10.63.255`\n\n**例题4**：一家公司申请到的网络地址是`202.119.230.0`，现在由于工作上的需要，要把该网络划分为14个子网，并且又希望每个子网的规模尽可能的大，则应选用的子网掩码是多少？\n**分析**：若全0、全1的子网地址可以分配，则若借用x位进行子网划分，可以划分出$2^x$个子网；反之，则可以划分$2^x-2$个子网。对于本题中，x=4满足需求。因为是C类地址，所以其子网掩码是24+4=28比特的1, 32-28=4比特的0。\n**答案**： `255.255.255.11110000`即 `255.255.255.240`\n\n**例题5**：设有一个网络，其网络地址为`210.10.30.0`，若其选用的子网掩码是`255.255.255.192`，则：\n**（1）可以划分多少个子网（注：全0全1的子网地址不分配）**\n**分析**：因为该网络是一个C类网络，默认的子网掩码是`255.255.255.0`，因为`192=11000000B`, 可见，是从主机号里面是借了2位进行子网划分，又因为**全0全1 的子网地址不分配**。\n**答案**：划分子网的个数是$2^2-2=2$\n**（2）每个子网容纳的主机个数是多少？**\n**分析**：因为主机号部分的位数也就是子网掩码中0的个数，有6位。\n答案：每个子网容纳的主机个数是 $2^6-2=62$\n**注意**：即使题目中没有说明，全零和全1的主机地址始终是不分配的\n**（3）每个子网的子网地址分别是什么？**\n**分析**：子网地址中高24位是网络号部分，肯定是`210.10.30`，子网地址中主机号部分是全0，只有子网号这两位去除全0和全1外，还有两种选择，一个是01，一个是10，分别分配给两个子网。\n**答案**：子网1： `210.10.30.01000000`即`210.10.30.64`\n子网2：`210.10.30.10000000`即`210.10.30.128`\n**（4）每个子网中可分配的IP地址的范围多少？广播地址是多少？**\n**分析**：每个子网中第一个可用的IP地址就是主机号部分除了最后一位为1，其余位均为0的地址，最后一个可分配的IP地址是刚好反过来，主机号部分最后一位是0，其余位均为1。\n**答案**：子网1： `210.10.30.01000001`至 `210.10.30.01111110`。即`210.10.30.65`至`210.10.30.126`\n广播地址：`210.10.30.01111111`即`210.10.30.127`\n子网2：`210.10.30.10000001`至`210.10.30.10111110`。即`210.10.30.128`至`210.10.30.190`\n广播地址： `210.10.30.10111111`即`210.10.30.191`\n## 2.8 无分类编制CIDR(构造超网)\n（1）CIDR\n**CIDR消除了传统的A类、B类和C类地址以及划分子网的概念**。CIDR使IP地址从三级编址（使用子网掩码）又回到了两级编织，但这已是**无分类的两级编址**，记为：`IP地址::= {<网络前缀>,<主机号>}`\n（2）CIDR记法\nCIDR使用斜线记法，即在IP地址后面加上斜线\"/\"，然后写上网络前缀所占的位数；CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。我们只要知道CIDR地址块中的任一地址，就可以知道这个地址块的起始地址(即最小地址)和最大地址，以及地址块中的地址数。\n例如：已经IP地址`128.14.35.7/20`是某CIDR地址块中的一个地址，现在把它写成二进制表示，其中的前20位是网络前缀，而前缀后面的12位是主机号。\n`128.14.35.7/20`=`10000000 00001110 0010`0011 00000111（前20位是网络前缀，后12位是主机号）\n这个地址所在的地址块中的最小地址和最大地址可以很方便的得出：\n最小地址： `10000000 00001110 0010`0000 00000000 即`128.14.32.0` \n最大地址：`10000000 00001110 0010`1111 11111111 即`128.14.47.255`\n当然，这两个主机号是全0和全1的地址一般不分配。通常只用这两个地址之间的地址。\n（3）地址掩码\n为了更方便地进行路由选择，CIDR使用32位的地址掩码（也可称子网掩码）。网络前缀全1，主机号全0。\n注：CIDR不使用子网，是指CIDR并没有在32位地址中指明若干位作为子网字段。但分配到一个CIDR地址块的单位，仍然可以在本单位内根据需要划分出一些子网。这些子网也都只有一个网络前缀和一个主机号字段，但网络的前缀比整个单位的网络前缀要长些。\n（4）例题\n**例题1**：`128.14.32.0/20`表示的地址块共有多少个地址？最大和最小的地址分别是什么？\n**分析**：因为是一个/20的地址块，所以主机号部分共有32-20=12位，所以地址个数是$2^{12}=4096$个。如图为CIDR地址块中最小和最大地址示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE11-CIDR%E5%9C%B0%E5%9D%80%E5%9D%97.JPG\" width=\"70%\" height=\"70%\"> **例题2**：假设某ISP（因特网服务提供者）拥有CIDR地址块`202.192.0.0/16`。先后有四所大学（A、B、C、D）向该ISP分别申请大小为4000、2000、4000、 8000个IP地址的地址块，试为ISP给这四所大学分配地址块。\n**分析**：\n**A大学**：$2^{12}=4096>4000$，所以地址块中主机号部分是12位，网络前缀的长度=32-12=20位\n起始地址：`202.192.0000`0000.0/20 即`202.192.0.0/20`\n结束地址：`202.192.0000`1111.255 即`202.192.15.255`\n**B大学**：`2^{11}=2048>2000`，网络前缀的长度=32-11=21位\n起始地址： `202.192.00010`000.0/21 即`202.192.16.0/21`\n结束地址：`202.192.00010`111.255 即`202.192.23.255`\n**C大学**：$2^{12}=4096>4000$，网络前缀的长度=32-12=20位\n起始地址：`202.192.0010`0000.0/20 即`202.192.32.0/20`\n结束地址：`202.192.0010`1111.255 即`202.192.47.255`\n**D大学**：$2^{13}=8192>8000$，网络前缀的长度=32-13=19位\n起始地址：`202.192.010`00000.0/19 即`202.192.64.0/19`\n结束地址：`202.192.010`11111.255 即`202.192.95.255`\n## 2.9 IP分组转发的流程\n**路由表的表项 ：（目的网络地址，子网掩码，下一跳路由器IP地址）**\n**示例**：已知图4-24所示的互联网，以及路由器$R_1$中的部分路由表。现在源主机$H_1$向目的主机$H_2$发送分组。试讨论$R_1$收到$H_1$向$H_2$发送的分组后查找路由表的过程。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE12-IP%E5%88%86%E7%BB%84%E8%BD%AC%E5%8F%91.JPG\" width=\"80%\" height=\"80%\"> **分析**：\n- 源主机$H_1$向目的主机$H_2$发送的分组的目的地址是$H_2$的IP地址：128.30.33.138。\n- 源主机$H_1$首先要进行的操作是要判断：发送的这个分组，是在本子网上进行直接交付还是要通过本子网上的路由器进行间接交付？\n - 源主机$H_1$把本子网的子网掩码`255.255.255.128`与目的主机$H_2$的IP地址`128.30.33.138`逐位相与(AND操作)，得出`128.30.33.128`，它不等于$H_1$的网络地址`128.30.33.0`。这说明$H_2$与$H_1$不在同一个子网上。因此$H_1$不能把分组直接交付$H_2$，而必须交给子网上的默认路由器$R_1$，由$R_1$来转发。\n- 路由器$R_1$在收到一个分组后，就在其路由表中逐行寻找有无匹配的网络地址。\n - 先看$R_1$路由表中的第一行。用这一行的子网掩码`255.255.255.128`和收到的分组的目的地址`128.30.33.138`逐位相与，得出`128.30.33.128`。然后和这一行给出的目的网络地址`128.30.33.0`进行比较。但比较的结果是不一致,即不匹配。\n- 用同样方法继续往下找第二行。用第二行的子网掩码`255.255.255.128`和该分组的目的地址`128.30.33.138`逐位相与，结果是`128.30.33.128`。这个结果和第二行的目的网络地址`128.30.33.128`相匹配，说明这个网络(子网2)就是收到的分组所要寻找的目的网络。于是不需要再继续查找下去。$R_1$把分组从接口1直接交付主机$H_2$（它们都在一个子网上）。\n\n## 2.10 网际控制报文协议ICMP\n(1)ICMP\n- 为更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP(Internet Control Message Protocol)。\n- ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP不是高层协议，是IP层的协议。\n- ICMP报文作为IP层数据报的数据，加上数据报的首部，组成IP数组报发送出去。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/ICMP%E6%8A%A5%E6%96%87%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"60%\" height=\"60%\"> (2)ICMP报文种类\nICMP报文的种类有两种，即**ICMP差错报文**和**ICMP询问报文**。\nICMP差错报告报文分五种：\n\n- 终点不可达\n- 时间超过\n- 源站抑制\n- 参数问题\n- 路由重定向\n\n常用的ICMP询问报文有两种：\n\n- 回送请求和回答报文\n- 时间戳请求和回答报文\n\n（3）ICMP的应用\nICMP协议可以实现网络可达性检查、网络时延测量、网络路由追踪、网络安全排查等方面都有重要的应用。\n- Tracert（跟踪路由）基于**ICMP终点不可达和时间超过差错报告报文**原理实现的。\n- Ping（因特网包探索器）基于**ICMP询问报文类型中的回送请求和回答报文**实现的。\n\n## 2.11 虚拟专用网络VPN和网络地址转换NAT\n**虚拟专用网**：利用公共网络（如Internet）来构建的专用网络技术，保证了VPN中任何一对计算机之间的通信对外界是隐藏的。\n（1）VPN的编址\nVPN所提供的编址选择与专用网络所提供的是一样的，可以根据需要选择\n- 本地地址——仅在机构内部使用的IP地址，可以由本机构自行分配，而不需要向因特网的管理机构申请\n- 全球地址——全球惟一的IP地址，必须向因特网的管理机构申请\n\n本地地址：IANA保留了三块只能用于专用互联网内部通信的IP地址空间：\n前缀 最低地址 最高地址\n`10/8` `10.0.0.0` `10.255.255.255`\n`172.16/12` `172.16.0.0` `172.31.255.255`\n`192.168/16` `192.168.0.0` `192.168.255.255`\n（2）VPN的工作原理\n- VPN的实现主要使用了两种基本技术：隧道传输和加密技术。\n- VPN定义了两个网络的路由器之间通过Internet的一个隧道，并使用IP-in-IP封装通过隧道转发数据报。\n- 为了保证保密性，VPN把外发的数据报加密后，封装在另一个数据报中传输。\n- 隧道接收路由器将数据报解密，还原出内层数据报，然后转发该数据报。\n\n（3）网络地址转换NAT\n网络地址转换NAT(Network Address Translation)方法于1994年提出，用来解决本地编址的内部网络与外网通信的问题。需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球地址IPG。所有使用本地地址的主机在和外界通信时都要在NAT路由器上将其本地地址转换成IPG才能和因特网连接。\n\n## 2.12 下一代网际协议IPv6\nIPv6 将地址从IPv4的32bit增大到了128bit。\n\n# 3.运输层\n## 3.1 运输层\n### 运输层的作用\n网络层为**主机之间**提供逻辑通信，而运输层为**应用进程之间**提供端到端的逻辑通信，如下图所示:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E8%BF%90%E8%BE%93%E5%B1%82%E4%BD%9C%E7%94%A8.JPG\" width=\"70%\" height=\"50%\">\n\n### 运输层的两个主要协议\nTCP/IP运输层的两个主要协议都是因特网的正式标准，即：\n- 用户数据报协议UDP\n- 传输控制协议TCP\n\n下图给出了这两种协议在协议栈中的位置：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.JPG\" width=\"40%\" height=\"40%\"> 按OSI的术语，两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元TPDU。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为**TCP报文段(segment)**或**UDP用户数据报**。\nUDP与TCP对比：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E7%89%B9%E7%82%B9%E5%AF%B9%E6%AF%94.JPG\" width=\"70%\" height=\"50%\"> 一些应用和应用层协议主要使用的运输层协议(TCP或UDP)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E5%BA%94%E7%94%A8%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8D%8F%E8%AE%AE.JPG\" width=\"70%\" height=\"70%\">\n### 端口\n运输层具有复用和分用的功能：\n- 应用层所有的应用进程可以通过运输层再传送到IP层（网络层），这就是**复用**；\n- 运输层从IP层收到数据后必须交付指明的应用进程，这就是**分用**。\n\n端口：是**应用层的各种协议进程与运输实体进行层间交互的一种地址**：\n- 在UDP和TCP的首部格式中，都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付给应用层的目的应用进程。\n- TCP/IP运输层用一个16位端口号来标志一个端口。\n- 因此，**两个计算机中的进程要相互通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）**。\n\n因特网上的计算机通信是采用客户-服务器的方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类：\n（1）**服务器端使用的端口号**\n分为两类：熟知端口号和登记端口号。\n- **熟知端口号**：数值为0~1023。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。\n下图为一些常用的熟知端口号：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E7%86%9F%E7%9F%A5%E7%AB%AF%E5%8F%A3%E5%8F%B7.JPG\" width=\"70%\" height=\"50%\">\n- **登记端口号**：数值为1024~49151。为没有熟知端口号的应用程序使用。但要使用须在IANA按规定登记，以防重复。\n\n（2）**客户端使用的端口号**\n数值为49152~65535。这类端口号留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。\n\n## 3.2 用户数据报协议UDP\n### UDP概述\nUDP的主要特点：\n- **UDP是无连接的**，即发送数据之前不需要建立连接\n- **UDP使用尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的连接状态表\n- **UDP是面向报文的**。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E6%98%AF%E9%9D%A2%E5%90%91%E6%8A%A5%E6%96%87.JPG\" width=\"60%\" height=\"60%\">\n- **UDP没有拥塞控制**，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用很重要，很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。\n- **UDP支持一对一，一对多，多对一和多对多的交互通信**。\n- **UDP的首部开销小**，只有8个字节，比TCP的20个字节的首部要短。\n\n### UDP的首部格式\n用户数据报UDP有两个字段：数据字段和首部字段。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E9%A6%96%E9%83%A8.JPG\" width=\"60%\" height=\"60%\"> 首部字段很简单，只有8个字节，由四个字段组成，如上图所示。**每个字段的长度都是两个字节**。各字节具体含义如下：\n- **源端口**：源端口号。在需要对方回信时选用。不需要时可用全0。\n- **目的端口**：目的端口号。这在终点交付报文时必须要使用到。\n当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点——应用进程。下图就是UDP基于端口分用的示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%9F%BA%E4%BA%8E%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%88%86%E7%94%A8.JPG\" width=\"40%\" height=\"40%\">\n- **长度**：UDP用户数据报的长度，其最小值是8（仅有首部）。\n- **检验和**： 检测UDP用户数据报在传输中是否有错。有错就丢弃。\nUDP用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。\nUDP计算检验和的方法和计算IP数据报首部检验和的方法类似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把**首部和数据部分一起都检验**。\n\n### UDP实例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%AE%9E%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n## 3.3 传输控制协议TCP\n### TCP的特点\nTCP是TCP/IP体系中非常复杂的一个协议。下面介绍TCP最主要的特点：\n- TCP是**面向连接的运输层协议**。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。\n- 每一条TCP连接只能有两个**端点**（即套接字），每一条TCP连接只能是**点对点**的(一对一)。\n- TCP提供**可靠交付**的服务。通过TCP连接传送的数据，无差错，不丢失，不重复，并且按序到达。\n- TCP提供**全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事情，而TCP在合适的时候把数据发送出去。在接受时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。\n- **面向字节流**。TCP中的\"流\"指的是**流入到进程或从进程流出的字节序列**。“面向字节流”的含义是：虽然应用程序和TCP交互的是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的**无结构的字节流**。TCP并不知道所传送的字节流的含义。但接收方的应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接受方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。\n下图为TCP面向字节流的概念：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E6%A6%82%E5%BF%B5.JPG\" width=\"80%\" height=\"80%\">上图指出，TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节（UDP发送的报文长度是应用进程给出的）。\n\n### 套接字\n每一条TCP连接有两个**端点**，TCP的连接端点叫做**套接字(socket)**。\n套接字： `套接字socket = (IP地址：端口号)`\n每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定。即：\n`TCP连接 ::= {socket1, socket2} = {(IP1, port1), (IP2, port2)}`\n### TCP报文段的首部格式\nTCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而**TCP的全部功能都体现在它首部中各字段的作用**。\nTCP报文段首部的前20个字节是固定的，后面有$4n$字节是根据需要而增加的选项($n$是整数)。因此TCP首部的最小长度是20字节。\n下图为TCP报文段的首部格式：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E6%8A%A5%E6%96%87%E6%AE%B5%E7%9A%84%E9%A6%96%E9%83%A8%E6%A0%BC%E5%BC%8F.JPG\" width=\"75%\" height=\"75%\"> 首部固定部分各字段的意义如下：\n- **源端口**和**目的端口**：各占2个字节，分别写入源端口号和目的端口号。\n- **序号**：占4个字节。首部中的序号字段值指的是**本报文段所发送的数据的第一个字节的序号**。序号范围是$[0,2^32-1]$，共$2^32$个序号。序号增加到$2^32-1$后，下一个序号就又回到0。TCP是面向字节流的。在一个TCP连接中传送的字节流中的**每一个字节都按顺序编号**。整个要传送的字节流的起始序号必须在连接建立时设置。\n- **确认号**：占4个字节，是**期望收到对方下一个报文段的第一个数据字节的序号**。若确认号等于$N$，则表明：到序号$N-1$为止的所有数据都已正确收到。\n- **数据偏移**：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，即指出TCP报文段的首部长度。\n- **保留**：占6位，保留为今后使用，目前置为0。\n- 6个**控制位**：\n - **紧急URG(URGent)**：当URG=1时，表明紧急指针字段有效。当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的**最前面**，而在紧急数据后面的数据仍是普通数据。这时要与首部中的**紧急指针**字段配合使用。\n - **确认ACK(ACKnowlegment)**： **仅当ACK=1时确认号字段才有效**。当ACK=0时，确认号字段无效。**TCP规定，在连接建立后，所有传送的报文段都必须把ACK置1**。\n - **推送PSH(PuSH)**：用的很少。\n - **复位RST(ReSeT)**:当RST=1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。\n - **同步SYN**：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应的报文段中使用SYN=1和ACK=1。因此，**SYN置为1就表示这是一个连接请求或者连接接受报文**。\n - **终止FIN**：用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。\n- **窗口**：占2个字节。窗口值是$[0,2^16-1]$之间的整数。窗口指的是发送本报文段的一方的**接收窗口**（而不是自己的发送窗口）。窗口值告诉对方：**从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量**。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，**窗口值作为接收方让发送方设置其发送窗口的依据**。\n例如：设确认号是701，窗口字段是1000。这就表明，从701号算起，发送此报文段的一方还有接受1000个字节数据（字节序号是701~1700）的接受缓存空间。\n- **检验和**：占2个字节。检验和字段检验的范围包括首部和数据这两个部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。\n- **紧急指针**：占2个字节。紧急指针仅在URG=1时才有意义。紧急指针指出了紧急数据的末尾在报文段中的位置。\n- **选项**：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。其中有**最大报文段长度MSS**、**窗口扩大**、**时间戳**、**选择确认(SACK)**等选项。\n\n### TCP的运输连接管理\nTCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向来连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：**连接建立、数据传送和连接释放**。\n在TCP连接建立过程中要解决以下三个问题：\n（1）要使每一方能够明确知道对方的存在。\n（2）要允许双方协商一些参数（如最大窗口值，是否使用窗口扩大选项和时间戳选项等）。\n（3）能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。\nTCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做**客户(client)**，而被动等待连接建立的应用进程叫**服务器(server)**。\n#### TCP的连接建立\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B.JPG\" width=\"80%\" height=\"80%\"> 上图为TCP的建立连接的过程：\n- 假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。\n- 最初两端的TCP进程都处于CLOSED(关闭)状态。注意，**A主动打开连接**，而**B被动打开连接**。\n- B的TCP服务器进程先创建**传输控制块TCB**，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN(收听)状态，等待客户的连接请求。如有，即作出响应。\n- A的TCP客户进程也是首先创建**传输控制模块TCB**，然后向B发出连接请求报文段，首部中的同步位SYN置1，同时选择一个初始序号seq=x。TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但要**消耗掉一个序号**。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。\n- B收到连接请求报文后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。注意，此SYN报文段也不能携带数据，但同样需要**消耗掉一个序号**。这是TCP服务器进程进入SYN-RCVD(同步收到状态)。\n- TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP规定，ACK报文段可以携带数据。但**如果不携带数据则不消耗序号**，在此情况下，下一个数据报文段的序号仍是seq=x+1。这是TCP连接已经建立，A进入ESTABLISHED(已建立连接)状态。\n- 当B收到A的确认后，也进入ESTABLISHED状态。\n- 上面给出的连接建立的过程叫做**三次握手**。\n\n为什么A还要发送一次确认呢？\n- 这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。\n- “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。\n\n#### TCP的连接释放\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E9%87%8A%E6%94%BE.JPG\" width=\"80%\" height=\"80%\"> 数据传输结束后，通信的双方都可释放连接，上图为TCP连接释放的过程：\n- 现在A和B都处于ESTABLISHED状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq=u，它等于前面已经传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1(终止等待1)状态，等待B的确认。注意，TCP规定，FIN报文段即使不携带数据，也消耗掉一个序号。\n- B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B前面已经传送过的数据的最后一个字节的序号加1。然后B就进入CLOSED-WAIT(关闭等待)状态。TCP服务器进程这时应通知高层应用进程，因为从A到B这个方向的连接就释放了，这时的TCP连接就处于**半关闭(half-close)**状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。\n- A收到来自B的确认后，就进入FIN-WAIT2(终止等待2)状态，等待B发出的连接释放报文。\n- 若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这是B发出的连接释放报文段必须使FIN=1。现假定B的序号为w(在半关闭状态B可能又发送了一些数据)。B还必须重复上次已发送过的确认号ack=u+1。这时B就进入LAST-ACK(最后确认)状态，等待A的确认。\n- A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1。然后进入到TIME-WAIT(时间等待)状态。请注意，现在TCP连接还没有释放掉。必须经过**时间等待计时器(TIME-WAIT timer)**设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做**最长报文段寿命(Maximum Segment Lifetime)**。当A撤销掉相应的传输控制块TCB后，就结束了这次的TCP连接。\n- B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。注意到，B结束TCP连接的时间要比A早一些。\n- 上述的TCP连接释放过程是四次挥手。\n\n为什么A在TIME-WAIT状态必须等待2MSL的时间呢？有两个理由：\n- 第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态。\n- 第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有的报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。\n\n除时间等待计时器外，TCP还设有一个**保活计时器(keepalive timer)**。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不再白白等待下去。这就是保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。\n\n# 4.应用层\n## 域名系统(DNS)\n- 域名系统是因特网使用的命名系统，完成域名解析，将域名解析到特定的IP地址。\n- DNS采用客户/服务器应用模式，其核心是分级的、基于域的命名机制以及实现该命名机制的分布式数据库系统。\n- 域名解析是由若干个域名服务器程序完成的。域名服务器程序在专设的节点上运行，运行该程序的节点称为域名服务器。\n\n**域名解析**\n- `zh.wikipedia.org`作为一个域名就和IP地址`208.80.154.225`相对应。DNS就像是一个自动的电话号码簿，我们可以直接拨打wikipedia的名字来代替电话号码（IP地址）。DNS在我们直接调用网站的名字以后就会将像`zh.wikipedia.org`一样便于人类使用的名字转化成像`208.80.154.225`一样便于机器识别的IP地址。\n- DNS查询有两种方式：递归和迭代。DNS客户端设置使用的DNS服务器一般都是递归服务器，它负责全权处理客户端的DNS查询请求，直到返回最终结果。而DNS服务器之间一般采用迭代查询方式。\n\n以查询`zh.wikipedia.org`为例：\n- 客户端发送查询报文\"query zh.wikipedia.org\"至DNS服务器，DNS服务器首先检查自身缓存，如果存在记录则直接返回结果。\n- 如果记录老化或不存在，则\n - DNS服务器向根域名服务器发送查询报文\"query zh.wikipedia.org\"，根域名服务器返回`.org`域的权威域名服务器地址，这一级首先会返回的是顶级域名的权威域名服务器。\n - DNS服务器向`.org`域的权威域名服务器发送查询报文\"query zh.wikipedia.org\"，得到`.wikipedia.org`域的权威域名服务器地址。\n - DNS服务器向`.wikipedia.org`域的权威域名服务器发送查询报文\"query zh.wikipedia.org\"，得到主机`zh`的A记录，存入自身缓存并返回给客户端。\n \n## 远程登录(Telnet)\n- 远程登录是因特网的基本应用服务之一，采用客户机/服务器模式。\n- 用户可以使用Telnet登录到远地的另一台主机上。\n- Telent能将用户的击键传到远程主机，同时也能将远程主机的输出通过TCP连接返回到用户屏幕。\n- 远程桌面（RDP）就是在TELNET技术上发展起来的。\n\n## 文件传输协议(FTP)\n- FTP(File Transfer Protocol)是Internet上使用得最为广泛的文件传送协议。FTP提供交互式的访问，允许客户上传文件到服务器或者从服务器下载文件。\n- FTP屏蔽了各个计算机系统的差异，适合在异构计算机之间传送文件。\n- 文件传输协议FTP基于TCP，采用客户/服务器模式，提供文件传送基本网络服务。\n- 一个FTP服务器进程可同时为多个客户进程提供服务。FTP服务器包括两部分：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求。\n\n## 动态主机配置协议(DHCP)\n- 动态主机配置协议允许一台计算机加入新网可自动获取网络配置信息，不用人工参与。\n- 网络计算机需要配置的项目包括：IP地址、子网掩码、默认路由器的IP地址、以及域名服务器的IP地址。\n- DHCP采用客户/服务器模式。\n\n## 电子邮件系统(E-mail)\n暂略\n\n## 万维网(WWW)\n- 万维网WWW(World Wide Web)并非某种特殊的计算机网络。\n- 万维网是一个大规模的、联机式的信息储藏所。\n- 万维网用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。\n- 这种访问方式称为“链接”。\n\n### 万维网的工作方式\n- 万维网以客户服务器方式工作。\n- 浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。\n- 客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。\n- 在一个客户程序主窗口上显示出的万维网文档称为页面(page)。\n\n### 万维网必须解决的问题\n- 怎样标志分布在整个因特网上的万维网文档？\n - 使用统一资源定位符URL(Uniform Resource Locator)来标志万维网上的各种文档,使每一个文档在整个因特网的范围内具有惟一的标识符URL。\n- 用什么协议实现万维网上各种超链的链接？\n - 在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是**超文本传送协议HTTP**(HyperText Transfer Protocol)。\n - HTTP是一个**应用层协议**，它使用TCP连接进行可靠的传送。\n- 怎样使各种万维网文档都能在因特网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？\n - 超文本标记语言HTML(HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。\n- 怎样使用户能够很方便地找到所需的信息？\n - 为了在万维网上方便地查找信息，用户可使用各种搜索工具，例如：`Google(http://www.google.com.hk)`。\n\n### 统一资源定位符URL\n- 统一资源定位符URL是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。\n- URL给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。\n- 只要能够对资源定位，系统就可以对资源进行各种操作，如存取、更新、替换和查找其属性。\n- URL 相当于一个文件名在网络范围的扩展。因此 URL 是与因特网相连的机器上任何可访问对象的一个指针。\n- 由以冒号隔开的两大部分组成，并且在 URL 中的字符对大写或小写没有要求。URL的一般形式是：`<URL的访问方式>://<主机>:<端口>/<路径>`。\n - 其中，<URL的访问方式>可为文件传输协议FTP或超文本传送协议HTTP。如使用FTP的URL举例：`ftp://rtfm.mit.edu/pub/abc.txt`，使用HTTP的URL举例：`http://shopping.dangdang.com`\n - <主机> 是存放资源的主机在因特网中的域名。\n - <端口>/<路径>有时可忽略。\n\n### 超文本传送协议HTTP\n- Ted Nelson1963年新创了hypertext和hypermedia：\n - 超文本(hypertext)是显示在计算机或其他电子设备上，具有超链(hyperlink)指向其他文本的文本。\n 例如：`<a href=\"http://www.w3.org\">W3C organization website</a>`\n - 超媒体(hypermedia)是超文本的扩充，是图片、视频和声音以及文本的复合体。\n- 万维网是分布式超媒体(hypermedia)系统。超文本、超媒体页面通过超链相互连接。\n- HTTP是面向事务的(transaction-oriented)应用层协议，是在万维网上可靠地交换文件（各种多媒体文件）的重要基础。\n- HTTP的工作过程:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BA%94%E7%94%A8%E5%B1%82/http%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.JPG\" width=\"50%\" height=\"50%\">\n- 用户点击超链后所发生的事件：\n - 浏览器分析超链指向页面“我校学科楼组团正式启用”的 URL\n - 浏览器向DNS服务器请求解析 www.njupt.edu.cn 的 IP 地址\n - 域名系统解析出南京邮电大学Web服务器的 IP 地址\n - 浏览器与web服务器建立 TCP 连接\n - 浏览器发出取文件HTTP请求：GET /s/222/t/1100/41/fd/info82429.htm HTTP/1.1\n - Web服务器 做出响应，把文件 info82429.htm 发给浏览器\n - TCP 连接释放\n - 浏览器显示info82429.htm中的所有文本。\n\n# 5.参考资料\n- [网络技术与应用，南京邮电大学](http://www.icourse163.org/course/NJUPT-1001639008?tid=1001719010)\n- 计算机网络，谢希仁\n","source":"_posts/计算机网络笔记.md","raw":"---\ntitle: 计算机网络笔记\nmathjax: true\ndate: 2017-12-28 15:49:50\ncategories:\n- 计算机基础 \ntags:\n---\n# 1.计算机网络体系结构\n- **协议**：协议是控制两个对等实体（或多个实体）进行通信的规则的集合。网络协议主要由以下三要素组成：语法、语义、同步。\n- **网络体系结构**：网络体系结构是计算机网络的分层、每层的功能以及每层使用到的协议的集合。\n\n<!-- more --> \n\n## 1.1 计算机网络体系结构\n\n- 国际标准化组织（ISO）提出**开放系统互连参考模型OSI/RM**(Open System Interconnection Reference Model)。OSI是一个七层协议体系结构，如图1(a)。\n- 美国国防部提出**TCP/IP体系结构**，TCP/IP是一个四层的体系结构，如图1(b)。\n- OSI的七层体系结构的理论完整，但即复杂又不实用。TCP/IP是事实上的国际标准。\n- 从实质上讲，TCP/IP只有最上面的三层，因为最下面的网络接口层并没有什么具体内容。因此在学习计算机网络的原理时，采用折中的办法，即综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，如图1(c)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"70%\">\n\n## 1.2 各层的主要功能\n（1）**应用层**(application layer)\n\n- 功能：应用层是体系结构中的最高层。应用层的任务是**通过应用进程间的交互来完成特定网络应用**。这里的**进程**就是指**主机中正在运行的程序**。\n- 协议：应用层协议定义的是**应用进程间通信和交互的规则**。对于不同的网络应用需要有不同的应用层协议。应用层协议有：域名系统DNS，支持万维网应用的**HTTP**协议，支持电子邮件的**SMTP**协议，支持文件传送的**FTP**协议等。我们把应用层交互的数据单元成为**报文**(message)。\n\n（2）**运输层**(transport layer)\n\n- 功能：运输层的任务就是负责向**两个主机中进程之间的通信**提供**通用的数据传输**服务。应用进程利用该服务传送应用层报文。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付给上面应用层中的相应的进程。\n- 协议：运输层主要使用两种协议：1.**传输控制协议TCP**——提供面向连接的、可靠的数据服务，数据传输的单位是**报文段**(segment)；2.**用户数据包协议UDP**——提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是**用户数据报**。\n- 重要设备：网关(gateway)。\n\n（3）**网络层**(network layer)\n\n- 功能：（1）网络层负责为分组交换网上的不同**主机**提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成**分组**或**包**进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫做**IP数据报**或简称**数据报**；\n注：无论在哪一层传送的数据单元，都可笼统地用**“分组”**来表示\n（2）网络层的另一个任务是选择合适的路由，使源主机运输层传下来的分组，能够通过网络中的路由器找到目的主机。\n- 协议：（1）互联网是大量的**异构**网络通过**路由器**相互连接起来的。互联网使用的网络协议是无连接的**网际协议IP**(Internet Protocol)和许多种路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**；（2）与IP协议配套使用的还有三个协议：地址解析协议ARP、网际控制报文协议ICMP和网际组管理协议IGMP；（3）路由选择协议。\n- 重要的设备：路由器(router)。\n\n（4）**数据链路层**(data link layer)\n\n- 功能：两台主机之间的数据传输，总是在一段一段的**链路**上传送的，也就是说，在两个相邻结点之间（主机和路由器之间或两个路由器之间）传送数据是直接传送的（点对点）。数据链路层把网络层交下来的IP数据报（或数据报/分组/包）**封装成帧**(framing)发送到链路上，在两个相邻结点间的链路上传送**帧**(frame)，以及把接受到的帧中的数据取出并上交给网络层。\n- 重要设备：网桥(bridge)、交换机（多接口的网桥）。\n\n（5）**物理层**(physical layer)\n\n- 功能：在物理层上所数据的单位是**比特**。物理层的任务就是**透明地传送比特流**。也就是说，发送方发送1(或0)时，接收方应当收到1(或0)而不是0(或1)。因此物理层要考虑用多大的电压代表\"1\"或\"0\"，以及接收方如何识别出发送方所发送的比特，物理层还要确定连接电缆的插头应当有多少根引脚以及各条引脚应如何连接。注意，传递信息所利用的一些物理媒体/传输媒体，如双绞线、同轴电缆、光缆、无线信道等，并不在物理层协议之内而是在物理层协议的下面，有人把物理媒体称为第0层。\n综上，物理层的作用正视要经可能的屏蔽掉传输媒体和通信手段的差异，是物理层之上的数据链路层感觉不到这些差异，使数据链路层只需要考虑如何完成本层的协议和服务。\n- 中间设备：转发器(repeater)\n\n## 1.3 数据在各层之间的传递过程\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE2_%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%90%84%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E9%80%92%E8%BF%87%E7%A8%8B.JPG\" width=\"80%\" height=\"80%\">\n\n- 假定主机1的应用进程$AP_1$向主机2的应用进程$AP_2$传送数据。\n- $AP_1$先将其数据交给本主机的第5层(应用层)。第5层加上必要的控制信息$H_5$就变成了下一层的数据单元。第4层(运输层)收到这个数据单元后，加上本层的控制信息$H_4$，再交给第3层(网络层)，成为第3层的数据单元。依此类推。不过到了第2层(数据链路层)后，控制信息被分成两部分，分别加到本层数据单元的首部($H_2$)和尾部($T_2$)；而第1层(物理层)由于是比特流的传送，所以不再加上控制信息。\n- 当这一串的比特流离开主机1经网络的物理媒体传送到路由器时，就从路由器的第一层一次上升到第三层。每一层都根据控制信息进行必要的操作，然后将控制信息剥去，将该层剩下的数据单元交给更高的一层。当分组上升到第3层时，就根据首部中的目的地址查找路由器中的转发表，找到转发分组的接口，然后往下传送到第2层，加上新的首部和尾部，再到最下面的第1层，然后在物理媒体上把每一个比特发送出去。\n- 当这一串的比特流离开路由器到达目的主机2时，就从主机2的第1层按照上面讲过的方式，一次上升到第5层。最后，把应用进程$AP_1$发送的数据交给目的站的应用进程$AP_2$。\n- 对于用户来说，这个复杂的过程被屏蔽了，以至于感觉应用进程$AP_1$是直接把数据交给了应用进程$AP_2$。同理，任何两个同样的层次（例如两个系统的第4层）之间，也好像如同图2中的水平虚线所示的那样，把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层“之间的通信。之前提到的各层协议，实际上就是在各个对等层之间传递数据时的各项规定。\n\n## 1.4 TCP/IP体系结构\n前面已经说过，TCP/IP的体系结构比较简单，它只有四层。图3给出了用这四层协议表示方法的例子。注意，图中的路由器在转发分组时最高只用到网络层而没有使用运输层和应用层。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE3_TCPIP%E5%9B%9B%E5%B1%82%E5%8D%8F%E8%AE%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n\n还有一种方法，就是分层次画出具体的协议来表示TCP/IP协议族，如图4。它的特点是上下两头大而中间小：应用层和网络接口层都有多种协议，而中间的IP层很小，上层的各种协议都向下汇聚到一个IP协议中。这种像沙漏计时器形状的TCP/IP协议族表明：TCP/IP协议**可以为各式各样的应用提供服务**（所谓的everying over IP），同时TCP/IP协议也**允许IP协议在各式各样的网络构成的互联网上运行**（所谓的 IP over everything）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE4_%E6%B2%99%E6%BC%8F%E8%AE%A1%E6%97%B6%E5%99%A8%E5%BD%A2%E7%8A%B6%E7%9A%84TCP-IP%E5%8D%8F%E8%AE%AE%E6%97%8F.JPG\" width=\"70%\" height=\"70%\">\n\n# 2.网络层\n## 2.1网际协议IP\n互联网由多种异构网络互连而成，参加互联的计算机网络都使用相同的网际协议IP，因此实现互联。\n网际协议IP是TCP/IP体系中两个最重要的协议之一。与IP协议配套使用的还有三个协议：\n\n- 地址解析协议ARP \n- 网际控制报文协议ICMP\n- 网际组管理协议IGMP\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE-%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE%E9%85%8D%E5%A5%97%E5%8D%8F%E8%AE%AE.JPG\" width=\"40%\" height=\"40%\">\n## 2.2 IP地址及其表示方法\n整个的互联就是一个单一的、抽象的网络。IP地址就是给因特网上的每一个主机(或路由器)的每一个接口分配一个在全世界范围内位移的**32位**的标识符。IP地址的结构使我们可以在互联网上很方便地进行寻址。\nIP地址的编制方法经过了三个历史阶段：\n\n- 分类的IP地址。\n- 子网的划分。这是对最基本的编址方法的改进。\n- 构成超网。这是无分类编制方法。\n\n## 2.3 分类的IP地址\n（1）概念\n分类的IP地址就是将IP地址划分为若干个固定类，每一类地址都由两个固定长度的字段组成，记为：` IP地址 ::= {<网络号>,<主机号>}`\n注：第一个字段是**网络号**，它标志主机（或路由器）所连接到的网络。一个网络号在整个互联网内必须是唯一的。第二个字段是**主机号**，它标志该主机（或路由器）。一个主机号在它前面所指明的网络范围内必须是唯一的。故，**一个IP地址在整个互联网范围内是唯一的**。\n图5给出了各种IP地址的网络号字段和主机号字段。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE5-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%86%E7%B1%BB.JPG\" width=\"60%\" height=\"60%\">（2）点分十进制记法\n对主机和路由器来说，IP地址都是32位的二进制代码。为了提高可读性，常采用点分十进制记法。如图6所示。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE6-%E7%82%B9%E5%88%86%E5%8D%81%E8%BF%9B%E5%88%B6%E8%AE%B0%E6%B3%95.JPG\" width=\"90%\" height=\"90%\"> （3）常用的三种类别的IP地址\n图7为IP地址的指派范围：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE7-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E6%8C%87%E6%B4%BE%E8%8C%83%E5%9B%B4.JPG\" width=\"100%\" height=\"100%\"> 注1：(1)A类地址的网络号字段占1个字节，有7位可用（第一位已固定为0），可指派的网络号个数为126(即$2^7-2$)。减2的原因：网络号字段为全0的IP地址和网络号为127(即01111111)保留;(2)A类地址的主机号占3个字节，最大主机数是$2^{24}-2$，即16777214。减2的原因：全0的主机号字段和全1的主机号字段保留;(3)IP地址空间共有$2^{32}$个地址，整个A类网络地址空间共有$2^{31}$个地址。故占整个IP地址空间的50%。\n注2：(1)B类地址的网络号字段有2个字节，有14位可用(前两位固定为10)。无论如何取也不会全0或全1，因此不存在减2。但`128(1000 0000).0.0.0`默认不分配，可指派的最小网络地址是`128.1(0000 0001).0.0`。因此B类地址可指派的网络数为$2^{14}-1$，即16383;(2)B类地址的每一个网络上的最大主机数为$2^{16}-2$，即65534。全0和全1的主机号保留;(3)整个B类地址空间共约$2^{30}$个地址，占整个IP地址空间的25%。\n注3：(1)C类地址的网络号字段有3个字节，有21位可用（前面3为固定为110），C类网络地址`192(1100 0000).0.0.0`也是不指派的，故C类最小网络地址为`192.0.1(0000 0001).0`，故C类地址可指派的网络数为$2^{21}-1$，即2097151个;(2)每一个C类地址的最大主机数是$2^8-2$，即254个;(3)整个C类地址空间共约$2^{29}$个地址，占整个IP地址的12.5%。\n（4）IP地址的重要特点\n- IP地址分两个等级的好处是：\n - 第一，IP地址管理机构在分配IP地址时只分配网络号（第一级），而剩下的主机号（第二级）则由得到该网络号的单位自行分配。\n - 第二，路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目的主机），这样就可以使得路由表中的项目数大幅减少，从而减少了路由表所占的存储空间以及查找路由表的时间。\n- 实际上IP地址是标志一个主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址，其网络号必须是不同的。由于一个路由器至少应当连接到两个网络，因此一个路由器至少应当有两个不同的IP地址。\n- 按照互联网的观点，一个网络是指具有相同网络号的主机的集合。因此，用转发器或网桥连接起来的若干个局域网仍为一个网络，因为这些局域网都有相同的网络号。具有不同网络号的局域网必须使用路由器进行互联。\n\n（5）示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE8-%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%AD%E7%9A%84IP%E5%9C%B0%E5%9D%80.JPG\" width=\"75%\" height=\"75%\"> 图8为三个局域网（LAN_1,LAN_2,LAN_3）通过三个路由器(R_1,R_2,R_3)互连起来所构成的一个互联网。其中局域网LAN_2是由两个网段通过网桥B互连的。图中的小圆圈表示需要有一个IP地址。\n从图中可以注意到：\n- 在同一个局域网上的主机或路由器的IP地址中的网络号必须是一样的。图中所示的网络号是IP地址中的网络号字段的值，也即主机号全为0的网络IP地址。\n- 用网桥（它只在链路层工作）互联的网段仍然是一个局域网，只能有一个网络号。\n- 路由器总是具有两个或两个以上的IP地址。即路由器的每一个接口都有一个不同的网络号的IP地址。\n\n## 2.4 IP地址与硬件地址\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE9-IP%E5%9C%B0%E5%9D%80%E4%B8%8E%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80%E7%9A%84%E5%8C%BA%E5%88%AB.JPG\" width=\"70%\" height=\"70%\"> IP地址放在IP数据报的首部，而硬件地址则放在MAC帧的首部。在网络层和网络层以上使用的是IP地址，而数据链路层及以下使用的是硬件地址。如图9中，当IP数据报放入数据链路层的MAC帧中以后，整个的IP数据报就成为MAC帧的数据，因而在数据链路层看不见数据报的IP地址。\n\n## 2.5 地址解析协议ARP\n地址解析协议ARP为网络层IP地址和数据链路层MAC地址提供动态映射，即`IP地址->MAC地址`。\n\n- ARP使用广播的方式获得物理地址。\n- ARP高速缓存：\n - 每一个主机中都设有一个ARP高速缓存(ARP cache)，里面存放的是最近获得的局域网上各主机和路由器的IP地址到硬件地址的映射表。\n - 所以，当发送分组时，计算机在发送ARP请求之前总是先在ARP缓存中寻找所需的绑定，若有，则无须广播。\n - 可以通过命令 “ arp -a” 来查看本机的ARP缓存中内容。\n\n## 2.6 IP数据报的格式\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE10-IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"80%\" height=\"80%\">\n## 2.7 划分子网\n（1）划分子网\n从1985年起在IP地址中又增加了一个“子网号字段”，使两级的IP地址变成为三级的IP地址。这种做法叫做**划分子网**，或子网寻址或子网路由选择。\n划分子网的基本思路如下：\n\n - 划分子网的方法是**从网络的主机号借用若干位作为子网号**，而主机号也就相应减少了若干位。于是两级IP地址在**本单位内部**就变成了**三级IP地址**：网络号、子网号和主机号，记为\n`IP地址::={<网络号>,<子网号>,<主机号>}`\n - 子网号在网外是不可见的，仅在子网内使用\n - 凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付给目的主机。\n\n（2）子网掩码\n子网掩码：子网号的位数是可变的，为了反映有多少位用于表示子网号，采用子网掩码。\n`  IP地址　::={<网络号>,<子网号>,<主机号>}`\n`子网掩码::={11....11,11....11,00....00}`（即网络号和子网号全1，主机号全0）\n（3）默认子网掩码\nA类网络：`255.0.0.0`\nB类网络：`255.255.0.0`\nC类网络：`255.255.255.0`\n（4）广播地址\n用途：要用广播的方式（一对所有进行通信）发送一个分组时，目的IP地址是一个广播地址。\n特点：主机号部分全1\n（5）例题\n**例题1**：假如在一个B类网络`128.10.0.0`中，我们准备从16位主机号部分里借用3位进行子网划分，求对应的子网掩码 。\n**分析**：因为是B类网络，所以网络号部分是16位，又因为子网号部分是3位，所以子网掩码里就有16+3=19位1，剩下的32-19=13位主机号部分全0。\n**结果**：`11111111 11111111 11100000 00000000`，即`255.255.224.0`\n\n**例题2**：假如一台主机的IP地址是`128.10.32.6`，子网掩码是`255.255.224.0`，那么该主机所在子网的子网地址又是什么呢？\n**分析**：子网地址也是一个特殊的IP地址，就是网络号部分和子网号部分不变，主机号部分全零的地址。用逻辑“与” 操作。\n`子网地址 = 主机IP地址 AND 子网掩码`\n**答案**：子网地址 = `128.10.00100000.6`AND`255.255.11100000.0`=`128. 10.00100000.0`=`128. 10.32.0`\n\n**例题3**：在子网128.10.32.0中，广播地址是多少呢？\n**答案**：把主机号部分(13位)变成全1，`128.10.00111111.11111111`即`128.10.63.255`\n\n**例题4**：一家公司申请到的网络地址是`202.119.230.0`，现在由于工作上的需要，要把该网络划分为14个子网，并且又希望每个子网的规模尽可能的大，则应选用的子网掩码是多少？\n**分析**：若全0、全1的子网地址可以分配，则若借用x位进行子网划分，可以划分出$2^x$个子网；反之，则可以划分$2^x-2$个子网。对于本题中，x=4满足需求。因为是C类地址，所以其子网掩码是24+4=28比特的1, 32-28=4比特的0。\n**答案**： `255.255.255.11110000`即 `255.255.255.240`\n\n**例题5**：设有一个网络，其网络地址为`210.10.30.0`，若其选用的子网掩码是`255.255.255.192`，则：\n**（1）可以划分多少个子网（注：全0全1的子网地址不分配）**\n**分析**：因为该网络是一个C类网络，默认的子网掩码是`255.255.255.0`，因为`192=11000000B`, 可见，是从主机号里面是借了2位进行子网划分，又因为**全0全1 的子网地址不分配**。\n**答案**：划分子网的个数是$2^2-2=2$\n**（2）每个子网容纳的主机个数是多少？**\n**分析**：因为主机号部分的位数也就是子网掩码中0的个数，有6位。\n答案：每个子网容纳的主机个数是 $2^6-2=62$\n**注意**：即使题目中没有说明，全零和全1的主机地址始终是不分配的\n**（3）每个子网的子网地址分别是什么？**\n**分析**：子网地址中高24位是网络号部分，肯定是`210.10.30`，子网地址中主机号部分是全0，只有子网号这两位去除全0和全1外，还有两种选择，一个是01，一个是10，分别分配给两个子网。\n**答案**：子网1： `210.10.30.01000000`即`210.10.30.64`\n子网2：`210.10.30.10000000`即`210.10.30.128`\n**（4）每个子网中可分配的IP地址的范围多少？广播地址是多少？**\n**分析**：每个子网中第一个可用的IP地址就是主机号部分除了最后一位为1，其余位均为0的地址，最后一个可分配的IP地址是刚好反过来，主机号部分最后一位是0，其余位均为1。\n**答案**：子网1： `210.10.30.01000001`至 `210.10.30.01111110`。即`210.10.30.65`至`210.10.30.126`\n广播地址：`210.10.30.01111111`即`210.10.30.127`\n子网2：`210.10.30.10000001`至`210.10.30.10111110`。即`210.10.30.128`至`210.10.30.190`\n广播地址： `210.10.30.10111111`即`210.10.30.191`\n## 2.8 无分类编制CIDR(构造超网)\n（1）CIDR\n**CIDR消除了传统的A类、B类和C类地址以及划分子网的概念**。CIDR使IP地址从三级编址（使用子网掩码）又回到了两级编织，但这已是**无分类的两级编址**，记为：`IP地址::= {<网络前缀>,<主机号>}`\n（2）CIDR记法\nCIDR使用斜线记法，即在IP地址后面加上斜线\"/\"，然后写上网络前缀所占的位数；CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。我们只要知道CIDR地址块中的任一地址，就可以知道这个地址块的起始地址(即最小地址)和最大地址，以及地址块中的地址数。\n例如：已经IP地址`128.14.35.7/20`是某CIDR地址块中的一个地址，现在把它写成二进制表示，其中的前20位是网络前缀，而前缀后面的12位是主机号。\n`128.14.35.7/20`=`10000000 00001110 0010`0011 00000111（前20位是网络前缀，后12位是主机号）\n这个地址所在的地址块中的最小地址和最大地址可以很方便的得出：\n最小地址： `10000000 00001110 0010`0000 00000000 即`128.14.32.0` \n最大地址：`10000000 00001110 0010`1111 11111111 即`128.14.47.255`\n当然，这两个主机号是全0和全1的地址一般不分配。通常只用这两个地址之间的地址。\n（3）地址掩码\n为了更方便地进行路由选择，CIDR使用32位的地址掩码（也可称子网掩码）。网络前缀全1，主机号全0。\n注：CIDR不使用子网，是指CIDR并没有在32位地址中指明若干位作为子网字段。但分配到一个CIDR地址块的单位，仍然可以在本单位内根据需要划分出一些子网。这些子网也都只有一个网络前缀和一个主机号字段，但网络的前缀比整个单位的网络前缀要长些。\n（4）例题\n**例题1**：`128.14.32.0/20`表示的地址块共有多少个地址？最大和最小的地址分别是什么？\n**分析**：因为是一个/20的地址块，所以主机号部分共有32-20=12位，所以地址个数是$2^{12}=4096$个。如图为CIDR地址块中最小和最大地址示例：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE11-CIDR%E5%9C%B0%E5%9D%80%E5%9D%97.JPG\" width=\"70%\" height=\"70%\"> **例题2**：假设某ISP（因特网服务提供者）拥有CIDR地址块`202.192.0.0/16`。先后有四所大学（A、B、C、D）向该ISP分别申请大小为4000、2000、4000、 8000个IP地址的地址块，试为ISP给这四所大学分配地址块。\n**分析**：\n**A大学**：$2^{12}=4096>4000$，所以地址块中主机号部分是12位，网络前缀的长度=32-12=20位\n起始地址：`202.192.0000`0000.0/20 即`202.192.0.0/20`\n结束地址：`202.192.0000`1111.255 即`202.192.15.255`\n**B大学**：`2^{11}=2048>2000`，网络前缀的长度=32-11=21位\n起始地址： `202.192.00010`000.0/21 即`202.192.16.0/21`\n结束地址：`202.192.00010`111.255 即`202.192.23.255`\n**C大学**：$2^{12}=4096>4000$，网络前缀的长度=32-12=20位\n起始地址：`202.192.0010`0000.0/20 即`202.192.32.0/20`\n结束地址：`202.192.0010`1111.255 即`202.192.47.255`\n**D大学**：$2^{13}=8192>8000$，网络前缀的长度=32-13=19位\n起始地址：`202.192.010`00000.0/19 即`202.192.64.0/19`\n结束地址：`202.192.010`11111.255 即`202.192.95.255`\n## 2.9 IP分组转发的流程\n**路由表的表项 ：（目的网络地址，子网掩码，下一跳路由器IP地址）**\n**示例**：已知图4-24所示的互联网，以及路由器$R_1$中的部分路由表。现在源主机$H_1$向目的主机$H_2$发送分组。试讨论$R_1$收到$H_1$向$H_2$发送的分组后查找路由表的过程。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE12-IP%E5%88%86%E7%BB%84%E8%BD%AC%E5%8F%91.JPG\" width=\"80%\" height=\"80%\"> **分析**：\n- 源主机$H_1$向目的主机$H_2$发送的分组的目的地址是$H_2$的IP地址：128.30.33.138。\n- 源主机$H_1$首先要进行的操作是要判断：发送的这个分组，是在本子网上进行直接交付还是要通过本子网上的路由器进行间接交付？\n - 源主机$H_1$把本子网的子网掩码`255.255.255.128`与目的主机$H_2$的IP地址`128.30.33.138`逐位相与(AND操作)，得出`128.30.33.128`，它不等于$H_1$的网络地址`128.30.33.0`。这说明$H_2$与$H_1$不在同一个子网上。因此$H_1$不能把分组直接交付$H_2$，而必须交给子网上的默认路由器$R_1$，由$R_1$来转发。\n- 路由器$R_1$在收到一个分组后，就在其路由表中逐行寻找有无匹配的网络地址。\n - 先看$R_1$路由表中的第一行。用这一行的子网掩码`255.255.255.128`和收到的分组的目的地址`128.30.33.138`逐位相与，得出`128.30.33.128`。然后和这一行给出的目的网络地址`128.30.33.0`进行比较。但比较的结果是不一致,即不匹配。\n- 用同样方法继续往下找第二行。用第二行的子网掩码`255.255.255.128`和该分组的目的地址`128.30.33.138`逐位相与，结果是`128.30.33.128`。这个结果和第二行的目的网络地址`128.30.33.128`相匹配，说明这个网络(子网2)就是收到的分组所要寻找的目的网络。于是不需要再继续查找下去。$R_1$把分组从接口1直接交付主机$H_2$（它们都在一个子网上）。\n\n## 2.10 网际控制报文协议ICMP\n(1)ICMP\n- 为更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP(Internet Control Message Protocol)。\n- ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP不是高层协议，是IP层的协议。\n- ICMP报文作为IP层数据报的数据，加上数据报的首部，组成IP数组报发送出去。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/ICMP%E6%8A%A5%E6%96%87%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"60%\" height=\"60%\"> (2)ICMP报文种类\nICMP报文的种类有两种，即**ICMP差错报文**和**ICMP询问报文**。\nICMP差错报告报文分五种：\n\n- 终点不可达\n- 时间超过\n- 源站抑制\n- 参数问题\n- 路由重定向\n\n常用的ICMP询问报文有两种：\n\n- 回送请求和回答报文\n- 时间戳请求和回答报文\n\n（3）ICMP的应用\nICMP协议可以实现网络可达性检查、网络时延测量、网络路由追踪、网络安全排查等方面都有重要的应用。\n- Tracert（跟踪路由）基于**ICMP终点不可达和时间超过差错报告报文**原理实现的。\n- Ping（因特网包探索器）基于**ICMP询问报文类型中的回送请求和回答报文**实现的。\n\n## 2.11 虚拟专用网络VPN和网络地址转换NAT\n**虚拟专用网**：利用公共网络（如Internet）来构建的专用网络技术，保证了VPN中任何一对计算机之间的通信对外界是隐藏的。\n（1）VPN的编址\nVPN所提供的编址选择与专用网络所提供的是一样的，可以根据需要选择\n- 本地地址——仅在机构内部使用的IP地址，可以由本机构自行分配，而不需要向因特网的管理机构申请\n- 全球地址——全球惟一的IP地址，必须向因特网的管理机构申请\n\n本地地址：IANA保留了三块只能用于专用互联网内部通信的IP地址空间：\n前缀 最低地址 最高地址\n`10/8` `10.0.0.0` `10.255.255.255`\n`172.16/12` `172.16.0.0` `172.31.255.255`\n`192.168/16` `192.168.0.0` `192.168.255.255`\n（2）VPN的工作原理\n- VPN的实现主要使用了两种基本技术：隧道传输和加密技术。\n- VPN定义了两个网络的路由器之间通过Internet的一个隧道，并使用IP-in-IP封装通过隧道转发数据报。\n- 为了保证保密性，VPN把外发的数据报加密后，封装在另一个数据报中传输。\n- 隧道接收路由器将数据报解密，还原出内层数据报，然后转发该数据报。\n\n（3）网络地址转换NAT\n网络地址转换NAT(Network Address Translation)方法于1994年提出，用来解决本地编址的内部网络与外网通信的问题。需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球地址IPG。所有使用本地地址的主机在和外界通信时都要在NAT路由器上将其本地地址转换成IPG才能和因特网连接。\n\n## 2.12 下一代网际协议IPv6\nIPv6 将地址从IPv4的32bit增大到了128bit。\n\n# 3.运输层\n## 3.1 运输层\n### 运输层的作用\n网络层为**主机之间**提供逻辑通信，而运输层为**应用进程之间**提供端到端的逻辑通信，如下图所示:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E8%BF%90%E8%BE%93%E5%B1%82%E4%BD%9C%E7%94%A8.JPG\" width=\"70%\" height=\"50%\">\n\n### 运输层的两个主要协议\nTCP/IP运输层的两个主要协议都是因特网的正式标准，即：\n- 用户数据报协议UDP\n- 传输控制协议TCP\n\n下图给出了这两种协议在协议栈中的位置：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.JPG\" width=\"40%\" height=\"40%\"> 按OSI的术语，两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元TPDU。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为**TCP报文段(segment)**或**UDP用户数据报**。\nUDP与TCP对比：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E7%89%B9%E7%82%B9%E5%AF%B9%E6%AF%94.JPG\" width=\"70%\" height=\"50%\"> 一些应用和应用层协议主要使用的运输层协议(TCP或UDP)：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E5%BA%94%E7%94%A8%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8D%8F%E8%AE%AE.JPG\" width=\"70%\" height=\"70%\">\n### 端口\n运输层具有复用和分用的功能：\n- 应用层所有的应用进程可以通过运输层再传送到IP层（网络层），这就是**复用**；\n- 运输层从IP层收到数据后必须交付指明的应用进程，这就是**分用**。\n\n端口：是**应用层的各种协议进程与运输实体进行层间交互的一种地址**：\n- 在UDP和TCP的首部格式中，都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付给应用层的目的应用进程。\n- TCP/IP运输层用一个16位端口号来标志一个端口。\n- 因此，**两个计算机中的进程要相互通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）**。\n\n因特网上的计算机通信是采用客户-服务器的方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类：\n（1）**服务器端使用的端口号**\n分为两类：熟知端口号和登记端口号。\n- **熟知端口号**：数值为0~1023。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。\n下图为一些常用的熟知端口号：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E7%86%9F%E7%9F%A5%E7%AB%AF%E5%8F%A3%E5%8F%B7.JPG\" width=\"70%\" height=\"50%\">\n- **登记端口号**：数值为1024~49151。为没有熟知端口号的应用程序使用。但要使用须在IANA按规定登记，以防重复。\n\n（2）**客户端使用的端口号**\n数值为49152~65535。这类端口号留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。\n\n## 3.2 用户数据报协议UDP\n### UDP概述\nUDP的主要特点：\n- **UDP是无连接的**，即发送数据之前不需要建立连接\n- **UDP使用尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的连接状态表\n- **UDP是面向报文的**。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。如下图所示：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E6%98%AF%E9%9D%A2%E5%90%91%E6%8A%A5%E6%96%87.JPG\" width=\"60%\" height=\"60%\">\n- **UDP没有拥塞控制**，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用很重要，很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。\n- **UDP支持一对一，一对多，多对一和多对多的交互通信**。\n- **UDP的首部开销小**，只有8个字节，比TCP的20个字节的首部要短。\n\n### UDP的首部格式\n用户数据报UDP有两个字段：数据字段和首部字段。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E9%A6%96%E9%83%A8.JPG\" width=\"60%\" height=\"60%\"> 首部字段很简单，只有8个字节，由四个字段组成，如上图所示。**每个字段的长度都是两个字节**。各字节具体含义如下：\n- **源端口**：源端口号。在需要对方回信时选用。不需要时可用全0。\n- **目的端口**：目的端口号。这在终点交付报文时必须要使用到。\n当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点——应用进程。下图就是UDP基于端口分用的示意图：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%9F%BA%E4%BA%8E%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%88%86%E7%94%A8.JPG\" width=\"40%\" height=\"40%\">\n- **长度**：UDP用户数据报的长度，其最小值是8（仅有首部）。\n- **检验和**： 检测UDP用户数据报在传输中是否有错。有错就丢弃。\nUDP用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。\nUDP计算检验和的方法和计算IP数据报首部检验和的方法类似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把**首部和数据部分一起都检验**。\n\n### UDP实例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%AE%9E%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\">\n## 3.3 传输控制协议TCP\n### TCP的特点\nTCP是TCP/IP体系中非常复杂的一个协议。下面介绍TCP最主要的特点：\n- TCP是**面向连接的运输层协议**。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。\n- 每一条TCP连接只能有两个**端点**（即套接字），每一条TCP连接只能是**点对点**的(一对一)。\n- TCP提供**可靠交付**的服务。通过TCP连接传送的数据，无差错，不丢失，不重复，并且按序到达。\n- TCP提供**全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事情，而TCP在合适的时候把数据发送出去。在接受时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。\n- **面向字节流**。TCP中的\"流\"指的是**流入到进程或从进程流出的字节序列**。“面向字节流”的含义是：虽然应用程序和TCP交互的是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的**无结构的字节流**。TCP并不知道所传送的字节流的含义。但接收方的应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接受方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。\n下图为TCP面向字节流的概念：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E6%A6%82%E5%BF%B5.JPG\" width=\"80%\" height=\"80%\">上图指出，TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节（UDP发送的报文长度是应用进程给出的）。\n\n### 套接字\n每一条TCP连接有两个**端点**，TCP的连接端点叫做**套接字(socket)**。\n套接字： `套接字socket = (IP地址：端口号)`\n每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定。即：\n`TCP连接 ::= {socket1, socket2} = {(IP1, port1), (IP2, port2)}`\n### TCP报文段的首部格式\nTCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而**TCP的全部功能都体现在它首部中各字段的作用**。\nTCP报文段首部的前20个字节是固定的，后面有$4n$字节是根据需要而增加的选项($n$是整数)。因此TCP首部的最小长度是20字节。\n下图为TCP报文段的首部格式：\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E6%8A%A5%E6%96%87%E6%AE%B5%E7%9A%84%E9%A6%96%E9%83%A8%E6%A0%BC%E5%BC%8F.JPG\" width=\"75%\" height=\"75%\"> 首部固定部分各字段的意义如下：\n- **源端口**和**目的端口**：各占2个字节，分别写入源端口号和目的端口号。\n- **序号**：占4个字节。首部中的序号字段值指的是**本报文段所发送的数据的第一个字节的序号**。序号范围是$[0,2^32-1]$，共$2^32$个序号。序号增加到$2^32-1$后，下一个序号就又回到0。TCP是面向字节流的。在一个TCP连接中传送的字节流中的**每一个字节都按顺序编号**。整个要传送的字节流的起始序号必须在连接建立时设置。\n- **确认号**：占4个字节，是**期望收到对方下一个报文段的第一个数据字节的序号**。若确认号等于$N$，则表明：到序号$N-1$为止的所有数据都已正确收到。\n- **数据偏移**：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，即指出TCP报文段的首部长度。\n- **保留**：占6位，保留为今后使用，目前置为0。\n- 6个**控制位**：\n - **紧急URG(URGent)**：当URG=1时，表明紧急指针字段有效。当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的**最前面**，而在紧急数据后面的数据仍是普通数据。这时要与首部中的**紧急指针**字段配合使用。\n - **确认ACK(ACKnowlegment)**： **仅当ACK=1时确认号字段才有效**。当ACK=0时，确认号字段无效。**TCP规定，在连接建立后，所有传送的报文段都必须把ACK置1**。\n - **推送PSH(PuSH)**：用的很少。\n - **复位RST(ReSeT)**:当RST=1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。\n - **同步SYN**：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应的报文段中使用SYN=1和ACK=1。因此，**SYN置为1就表示这是一个连接请求或者连接接受报文**。\n - **终止FIN**：用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。\n- **窗口**：占2个字节。窗口值是$[0,2^16-1]$之间的整数。窗口指的是发送本报文段的一方的**接收窗口**（而不是自己的发送窗口）。窗口值告诉对方：**从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量**。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，**窗口值作为接收方让发送方设置其发送窗口的依据**。\n例如：设确认号是701，窗口字段是1000。这就表明，从701号算起，发送此报文段的一方还有接受1000个字节数据（字节序号是701~1700）的接受缓存空间。\n- **检验和**：占2个字节。检验和字段检验的范围包括首部和数据这两个部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。\n- **紧急指针**：占2个字节。紧急指针仅在URG=1时才有意义。紧急指针指出了紧急数据的末尾在报文段中的位置。\n- **选项**：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。其中有**最大报文段长度MSS**、**窗口扩大**、**时间戳**、**选择确认(SACK)**等选项。\n\n### TCP的运输连接管理\nTCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向来连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：**连接建立、数据传送和连接释放**。\n在TCP连接建立过程中要解决以下三个问题：\n（1）要使每一方能够明确知道对方的存在。\n（2）要允许双方协商一些参数（如最大窗口值，是否使用窗口扩大选项和时间戳选项等）。\n（3）能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。\nTCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做**客户(client)**，而被动等待连接建立的应用进程叫**服务器(server)**。\n#### TCP的连接建立\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B.JPG\" width=\"80%\" height=\"80%\"> 上图为TCP的建立连接的过程：\n- 假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。\n- 最初两端的TCP进程都处于CLOSED(关闭)状态。注意，**A主动打开连接**，而**B被动打开连接**。\n- B的TCP服务器进程先创建**传输控制块TCB**，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN(收听)状态，等待客户的连接请求。如有，即作出响应。\n- A的TCP客户进程也是首先创建**传输控制模块TCB**，然后向B发出连接请求报文段，首部中的同步位SYN置1，同时选择一个初始序号seq=x。TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但要**消耗掉一个序号**。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。\n- B收到连接请求报文后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。注意，此SYN报文段也不能携带数据，但同样需要**消耗掉一个序号**。这是TCP服务器进程进入SYN-RCVD(同步收到状态)。\n- TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP规定，ACK报文段可以携带数据。但**如果不携带数据则不消耗序号**，在此情况下，下一个数据报文段的序号仍是seq=x+1。这是TCP连接已经建立，A进入ESTABLISHED(已建立连接)状态。\n- 当B收到A的确认后，也进入ESTABLISHED状态。\n- 上面给出的连接建立的过程叫做**三次握手**。\n\n为什么A还要发送一次确认呢？\n- 这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。\n- “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。\n\n#### TCP的连接释放\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E9%87%8A%E6%94%BE.JPG\" width=\"80%\" height=\"80%\"> 数据传输结束后，通信的双方都可释放连接，上图为TCP连接释放的过程：\n- 现在A和B都处于ESTABLISHED状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq=u，它等于前面已经传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1(终止等待1)状态，等待B的确认。注意，TCP规定，FIN报文段即使不携带数据，也消耗掉一个序号。\n- B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B前面已经传送过的数据的最后一个字节的序号加1。然后B就进入CLOSED-WAIT(关闭等待)状态。TCP服务器进程这时应通知高层应用进程，因为从A到B这个方向的连接就释放了，这时的TCP连接就处于**半关闭(half-close)**状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。\n- A收到来自B的确认后，就进入FIN-WAIT2(终止等待2)状态，等待B发出的连接释放报文。\n- 若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这是B发出的连接释放报文段必须使FIN=1。现假定B的序号为w(在半关闭状态B可能又发送了一些数据)。B还必须重复上次已发送过的确认号ack=u+1。这时B就进入LAST-ACK(最后确认)状态，等待A的确认。\n- A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1。然后进入到TIME-WAIT(时间等待)状态。请注意，现在TCP连接还没有释放掉。必须经过**时间等待计时器(TIME-WAIT timer)**设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做**最长报文段寿命(Maximum Segment Lifetime)**。当A撤销掉相应的传输控制块TCB后，就结束了这次的TCP连接。\n- B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。注意到，B结束TCP连接的时间要比A早一些。\n- 上述的TCP连接释放过程是四次挥手。\n\n为什么A在TIME-WAIT状态必须等待2MSL的时间呢？有两个理由：\n- 第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态。\n- 第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有的报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。\n\n除时间等待计时器外，TCP还设有一个**保活计时器(keepalive timer)**。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不再白白等待下去。这就是保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。\n\n# 4.应用层\n## 域名系统(DNS)\n- 域名系统是因特网使用的命名系统，完成域名解析，将域名解析到特定的IP地址。\n- DNS采用客户/服务器应用模式，其核心是分级的、基于域的命名机制以及实现该命名机制的分布式数据库系统。\n- 域名解析是由若干个域名服务器程序完成的。域名服务器程序在专设的节点上运行，运行该程序的节点称为域名服务器。\n\n**域名解析**\n- `zh.wikipedia.org`作为一个域名就和IP地址`208.80.154.225`相对应。DNS就像是一个自动的电话号码簿，我们可以直接拨打wikipedia的名字来代替电话号码（IP地址）。DNS在我们直接调用网站的名字以后就会将像`zh.wikipedia.org`一样便于人类使用的名字转化成像`208.80.154.225`一样便于机器识别的IP地址。\n- DNS查询有两种方式：递归和迭代。DNS客户端设置使用的DNS服务器一般都是递归服务器，它负责全权处理客户端的DNS查询请求，直到返回最终结果。而DNS服务器之间一般采用迭代查询方式。\n\n以查询`zh.wikipedia.org`为例：\n- 客户端发送查询报文\"query zh.wikipedia.org\"至DNS服务器，DNS服务器首先检查自身缓存，如果存在记录则直接返回结果。\n- 如果记录老化或不存在，则\n - DNS服务器向根域名服务器发送查询报文\"query zh.wikipedia.org\"，根域名服务器返回`.org`域的权威域名服务器地址，这一级首先会返回的是顶级域名的权威域名服务器。\n - DNS服务器向`.org`域的权威域名服务器发送查询报文\"query zh.wikipedia.org\"，得到`.wikipedia.org`域的权威域名服务器地址。\n - DNS服务器向`.wikipedia.org`域的权威域名服务器发送查询报文\"query zh.wikipedia.org\"，得到主机`zh`的A记录，存入自身缓存并返回给客户端。\n \n## 远程登录(Telnet)\n- 远程登录是因特网的基本应用服务之一，采用客户机/服务器模式。\n- 用户可以使用Telnet登录到远地的另一台主机上。\n- Telent能将用户的击键传到远程主机，同时也能将远程主机的输出通过TCP连接返回到用户屏幕。\n- 远程桌面（RDP）就是在TELNET技术上发展起来的。\n\n## 文件传输协议(FTP)\n- FTP(File Transfer Protocol)是Internet上使用得最为广泛的文件传送协议。FTP提供交互式的访问，允许客户上传文件到服务器或者从服务器下载文件。\n- FTP屏蔽了各个计算机系统的差异，适合在异构计算机之间传送文件。\n- 文件传输协议FTP基于TCP，采用客户/服务器模式，提供文件传送基本网络服务。\n- 一个FTP服务器进程可同时为多个客户进程提供服务。FTP服务器包括两部分：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求。\n\n## 动态主机配置协议(DHCP)\n- 动态主机配置协议允许一台计算机加入新网可自动获取网络配置信息，不用人工参与。\n- 网络计算机需要配置的项目包括：IP地址、子网掩码、默认路由器的IP地址、以及域名服务器的IP地址。\n- DHCP采用客户/服务器模式。\n\n## 电子邮件系统(E-mail)\n暂略\n\n## 万维网(WWW)\n- 万维网WWW(World Wide Web)并非某种特殊的计算机网络。\n- 万维网是一个大规模的、联机式的信息储藏所。\n- 万维网用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。\n- 这种访问方式称为“链接”。\n\n### 万维网的工作方式\n- 万维网以客户服务器方式工作。\n- 浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。\n- 客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。\n- 在一个客户程序主窗口上显示出的万维网文档称为页面(page)。\n\n### 万维网必须解决的问题\n- 怎样标志分布在整个因特网上的万维网文档？\n - 使用统一资源定位符URL(Uniform Resource Locator)来标志万维网上的各种文档,使每一个文档在整个因特网的范围内具有惟一的标识符URL。\n- 用什么协议实现万维网上各种超链的链接？\n - 在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是**超文本传送协议HTTP**(HyperText Transfer Protocol)。\n - HTTP是一个**应用层协议**，它使用TCP连接进行可靠的传送。\n- 怎样使各种万维网文档都能在因特网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？\n - 超文本标记语言HTML(HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。\n- 怎样使用户能够很方便地找到所需的信息？\n - 为了在万维网上方便地查找信息，用户可使用各种搜索工具，例如：`Google(http://www.google.com.hk)`。\n\n### 统一资源定位符URL\n- 统一资源定位符URL是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。\n- URL给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。\n- 只要能够对资源定位，系统就可以对资源进行各种操作，如存取、更新、替换和查找其属性。\n- URL 相当于一个文件名在网络范围的扩展。因此 URL 是与因特网相连的机器上任何可访问对象的一个指针。\n- 由以冒号隔开的两大部分组成，并且在 URL 中的字符对大写或小写没有要求。URL的一般形式是：`<URL的访问方式>://<主机>:<端口>/<路径>`。\n - 其中，<URL的访问方式>可为文件传输协议FTP或超文本传送协议HTTP。如使用FTP的URL举例：`ftp://rtfm.mit.edu/pub/abc.txt`，使用HTTP的URL举例：`http://shopping.dangdang.com`\n - <主机> 是存放资源的主机在因特网中的域名。\n - <端口>/<路径>有时可忽略。\n\n### 超文本传送协议HTTP\n- Ted Nelson1963年新创了hypertext和hypermedia：\n - 超文本(hypertext)是显示在计算机或其他电子设备上，具有超链(hyperlink)指向其他文本的文本。\n 例如：`<a href=\"http://www.w3.org\">W3C organization website</a>`\n - 超媒体(hypermedia)是超文本的扩充，是图片、视频和声音以及文本的复合体。\n- 万维网是分布式超媒体(hypermedia)系统。超文本、超媒体页面通过超链相互连接。\n- HTTP是面向事务的(transaction-oriented)应用层协议，是在万维网上可靠地交换文件（各种多媒体文件）的重要基础。\n- HTTP的工作过程:\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BA%94%E7%94%A8%E5%B1%82/http%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.JPG\" width=\"50%\" height=\"50%\">\n- 用户点击超链后所发生的事件：\n - 浏览器分析超链指向页面“我校学科楼组团正式启用”的 URL\n - 浏览器向DNS服务器请求解析 www.njupt.edu.cn 的 IP 地址\n - 域名系统解析出南京邮电大学Web服务器的 IP 地址\n - 浏览器与web服务器建立 TCP 连接\n - 浏览器发出取文件HTTP请求：GET /s/222/t/1100/41/fd/info82429.htm HTTP/1.1\n - Web服务器 做出响应，把文件 info82429.htm 发给浏览器\n - TCP 连接释放\n - 浏览器显示info82429.htm中的所有文本。\n\n# 5.参考资料\n- [网络技术与应用，南京邮电大学](http://www.icourse163.org/course/NJUPT-1001639008?tid=1001719010)\n- 计算机网络，谢希仁\n","slug":"计算机网络笔记","published":1,"updated":"2018-02-15T08:20:02.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w46006aqslphsd333eu","content":"<h1 id=\"1-计算机网络体系结构\"><a href=\"#1-计算机网络体系结构\" class=\"headerlink\" title=\"1.计算机网络体系结构\"></a>1.计算机网络体系结构</h1><ul>\n<li><strong>协议</strong>：协议是控制两个对等实体（或多个实体）进行通信的规则的集合。网络协议主要由以下三要素组成：语法、语义、同步。</li>\n<li><strong>网络体系结构</strong>：网络体系结构是计算机网络的分层、每层的功能以及每层使用到的协议的集合。</li>\n</ul>\n<a id=\"more\"></a> \n<h2 id=\"1-1-计算机网络体系结构\"><a href=\"#1-1-计算机网络体系结构\" class=\"headerlink\" title=\"1.1 计算机网络体系结构\"></a>1.1 计算机网络体系结构</h2><ul>\n<li>国际标准化组织（ISO）提出<strong>开放系统互连参考模型OSI/RM</strong>(Open System Interconnection Reference Model)。OSI是一个七层协议体系结构，如图1(a)。</li>\n<li>美国国防部提出<strong>TCP/IP体系结构</strong>，TCP/IP是一个四层的体系结构，如图1(b)。</li>\n<li>OSI的七层体系结构的理论完整，但即复杂又不实用。TCP/IP是事实上的国际标准。</li>\n<li>从实质上讲，TCP/IP只有最上面的三层，因为最下面的网络接口层并没有什么具体内容。因此在学习计算机网络的原理时，采用折中的办法，即综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，如图1(c)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"70%\"></p>\n<h2 id=\"1-2-各层的主要功能\"><a href=\"#1-2-各层的主要功能\" class=\"headerlink\" title=\"1.2 各层的主要功能\"></a>1.2 各层的主要功能</h2><p>（1）<strong>应用层</strong>(application layer)</p>\n<ul>\n<li>功能：应用层是体系结构中的最高层。应用层的任务是<strong>通过应用进程间的交互来完成特定网络应用</strong>。这里的<strong>进程</strong>就是指<strong>主机中正在运行的程序</strong>。</li>\n<li>协议：应用层协议定义的是<strong>应用进程间通信和交互的规则</strong>。对于不同的网络应用需要有不同的应用层协议。应用层协议有：域名系统DNS，支持万维网应用的<strong>HTTP</strong>协议，支持电子邮件的<strong>SMTP</strong>协议，支持文件传送的<strong>FTP</strong>协议等。我们把应用层交互的数据单元成为<strong>报文</strong>(message)。</li>\n</ul>\n<p>（2）<strong>运输层</strong>(transport layer)</p>\n<ul>\n<li>功能：运输层的任务就是负责向<strong>两个主机中进程之间的通信</strong>提供<strong>通用的数据传输</strong>服务。应用进程利用该服务传送应用层报文。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付给上面应用层中的相应的进程。</li>\n<li>协议：运输层主要使用两种协议：1.<strong>传输控制协议TCP</strong>——提供面向连接的、可靠的数据服务，数据传输的单位是<strong>报文段</strong>(segment)；2.<strong>用户数据包协议UDP</strong>——提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是<strong>用户数据报</strong>。</li>\n<li>重要设备：网关(gateway)。</li>\n</ul>\n<p>（3）<strong>网络层</strong>(network layer)</p>\n<ul>\n<li>功能：（1）网络层负责为分组交换网上的不同<strong>主机</strong>提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成<strong>分组</strong>或<strong>包</strong>进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫做<strong>IP数据报</strong>或简称<strong>数据报</strong>；<br>注：无论在哪一层传送的数据单元，都可笼统地用<strong>“分组”</strong>来表示<br>（2）网络层的另一个任务是选择合适的路由，使源主机运输层传下来的分组，能够通过网络中的路由器找到目的主机。</li>\n<li>协议：（1）互联网是大量的<strong>异构</strong>网络通过<strong>路由器</strong>相互连接起来的。互联网使用的网络协议是无连接的<strong>网际协议IP</strong>(Internet Protocol)和许多种路由选择协议，因此互联网的网络层也叫做<strong>网际层</strong>或<strong>IP层</strong>；（2）与IP协议配套使用的还有三个协议：地址解析协议ARP、网际控制报文协议ICMP和网际组管理协议IGMP；（3）路由选择协议。</li>\n<li>重要的设备：路由器(router)。</li>\n</ul>\n<p>（4）<strong>数据链路层</strong>(data link layer)</p>\n<ul>\n<li>功能：两台主机之间的数据传输，总是在一段一段的<strong>链路</strong>上传送的，也就是说，在两个相邻结点之间（主机和路由器之间或两个路由器之间）传送数据是直接传送的（点对点）。数据链路层把网络层交下来的IP数据报（或数据报/分组/包）<strong>封装成帧</strong>(framing)发送到链路上，在两个相邻结点间的链路上传送<strong>帧</strong>(frame)，以及把接受到的帧中的数据取出并上交给网络层。</li>\n<li>重要设备：网桥(bridge)、交换机（多接口的网桥）。</li>\n</ul>\n<p>（5）<strong>物理层</strong>(physical layer)</p>\n<ul>\n<li>功能：在物理层上所数据的单位是<strong>比特</strong>。物理层的任务就是<strong>透明地传送比特流</strong>。也就是说，发送方发送1(或0)时，接收方应当收到1(或0)而不是0(或1)。因此物理层要考虑用多大的电压代表”1”或”0”，以及接收方如何识别出发送方所发送的比特，物理层还要确定连接电缆的插头应当有多少根引脚以及各条引脚应如何连接。注意，传递信息所利用的一些物理媒体/传输媒体，如双绞线、同轴电缆、光缆、无线信道等，并不在物理层协议之内而是在物理层协议的下面，有人把物理媒体称为第0层。<br>综上，物理层的作用正视要经可能的屏蔽掉传输媒体和通信手段的差异，是物理层之上的数据链路层感觉不到这些差异，使数据链路层只需要考虑如何完成本层的协议和服务。</li>\n<li>中间设备：转发器(repeater)</li>\n</ul>\n<h2 id=\"1-3-数据在各层之间的传递过程\"><a href=\"#1-3-数据在各层之间的传递过程\" class=\"headerlink\" title=\"1.3 数据在各层之间的传递过程\"></a>1.3 数据在各层之间的传递过程</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE2_%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%90%84%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E9%80%92%E8%BF%87%E7%A8%8B.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假定主机1的应用进程$AP_1$向主机2的应用进程$AP_2$传送数据。</li>\n<li>$AP_1$先将其数据交给本主机的第5层(应用层)。第5层加上必要的控制信息$H_5$就变成了下一层的数据单元。第4层(运输层)收到这个数据单元后，加上本层的控制信息$H_4$，再交给第3层(网络层)，成为第3层的数据单元。依此类推。不过到了第2层(数据链路层)后，控制信息被分成两部分，分别加到本层数据单元的首部($H_2$)和尾部($T_2$)；而第1层(物理层)由于是比特流的传送，所以不再加上控制信息。</li>\n<li>当这一串的比特流离开主机1经网络的物理媒体传送到路由器时，就从路由器的第一层一次上升到第三层。每一层都根据控制信息进行必要的操作，然后将控制信息剥去，将该层剩下的数据单元交给更高的一层。当分组上升到第3层时，就根据首部中的目的地址查找路由器中的转发表，找到转发分组的接口，然后往下传送到第2层，加上新的首部和尾部，再到最下面的第1层，然后在物理媒体上把每一个比特发送出去。</li>\n<li>当这一串的比特流离开路由器到达目的主机2时，就从主机2的第1层按照上面讲过的方式，一次上升到第5层。最后，把应用进程$AP_1$发送的数据交给目的站的应用进程$AP_2$。</li>\n<li>对于用户来说，这个复杂的过程被屏蔽了，以至于感觉应用进程$AP_1$是直接把数据交给了应用进程$AP_2$。同理，任何两个同样的层次（例如两个系统的第4层）之间，也好像如同图2中的水平虚线所示的那样，把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层“之间的通信。之前提到的各层协议，实际上就是在各个对等层之间传递数据时的各项规定。</li>\n</ul>\n<h2 id=\"1-4-TCP-IP体系结构\"><a href=\"#1-4-TCP-IP体系结构\" class=\"headerlink\" title=\"1.4 TCP/IP体系结构\"></a>1.4 TCP/IP体系结构</h2><p>前面已经说过，TCP/IP的体系结构比较简单，它只有四层。图3给出了用这四层协议表示方法的例子。注意，图中的路由器在转发分组时最高只用到网络层而没有使用运输层和应用层。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE3_TCPIP%E5%9B%9B%E5%B1%82%E5%8D%8F%E8%AE%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"></p>\n<p>还有一种方法，就是分层次画出具体的协议来表示TCP/IP协议族，如图4。它的特点是上下两头大而中间小：应用层和网络接口层都有多种协议，而中间的IP层很小，上层的各种协议都向下汇聚到一个IP协议中。这种像沙漏计时器形状的TCP/IP协议族表明：TCP/IP协议<strong>可以为各式各样的应用提供服务</strong>（所谓的everying over IP），同时TCP/IP协议也<strong>允许IP协议在各式各样的网络构成的互联网上运行</strong>（所谓的 IP over everything）。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE4_%E6%B2%99%E6%BC%8F%E8%AE%A1%E6%97%B6%E5%99%A8%E5%BD%A2%E7%8A%B6%E7%9A%84TCP-IP%E5%8D%8F%E8%AE%AE%E6%97%8F.JPG\" width=\"70%\" height=\"70%\"></p>\n<h1 id=\"2-网络层\"><a href=\"#2-网络层\" class=\"headerlink\" title=\"2.网络层\"></a>2.网络层</h1><h2 id=\"2-1网际协议IP\"><a href=\"#2-1网际协议IP\" class=\"headerlink\" title=\"2.1网际协议IP\"></a>2.1网际协议IP</h2><p>互联网由多种异构网络互连而成，参加互联的计算机网络都使用相同的网际协议IP，因此实现互联。<br>网际协议IP是TCP/IP体系中两个最重要的协议之一。与IP协议配套使用的还有三个协议：</p>\n<ul>\n<li>地址解析协议ARP </li>\n<li>网际控制报文协议ICMP</li>\n<li>网际组管理协议IGMP</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE-%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE%E9%85%8D%E5%A5%97%E5%8D%8F%E8%AE%AE.JPG\" width=\"40%\" height=\"40%\"></p>\n<h2 id=\"2-2-IP地址及其表示方法\"><a href=\"#2-2-IP地址及其表示方法\" class=\"headerlink\" title=\"2.2 IP地址及其表示方法\"></a>2.2 IP地址及其表示方法</h2><p>整个的互联就是一个单一的、抽象的网络。IP地址就是给因特网上的每一个主机(或路由器)的每一个接口分配一个在全世界范围内位移的<strong>32位</strong>的标识符。IP地址的结构使我们可以在互联网上很方便地进行寻址。<br>IP地址的编制方法经过了三个历史阶段：</p>\n<ul>\n<li>分类的IP地址。</li>\n<li>子网的划分。这是对最基本的编址方法的改进。</li>\n<li>构成超网。这是无分类编制方法。</li>\n</ul>\n<h2 id=\"2-3-分类的IP地址\"><a href=\"#2-3-分类的IP地址\" class=\"headerlink\" title=\"2.3 分类的IP地址\"></a>2.3 分类的IP地址</h2><p>（1）概念<br>分类的IP地址就是将IP地址划分为若干个固定类，每一类地址都由两个固定长度的字段组成，记为：<code>IP地址 ::= {&lt;网络号&gt;,&lt;主机号&gt;}</code><br>注：第一个字段是<strong>网络号</strong>，它标志主机（或路由器）所连接到的网络。一个网络号在整个互联网内必须是唯一的。第二个字段是<strong>主机号</strong>，它标志该主机（或路由器）。一个主机号在它前面所指明的网络范围内必须是唯一的。故，<strong>一个IP地址在整个互联网范围内是唯一的</strong>。<br>图5给出了各种IP地址的网络号字段和主机号字段。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE5-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%86%E7%B1%BB.JPG\" width=\"60%\" height=\"60%\">（2）点分十进制记法<br>对主机和路由器来说，IP地址都是32位的二进制代码。为了提高可读性，常采用点分十进制记法。如图6所示。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE6-%E7%82%B9%E5%88%86%E5%8D%81%E8%BF%9B%E5%88%B6%E8%AE%B0%E6%B3%95.JPG\" width=\"90%\" height=\"90%\"> （3）常用的三种类别的IP地址<br>图7为IP地址的指派范围：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE7-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E6%8C%87%E6%B4%BE%E8%8C%83%E5%9B%B4.JPG\" width=\"100%\" height=\"100%\"> 注1：(1)A类地址的网络号字段占1个字节，有7位可用（第一位已固定为0），可指派的网络号个数为126(即$2^7-2$)。减2的原因：网络号字段为全0的IP地址和网络号为127(即01111111)保留;(2)A类地址的主机号占3个字节，最大主机数是$2^{24}-2$，即16777214。减2的原因：全0的主机号字段和全1的主机号字段保留;(3)IP地址空间共有$2^{32}$个地址，整个A类网络地址空间共有$2^{31}$个地址。故占整个IP地址空间的50%。<br>注2：(1)B类地址的网络号字段有2个字节，有14位可用(前两位固定为10)。无论如何取也不会全0或全1，因此不存在减2。但<code>128(1000 0000).0.0.0</code>默认不分配，可指派的最小网络地址是<code>128.1(0000 0001).0.0</code>。因此B类地址可指派的网络数为$2^{14}-1$，即16383;(2)B类地址的每一个网络上的最大主机数为$2^{16}-2$，即65534。全0和全1的主机号保留;(3)整个B类地址空间共约$2^{30}$个地址，占整个IP地址空间的25%。<br>注3：(1)C类地址的网络号字段有3个字节，有21位可用（前面3为固定为110），C类网络地址<code>192(1100 0000).0.0.0</code>也是不指派的，故C类最小网络地址为<code>192.0.1(0000 0001).0</code>，故C类地址可指派的网络数为$2^{21}-1$，即2097151个;(2)每一个C类地址的最大主机数是$2^8-2$，即254个;(3)整个C类地址空间共约$2^{29}$个地址，占整个IP地址的12.5%。<br>（4）IP地址的重要特点</p>\n<ul>\n<li>IP地址分两个等级的好处是：<ul>\n<li>第一，IP地址管理机构在分配IP地址时只分配网络号（第一级），而剩下的主机号（第二级）则由得到该网络号的单位自行分配。</li>\n<li>第二，路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目的主机），这样就可以使得路由表中的项目数大幅减少，从而减少了路由表所占的存储空间以及查找路由表的时间。</li>\n</ul>\n</li>\n<li>实际上IP地址是标志一个主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址，其网络号必须是不同的。由于一个路由器至少应当连接到两个网络，因此一个路由器至少应当有两个不同的IP地址。</li>\n<li>按照互联网的观点，一个网络是指具有相同网络号的主机的集合。因此，用转发器或网桥连接起来的若干个局域网仍为一个网络，因为这些局域网都有相同的网络号。具有不同网络号的局域网必须使用路由器进行互联。</li>\n</ul>\n<p>（5）示例<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE8-%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%AD%E7%9A%84IP%E5%9C%B0%E5%9D%80.JPG\" width=\"75%\" height=\"75%\"> 图8为三个局域网（LAN_1,LAN_2,LAN_3）通过三个路由器(R_1,R_2,R_3)互连起来所构成的一个互联网。其中局域网LAN_2是由两个网段通过网桥B互连的。图中的小圆圈表示需要有一个IP地址。<br>从图中可以注意到：</p>\n<ul>\n<li>在同一个局域网上的主机或路由器的IP地址中的网络号必须是一样的。图中所示的网络号是IP地址中的网络号字段的值，也即主机号全为0的网络IP地址。</li>\n<li>用网桥（它只在链路层工作）互联的网段仍然是一个局域网，只能有一个网络号。</li>\n<li>路由器总是具有两个或两个以上的IP地址。即路由器的每一个接口都有一个不同的网络号的IP地址。</li>\n</ul>\n<h2 id=\"2-4-IP地址与硬件地址\"><a href=\"#2-4-IP地址与硬件地址\" class=\"headerlink\" title=\"2.4 IP地址与硬件地址\"></a>2.4 IP地址与硬件地址</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE9-IP%E5%9C%B0%E5%9D%80%E4%B8%8E%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80%E7%9A%84%E5%8C%BA%E5%88%AB.JPG\" width=\"70%\" height=\"70%\"> IP地址放在IP数据报的首部，而硬件地址则放在MAC帧的首部。在网络层和网络层以上使用的是IP地址，而数据链路层及以下使用的是硬件地址。如图9中，当IP数据报放入数据链路层的MAC帧中以后，整个的IP数据报就成为MAC帧的数据，因而在数据链路层看不见数据报的IP地址。</p>\n<h2 id=\"2-5-地址解析协议ARP\"><a href=\"#2-5-地址解析协议ARP\" class=\"headerlink\" title=\"2.5 地址解析协议ARP\"></a>2.5 地址解析协议ARP</h2><p>地址解析协议ARP为网络层IP地址和数据链路层MAC地址提供动态映射，即<code>IP地址-&gt;MAC地址</code>。</p>\n<ul>\n<li>ARP使用广播的方式获得物理地址。</li>\n<li>ARP高速缓存：<ul>\n<li>每一个主机中都设有一个ARP高速缓存(ARP cache)，里面存放的是最近获得的局域网上各主机和路由器的IP地址到硬件地址的映射表。</li>\n<li>所以，当发送分组时，计算机在发送ARP请求之前总是先在ARP缓存中寻找所需的绑定，若有，则无须广播。</li>\n<li>可以通过命令 “ arp -a” 来查看本机的ARP缓存中内容。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-6-IP数据报的格式\"><a href=\"#2-6-IP数据报的格式\" class=\"headerlink\" title=\"2.6 IP数据报的格式\"></a>2.6 IP数据报的格式</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE10-IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"80%\" height=\"80%\"></p>\n<h2 id=\"2-7-划分子网\"><a href=\"#2-7-划分子网\" class=\"headerlink\" title=\"2.7 划分子网\"></a>2.7 划分子网</h2><p>（1）划分子网<br>从1985年起在IP地址中又增加了一个“子网号字段”，使两级的IP地址变成为三级的IP地址。这种做法叫做<strong>划分子网</strong>，或子网寻址或子网路由选择。<br>划分子网的基本思路如下：</p>\n<ul>\n<li>划分子网的方法是<strong>从网络的主机号借用若干位作为子网号</strong>，而主机号也就相应减少了若干位。于是两级IP地址在<strong>本单位内部</strong>就变成了<strong>三级IP地址</strong>：网络号、子网号和主机号，记为<br><code>IP地址::={&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}</code></li>\n<li>子网号在网外是不可见的，仅在子网内使用</li>\n<li>凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付给目的主机。</li>\n</ul>\n<p>（2）子网掩码<br>子网掩码：子网号的位数是可变的，为了反映有多少位用于表示子网号，采用子网掩码。<br><code>IP地址　::={&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}</code><br><code>子网掩码::={11....11,11....11,00....00}</code>（即网络号和子网号全1，主机号全0）<br>（3）默认子网掩码<br>A类网络：<code>255.0.0.0</code><br>B类网络：<code>255.255.0.0</code><br>C类网络：<code>255.255.255.0</code><br>（4）广播地址<br>用途：要用广播的方式（一对所有进行通信）发送一个分组时，目的IP地址是一个广播地址。<br>特点：主机号部分全1<br>（5）例题<br><strong>例题1</strong>：假如在一个B类网络<code>128.10.0.0</code>中，我们准备从16位主机号部分里借用3位进行子网划分，求对应的子网掩码 。<br><strong>分析</strong>：因为是B类网络，所以网络号部分是16位，又因为子网号部分是3位，所以子网掩码里就有16+3=19位1，剩下的32-19=13位主机号部分全0。<br><strong>结果</strong>：<code>11111111 11111111 11100000 00000000</code>，即<code>255.255.224.0</code></p>\n<p><strong>例题2</strong>：假如一台主机的IP地址是<code>128.10.32.6</code>，子网掩码是<code>255.255.224.0</code>，那么该主机所在子网的子网地址又是什么呢？<br><strong>分析</strong>：子网地址也是一个特殊的IP地址，就是网络号部分和子网号部分不变，主机号部分全零的地址。用逻辑“与” 操作。<br><code>子网地址 = 主机IP地址 AND 子网掩码</code><br><strong>答案</strong>：子网地址 = <code>128.10.00100000.6</code>AND<code>255.255.11100000.0</code>=<code>128. 10.00100000.0</code>=<code>128. 10.32.0</code></p>\n<p><strong>例题3</strong>：在子网128.10.32.0中，广播地址是多少呢？<br><strong>答案</strong>：把主机号部分(13位)变成全1，<code>128.10.00111111.11111111</code>即<code>128.10.63.255</code></p>\n<p><strong>例题4</strong>：一家公司申请到的网络地址是<code>202.119.230.0</code>，现在由于工作上的需要，要把该网络划分为14个子网，并且又希望每个子网的规模尽可能的大，则应选用的子网掩码是多少？<br><strong>分析</strong>：若全0、全1的子网地址可以分配，则若借用x位进行子网划分，可以划分出$2^x$个子网；反之，则可以划分$2^x-2$个子网。对于本题中，x=4满足需求。因为是C类地址，所以其子网掩码是24+4=28比特的1, 32-28=4比特的0。<br><strong>答案</strong>： <code>255.255.255.11110000</code>即 <code>255.255.255.240</code></p>\n<p><strong>例题5</strong>：设有一个网络，其网络地址为<code>210.10.30.0</code>，若其选用的子网掩码是<code>255.255.255.192</code>，则：<br><strong>（1）可以划分多少个子网（注：全0全1的子网地址不分配）</strong><br><strong>分析</strong>：因为该网络是一个C类网络，默认的子网掩码是<code>255.255.255.0</code>，因为<code>192=11000000B</code>, 可见，是从主机号里面是借了2位进行子网划分，又因为<strong>全0全1 的子网地址不分配</strong>。<br><strong>答案</strong>：划分子网的个数是$2^2-2=2$<br><strong>（2）每个子网容纳的主机个数是多少？</strong><br><strong>分析</strong>：因为主机号部分的位数也就是子网掩码中0的个数，有6位。<br>答案：每个子网容纳的主机个数是 $2^6-2=62$<br><strong>注意</strong>：即使题目中没有说明，全零和全1的主机地址始终是不分配的<br><strong>（3）每个子网的子网地址分别是什么？</strong><br><strong>分析</strong>：子网地址中高24位是网络号部分，肯定是<code>210.10.30</code>，子网地址中主机号部分是全0，只有子网号这两位去除全0和全1外，还有两种选择，一个是01，一个是10，分别分配给两个子网。<br><strong>答案</strong>：子网1： <code>210.10.30.01000000</code>即<code>210.10.30.64</code><br>子网2：<code>210.10.30.10000000</code>即<code>210.10.30.128</code><br><strong>（4）每个子网中可分配的IP地址的范围多少？广播地址是多少？</strong><br><strong>分析</strong>：每个子网中第一个可用的IP地址就是主机号部分除了最后一位为1，其余位均为0的地址，最后一个可分配的IP地址是刚好反过来，主机号部分最后一位是0，其余位均为1。<br><strong>答案</strong>：子网1： <code>210.10.30.01000001</code>至 <code>210.10.30.01111110</code>。即<code>210.10.30.65</code>至<code>210.10.30.126</code><br>广播地址：<code>210.10.30.01111111</code>即<code>210.10.30.127</code><br>子网2：<code>210.10.30.10000001</code>至<code>210.10.30.10111110</code>。即<code>210.10.30.128</code>至<code>210.10.30.190</code><br>广播地址： <code>210.10.30.10111111</code>即<code>210.10.30.191</code></p>\n<h2 id=\"2-8-无分类编制CIDR-构造超网\"><a href=\"#2-8-无分类编制CIDR-构造超网\" class=\"headerlink\" title=\"2.8 无分类编制CIDR(构造超网)\"></a>2.8 无分类编制CIDR(构造超网)</h2><p>（1）CIDR<br><strong>CIDR消除了传统的A类、B类和C类地址以及划分子网的概念</strong>。CIDR使IP地址从三级编址（使用子网掩码）又回到了两级编织，但这已是<strong>无分类的两级编址</strong>，记为：<code>IP地址::= {&lt;网络前缀&gt;,&lt;主机号&gt;}</code><br>（2）CIDR记法<br>CIDR使用斜线记法，即在IP地址后面加上斜线”/“，然后写上网络前缀所占的位数；CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。我们只要知道CIDR地址块中的任一地址，就可以知道这个地址块的起始地址(即最小地址)和最大地址，以及地址块中的地址数。<br>例如：已经IP地址<code>128.14.35.7/20</code>是某CIDR地址块中的一个地址，现在把它写成二进制表示，其中的前20位是网络前缀，而前缀后面的12位是主机号。<br><code>128.14.35.7/20</code>=<code>10000000 00001110 0010</code>0011 00000111（前20位是网络前缀，后12位是主机号）<br>这个地址所在的地址块中的最小地址和最大地址可以很方便的得出：<br>最小地址： <code>10000000 00001110 0010</code>0000 00000000 即<code>128.14.32.0</code><br>最大地址：<code>10000000 00001110 0010</code>1111 11111111 即<code>128.14.47.255</code><br>当然，这两个主机号是全0和全1的地址一般不分配。通常只用这两个地址之间的地址。<br>（3）地址掩码<br>为了更方便地进行路由选择，CIDR使用32位的地址掩码（也可称子网掩码）。网络前缀全1，主机号全0。<br>注：CIDR不使用子网，是指CIDR并没有在32位地址中指明若干位作为子网字段。但分配到一个CIDR地址块的单位，仍然可以在本单位内根据需要划分出一些子网。这些子网也都只有一个网络前缀和一个主机号字段，但网络的前缀比整个单位的网络前缀要长些。<br>（4）例题<br><strong>例题1</strong>：<code>128.14.32.0/20</code>表示的地址块共有多少个地址？最大和最小的地址分别是什么？<br><strong>分析</strong>：因为是一个/20的地址块，所以主机号部分共有32-20=12位，所以地址个数是$2^{12}=4096$个。如图为CIDR地址块中最小和最大地址示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE11-CIDR%E5%9C%B0%E5%9D%80%E5%9D%97.JPG\" width=\"70%\" height=\"70%\"> <strong>例题2</strong>：假设某ISP（因特网服务提供者）拥有CIDR地址块<code>202.192.0.0/16</code>。先后有四所大学（A、B、C、D）向该ISP分别申请大小为4000、2000、4000、 8000个IP地址的地址块，试为ISP给这四所大学分配地址块。<br><strong>分析</strong>：<br><strong>A大学</strong>：$2^{12}=4096&gt;4000$，所以地址块中主机号部分是12位，网络前缀的长度=32-12=20位<br>起始地址：<code>202.192.0000</code>0000.0/20 即<code>202.192.0.0/20</code><br>结束地址：<code>202.192.0000</code>1111.255 即<code>202.192.15.255</code><br><strong>B大学</strong>：<code>2^{11}=2048&gt;2000</code>，网络前缀的长度=32-11=21位<br>起始地址： <code>202.192.00010</code>000.0/21 即<code>202.192.16.0/21</code><br>结束地址：<code>202.192.00010</code>111.255 即<code>202.192.23.255</code><br><strong>C大学</strong>：$2^{12}=4096&gt;4000$，网络前缀的长度=32-12=20位<br>起始地址：<code>202.192.0010</code>0000.0/20 即<code>202.192.32.0/20</code><br>结束地址：<code>202.192.0010</code>1111.255 即<code>202.192.47.255</code><br><strong>D大学</strong>：$2^{13}=8192&gt;8000$，网络前缀的长度=32-13=19位<br>起始地址：<code>202.192.010</code>00000.0/19 即<code>202.192.64.0/19</code><br>结束地址：<code>202.192.010</code>11111.255 即<code>202.192.95.255</code></p>\n<h2 id=\"2-9-IP分组转发的流程\"><a href=\"#2-9-IP分组转发的流程\" class=\"headerlink\" title=\"2.9 IP分组转发的流程\"></a>2.9 IP分组转发的流程</h2><p><strong>路由表的表项 ：（目的网络地址，子网掩码，下一跳路由器IP地址）</strong><br><strong>示例</strong>：已知图4-24所示的互联网，以及路由器$R_1$中的部分路由表。现在源主机$H_1$向目的主机$H_2$发送分组。试讨论$R_1$收到$H_1$向$H_2$发送的分组后查找路由表的过程。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE12-IP%E5%88%86%E7%BB%84%E8%BD%AC%E5%8F%91.JPG\" width=\"80%\" height=\"80%\"> <strong>分析</strong>：</p>\n<ul>\n<li>源主机$H_1$向目的主机$H_2$发送的分组的目的地址是$H_2$的IP地址：128.30.33.138。</li>\n<li>源主机$H_1$首先要进行的操作是要判断：发送的这个分组，是在本子网上进行直接交付还是要通过本子网上的路由器进行间接交付？<ul>\n<li>源主机$H_1$把本子网的子网掩码<code>255.255.255.128</code>与目的主机$H_2$的IP地址<code>128.30.33.138</code>逐位相与(AND操作)，得出<code>128.30.33.128</code>，它不等于$H_1$的网络地址<code>128.30.33.0</code>。这说明$H_2$与$H_1$不在同一个子网上。因此$H_1$不能把分组直接交付$H_2$，而必须交给子网上的默认路由器$R_1$，由$R_1$来转发。</li>\n</ul>\n</li>\n<li>路由器$R_1$在收到一个分组后，就在其路由表中逐行寻找有无匹配的网络地址。<ul>\n<li>先看$R_1$路由表中的第一行。用这一行的子网掩码<code>255.255.255.128</code>和收到的分组的目的地址<code>128.30.33.138</code>逐位相与，得出<code>128.30.33.128</code>。然后和这一行给出的目的网络地址<code>128.30.33.0</code>进行比较。但比较的结果是不一致,即不匹配。</li>\n</ul>\n</li>\n<li>用同样方法继续往下找第二行。用第二行的子网掩码<code>255.255.255.128</code>和该分组的目的地址<code>128.30.33.138</code>逐位相与，结果是<code>128.30.33.128</code>。这个结果和第二行的目的网络地址<code>128.30.33.128</code>相匹配，说明这个网络(子网2)就是收到的分组所要寻找的目的网络。于是不需要再继续查找下去。$R_1$把分组从接口1直接交付主机$H_2$（它们都在一个子网上）。</li>\n</ul>\n<h2 id=\"2-10-网际控制报文协议ICMP\"><a href=\"#2-10-网际控制报文协议ICMP\" class=\"headerlink\" title=\"2.10 网际控制报文协议ICMP\"></a>2.10 网际控制报文协议ICMP</h2><p>(1)ICMP</p>\n<ul>\n<li>为更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP(Internet Control Message Protocol)。</li>\n<li>ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP不是高层协议，是IP层的协议。</li>\n<li>ICMP报文作为IP层数据报的数据，加上数据报的首部，组成IP数组报发送出去。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/ICMP%E6%8A%A5%E6%96%87%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"60%\" height=\"60%\"> (2)ICMP报文种类<br>ICMP报文的种类有两种，即<strong>ICMP差错报文</strong>和<strong>ICMP询问报文</strong>。<br>ICMP差错报告报文分五种：</p>\n<ul>\n<li>终点不可达</li>\n<li>时间超过</li>\n<li>源站抑制</li>\n<li>参数问题</li>\n<li>路由重定向</li>\n</ul>\n<p>常用的ICMP询问报文有两种：</p>\n<ul>\n<li>回送请求和回答报文</li>\n<li>时间戳请求和回答报文</li>\n</ul>\n<p>（3）ICMP的应用<br>ICMP协议可以实现网络可达性检查、网络时延测量、网络路由追踪、网络安全排查等方面都有重要的应用。</p>\n<ul>\n<li>Tracert（跟踪路由）基于<strong>ICMP终点不可达和时间超过差错报告报文</strong>原理实现的。</li>\n<li>Ping（因特网包探索器）基于<strong>ICMP询问报文类型中的回送请求和回答报文</strong>实现的。</li>\n</ul>\n<h2 id=\"2-11-虚拟专用网络VPN和网络地址转换NAT\"><a href=\"#2-11-虚拟专用网络VPN和网络地址转换NAT\" class=\"headerlink\" title=\"2.11 虚拟专用网络VPN和网络地址转换NAT\"></a>2.11 虚拟专用网络VPN和网络地址转换NAT</h2><p><strong>虚拟专用网</strong>：利用公共网络（如Internet）来构建的专用网络技术，保证了VPN中任何一对计算机之间的通信对外界是隐藏的。<br>（1）VPN的编址<br>VPN所提供的编址选择与专用网络所提供的是一样的，可以根据需要选择</p>\n<ul>\n<li>本地地址——仅在机构内部使用的IP地址，可以由本机构自行分配，而不需要向因特网的管理机构申请</li>\n<li>全球地址——全球惟一的IP地址，必须向因特网的管理机构申请</li>\n</ul>\n<p>本地地址：IANA保留了三块只能用于专用互联网内部通信的IP地址空间：<br>前缀 最低地址 最高地址<br><code>10/8</code> <code>10.0.0.0</code> <code>10.255.255.255</code><br><code>172.16/12</code> <code>172.16.0.0</code> <code>172.31.255.255</code><br><code>192.168/16</code> <code>192.168.0.0</code> <code>192.168.255.255</code><br>（2）VPN的工作原理</p>\n<ul>\n<li>VPN的实现主要使用了两种基本技术：隧道传输和加密技术。</li>\n<li>VPN定义了两个网络的路由器之间通过Internet的一个隧道，并使用IP-in-IP封装通过隧道转发数据报。</li>\n<li>为了保证保密性，VPN把外发的数据报加密后，封装在另一个数据报中传输。</li>\n<li>隧道接收路由器将数据报解密，还原出内层数据报，然后转发该数据报。</li>\n</ul>\n<p>（3）网络地址转换NAT<br>网络地址转换NAT(Network Address Translation)方法于1994年提出，用来解决本地编址的内部网络与外网通信的问题。需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球地址IPG。所有使用本地地址的主机在和外界通信时都要在NAT路由器上将其本地地址转换成IPG才能和因特网连接。</p>\n<h2 id=\"2-12-下一代网际协议IPv6\"><a href=\"#2-12-下一代网际协议IPv6\" class=\"headerlink\" title=\"2.12 下一代网际协议IPv6\"></a>2.12 下一代网际协议IPv6</h2><p>IPv6 将地址从IPv4的32bit增大到了128bit。</p>\n<h1 id=\"3-运输层\"><a href=\"#3-运输层\" class=\"headerlink\" title=\"3.运输层\"></a>3.运输层</h1><h2 id=\"3-1-运输层\"><a href=\"#3-1-运输层\" class=\"headerlink\" title=\"3.1 运输层\"></a>3.1 运输层</h2><h3 id=\"运输层的作用\"><a href=\"#运输层的作用\" class=\"headerlink\" title=\"运输层的作用\"></a>运输层的作用</h3><p>网络层为<strong>主机之间</strong>提供逻辑通信，而运输层为<strong>应用进程之间</strong>提供端到端的逻辑通信，如下图所示:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E8%BF%90%E8%BE%93%E5%B1%82%E4%BD%9C%E7%94%A8.JPG\" width=\"70%\" height=\"50%\"></p>\n<h3 id=\"运输层的两个主要协议\"><a href=\"#运输层的两个主要协议\" class=\"headerlink\" title=\"运输层的两个主要协议\"></a>运输层的两个主要协议</h3><p>TCP/IP运输层的两个主要协议都是因特网的正式标准，即：</p>\n<ul>\n<li>用户数据报协议UDP</li>\n<li>传输控制协议TCP</li>\n</ul>\n<p>下图给出了这两种协议在协议栈中的位置：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.JPG\" width=\"40%\" height=\"40%\"> 按OSI的术语，两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元TPDU。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为<strong>TCP报文段(segment)</strong>或<strong>UDP用户数据报</strong>。<br>UDP与TCP对比：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E7%89%B9%E7%82%B9%E5%AF%B9%E6%AF%94.JPG\" width=\"70%\" height=\"50%\"> 一些应用和应用层协议主要使用的运输层协议(TCP或UDP)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E5%BA%94%E7%94%A8%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8D%8F%E8%AE%AE.JPG\" width=\"70%\" height=\"70%\"></p>\n<h3 id=\"端口\"><a href=\"#端口\" class=\"headerlink\" title=\"端口\"></a>端口</h3><p>运输层具有复用和分用的功能：</p>\n<ul>\n<li>应用层所有的应用进程可以通过运输层再传送到IP层（网络层），这就是<strong>复用</strong>；</li>\n<li>运输层从IP层收到数据后必须交付指明的应用进程，这就是<strong>分用</strong>。</li>\n</ul>\n<p>端口：是<strong>应用层的各种协议进程与运输实体进行层间交互的一种地址</strong>：</p>\n<ul>\n<li>在UDP和TCP的首部格式中，都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付给应用层的目的应用进程。</li>\n<li>TCP/IP运输层用一个16位端口号来标志一个端口。</li>\n<li>因此，<strong>两个计算机中的进程要相互通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）</strong>。</li>\n</ul>\n<p>因特网上的计算机通信是采用客户-服务器的方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类：<br>（1）<strong>服务器端使用的端口号</strong><br>分为两类：熟知端口号和登记端口号。</p>\n<ul>\n<li><strong>熟知端口号</strong>：数值为0~1023。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。<br>下图为一些常用的熟知端口号：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E7%86%9F%E7%9F%A5%E7%AB%AF%E5%8F%A3%E5%8F%B7.JPG\" width=\"70%\" height=\"50%\"></li>\n<li><strong>登记端口号</strong>：数值为1024~49151。为没有熟知端口号的应用程序使用。但要使用须在IANA按规定登记，以防重复。</li>\n</ul>\n<p>（2）<strong>客户端使用的端口号</strong><br>数值为49152~65535。这类端口号留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。</p>\n<h2 id=\"3-2-用户数据报协议UDP\"><a href=\"#3-2-用户数据报协议UDP\" class=\"headerlink\" title=\"3.2 用户数据报协议UDP\"></a>3.2 用户数据报协议UDP</h2><h3 id=\"UDP概述\"><a href=\"#UDP概述\" class=\"headerlink\" title=\"UDP概述\"></a>UDP概述</h3><p>UDP的主要特点：</p>\n<ul>\n<li><strong>UDP是无连接的</strong>，即发送数据之前不需要建立连接</li>\n<li><strong>UDP使用尽最大努力交付</strong>，即不保证可靠交付，因此主机不需要维持复杂的连接状态表</li>\n<li><strong>UDP是面向报文的</strong>。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E6%98%AF%E9%9D%A2%E5%90%91%E6%8A%A5%E6%96%87.JPG\" width=\"60%\" height=\"60%\"></li>\n<li><strong>UDP没有拥塞控制</strong>，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用很重要，很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。</li>\n<li><strong>UDP支持一对一，一对多，多对一和多对多的交互通信</strong>。</li>\n<li><strong>UDP的首部开销小</strong>，只有8个字节，比TCP的20个字节的首部要短。</li>\n</ul>\n<h3 id=\"UDP的首部格式\"><a href=\"#UDP的首部格式\" class=\"headerlink\" title=\"UDP的首部格式\"></a>UDP的首部格式</h3><p>用户数据报UDP有两个字段：数据字段和首部字段。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E9%A6%96%E9%83%A8.JPG\" width=\"60%\" height=\"60%\"> 首部字段很简单，只有8个字节，由四个字段组成，如上图所示。<strong>每个字段的长度都是两个字节</strong>。各字节具体含义如下：</p>\n<ul>\n<li><strong>源端口</strong>：源端口号。在需要对方回信时选用。不需要时可用全0。</li>\n<li><strong>目的端口</strong>：目的端口号。这在终点交付报文时必须要使用到。<br>当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点——应用进程。下图就是UDP基于端口分用的示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%9F%BA%E4%BA%8E%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%88%86%E7%94%A8.JPG\" width=\"40%\" height=\"40%\"></li>\n<li><strong>长度</strong>：UDP用户数据报的长度，其最小值是8（仅有首部）。</li>\n<li><strong>检验和</strong>： 检测UDP用户数据报在传输中是否有错。有错就丢弃。<br>UDP用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。<br>UDP计算检验和的方法和计算IP数据报首部检验和的方法类似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把<strong>首部和数据部分一起都检验</strong>。</li>\n</ul>\n<h3 id=\"UDP实例\"><a href=\"#UDP实例\" class=\"headerlink\" title=\"UDP实例\"></a>UDP实例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%AE%9E%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"></p>\n<h2 id=\"3-3-传输控制协议TCP\"><a href=\"#3-3-传输控制协议TCP\" class=\"headerlink\" title=\"3.3 传输控制协议TCP\"></a>3.3 传输控制协议TCP</h2><h3 id=\"TCP的特点\"><a href=\"#TCP的特点\" class=\"headerlink\" title=\"TCP的特点\"></a>TCP的特点</h3><p>TCP是TCP/IP体系中非常复杂的一个协议。下面介绍TCP最主要的特点：</p>\n<ul>\n<li>TCP是<strong>面向连接的运输层协议</strong>。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。</li>\n<li>每一条TCP连接只能有两个<strong>端点</strong>（即套接字），每一条TCP连接只能是<strong>点对点</strong>的(一对一)。</li>\n<li>TCP提供<strong>可靠交付</strong>的服务。通过TCP连接传送的数据，无差错，不丢失，不重复，并且按序到达。</li>\n<li>TCP提供<strong>全双工通信</strong>。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事情，而TCP在合适的时候把数据发送出去。在接受时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。</li>\n<li><strong>面向字节流</strong>。TCP中的”流”指的是<strong>流入到进程或从进程流出的字节序列</strong>。“面向字节流”的含义是：虽然应用程序和TCP交互的是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的<strong>无结构的字节流</strong>。TCP并不知道所传送的字节流的含义。但接收方的应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接受方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。<br>下图为TCP面向字节流的概念：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E6%A6%82%E5%BF%B5.JPG\" width=\"80%\" height=\"80%\">上图指出，TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节（UDP发送的报文长度是应用进程给出的）。</li>\n</ul>\n<h3 id=\"套接字\"><a href=\"#套接字\" class=\"headerlink\" title=\"套接字\"></a>套接字</h3><p>每一条TCP连接有两个<strong>端点</strong>，TCP的连接端点叫做<strong>套接字(socket)</strong>。<br>套接字： <code>套接字socket = (IP地址：端口号)</code><br>每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定。即：<br><code>TCP连接 ::= {socket1, socket2} = {(IP1, port1), (IP2, port2)}</code></p>\n<h3 id=\"TCP报文段的首部格式\"><a href=\"#TCP报文段的首部格式\" class=\"headerlink\" title=\"TCP报文段的首部格式\"></a>TCP报文段的首部格式</h3><p>TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而<strong>TCP的全部功能都体现在它首部中各字段的作用</strong>。<br>TCP报文段首部的前20个字节是固定的，后面有$4n$字节是根据需要而增加的选项($n$是整数)。因此TCP首部的最小长度是20字节。<br>下图为TCP报文段的首部格式：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E6%8A%A5%E6%96%87%E6%AE%B5%E7%9A%84%E9%A6%96%E9%83%A8%E6%A0%BC%E5%BC%8F.JPG\" width=\"75%\" height=\"75%\"> 首部固定部分各字段的意义如下：</p>\n<ul>\n<li><strong>源端口</strong>和<strong>目的端口</strong>：各占2个字节，分别写入源端口号和目的端口号。</li>\n<li><strong>序号</strong>：占4个字节。首部中的序号字段值指的是<strong>本报文段所发送的数据的第一个字节的序号</strong>。序号范围是$[0,2^32-1]$，共$2^32$个序号。序号增加到$2^32-1$后，下一个序号就又回到0。TCP是面向字节流的。在一个TCP连接中传送的字节流中的<strong>每一个字节都按顺序编号</strong>。整个要传送的字节流的起始序号必须在连接建立时设置。</li>\n<li><strong>确认号</strong>：占4个字节，是<strong>期望收到对方下一个报文段的第一个数据字节的序号</strong>。若确认号等于$N$，则表明：到序号$N-1$为止的所有数据都已正确收到。</li>\n<li><strong>数据偏移</strong>：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，即指出TCP报文段的首部长度。</li>\n<li><strong>保留</strong>：占6位，保留为今后使用，目前置为0。</li>\n<li>6个<strong>控制位</strong>：<ul>\n<li><strong>紧急URG(URGent)</strong>：当URG=1时，表明紧急指针字段有效。当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的<strong>最前面</strong>，而在紧急数据后面的数据仍是普通数据。这时要与首部中的<strong>紧急指针</strong>字段配合使用。</li>\n<li><strong>确认ACK(ACKnowlegment)</strong>： <strong>仅当ACK=1时确认号字段才有效</strong>。当ACK=0时，确认号字段无效。<strong>TCP规定，在连接建立后，所有传送的报文段都必须把ACK置1</strong>。</li>\n<li><strong>推送PSH(PuSH)</strong>：用的很少。</li>\n<li><strong>复位RST(ReSeT)</strong>:当RST=1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。</li>\n<li><strong>同步SYN</strong>：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应的报文段中使用SYN=1和ACK=1。因此，<strong>SYN置为1就表示这是一个连接请求或者连接接受报文</strong>。</li>\n<li><strong>终止FIN</strong>：用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。</li>\n</ul>\n</li>\n<li><strong>窗口</strong>：占2个字节。窗口值是$[0,2^16-1]$之间的整数。窗口指的是发送本报文段的一方的<strong>接收窗口</strong>（而不是自己的发送窗口）。窗口值告诉对方：<strong>从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量</strong>。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，<strong>窗口值作为接收方让发送方设置其发送窗口的依据</strong>。<br>例如：设确认号是701，窗口字段是1000。这就表明，从701号算起，发送此报文段的一方还有接受1000个字节数据（字节序号是701~1700）的接受缓存空间。</li>\n<li><strong>检验和</strong>：占2个字节。检验和字段检验的范围包括首部和数据这两个部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。</li>\n<li><strong>紧急指针</strong>：占2个字节。紧急指针仅在URG=1时才有意义。紧急指针指出了紧急数据的末尾在报文段中的位置。</li>\n<li><strong>选项</strong>：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。其中有<strong>最大报文段长度MSS</strong>、<strong>窗口扩大</strong>、<strong>时间戳</strong>、<strong>选择确认(SACK)</strong>等选项。</li>\n</ul>\n<h3 id=\"TCP的运输连接管理\"><a href=\"#TCP的运输连接管理\" class=\"headerlink\" title=\"TCP的运输连接管理\"></a>TCP的运输连接管理</h3><p>TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向来连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：<strong>连接建立、数据传送和连接释放</strong>。<br>在TCP连接建立过程中要解决以下三个问题：<br>（1）要使每一方能够明确知道对方的存在。<br>（2）要允许双方协商一些参数（如最大窗口值，是否使用窗口扩大选项和时间戳选项等）。<br>（3）能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。<br>TCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做<strong>客户(client)</strong>，而被动等待连接建立的应用进程叫<strong>服务器(server)</strong>。</p>\n<h4 id=\"TCP的连接建立\"><a href=\"#TCP的连接建立\" class=\"headerlink\" title=\"TCP的连接建立\"></a>TCP的连接建立</h4><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B.JPG\" width=\"80%\" height=\"80%\"> 上图为TCP的建立连接的过程：</p>\n<ul>\n<li>假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。</li>\n<li>最初两端的TCP进程都处于CLOSED(关闭)状态。注意，<strong>A主动打开连接</strong>，而<strong>B被动打开连接</strong>。</li>\n<li>B的TCP服务器进程先创建<strong>传输控制块TCB</strong>，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN(收听)状态，等待客户的连接请求。如有，即作出响应。</li>\n<li>A的TCP客户进程也是首先创建<strong>传输控制模块TCB</strong>，然后向B发出连接请求报文段，首部中的同步位SYN置1，同时选择一个初始序号seq=x。TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但要<strong>消耗掉一个序号</strong>。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。</li>\n<li>B收到连接请求报文后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。注意，此SYN报文段也不能携带数据，但同样需要<strong>消耗掉一个序号</strong>。这是TCP服务器进程进入SYN-RCVD(同步收到状态)。</li>\n<li>TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP规定，ACK报文段可以携带数据。但<strong>如果不携带数据则不消耗序号</strong>，在此情况下，下一个数据报文段的序号仍是seq=x+1。这是TCP连接已经建立，A进入ESTABLISHED(已建立连接)状态。</li>\n<li>当B收到A的确认后，也进入ESTABLISHED状态。</li>\n<li>上面给出的连接建立的过程叫做<strong>三次握手</strong>。</li>\n</ul>\n<p>为什么A还要发送一次确认呢？</p>\n<ul>\n<li>这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。</li>\n<li>“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。</li>\n</ul>\n<h4 id=\"TCP的连接释放\"><a href=\"#TCP的连接释放\" class=\"headerlink\" title=\"TCP的连接释放\"></a>TCP的连接释放</h4><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E9%87%8A%E6%94%BE.JPG\" width=\"80%\" height=\"80%\"> 数据传输结束后，通信的双方都可释放连接，上图为TCP连接释放的过程：</p>\n<ul>\n<li>现在A和B都处于ESTABLISHED状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq=u，它等于前面已经传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1(终止等待1)状态，等待B的确认。注意，TCP规定，FIN报文段即使不携带数据，也消耗掉一个序号。</li>\n<li>B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B前面已经传送过的数据的最后一个字节的序号加1。然后B就进入CLOSED-WAIT(关闭等待)状态。TCP服务器进程这时应通知高层应用进程，因为从A到B这个方向的连接就释放了，这时的TCP连接就处于<strong>半关闭(half-close)</strong>状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。</li>\n<li>A收到来自B的确认后，就进入FIN-WAIT2(终止等待2)状态，等待B发出的连接释放报文。</li>\n<li>若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这是B发出的连接释放报文段必须使FIN=1。现假定B的序号为w(在半关闭状态B可能又发送了一些数据)。B还必须重复上次已发送过的确认号ack=u+1。这时B就进入LAST-ACK(最后确认)状态，等待A的确认。</li>\n<li>A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1。然后进入到TIME-WAIT(时间等待)状态。请注意，现在TCP连接还没有释放掉。必须经过<strong>时间等待计时器(TIME-WAIT timer)</strong>设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做<strong>最长报文段寿命(Maximum Segment Lifetime)</strong>。当A撤销掉相应的传输控制块TCB后，就结束了这次的TCP连接。</li>\n<li>B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。注意到，B结束TCP连接的时间要比A早一些。</li>\n<li>上述的TCP连接释放过程是四次挥手。</li>\n</ul>\n<p>为什么A在TIME-WAIT状态必须等待2MSL的时间呢？有两个理由：</p>\n<ul>\n<li>第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态。</li>\n<li>第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有的报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。</li>\n</ul>\n<p>除时间等待计时器外，TCP还设有一个<strong>保活计时器(keepalive timer)</strong>。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不再白白等待下去。这就是保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。</p>\n<h1 id=\"4-应用层\"><a href=\"#4-应用层\" class=\"headerlink\" title=\"4.应用层\"></a>4.应用层</h1><h2 id=\"域名系统-DNS\"><a href=\"#域名系统-DNS\" class=\"headerlink\" title=\"域名系统(DNS)\"></a>域名系统(DNS)</h2><ul>\n<li>域名系统是因特网使用的命名系统，完成域名解析，将域名解析到特定的IP地址。</li>\n<li>DNS采用客户/服务器应用模式，其核心是分级的、基于域的命名机制以及实现该命名机制的分布式数据库系统。</li>\n<li>域名解析是由若干个域名服务器程序完成的。域名服务器程序在专设的节点上运行，运行该程序的节点称为域名服务器。</li>\n</ul>\n<p><strong>域名解析</strong></p>\n<ul>\n<li><code>zh.wikipedia.org</code>作为一个域名就和IP地址<code>208.80.154.225</code>相对应。DNS就像是一个自动的电话号码簿，我们可以直接拨打wikipedia的名字来代替电话号码（IP地址）。DNS在我们直接调用网站的名字以后就会将像<code>zh.wikipedia.org</code>一样便于人类使用的名字转化成像<code>208.80.154.225</code>一样便于机器识别的IP地址。</li>\n<li>DNS查询有两种方式：递归和迭代。DNS客户端设置使用的DNS服务器一般都是递归服务器，它负责全权处理客户端的DNS查询请求，直到返回最终结果。而DNS服务器之间一般采用迭代查询方式。</li>\n</ul>\n<p>以查询<code>zh.wikipedia.org</code>为例：</p>\n<ul>\n<li>客户端发送查询报文”query zh.wikipedia.org”至DNS服务器，DNS服务器首先检查自身缓存，如果存在记录则直接返回结果。</li>\n<li>如果记录老化或不存在，则<ul>\n<li>DNS服务器向根域名服务器发送查询报文”query zh.wikipedia.org”，根域名服务器返回<code>.org</code>域的权威域名服务器地址，这一级首先会返回的是顶级域名的权威域名服务器。</li>\n<li>DNS服务器向<code>.org</code>域的权威域名服务器发送查询报文”query zh.wikipedia.org”，得到<code>.wikipedia.org</code>域的权威域名服务器地址。</li>\n<li>DNS服务器向<code>.wikipedia.org</code>域的权威域名服务器发送查询报文”query zh.wikipedia.org”，得到主机<code>zh</code>的A记录，存入自身缓存并返回给客户端。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"远程登录-Telnet\"><a href=\"#远程登录-Telnet\" class=\"headerlink\" title=\"远程登录(Telnet)\"></a>远程登录(Telnet)</h2><ul>\n<li>远程登录是因特网的基本应用服务之一，采用客户机/服务器模式。</li>\n<li>用户可以使用Telnet登录到远地的另一台主机上。</li>\n<li>Telent能将用户的击键传到远程主机，同时也能将远程主机的输出通过TCP连接返回到用户屏幕。</li>\n<li>远程桌面（RDP）就是在TELNET技术上发展起来的。</li>\n</ul>\n<h2 id=\"文件传输协议-FTP\"><a href=\"#文件传输协议-FTP\" class=\"headerlink\" title=\"文件传输协议(FTP)\"></a>文件传输协议(FTP)</h2><ul>\n<li>FTP(File Transfer Protocol)是Internet上使用得最为广泛的文件传送协议。FTP提供交互式的访问，允许客户上传文件到服务器或者从服务器下载文件。</li>\n<li>FTP屏蔽了各个计算机系统的差异，适合在异构计算机之间传送文件。</li>\n<li>文件传输协议FTP基于TCP，采用客户/服务器模式，提供文件传送基本网络服务。</li>\n<li>一个FTP服务器进程可同时为多个客户进程提供服务。FTP服务器包括两部分：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求。</li>\n</ul>\n<h2 id=\"动态主机配置协议-DHCP\"><a href=\"#动态主机配置协议-DHCP\" class=\"headerlink\" title=\"动态主机配置协议(DHCP)\"></a>动态主机配置协议(DHCP)</h2><ul>\n<li>动态主机配置协议允许一台计算机加入新网可自动获取网络配置信息，不用人工参与。</li>\n<li>网络计算机需要配置的项目包括：IP地址、子网掩码、默认路由器的IP地址、以及域名服务器的IP地址。</li>\n<li>DHCP采用客户/服务器模式。</li>\n</ul>\n<h2 id=\"电子邮件系统-E-mail\"><a href=\"#电子邮件系统-E-mail\" class=\"headerlink\" title=\"电子邮件系统(E-mail)\"></a>电子邮件系统(E-mail)</h2><p>暂略</p>\n<h2 id=\"万维网-WWW\"><a href=\"#万维网-WWW\" class=\"headerlink\" title=\"万维网(WWW)\"></a>万维网(WWW)</h2><ul>\n<li>万维网WWW(World Wide Web)并非某种特殊的计算机网络。</li>\n<li>万维网是一个大规模的、联机式的信息储藏所。</li>\n<li>万维网用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。</li>\n<li>这种访问方式称为“链接”。</li>\n</ul>\n<h3 id=\"万维网的工作方式\"><a href=\"#万维网的工作方式\" class=\"headerlink\" title=\"万维网的工作方式\"></a>万维网的工作方式</h3><ul>\n<li>万维网以客户服务器方式工作。</li>\n<li>浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。</li>\n<li>客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。</li>\n<li>在一个客户程序主窗口上显示出的万维网文档称为页面(page)。</li>\n</ul>\n<h3 id=\"万维网必须解决的问题\"><a href=\"#万维网必须解决的问题\" class=\"headerlink\" title=\"万维网必须解决的问题\"></a>万维网必须解决的问题</h3><ul>\n<li>怎样标志分布在整个因特网上的万维网文档？<ul>\n<li>使用统一资源定位符URL(Uniform Resource Locator)来标志万维网上的各种文档,使每一个文档在整个因特网的范围内具有惟一的标识符URL。</li>\n</ul>\n</li>\n<li>用什么协议实现万维网上各种超链的链接？<ul>\n<li>在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是<strong>超文本传送协议HTTP</strong>(HyperText Transfer Protocol)。</li>\n<li>HTTP是一个<strong>应用层协议</strong>，它使用TCP连接进行可靠的传送。</li>\n</ul>\n</li>\n<li>怎样使各种万维网文档都能在因特网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？<ul>\n<li>超文本标记语言HTML(HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。</li>\n</ul>\n</li>\n<li>怎样使用户能够很方便地找到所需的信息？<ul>\n<li>为了在万维网上方便地查找信息，用户可使用各种搜索工具，例如：<code>Google(http://www.google.com.hk)</code>。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"统一资源定位符URL\"><a href=\"#统一资源定位符URL\" class=\"headerlink\" title=\"统一资源定位符URL\"></a>统一资源定位符URL</h3><ul>\n<li>统一资源定位符URL是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。</li>\n<li>URL给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。</li>\n<li>只要能够对资源定位，系统就可以对资源进行各种操作，如存取、更新、替换和查找其属性。</li>\n<li>URL 相当于一个文件名在网络范围的扩展。因此 URL 是与因特网相连的机器上任何可访问对象的一个指针。</li>\n<li>由以冒号隔开的两大部分组成，并且在 URL 中的字符对大写或小写没有要求。URL的一般形式是：<code>&lt;URL的访问方式&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;</code>。<ul>\n<li>其中，<url的访问方式>可为文件传输协议FTP或超文本传送协议HTTP。如使用FTP的URL举例：<code>ftp://rtfm.mit.edu/pub/abc.txt</code>，使用HTTP的URL举例：<code>http://shopping.dangdang.com</code></url的访问方式></li>\n<li>&lt;主机&gt; 是存放资源的主机在因特网中的域名。</li>\n<li>&lt;端口&gt;/&lt;路径&gt;有时可忽略。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"超文本传送协议HTTP\"><a href=\"#超文本传送协议HTTP\" class=\"headerlink\" title=\"超文本传送协议HTTP\"></a>超文本传送协议HTTP</h3><ul>\n<li>Ted Nelson1963年新创了hypertext和hypermedia：<ul>\n<li>超文本(hypertext)是显示在计算机或其他电子设备上，具有超链(hyperlink)指向其他文本的文本。<br>例如：<code>&lt;a href=&quot;http://www.w3.org&quot;&gt;W3C organization website&lt;/a&gt;</code></li>\n<li>超媒体(hypermedia)是超文本的扩充，是图片、视频和声音以及文本的复合体。</li>\n</ul>\n</li>\n<li>万维网是分布式超媒体(hypermedia)系统。超文本、超媒体页面通过超链相互连接。</li>\n<li>HTTP是面向事务的(transaction-oriented)应用层协议，是在万维网上可靠地交换文件（各种多媒体文件）的重要基础。</li>\n<li>HTTP的工作过程:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BA%94%E7%94%A8%E5%B1%82/http%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>用户点击超链后所发生的事件：<ul>\n<li>浏览器分析超链指向页面“我校学科楼组团正式启用”的 URL</li>\n<li>浏览器向DNS服务器请求解析 www.njupt.edu.cn 的 IP 地址</li>\n<li>域名系统解析出南京邮电大学Web服务器的 IP 地址</li>\n<li>浏览器与web服务器建立 TCP 连接</li>\n<li>浏览器发出取文件HTTP请求：GET /s/222/t/1100/41/fd/info82429.htm HTTP/1.1</li>\n<li>Web服务器 做出响应，把文件 info82429.htm 发给浏览器</li>\n<li>TCP 连接释放</li>\n<li>浏览器显示info82429.htm中的所有文本。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h1><ul>\n<li><a href=\"http://www.icourse163.org/course/NJUPT-1001639008?tid=1001719010\" target=\"_blank\" rel=\"noopener\">网络技术与应用，南京邮电大学</a></li>\n<li>计算机网络，谢希仁</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-计算机网络体系结构\"><a href=\"#1-计算机网络体系结构\" class=\"headerlink\" title=\"1.计算机网络体系结构\"></a>1.计算机网络体系结构</h1><ul>\n<li><strong>协议</strong>：协议是控制两个对等实体（或多个实体）进行通信的规则的集合。网络协议主要由以下三要素组成：语法、语义、同步。</li>\n<li><strong>网络体系结构</strong>：网络体系结构是计算机网络的分层、每层的功能以及每层使用到的协议的集合。</li>\n</ul>","more":"<h2 id=\"1-1-计算机网络体系结构\"><a href=\"#1-1-计算机网络体系结构\" class=\"headerlink\" title=\"1.1 计算机网络体系结构\"></a>1.1 计算机网络体系结构</h2><ul>\n<li>国际标准化组织（ISO）提出<strong>开放系统互连参考模型OSI/RM</strong>(Open System Interconnection Reference Model)。OSI是一个七层协议体系结构，如图1(a)。</li>\n<li>美国国防部提出<strong>TCP/IP体系结构</strong>，TCP/IP是一个四层的体系结构，如图1(b)。</li>\n<li>OSI的七层体系结构的理论完整，但即复杂又不实用。TCP/IP是事实上的国际标准。</li>\n<li>从实质上讲，TCP/IP只有最上面的三层，因为最下面的网络接口层并没有什么具体内容。因此在学习计算机网络的原理时，采用折中的办法，即综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，如图1(c)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE1_%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.JPG\" width=\"70%\" height=\"70%\"></p>\n<h2 id=\"1-2-各层的主要功能\"><a href=\"#1-2-各层的主要功能\" class=\"headerlink\" title=\"1.2 各层的主要功能\"></a>1.2 各层的主要功能</h2><p>（1）<strong>应用层</strong>(application layer)</p>\n<ul>\n<li>功能：应用层是体系结构中的最高层。应用层的任务是<strong>通过应用进程间的交互来完成特定网络应用</strong>。这里的<strong>进程</strong>就是指<strong>主机中正在运行的程序</strong>。</li>\n<li>协议：应用层协议定义的是<strong>应用进程间通信和交互的规则</strong>。对于不同的网络应用需要有不同的应用层协议。应用层协议有：域名系统DNS，支持万维网应用的<strong>HTTP</strong>协议，支持电子邮件的<strong>SMTP</strong>协议，支持文件传送的<strong>FTP</strong>协议等。我们把应用层交互的数据单元成为<strong>报文</strong>(message)。</li>\n</ul>\n<p>（2）<strong>运输层</strong>(transport layer)</p>\n<ul>\n<li>功能：运输层的任务就是负责向<strong>两个主机中进程之间的通信</strong>提供<strong>通用的数据传输</strong>服务。应用进程利用该服务传送应用层报文。由于一个主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付给上面应用层中的相应的进程。</li>\n<li>协议：运输层主要使用两种协议：1.<strong>传输控制协议TCP</strong>——提供面向连接的、可靠的数据服务，数据传输的单位是<strong>报文段</strong>(segment)；2.<strong>用户数据包协议UDP</strong>——提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是<strong>用户数据报</strong>。</li>\n<li>重要设备：网关(gateway)。</li>\n</ul>\n<p>（3）<strong>网络层</strong>(network layer)</p>\n<ul>\n<li>功能：（1）网络层负责为分组交换网上的不同<strong>主机</strong>提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成<strong>分组</strong>或<strong>包</strong>进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫做<strong>IP数据报</strong>或简称<strong>数据报</strong>；<br>注：无论在哪一层传送的数据单元，都可笼统地用<strong>“分组”</strong>来表示<br>（2）网络层的另一个任务是选择合适的路由，使源主机运输层传下来的分组，能够通过网络中的路由器找到目的主机。</li>\n<li>协议：（1）互联网是大量的<strong>异构</strong>网络通过<strong>路由器</strong>相互连接起来的。互联网使用的网络协议是无连接的<strong>网际协议IP</strong>(Internet Protocol)和许多种路由选择协议，因此互联网的网络层也叫做<strong>网际层</strong>或<strong>IP层</strong>；（2）与IP协议配套使用的还有三个协议：地址解析协议ARP、网际控制报文协议ICMP和网际组管理协议IGMP；（3）路由选择协议。</li>\n<li>重要的设备：路由器(router)。</li>\n</ul>\n<p>（4）<strong>数据链路层</strong>(data link layer)</p>\n<ul>\n<li>功能：两台主机之间的数据传输，总是在一段一段的<strong>链路</strong>上传送的，也就是说，在两个相邻结点之间（主机和路由器之间或两个路由器之间）传送数据是直接传送的（点对点）。数据链路层把网络层交下来的IP数据报（或数据报/分组/包）<strong>封装成帧</strong>(framing)发送到链路上，在两个相邻结点间的链路上传送<strong>帧</strong>(frame)，以及把接受到的帧中的数据取出并上交给网络层。</li>\n<li>重要设备：网桥(bridge)、交换机（多接口的网桥）。</li>\n</ul>\n<p>（5）<strong>物理层</strong>(physical layer)</p>\n<ul>\n<li>功能：在物理层上所数据的单位是<strong>比特</strong>。物理层的任务就是<strong>透明地传送比特流</strong>。也就是说，发送方发送1(或0)时，接收方应当收到1(或0)而不是0(或1)。因此物理层要考虑用多大的电压代表”1”或”0”，以及接收方如何识别出发送方所发送的比特，物理层还要确定连接电缆的插头应当有多少根引脚以及各条引脚应如何连接。注意，传递信息所利用的一些物理媒体/传输媒体，如双绞线、同轴电缆、光缆、无线信道等，并不在物理层协议之内而是在物理层协议的下面，有人把物理媒体称为第0层。<br>综上，物理层的作用正视要经可能的屏蔽掉传输媒体和通信手段的差异，是物理层之上的数据链路层感觉不到这些差异，使数据链路层只需要考虑如何完成本层的协议和服务。</li>\n<li>中间设备：转发器(repeater)</li>\n</ul>\n<h2 id=\"1-3-数据在各层之间的传递过程\"><a href=\"#1-3-数据在各层之间的传递过程\" class=\"headerlink\" title=\"1.3 数据在各层之间的传递过程\"></a>1.3 数据在各层之间的传递过程</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE2_%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%90%84%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BC%A0%E9%80%92%E8%BF%87%E7%A8%8B.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假定主机1的应用进程$AP_1$向主机2的应用进程$AP_2$传送数据。</li>\n<li>$AP_1$先将其数据交给本主机的第5层(应用层)。第5层加上必要的控制信息$H_5$就变成了下一层的数据单元。第4层(运输层)收到这个数据单元后，加上本层的控制信息$H_4$，再交给第3层(网络层)，成为第3层的数据单元。依此类推。不过到了第2层(数据链路层)后，控制信息被分成两部分，分别加到本层数据单元的首部($H_2$)和尾部($T_2$)；而第1层(物理层)由于是比特流的传送，所以不再加上控制信息。</li>\n<li>当这一串的比特流离开主机1经网络的物理媒体传送到路由器时，就从路由器的第一层一次上升到第三层。每一层都根据控制信息进行必要的操作，然后将控制信息剥去，将该层剩下的数据单元交给更高的一层。当分组上升到第3层时，就根据首部中的目的地址查找路由器中的转发表，找到转发分组的接口，然后往下传送到第2层，加上新的首部和尾部，再到最下面的第1层，然后在物理媒体上把每一个比特发送出去。</li>\n<li>当这一串的比特流离开路由器到达目的主机2时，就从主机2的第1层按照上面讲过的方式，一次上升到第5层。最后，把应用进程$AP_1$发送的数据交给目的站的应用进程$AP_2$。</li>\n<li>对于用户来说，这个复杂的过程被屏蔽了，以至于感觉应用进程$AP_1$是直接把数据交给了应用进程$AP_2$。同理，任何两个同样的层次（例如两个系统的第4层）之间，也好像如同图2中的水平虚线所示的那样，把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层“之间的通信。之前提到的各层协议，实际上就是在各个对等层之间传递数据时的各项规定。</li>\n</ul>\n<h2 id=\"1-4-TCP-IP体系结构\"><a href=\"#1-4-TCP-IP体系结构\" class=\"headerlink\" title=\"1.4 TCP/IP体系结构\"></a>1.4 TCP/IP体系结构</h2><p>前面已经说过，TCP/IP的体系结构比较简单，它只有四层。图3给出了用这四层协议表示方法的例子。注意，图中的路由器在转发分组时最高只用到网络层而没有使用运输层和应用层。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE3_TCPIP%E5%9B%9B%E5%B1%82%E5%8D%8F%E8%AE%AE%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95%E7%A4%BA%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"></p>\n<p>还有一种方法，就是分层次画出具体的协议来表示TCP/IP协议族，如图4。它的特点是上下两头大而中间小：应用层和网络接口层都有多种协议，而中间的IP层很小，上层的各种协议都向下汇聚到一个IP协议中。这种像沙漏计时器形状的TCP/IP协议族表明：TCP/IP协议<strong>可以为各式各样的应用提供服务</strong>（所谓的everying over IP），同时TCP/IP协议也<strong>允许IP协议在各式各样的网络构成的互联网上运行</strong>（所谓的 IP over everything）。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%9B%BE4_%E6%B2%99%E6%BC%8F%E8%AE%A1%E6%97%B6%E5%99%A8%E5%BD%A2%E7%8A%B6%E7%9A%84TCP-IP%E5%8D%8F%E8%AE%AE%E6%97%8F.JPG\" width=\"70%\" height=\"70%\"></p>\n<h1 id=\"2-网络层\"><a href=\"#2-网络层\" class=\"headerlink\" title=\"2.网络层\"></a>2.网络层</h1><h2 id=\"2-1网际协议IP\"><a href=\"#2-1网际协议IP\" class=\"headerlink\" title=\"2.1网际协议IP\"></a>2.1网际协议IP</h2><p>互联网由多种异构网络互连而成，参加互联的计算机网络都使用相同的网际协议IP，因此实现互联。<br>网际协议IP是TCP/IP体系中两个最重要的协议之一。与IP协议配套使用的还有三个协议：</p>\n<ul>\n<li>地址解析协议ARP </li>\n<li>网际控制报文协议ICMP</li>\n<li>网际组管理协议IGMP</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE-%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE%E9%85%8D%E5%A5%97%E5%8D%8F%E8%AE%AE.JPG\" width=\"40%\" height=\"40%\"></p>\n<h2 id=\"2-2-IP地址及其表示方法\"><a href=\"#2-2-IP地址及其表示方法\" class=\"headerlink\" title=\"2.2 IP地址及其表示方法\"></a>2.2 IP地址及其表示方法</h2><p>整个的互联就是一个单一的、抽象的网络。IP地址就是给因特网上的每一个主机(或路由器)的每一个接口分配一个在全世界范围内位移的<strong>32位</strong>的标识符。IP地址的结构使我们可以在互联网上很方便地进行寻址。<br>IP地址的编制方法经过了三个历史阶段：</p>\n<ul>\n<li>分类的IP地址。</li>\n<li>子网的划分。这是对最基本的编址方法的改进。</li>\n<li>构成超网。这是无分类编制方法。</li>\n</ul>\n<h2 id=\"2-3-分类的IP地址\"><a href=\"#2-3-分类的IP地址\" class=\"headerlink\" title=\"2.3 分类的IP地址\"></a>2.3 分类的IP地址</h2><p>（1）概念<br>分类的IP地址就是将IP地址划分为若干个固定类，每一类地址都由两个固定长度的字段组成，记为：<code>IP地址 ::= {&lt;网络号&gt;,&lt;主机号&gt;}</code><br>注：第一个字段是<strong>网络号</strong>，它标志主机（或路由器）所连接到的网络。一个网络号在整个互联网内必须是唯一的。第二个字段是<strong>主机号</strong>，它标志该主机（或路由器）。一个主机号在它前面所指明的网络范围内必须是唯一的。故，<strong>一个IP地址在整个互联网范围内是唯一的</strong>。<br>图5给出了各种IP地址的网络号字段和主机号字段。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE5-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E5%88%86%E7%B1%BB.JPG\" width=\"60%\" height=\"60%\">（2）点分十进制记法<br>对主机和路由器来说，IP地址都是32位的二进制代码。为了提高可读性，常采用点分十进制记法。如图6所示。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE6-%E7%82%B9%E5%88%86%E5%8D%81%E8%BF%9B%E5%88%B6%E8%AE%B0%E6%B3%95.JPG\" width=\"90%\" height=\"90%\"> （3）常用的三种类别的IP地址<br>图7为IP地址的指派范围：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE7-IP%E5%9C%B0%E5%9D%80%E7%9A%84%E6%8C%87%E6%B4%BE%E8%8C%83%E5%9B%B4.JPG\" width=\"100%\" height=\"100%\"> 注1：(1)A类地址的网络号字段占1个字节，有7位可用（第一位已固定为0），可指派的网络号个数为126(即$2^7-2$)。减2的原因：网络号字段为全0的IP地址和网络号为127(即01111111)保留;(2)A类地址的主机号占3个字节，最大主机数是$2^{24}-2$，即16777214。减2的原因：全0的主机号字段和全1的主机号字段保留;(3)IP地址空间共有$2^{32}$个地址，整个A类网络地址空间共有$2^{31}$个地址。故占整个IP地址空间的50%。<br>注2：(1)B类地址的网络号字段有2个字节，有14位可用(前两位固定为10)。无论如何取也不会全0或全1，因此不存在减2。但<code>128(1000 0000).0.0.0</code>默认不分配，可指派的最小网络地址是<code>128.1(0000 0001).0.0</code>。因此B类地址可指派的网络数为$2^{14}-1$，即16383;(2)B类地址的每一个网络上的最大主机数为$2^{16}-2$，即65534。全0和全1的主机号保留;(3)整个B类地址空间共约$2^{30}$个地址，占整个IP地址空间的25%。<br>注3：(1)C类地址的网络号字段有3个字节，有21位可用（前面3为固定为110），C类网络地址<code>192(1100 0000).0.0.0</code>也是不指派的，故C类最小网络地址为<code>192.0.1(0000 0001).0</code>，故C类地址可指派的网络数为$2^{21}-1$，即2097151个;(2)每一个C类地址的最大主机数是$2^8-2$，即254个;(3)整个C类地址空间共约$2^{29}$个地址，占整个IP地址的12.5%。<br>（4）IP地址的重要特点</p>\n<ul>\n<li>IP地址分两个等级的好处是：<ul>\n<li>第一，IP地址管理机构在分配IP地址时只分配网络号（第一级），而剩下的主机号（第二级）则由得到该网络号的单位自行分配。</li>\n<li>第二，路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目的主机），这样就可以使得路由表中的项目数大幅减少，从而减少了路由表所占的存储空间以及查找路由表的时间。</li>\n</ul>\n</li>\n<li>实际上IP地址是标志一个主机（或路由器）和一条链路的接口。当一个主机同时连接到两个网络上时，该主机就必须同时具有两个相应的IP地址，其网络号必须是不同的。由于一个路由器至少应当连接到两个网络，因此一个路由器至少应当有两个不同的IP地址。</li>\n<li>按照互联网的观点，一个网络是指具有相同网络号的主机的集合。因此，用转发器或网桥连接起来的若干个局域网仍为一个网络，因为这些局域网都有相同的网络号。具有不同网络号的局域网必须使用路由器进行互联。</li>\n</ul>\n<p>（5）示例<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE8-%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%AD%E7%9A%84IP%E5%9C%B0%E5%9D%80.JPG\" width=\"75%\" height=\"75%\"> 图8为三个局域网（LAN_1,LAN_2,LAN_3）通过三个路由器(R_1,R_2,R_3)互连起来所构成的一个互联网。其中局域网LAN_2是由两个网段通过网桥B互连的。图中的小圆圈表示需要有一个IP地址。<br>从图中可以注意到：</p>\n<ul>\n<li>在同一个局域网上的主机或路由器的IP地址中的网络号必须是一样的。图中所示的网络号是IP地址中的网络号字段的值，也即主机号全为0的网络IP地址。</li>\n<li>用网桥（它只在链路层工作）互联的网段仍然是一个局域网，只能有一个网络号。</li>\n<li>路由器总是具有两个或两个以上的IP地址。即路由器的每一个接口都有一个不同的网络号的IP地址。</li>\n</ul>\n<h2 id=\"2-4-IP地址与硬件地址\"><a href=\"#2-4-IP地址与硬件地址\" class=\"headerlink\" title=\"2.4 IP地址与硬件地址\"></a>2.4 IP地址与硬件地址</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE9-IP%E5%9C%B0%E5%9D%80%E4%B8%8E%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80%E7%9A%84%E5%8C%BA%E5%88%AB.JPG\" width=\"70%\" height=\"70%\"> IP地址放在IP数据报的首部，而硬件地址则放在MAC帧的首部。在网络层和网络层以上使用的是IP地址，而数据链路层及以下使用的是硬件地址。如图9中，当IP数据报放入数据链路层的MAC帧中以后，整个的IP数据报就成为MAC帧的数据，因而在数据链路层看不见数据报的IP地址。</p>\n<h2 id=\"2-5-地址解析协议ARP\"><a href=\"#2-5-地址解析协议ARP\" class=\"headerlink\" title=\"2.5 地址解析协议ARP\"></a>2.5 地址解析协议ARP</h2><p>地址解析协议ARP为网络层IP地址和数据链路层MAC地址提供动态映射，即<code>IP地址-&gt;MAC地址</code>。</p>\n<ul>\n<li>ARP使用广播的方式获得物理地址。</li>\n<li>ARP高速缓存：<ul>\n<li>每一个主机中都设有一个ARP高速缓存(ARP cache)，里面存放的是最近获得的局域网上各主机和路由器的IP地址到硬件地址的映射表。</li>\n<li>所以，当发送分组时，计算机在发送ARP请求之前总是先在ARP缓存中寻找所需的绑定，若有，则无须广播。</li>\n<li>可以通过命令 “ arp -a” 来查看本机的ARP缓存中内容。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-6-IP数据报的格式\"><a href=\"#2-6-IP数据报的格式\" class=\"headerlink\" title=\"2.6 IP数据报的格式\"></a>2.6 IP数据报的格式</h2><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE10-IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"80%\" height=\"80%\"></p>\n<h2 id=\"2-7-划分子网\"><a href=\"#2-7-划分子网\" class=\"headerlink\" title=\"2.7 划分子网\"></a>2.7 划分子网</h2><p>（1）划分子网<br>从1985年起在IP地址中又增加了一个“子网号字段”，使两级的IP地址变成为三级的IP地址。这种做法叫做<strong>划分子网</strong>，或子网寻址或子网路由选择。<br>划分子网的基本思路如下：</p>\n<ul>\n<li>划分子网的方法是<strong>从网络的主机号借用若干位作为子网号</strong>，而主机号也就相应减少了若干位。于是两级IP地址在<strong>本单位内部</strong>就变成了<strong>三级IP地址</strong>：网络号、子网号和主机号，记为<br><code>IP地址::={&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}</code></li>\n<li>子网号在网外是不可见的，仅在子网内使用</li>\n<li>凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据IP数据报的目的网络号找到连接在本单位网络上的路由器。但此路由器在收到IP数据报后，再按目的网络号和子网号找到目的子网，把IP数据报交付给目的主机。</li>\n</ul>\n<p>（2）子网掩码<br>子网掩码：子网号的位数是可变的，为了反映有多少位用于表示子网号，采用子网掩码。<br><code>IP地址　::={&lt;网络号&gt;,&lt;子网号&gt;,&lt;主机号&gt;}</code><br><code>子网掩码::={11....11,11....11,00....00}</code>（即网络号和子网号全1，主机号全0）<br>（3）默认子网掩码<br>A类网络：<code>255.0.0.0</code><br>B类网络：<code>255.255.0.0</code><br>C类网络：<code>255.255.255.0</code><br>（4）广播地址<br>用途：要用广播的方式（一对所有进行通信）发送一个分组时，目的IP地址是一个广播地址。<br>特点：主机号部分全1<br>（5）例题<br><strong>例题1</strong>：假如在一个B类网络<code>128.10.0.0</code>中，我们准备从16位主机号部分里借用3位进行子网划分，求对应的子网掩码 。<br><strong>分析</strong>：因为是B类网络，所以网络号部分是16位，又因为子网号部分是3位，所以子网掩码里就有16+3=19位1，剩下的32-19=13位主机号部分全0。<br><strong>结果</strong>：<code>11111111 11111111 11100000 00000000</code>，即<code>255.255.224.0</code></p>\n<p><strong>例题2</strong>：假如一台主机的IP地址是<code>128.10.32.6</code>，子网掩码是<code>255.255.224.0</code>，那么该主机所在子网的子网地址又是什么呢？<br><strong>分析</strong>：子网地址也是一个特殊的IP地址，就是网络号部分和子网号部分不变，主机号部分全零的地址。用逻辑“与” 操作。<br><code>子网地址 = 主机IP地址 AND 子网掩码</code><br><strong>答案</strong>：子网地址 = <code>128.10.00100000.6</code>AND<code>255.255.11100000.0</code>=<code>128. 10.00100000.0</code>=<code>128. 10.32.0</code></p>\n<p><strong>例题3</strong>：在子网128.10.32.0中，广播地址是多少呢？<br><strong>答案</strong>：把主机号部分(13位)变成全1，<code>128.10.00111111.11111111</code>即<code>128.10.63.255</code></p>\n<p><strong>例题4</strong>：一家公司申请到的网络地址是<code>202.119.230.0</code>，现在由于工作上的需要，要把该网络划分为14个子网，并且又希望每个子网的规模尽可能的大，则应选用的子网掩码是多少？<br><strong>分析</strong>：若全0、全1的子网地址可以分配，则若借用x位进行子网划分，可以划分出$2^x$个子网；反之，则可以划分$2^x-2$个子网。对于本题中，x=4满足需求。因为是C类地址，所以其子网掩码是24+4=28比特的1, 32-28=4比特的0。<br><strong>答案</strong>： <code>255.255.255.11110000</code>即 <code>255.255.255.240</code></p>\n<p><strong>例题5</strong>：设有一个网络，其网络地址为<code>210.10.30.0</code>，若其选用的子网掩码是<code>255.255.255.192</code>，则：<br><strong>（1）可以划分多少个子网（注：全0全1的子网地址不分配）</strong><br><strong>分析</strong>：因为该网络是一个C类网络，默认的子网掩码是<code>255.255.255.0</code>，因为<code>192=11000000B</code>, 可见，是从主机号里面是借了2位进行子网划分，又因为<strong>全0全1 的子网地址不分配</strong>。<br><strong>答案</strong>：划分子网的个数是$2^2-2=2$<br><strong>（2）每个子网容纳的主机个数是多少？</strong><br><strong>分析</strong>：因为主机号部分的位数也就是子网掩码中0的个数，有6位。<br>答案：每个子网容纳的主机个数是 $2^6-2=62$<br><strong>注意</strong>：即使题目中没有说明，全零和全1的主机地址始终是不分配的<br><strong>（3）每个子网的子网地址分别是什么？</strong><br><strong>分析</strong>：子网地址中高24位是网络号部分，肯定是<code>210.10.30</code>，子网地址中主机号部分是全0，只有子网号这两位去除全0和全1外，还有两种选择，一个是01，一个是10，分别分配给两个子网。<br><strong>答案</strong>：子网1： <code>210.10.30.01000000</code>即<code>210.10.30.64</code><br>子网2：<code>210.10.30.10000000</code>即<code>210.10.30.128</code><br><strong>（4）每个子网中可分配的IP地址的范围多少？广播地址是多少？</strong><br><strong>分析</strong>：每个子网中第一个可用的IP地址就是主机号部分除了最后一位为1，其余位均为0的地址，最后一个可分配的IP地址是刚好反过来，主机号部分最后一位是0，其余位均为1。<br><strong>答案</strong>：子网1： <code>210.10.30.01000001</code>至 <code>210.10.30.01111110</code>。即<code>210.10.30.65</code>至<code>210.10.30.126</code><br>广播地址：<code>210.10.30.01111111</code>即<code>210.10.30.127</code><br>子网2：<code>210.10.30.10000001</code>至<code>210.10.30.10111110</code>。即<code>210.10.30.128</code>至<code>210.10.30.190</code><br>广播地址： <code>210.10.30.10111111</code>即<code>210.10.30.191</code></p>\n<h2 id=\"2-8-无分类编制CIDR-构造超网\"><a href=\"#2-8-无分类编制CIDR-构造超网\" class=\"headerlink\" title=\"2.8 无分类编制CIDR(构造超网)\"></a>2.8 无分类编制CIDR(构造超网)</h2><p>（1）CIDR<br><strong>CIDR消除了传统的A类、B类和C类地址以及划分子网的概念</strong>。CIDR使IP地址从三级编址（使用子网掩码）又回到了两级编织，但这已是<strong>无分类的两级编址</strong>，记为：<code>IP地址::= {&lt;网络前缀&gt;,&lt;主机号&gt;}</code><br>（2）CIDR记法<br>CIDR使用斜线记法，即在IP地址后面加上斜线”/“，然后写上网络前缀所占的位数；CIDR把网络前缀都相同的连续的IP地址组成一个CIDR地址块。我们只要知道CIDR地址块中的任一地址，就可以知道这个地址块的起始地址(即最小地址)和最大地址，以及地址块中的地址数。<br>例如：已经IP地址<code>128.14.35.7/20</code>是某CIDR地址块中的一个地址，现在把它写成二进制表示，其中的前20位是网络前缀，而前缀后面的12位是主机号。<br><code>128.14.35.7/20</code>=<code>10000000 00001110 0010</code>0011 00000111（前20位是网络前缀，后12位是主机号）<br>这个地址所在的地址块中的最小地址和最大地址可以很方便的得出：<br>最小地址： <code>10000000 00001110 0010</code>0000 00000000 即<code>128.14.32.0</code><br>最大地址：<code>10000000 00001110 0010</code>1111 11111111 即<code>128.14.47.255</code><br>当然，这两个主机号是全0和全1的地址一般不分配。通常只用这两个地址之间的地址。<br>（3）地址掩码<br>为了更方便地进行路由选择，CIDR使用32位的地址掩码（也可称子网掩码）。网络前缀全1，主机号全0。<br>注：CIDR不使用子网，是指CIDR并没有在32位地址中指明若干位作为子网字段。但分配到一个CIDR地址块的单位，仍然可以在本单位内根据需要划分出一些子网。这些子网也都只有一个网络前缀和一个主机号字段，但网络的前缀比整个单位的网络前缀要长些。<br>（4）例题<br><strong>例题1</strong>：<code>128.14.32.0/20</code>表示的地址块共有多少个地址？最大和最小的地址分别是什么？<br><strong>分析</strong>：因为是一个/20的地址块，所以主机号部分共有32-20=12位，所以地址个数是$2^{12}=4096$个。如图为CIDR地址块中最小和最大地址示例：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE11-CIDR%E5%9C%B0%E5%9D%80%E5%9D%97.JPG\" width=\"70%\" height=\"70%\"> <strong>例题2</strong>：假设某ISP（因特网服务提供者）拥有CIDR地址块<code>202.192.0.0/16</code>。先后有四所大学（A、B、C、D）向该ISP分别申请大小为4000、2000、4000、 8000个IP地址的地址块，试为ISP给这四所大学分配地址块。<br><strong>分析</strong>：<br><strong>A大学</strong>：$2^{12}=4096&gt;4000$，所以地址块中主机号部分是12位，网络前缀的长度=32-12=20位<br>起始地址：<code>202.192.0000</code>0000.0/20 即<code>202.192.0.0/20</code><br>结束地址：<code>202.192.0000</code>1111.255 即<code>202.192.15.255</code><br><strong>B大学</strong>：<code>2^{11}=2048&gt;2000</code>，网络前缀的长度=32-11=21位<br>起始地址： <code>202.192.00010</code>000.0/21 即<code>202.192.16.0/21</code><br>结束地址：<code>202.192.00010</code>111.255 即<code>202.192.23.255</code><br><strong>C大学</strong>：$2^{12}=4096&gt;4000$，网络前缀的长度=32-12=20位<br>起始地址：<code>202.192.0010</code>0000.0/20 即<code>202.192.32.0/20</code><br>结束地址：<code>202.192.0010</code>1111.255 即<code>202.192.47.255</code><br><strong>D大学</strong>：$2^{13}=8192&gt;8000$，网络前缀的长度=32-13=19位<br>起始地址：<code>202.192.010</code>00000.0/19 即<code>202.192.64.0/19</code><br>结束地址：<code>202.192.010</code>11111.255 即<code>202.192.95.255</code></p>\n<h2 id=\"2-9-IP分组转发的流程\"><a href=\"#2-9-IP分组转发的流程\" class=\"headerlink\" title=\"2.9 IP分组转发的流程\"></a>2.9 IP分组转发的流程</h2><p><strong>路由表的表项 ：（目的网络地址，子网掩码，下一跳路由器IP地址）</strong><br><strong>示例</strong>：已知图4-24所示的互联网，以及路由器$R_1$中的部分路由表。现在源主机$H_1$向目的主机$H_2$发送分组。试讨论$R_1$收到$H_1$向$H_2$发送的分组后查找路由表的过程。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/%E5%9B%BE12-IP%E5%88%86%E7%BB%84%E8%BD%AC%E5%8F%91.JPG\" width=\"80%\" height=\"80%\"> <strong>分析</strong>：</p>\n<ul>\n<li>源主机$H_1$向目的主机$H_2$发送的分组的目的地址是$H_2$的IP地址：128.30.33.138。</li>\n<li>源主机$H_1$首先要进行的操作是要判断：发送的这个分组，是在本子网上进行直接交付还是要通过本子网上的路由器进行间接交付？<ul>\n<li>源主机$H_1$把本子网的子网掩码<code>255.255.255.128</code>与目的主机$H_2$的IP地址<code>128.30.33.138</code>逐位相与(AND操作)，得出<code>128.30.33.128</code>，它不等于$H_1$的网络地址<code>128.30.33.0</code>。这说明$H_2$与$H_1$不在同一个子网上。因此$H_1$不能把分组直接交付$H_2$，而必须交给子网上的默认路由器$R_1$，由$R_1$来转发。</li>\n</ul>\n</li>\n<li>路由器$R_1$在收到一个分组后，就在其路由表中逐行寻找有无匹配的网络地址。<ul>\n<li>先看$R_1$路由表中的第一行。用这一行的子网掩码<code>255.255.255.128</code>和收到的分组的目的地址<code>128.30.33.138</code>逐位相与，得出<code>128.30.33.128</code>。然后和这一行给出的目的网络地址<code>128.30.33.0</code>进行比较。但比较的结果是不一致,即不匹配。</li>\n</ul>\n</li>\n<li>用同样方法继续往下找第二行。用第二行的子网掩码<code>255.255.255.128</code>和该分组的目的地址<code>128.30.33.138</code>逐位相与，结果是<code>128.30.33.128</code>。这个结果和第二行的目的网络地址<code>128.30.33.128</code>相匹配，说明这个网络(子网2)就是收到的分组所要寻找的目的网络。于是不需要再继续查找下去。$R_1$把分组从接口1直接交付主机$H_2$（它们都在一个子网上）。</li>\n</ul>\n<h2 id=\"2-10-网际控制报文协议ICMP\"><a href=\"#2-10-网际控制报文协议ICMP\" class=\"headerlink\" title=\"2.10 网际控制报文协议ICMP\"></a>2.10 网际控制报文协议ICMP</h2><p>(1)ICMP</p>\n<ul>\n<li>为更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP(Internet Control Message Protocol)。</li>\n<li>ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告。ICMP不是高层协议，是IP层的协议。</li>\n<li>ICMP报文作为IP层数据报的数据，加上数据报的首部，组成IP数组报发送出去。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E7%BD%91%E7%BB%9C%E5%B1%82/ICMP%E6%8A%A5%E6%96%87%E7%9A%84%E6%A0%BC%E5%BC%8F.JPG\" width=\"60%\" height=\"60%\"> (2)ICMP报文种类<br>ICMP报文的种类有两种，即<strong>ICMP差错报文</strong>和<strong>ICMP询问报文</strong>。<br>ICMP差错报告报文分五种：</p>\n<ul>\n<li>终点不可达</li>\n<li>时间超过</li>\n<li>源站抑制</li>\n<li>参数问题</li>\n<li>路由重定向</li>\n</ul>\n<p>常用的ICMP询问报文有两种：</p>\n<ul>\n<li>回送请求和回答报文</li>\n<li>时间戳请求和回答报文</li>\n</ul>\n<p>（3）ICMP的应用<br>ICMP协议可以实现网络可达性检查、网络时延测量、网络路由追踪、网络安全排查等方面都有重要的应用。</p>\n<ul>\n<li>Tracert（跟踪路由）基于<strong>ICMP终点不可达和时间超过差错报告报文</strong>原理实现的。</li>\n<li>Ping（因特网包探索器）基于<strong>ICMP询问报文类型中的回送请求和回答报文</strong>实现的。</li>\n</ul>\n<h2 id=\"2-11-虚拟专用网络VPN和网络地址转换NAT\"><a href=\"#2-11-虚拟专用网络VPN和网络地址转换NAT\" class=\"headerlink\" title=\"2.11 虚拟专用网络VPN和网络地址转换NAT\"></a>2.11 虚拟专用网络VPN和网络地址转换NAT</h2><p><strong>虚拟专用网</strong>：利用公共网络（如Internet）来构建的专用网络技术，保证了VPN中任何一对计算机之间的通信对外界是隐藏的。<br>（1）VPN的编址<br>VPN所提供的编址选择与专用网络所提供的是一样的，可以根据需要选择</p>\n<ul>\n<li>本地地址——仅在机构内部使用的IP地址，可以由本机构自行分配，而不需要向因特网的管理机构申请</li>\n<li>全球地址——全球惟一的IP地址，必须向因特网的管理机构申请</li>\n</ul>\n<p>本地地址：IANA保留了三块只能用于专用互联网内部通信的IP地址空间：<br>前缀 最低地址 最高地址<br><code>10/8</code> <code>10.0.0.0</code> <code>10.255.255.255</code><br><code>172.16/12</code> <code>172.16.0.0</code> <code>172.31.255.255</code><br><code>192.168/16</code> <code>192.168.0.0</code> <code>192.168.255.255</code><br>（2）VPN的工作原理</p>\n<ul>\n<li>VPN的实现主要使用了两种基本技术：隧道传输和加密技术。</li>\n<li>VPN定义了两个网络的路由器之间通过Internet的一个隧道，并使用IP-in-IP封装通过隧道转发数据报。</li>\n<li>为了保证保密性，VPN把外发的数据报加密后，封装在另一个数据报中传输。</li>\n<li>隧道接收路由器将数据报解密，还原出内层数据报，然后转发该数据报。</li>\n</ul>\n<p>（3）网络地址转换NAT<br>网络地址转换NAT(Network Address Translation)方法于1994年提出，用来解决本地编址的内部网络与外网通信的问题。需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球地址IPG。所有使用本地地址的主机在和外界通信时都要在NAT路由器上将其本地地址转换成IPG才能和因特网连接。</p>\n<h2 id=\"2-12-下一代网际协议IPv6\"><a href=\"#2-12-下一代网际协议IPv6\" class=\"headerlink\" title=\"2.12 下一代网际协议IPv6\"></a>2.12 下一代网际协议IPv6</h2><p>IPv6 将地址从IPv4的32bit增大到了128bit。</p>\n<h1 id=\"3-运输层\"><a href=\"#3-运输层\" class=\"headerlink\" title=\"3.运输层\"></a>3.运输层</h1><h2 id=\"3-1-运输层\"><a href=\"#3-1-运输层\" class=\"headerlink\" title=\"3.1 运输层\"></a>3.1 运输层</h2><h3 id=\"运输层的作用\"><a href=\"#运输层的作用\" class=\"headerlink\" title=\"运输层的作用\"></a>运输层的作用</h3><p>网络层为<strong>主机之间</strong>提供逻辑通信，而运输层为<strong>应用进程之间</strong>提供端到端的逻辑通信，如下图所示:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E8%BF%90%E8%BE%93%E5%B1%82%E4%BD%9C%E7%94%A8.JPG\" width=\"70%\" height=\"50%\"></p>\n<h3 id=\"运输层的两个主要协议\"><a href=\"#运输层的两个主要协议\" class=\"headerlink\" title=\"运输层的两个主要协议\"></a>运输层的两个主要协议</h3><p>TCP/IP运输层的两个主要协议都是因特网的正式标准，即：</p>\n<ul>\n<li>用户数据报协议UDP</li>\n<li>传输控制协议TCP</li>\n</ul>\n<p>下图给出了这两种协议在协议栈中的位置：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E5%8D%8F%E8%AE%AE%E6%A0%88.JPG\" width=\"40%\" height=\"40%\"> 按OSI的术语，两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元TPDU。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为<strong>TCP报文段(segment)</strong>或<strong>UDP用户数据报</strong>。<br>UDP与TCP对比：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E4%B8%8ETCP%E7%89%B9%E7%82%B9%E5%AF%B9%E6%AF%94.JPG\" width=\"70%\" height=\"50%\"> 一些应用和应用层协议主要使用的运输层协议(TCP或UDP)：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E5%BA%94%E7%94%A8%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8D%8F%E8%AE%AE.JPG\" width=\"70%\" height=\"70%\"></p>\n<h3 id=\"端口\"><a href=\"#端口\" class=\"headerlink\" title=\"端口\"></a>端口</h3><p>运输层具有复用和分用的功能：</p>\n<ul>\n<li>应用层所有的应用进程可以通过运输层再传送到IP层（网络层），这就是<strong>复用</strong>；</li>\n<li>运输层从IP层收到数据后必须交付指明的应用进程，这就是<strong>分用</strong>。</li>\n</ul>\n<p>端口：是<strong>应用层的各种协议进程与运输实体进行层间交互的一种地址</strong>：</p>\n<ul>\n<li>在UDP和TCP的首部格式中，都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付给应用层的目的应用进程。</li>\n<li>TCP/IP运输层用一个16位端口号来标志一个端口。</li>\n<li>因此，<strong>两个计算机中的进程要相互通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）</strong>。</li>\n</ul>\n<p>因特网上的计算机通信是采用客户-服务器的方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类：<br>（1）<strong>服务器端使用的端口号</strong><br>分为两类：熟知端口号和登记端口号。</p>\n<ul>\n<li><strong>熟知端口号</strong>：数值为0~1023。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。<br>下图为一些常用的熟知端口号：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/%E7%86%9F%E7%9F%A5%E7%AB%AF%E5%8F%A3%E5%8F%B7.JPG\" width=\"70%\" height=\"50%\"></li>\n<li><strong>登记端口号</strong>：数值为1024~49151。为没有熟知端口号的应用程序使用。但要使用须在IANA按规定登记，以防重复。</li>\n</ul>\n<p>（2）<strong>客户端使用的端口号</strong><br>数值为49152~65535。这类端口号留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。</p>\n<h2 id=\"3-2-用户数据报协议UDP\"><a href=\"#3-2-用户数据报协议UDP\" class=\"headerlink\" title=\"3.2 用户数据报协议UDP\"></a>3.2 用户数据报协议UDP</h2><h3 id=\"UDP概述\"><a href=\"#UDP概述\" class=\"headerlink\" title=\"UDP概述\"></a>UDP概述</h3><p>UDP的主要特点：</p>\n<ul>\n<li><strong>UDP是无连接的</strong>，即发送数据之前不需要建立连接</li>\n<li><strong>UDP使用尽最大努力交付</strong>，即不保证可靠交付，因此主机不需要维持复杂的连接状态表</li>\n<li><strong>UDP是面向报文的</strong>。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。如下图所示：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E6%98%AF%E9%9D%A2%E5%90%91%E6%8A%A5%E6%96%87.JPG\" width=\"60%\" height=\"60%\"></li>\n<li><strong>UDP没有拥塞控制</strong>，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用很重要，很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。</li>\n<li><strong>UDP支持一对一，一对多，多对一和多对多的交互通信</strong>。</li>\n<li><strong>UDP的首部开销小</strong>，只有8个字节，比TCP的20个字节的首部要短。</li>\n</ul>\n<h3 id=\"UDP的首部格式\"><a href=\"#UDP的首部格式\" class=\"headerlink\" title=\"UDP的首部格式\"></a>UDP的首部格式</h3><p>用户数据报UDP有两个字段：数据字段和首部字段。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E9%A6%96%E9%83%A8.JPG\" width=\"60%\" height=\"60%\"> 首部字段很简单，只有8个字节，由四个字段组成，如上图所示。<strong>每个字段的长度都是两个字节</strong>。各字节具体含义如下：</p>\n<ul>\n<li><strong>源端口</strong>：源端口号。在需要对方回信时选用。不需要时可用全0。</li>\n<li><strong>目的端口</strong>：目的端口号。这在终点交付报文时必须要使用到。<br>当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点——应用进程。下图就是UDP基于端口分用的示意图：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%9F%BA%E4%BA%8E%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%88%86%E7%94%A8.JPG\" width=\"40%\" height=\"40%\"></li>\n<li><strong>长度</strong>：UDP用户数据报的长度，其最小值是8（仅有首部）。</li>\n<li><strong>检验和</strong>： 检测UDP用户数据报在传输中是否有错。有错就丢弃。<br>UDP用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。<br>UDP计算检验和的方法和计算IP数据报首部检验和的方法类似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把<strong>首部和数据部分一起都检验</strong>。</li>\n</ul>\n<h3 id=\"UDP实例\"><a href=\"#UDP实例\" class=\"headerlink\" title=\"UDP实例\"></a>UDP实例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/UDP%E5%AE%9E%E4%BE%8B.JPG\" width=\"70%\" height=\"70%\"></p>\n<h2 id=\"3-3-传输控制协议TCP\"><a href=\"#3-3-传输控制协议TCP\" class=\"headerlink\" title=\"3.3 传输控制协议TCP\"></a>3.3 传输控制协议TCP</h2><h3 id=\"TCP的特点\"><a href=\"#TCP的特点\" class=\"headerlink\" title=\"TCP的特点\"></a>TCP的特点</h3><p>TCP是TCP/IP体系中非常复杂的一个协议。下面介绍TCP最主要的特点：</p>\n<ul>\n<li>TCP是<strong>面向连接的运输层协议</strong>。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。</li>\n<li>每一条TCP连接只能有两个<strong>端点</strong>（即套接字），每一条TCP连接只能是<strong>点对点</strong>的(一对一)。</li>\n<li>TCP提供<strong>可靠交付</strong>的服务。通过TCP连接传送的数据，无差错，不丢失，不重复，并且按序到达。</li>\n<li>TCP提供<strong>全双工通信</strong>。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事情，而TCP在合适的时候把数据发送出去。在接受时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。</li>\n<li><strong>面向字节流</strong>。TCP中的”流”指的是<strong>流入到进程或从进程流出的字节序列</strong>。“面向字节流”的含义是：虽然应用程序和TCP交互的是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的<strong>无结构的字节流</strong>。TCP并不知道所传送的字节流的含义。但接收方的应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接受方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。<br>下图为TCP面向字节流的概念：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84%E6%A6%82%E5%BF%B5.JPG\" width=\"80%\" height=\"80%\">上图指出，TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少字节（UDP发送的报文长度是应用进程给出的）。</li>\n</ul>\n<h3 id=\"套接字\"><a href=\"#套接字\" class=\"headerlink\" title=\"套接字\"></a>套接字</h3><p>每一条TCP连接有两个<strong>端点</strong>，TCP的连接端点叫做<strong>套接字(socket)</strong>。<br>套接字： <code>套接字socket = (IP地址：端口号)</code><br>每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定。即：<br><code>TCP连接 ::= {socket1, socket2} = {(IP1, port1), (IP2, port2)}</code></p>\n<h3 id=\"TCP报文段的首部格式\"><a href=\"#TCP报文段的首部格式\" class=\"headerlink\" title=\"TCP报文段的首部格式\"></a>TCP报文段的首部格式</h3><p>TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而<strong>TCP的全部功能都体现在它首部中各字段的作用</strong>。<br>TCP报文段首部的前20个字节是固定的，后面有$4n$字节是根据需要而增加的选项($n$是整数)。因此TCP首部的最小长度是20字节。<br>下图为TCP报文段的首部格式：<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E6%8A%A5%E6%96%87%E6%AE%B5%E7%9A%84%E9%A6%96%E9%83%A8%E6%A0%BC%E5%BC%8F.JPG\" width=\"75%\" height=\"75%\"> 首部固定部分各字段的意义如下：</p>\n<ul>\n<li><strong>源端口</strong>和<strong>目的端口</strong>：各占2个字节，分别写入源端口号和目的端口号。</li>\n<li><strong>序号</strong>：占4个字节。首部中的序号字段值指的是<strong>本报文段所发送的数据的第一个字节的序号</strong>。序号范围是$[0,2^32-1]$，共$2^32$个序号。序号增加到$2^32-1$后，下一个序号就又回到0。TCP是面向字节流的。在一个TCP连接中传送的字节流中的<strong>每一个字节都按顺序编号</strong>。整个要传送的字节流的起始序号必须在连接建立时设置。</li>\n<li><strong>确认号</strong>：占4个字节，是<strong>期望收到对方下一个报文段的第一个数据字节的序号</strong>。若确认号等于$N$，则表明：到序号$N-1$为止的所有数据都已正确收到。</li>\n<li><strong>数据偏移</strong>：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，即指出TCP报文段的首部长度。</li>\n<li><strong>保留</strong>：占6位，保留为今后使用，目前置为0。</li>\n<li>6个<strong>控制位</strong>：<ul>\n<li><strong>紧急URG(URGent)</strong>：当URG=1时，表明紧急指针字段有效。当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的<strong>最前面</strong>，而在紧急数据后面的数据仍是普通数据。这时要与首部中的<strong>紧急指针</strong>字段配合使用。</li>\n<li><strong>确认ACK(ACKnowlegment)</strong>： <strong>仅当ACK=1时确认号字段才有效</strong>。当ACK=0时，确认号字段无效。<strong>TCP规定，在连接建立后，所有传送的报文段都必须把ACK置1</strong>。</li>\n<li><strong>推送PSH(PuSH)</strong>：用的很少。</li>\n<li><strong>复位RST(ReSeT)</strong>:当RST=1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。</li>\n<li><strong>同步SYN</strong>：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应的报文段中使用SYN=1和ACK=1。因此，<strong>SYN置为1就表示这是一个连接请求或者连接接受报文</strong>。</li>\n<li><strong>终止FIN</strong>：用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。</li>\n</ul>\n</li>\n<li><strong>窗口</strong>：占2个字节。窗口值是$[0,2^16-1]$之间的整数。窗口指的是发送本报文段的一方的<strong>接收窗口</strong>（而不是自己的发送窗口）。窗口值告诉对方：<strong>从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量</strong>。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，<strong>窗口值作为接收方让发送方设置其发送窗口的依据</strong>。<br>例如：设确认号是701，窗口字段是1000。这就表明，从701号算起，发送此报文段的一方还有接受1000个字节数据（字节序号是701~1700）的接受缓存空间。</li>\n<li><strong>检验和</strong>：占2个字节。检验和字段检验的范围包括首部和数据这两个部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。</li>\n<li><strong>紧急指针</strong>：占2个字节。紧急指针仅在URG=1时才有意义。紧急指针指出了紧急数据的末尾在报文段中的位置。</li>\n<li><strong>选项</strong>：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。其中有<strong>最大报文段长度MSS</strong>、<strong>窗口扩大</strong>、<strong>时间戳</strong>、<strong>选择确认(SACK)</strong>等选项。</li>\n</ul>\n<h3 id=\"TCP的运输连接管理\"><a href=\"#TCP的运输连接管理\" class=\"headerlink\" title=\"TCP的运输连接管理\"></a>TCP的运输连接管理</h3><p>TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向来连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：<strong>连接建立、数据传送和连接释放</strong>。<br>在TCP连接建立过程中要解决以下三个问题：<br>（1）要使每一方能够明确知道对方的存在。<br>（2）要允许双方协商一些参数（如最大窗口值，是否使用窗口扩大选项和时间戳选项等）。<br>（3）能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。<br>TCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做<strong>客户(client)</strong>，而被动等待连接建立的应用进程叫<strong>服务器(server)</strong>。</p>\n<h4 id=\"TCP的连接建立\"><a href=\"#TCP的连接建立\" class=\"headerlink\" title=\"TCP的连接建立\"></a>TCP的连接建立</h4><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B.JPG\" width=\"80%\" height=\"80%\"> 上图为TCP的建立连接的过程：</p>\n<ul>\n<li>假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。</li>\n<li>最初两端的TCP进程都处于CLOSED(关闭)状态。注意，<strong>A主动打开连接</strong>，而<strong>B被动打开连接</strong>。</li>\n<li>B的TCP服务器进程先创建<strong>传输控制块TCB</strong>，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN(收听)状态，等待客户的连接请求。如有，即作出响应。</li>\n<li>A的TCP客户进程也是首先创建<strong>传输控制模块TCB</strong>，然后向B发出连接请求报文段，首部中的同步位SYN置1，同时选择一个初始序号seq=x。TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但要<strong>消耗掉一个序号</strong>。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。</li>\n<li>B收到连接请求报文后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。注意，此SYN报文段也不能携带数据，但同样需要<strong>消耗掉一个序号</strong>。这是TCP服务器进程进入SYN-RCVD(同步收到状态)。</li>\n<li>TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1。TCP规定，ACK报文段可以携带数据。但<strong>如果不携带数据则不消耗序号</strong>，在此情况下，下一个数据报文段的序号仍是seq=x+1。这是TCP连接已经建立，A进入ESTABLISHED(已建立连接)状态。</li>\n<li>当B收到A的确认后，也进入ESTABLISHED状态。</li>\n<li>上面给出的连接建立的过程叫做<strong>三次握手</strong>。</li>\n</ul>\n<p>为什么A还要发送一次确认呢？</p>\n<ul>\n<li>这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。</li>\n<li>“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。</li>\n</ul>\n<h4 id=\"TCP的连接释放\"><a href=\"#TCP的连接释放\" class=\"headerlink\" title=\"TCP的连接释放\"></a>TCP的连接释放</h4><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%BF%90%E8%BE%93%E5%B1%82/TCP%E8%BF%9E%E6%8E%A5%E9%87%8A%E6%94%BE.JPG\" width=\"80%\" height=\"80%\"> 数据传输结束后，通信的双方都可释放连接，上图为TCP连接释放的过程：</p>\n<ul>\n<li>现在A和B都处于ESTABLISHED状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq=u，它等于前面已经传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1(终止等待1)状态，等待B的确认。注意，TCP规定，FIN报文段即使不携带数据，也消耗掉一个序号。</li>\n<li>B收到连接释放报文段后即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B前面已经传送过的数据的最后一个字节的序号加1。然后B就进入CLOSED-WAIT(关闭等待)状态。TCP服务器进程这时应通知高层应用进程，因为从A到B这个方向的连接就释放了，这时的TCP连接就处于<strong>半关闭(half-close)</strong>状态，即A已经没有数据要发送了，但B若发送数据，A仍要接受。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。</li>\n<li>A收到来自B的确认后，就进入FIN-WAIT2(终止等待2)状态，等待B发出的连接释放报文。</li>\n<li>若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这是B发出的连接释放报文段必须使FIN=1。现假定B的序号为w(在半关闭状态B可能又发送了一些数据)。B还必须重复上次已发送过的确认号ack=u+1。这时B就进入LAST-ACK(最后确认)状态，等待A的确认。</li>\n<li>A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1。然后进入到TIME-WAIT(时间等待)状态。请注意，现在TCP连接还没有释放掉。必须经过<strong>时间等待计时器(TIME-WAIT timer)</strong>设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做<strong>最长报文段寿命(Maximum Segment Lifetime)</strong>。当A撤销掉相应的传输控制块TCB后，就结束了这次的TCP连接。</li>\n<li>B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。注意到，B结束TCP连接的时间要比A早一些。</li>\n<li>上述的TCP连接释放过程是四次挥手。</li>\n</ul>\n<p>为什么A在TIME-WAIT状态必须等待2MSL的时间呢？有两个理由：</p>\n<ul>\n<li>第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态。</li>\n<li>第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有的报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。</li>\n</ul>\n<p>除时间等待计时器外，TCP还设有一个<strong>保活计时器(keepalive timer)</strong>。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不再白白等待下去。这就是保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。</p>\n<h1 id=\"4-应用层\"><a href=\"#4-应用层\" class=\"headerlink\" title=\"4.应用层\"></a>4.应用层</h1><h2 id=\"域名系统-DNS\"><a href=\"#域名系统-DNS\" class=\"headerlink\" title=\"域名系统(DNS)\"></a>域名系统(DNS)</h2><ul>\n<li>域名系统是因特网使用的命名系统，完成域名解析，将域名解析到特定的IP地址。</li>\n<li>DNS采用客户/服务器应用模式，其核心是分级的、基于域的命名机制以及实现该命名机制的分布式数据库系统。</li>\n<li>域名解析是由若干个域名服务器程序完成的。域名服务器程序在专设的节点上运行，运行该程序的节点称为域名服务器。</li>\n</ul>\n<p><strong>域名解析</strong></p>\n<ul>\n<li><code>zh.wikipedia.org</code>作为一个域名就和IP地址<code>208.80.154.225</code>相对应。DNS就像是一个自动的电话号码簿，我们可以直接拨打wikipedia的名字来代替电话号码（IP地址）。DNS在我们直接调用网站的名字以后就会将像<code>zh.wikipedia.org</code>一样便于人类使用的名字转化成像<code>208.80.154.225</code>一样便于机器识别的IP地址。</li>\n<li>DNS查询有两种方式：递归和迭代。DNS客户端设置使用的DNS服务器一般都是递归服务器，它负责全权处理客户端的DNS查询请求，直到返回最终结果。而DNS服务器之间一般采用迭代查询方式。</li>\n</ul>\n<p>以查询<code>zh.wikipedia.org</code>为例：</p>\n<ul>\n<li>客户端发送查询报文”query zh.wikipedia.org”至DNS服务器，DNS服务器首先检查自身缓存，如果存在记录则直接返回结果。</li>\n<li>如果记录老化或不存在，则<ul>\n<li>DNS服务器向根域名服务器发送查询报文”query zh.wikipedia.org”，根域名服务器返回<code>.org</code>域的权威域名服务器地址，这一级首先会返回的是顶级域名的权威域名服务器。</li>\n<li>DNS服务器向<code>.org</code>域的权威域名服务器发送查询报文”query zh.wikipedia.org”，得到<code>.wikipedia.org</code>域的权威域名服务器地址。</li>\n<li>DNS服务器向<code>.wikipedia.org</code>域的权威域名服务器发送查询报文”query zh.wikipedia.org”，得到主机<code>zh</code>的A记录，存入自身缓存并返回给客户端。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"远程登录-Telnet\"><a href=\"#远程登录-Telnet\" class=\"headerlink\" title=\"远程登录(Telnet)\"></a>远程登录(Telnet)</h2><ul>\n<li>远程登录是因特网的基本应用服务之一，采用客户机/服务器模式。</li>\n<li>用户可以使用Telnet登录到远地的另一台主机上。</li>\n<li>Telent能将用户的击键传到远程主机，同时也能将远程主机的输出通过TCP连接返回到用户屏幕。</li>\n<li>远程桌面（RDP）就是在TELNET技术上发展起来的。</li>\n</ul>\n<h2 id=\"文件传输协议-FTP\"><a href=\"#文件传输协议-FTP\" class=\"headerlink\" title=\"文件传输协议(FTP)\"></a>文件传输协议(FTP)</h2><ul>\n<li>FTP(File Transfer Protocol)是Internet上使用得最为广泛的文件传送协议。FTP提供交互式的访问，允许客户上传文件到服务器或者从服务器下载文件。</li>\n<li>FTP屏蔽了各个计算机系统的差异，适合在异构计算机之间传送文件。</li>\n<li>文件传输协议FTP基于TCP，采用客户/服务器模式，提供文件传送基本网络服务。</li>\n<li>一个FTP服务器进程可同时为多个客户进程提供服务。FTP服务器包括两部分：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求。</li>\n</ul>\n<h2 id=\"动态主机配置协议-DHCP\"><a href=\"#动态主机配置协议-DHCP\" class=\"headerlink\" title=\"动态主机配置协议(DHCP)\"></a>动态主机配置协议(DHCP)</h2><ul>\n<li>动态主机配置协议允许一台计算机加入新网可自动获取网络配置信息，不用人工参与。</li>\n<li>网络计算机需要配置的项目包括：IP地址、子网掩码、默认路由器的IP地址、以及域名服务器的IP地址。</li>\n<li>DHCP采用客户/服务器模式。</li>\n</ul>\n<h2 id=\"电子邮件系统-E-mail\"><a href=\"#电子邮件系统-E-mail\" class=\"headerlink\" title=\"电子邮件系统(E-mail)\"></a>电子邮件系统(E-mail)</h2><p>暂略</p>\n<h2 id=\"万维网-WWW\"><a href=\"#万维网-WWW\" class=\"headerlink\" title=\"万维网(WWW)\"></a>万维网(WWW)</h2><ul>\n<li>万维网WWW(World Wide Web)并非某种特殊的计算机网络。</li>\n<li>万维网是一个大规模的、联机式的信息储藏所。</li>\n<li>万维网用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。</li>\n<li>这种访问方式称为“链接”。</li>\n</ul>\n<h3 id=\"万维网的工作方式\"><a href=\"#万维网的工作方式\" class=\"headerlink\" title=\"万维网的工作方式\"></a>万维网的工作方式</h3><ul>\n<li>万维网以客户服务器方式工作。</li>\n<li>浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。</li>\n<li>客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。</li>\n<li>在一个客户程序主窗口上显示出的万维网文档称为页面(page)。</li>\n</ul>\n<h3 id=\"万维网必须解决的问题\"><a href=\"#万维网必须解决的问题\" class=\"headerlink\" title=\"万维网必须解决的问题\"></a>万维网必须解决的问题</h3><ul>\n<li>怎样标志分布在整个因特网上的万维网文档？<ul>\n<li>使用统一资源定位符URL(Uniform Resource Locator)来标志万维网上的各种文档,使每一个文档在整个因特网的范围内具有惟一的标识符URL。</li>\n</ul>\n</li>\n<li>用什么协议实现万维网上各种超链的链接？<ul>\n<li>在万维网客户程序与万维网服务器程序之间进行交互所使用的协议，是<strong>超文本传送协议HTTP</strong>(HyperText Transfer Protocol)。</li>\n<li>HTTP是一个<strong>应用层协议</strong>，它使用TCP连接进行可靠的传送。</li>\n</ul>\n</li>\n<li>怎样使各种万维网文档都能在因特网上的各种计算机上显示出来，同时使用户清楚地知道在什么地方存在着超链？<ul>\n<li>超文本标记语言HTML(HyperText Markup Language)使得万维网页面的设计者可以很方便地用一个超链从本页面的某处链接到因特网上的任何一个万维网页面，并且能够在自己的计算机屏幕上将这些页面显示出来。</li>\n</ul>\n</li>\n<li>怎样使用户能够很方便地找到所需的信息？<ul>\n<li>为了在万维网上方便地查找信息，用户可使用各种搜索工具，例如：<code>Google(http://www.google.com.hk)</code>。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"统一资源定位符URL\"><a href=\"#统一资源定位符URL\" class=\"headerlink\" title=\"统一资源定位符URL\"></a>统一资源定位符URL</h3><ul>\n<li>统一资源定位符URL是对可以从因特网上得到的资源的位置和访问方法的一种简洁的表示。</li>\n<li>URL给资源的位置提供一种抽象的识别方法，并用这种方法给资源定位。</li>\n<li>只要能够对资源定位，系统就可以对资源进行各种操作，如存取、更新、替换和查找其属性。</li>\n<li>URL 相当于一个文件名在网络范围的扩展。因此 URL 是与因特网相连的机器上任何可访问对象的一个指针。</li>\n<li>由以冒号隔开的两大部分组成，并且在 URL 中的字符对大写或小写没有要求。URL的一般形式是：<code>&lt;URL的访问方式&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;</code>。<ul>\n<li>其中，<url的访问方式>可为文件传输协议FTP或超文本传送协议HTTP。如使用FTP的URL举例：<code>ftp://rtfm.mit.edu/pub/abc.txt</code>，使用HTTP的URL举例：<code>http://shopping.dangdang.com</code></url的访问方式></li>\n<li>&lt;主机&gt; 是存放资源的主机在因特网中的域名。</li>\n<li>&lt;端口&gt;/&lt;路径&gt;有时可忽略。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"超文本传送协议HTTP\"><a href=\"#超文本传送协议HTTP\" class=\"headerlink\" title=\"超文本传送协议HTTP\"></a>超文本传送协议HTTP</h3><ul>\n<li>Ted Nelson1963年新创了hypertext和hypermedia：<ul>\n<li>超文本(hypertext)是显示在计算机或其他电子设备上，具有超链(hyperlink)指向其他文本的文本。<br>例如：<code>&lt;a href=&quot;http://www.w3.org&quot;&gt;W3C organization website&lt;/a&gt;</code></li>\n<li>超媒体(hypermedia)是超文本的扩充，是图片、视频和声音以及文本的复合体。</li>\n</ul>\n</li>\n<li>万维网是分布式超媒体(hypermedia)系统。超文本、超媒体页面通过超链相互连接。</li>\n<li>HTTP是面向事务的(transaction-oriented)应用层协议，是在万维网上可靠地交换文件（各种多媒体文件）的重要基础。</li>\n<li>HTTP的工作过程:<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E5%BA%94%E7%94%A8%E5%B1%82/http%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.JPG\" width=\"50%\" height=\"50%\"></li>\n<li>用户点击超链后所发生的事件：<ul>\n<li>浏览器分析超链指向页面“我校学科楼组团正式启用”的 URL</li>\n<li>浏览器向DNS服务器请求解析 www.njupt.edu.cn 的 IP 地址</li>\n<li>域名系统解析出南京邮电大学Web服务器的 IP 地址</li>\n<li>浏览器与web服务器建立 TCP 连接</li>\n<li>浏览器发出取文件HTTP请求：GET /s/222/t/1100/41/fd/info82429.htm HTTP/1.1</li>\n<li>Web服务器 做出响应，把文件 info82429.htm 发给浏览器</li>\n<li>TCP 连接释放</li>\n<li>浏览器显示info82429.htm中的所有文本。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h1><ul>\n<li><a href=\"http://www.icourse163.org/course/NJUPT-1001639008?tid=1001719010\" target=\"_blank\" rel=\"noopener\">网络技术与应用，南京邮电大学</a></li>\n<li>计算机网络，谢希仁</li>\n</ul>"},{"title":"深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化","mathjax":true,"date":"2017-12-27T07:49:50.000Z","_content":"# **1.深度学习的实用层面**\n## **1.1 建立机器学习应用**\n### **训练/开发/测试集**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%861.JPG\" width=\"70%\" height=\"70%\">在实际中应用机器学习是一个高度迭代的过程：\n- 在构建一个神经网络的时，需要设置许多超参数，例如神经网络的层数、每个隐藏层包含的神经元个数、学习速率、激活函数的选择等。实际上很难在第一次设置的时候就选择到这些最佳的参数，而是需要通过不断地迭代更新来获得。\n- 迭代的过程如下：先有个想法，先选择初始的参数值，构建神经网络模型结构；然后通过代码实现；最后，通过实验验证。根据实验结果，对参数进行适当的调整优化，再进行下一次的Idea->Code->Experiment循环。\n- 恰当的将数据分为训练/开发/测试集，可使得迭代效率更高。\n\n<!-- more --> \n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%862.JPG\" width=\"90%\" height=\"90%\">一般地，将所有的样本数据分成三个部分：训练(Train)/开发(Dev)/测试(Test)集：\n- 训练集用来训练你的模型；\n- 开发集又称交叉验证集(cross validation set)，用来验证不同算法的表现情况，从中选择最好的模型；\n- 测试集用来测试最好模型的实际表现，给出该模型的无偏估计。\n\n关于数据集的比例划分，在以前，可获得的数据量不是很大的情况：\n- 通常设置训练集和测试集的数量比例为70%和30%。如果有开发集，则设置比例为60%、20%、20%，分别对应训练/测试/开发集。\n- 这种比例分配在样本数量不是很大的情况下，例如100,1000,10000，是比较科学的。\n \n关于数据集的比例划分，在如今，大数据的时代：\n- 如果数据量很大的时候，例如数据量达100万，70%/30%或60%/20%/20%的比例分配是不合理的。\n- 因为开发集的目的是用来比较验证不同模型的优劣，从而选择更好的模型。因此，通常不需要所有样本的20%这么多的数据来进行验证。例如对于100万的样本，往往只需要10000个样本来做验证就够了。测试集的目的是给出已选定最优模型的无偏估计。对于100万的样本，往往也只需要10000个样本就够了。\n- 科学的做法是要将开发集和测试集的比例设置得很低。因此，对于大数据样本，训练/开发/测试集的比例通常可以设置为98%/1%/1%，或者99%/0.5%/0.5%。样本数据量越大，相应的开发/测试集的比例可以设置的越低一些。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%863.JPG\" width=\"80%\" height=\"80%\">现代深度学习还有个重要的问题就是训练集和测试集的分布不匹配，意为是训练集和测试集来自于不同的分布。例如：\n- 对于一个手机app，可以让用户上传图片，然后app识别出猫的图片。该应用中，训练集可能是从网络抓取的图片，而开发和测试集可能来自不同用户的上传的猫的照片。\n- 从网络抓取的图片可能像素较高且拍摄专业等等，而用户上传的图片可能像素较低且模糊等等。因此，训练集和验证/测试集可能来自不同的分布。\n- **解决方法：保证开发集和测试集来自于同一分布。**\n\n注意：\n- 如果不需要对最终选定的神经网络做出无偏估计，可以没有测试集，只有训练/开发集（也有人说成只有训练/测试集，都可以）。\n\n### **偏差/方差**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 对于只有$x_1$和$x_2$两个特征的二维数据集，可以绘制数据，可视化偏差和方差。如上图所示：\n- 左：高偏差，欠拟合\n- 中：恰好\n- 右：高方差，过拟合\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"80%\" height=\"80%\"> 对于高维数据，无法绘制数据以及可视化决策边界。但可通过几个指标来理解偏差和方差。\n基于人工误差（或贝叶斯误差或最优误差)非常低（约为0%）并且训练集和开发集都来自于同一分布这两个假设，如上图所示：\n- 训练集误差为1%/开发集误差11%，结合两者说明该算法在训练集上过拟合，导致在开发集上的泛化性能不好，推出高方差。\n- 训练集误差为15%，在训练集上欠拟合，推出高偏差。开发集误差16%，相比于训练集误差只高1%，并不存在高方差。\n- 训练集误差为15%，推出高偏差。开发集误差30%，相比于训练集误差高15%，推出高方差。\n- 训练集误差为0.5%，低偏差。开发集误差1%，相比于训练集误差只高0.5%，低方差。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"70%\" height=\"70%\"> 上图展示了高偏差和高方差同时存在的可视化情形：\n- 决策边界为线性，欠拟合，高偏差\n- 在局部发生过拟合，高方差\n- 该情形在二维情况下看起来不自然，但对于高维数据，这种情况是容易发生的。\n\n### **机器学习的基本准则**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99.JPG\" width=\"70%\" height=\"70%\"> 当训练好最初的神经网络时：\n- 高偏差？通过训练集表现来确定，若存在高偏差，则可通过更大的网络或训练更长时间来解决。\n- 高方差？通过开发集表现来确定，若存在高方差，则可通过获取更多数据及正则化来解决。\n- 直到找到低偏差且低方差的网络。\n\n关于偏差和方差的权衡：\n- 在早期的机器学习时代，有很多关于偏差和方差的权衡的讨论，因为当时没有能够单独减小偏差和单独减小方差的工具。\n- 而在如今的深度学习和大数据时代，通过扩大网络几乎总是能够较小偏差而不增大方差（只要用恰当的方式正则化）；通过获得更多数据几乎总是能够减小方差而不增大偏差。因此，这也解释了为何深度学习在监督学习中如此有效。\n\n## **1.2 正则化神经网络**\n### **正则化**\n获得更多数据和正则化都是解决过拟合(高方差)的有效方法，但很多时候并不能总是获得更多数据或者获得更多数据的代价太高。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%AD%A3%E5%88%99%E5%8C%96-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.JPG\" width=\"80%\" height=\"80%\">先介绍在逻辑回归中应用正则化，如图：\n- 逻辑回归：$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})$\n- 参数：$w \\in R^{n_x}$，$b\\in R$\n- 目的：$\\min\\limits_{w,b} J(w,b)$；\n- $J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_2^2$\n - L2正则化：`$||w||_2^2=\\sum_{j=1}^{n_x}w_j^2=w^Tw$`，其中$\\lambda$是正则化参数\n- $J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_1$\n - L1正则化：`$||w||_1=\\sum_{j=1}^{n_x}|w_j|$`，其中$\\lambda$是正则化参数\n- 若使用L1正则化，$w$最后会变得稀疏，即$w$中会有很多0。有人认为这有助于压缩模型，因为有一部分参数是0，只需较少的内存来存储模型。\n然而在实践中发现，通过L1正则化让模型变得稀疏带来的收效甚微。故吴恩达觉得至少在压缩模型的目标上，它的作用不大。\n总之，在训练神经网络中，L2正则化应用地更频繁。\n- 只正则化参数$w$，而省略正则化参数$b$的原因是：$w$是高维矢量参数，$b$只是一个标量，几乎所有的参数都集中在$w$中，$b$只是大量参数中的一个，故可省略。\n- 注意，在python中，由于`lambda`是保留字，为了避免冲突，故在编程练习中使用`lambd`来表示$\\lambda$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"50%\" height=\"50%\"> 在神经网络中应用正则化，如图：\n- 代价函数：`$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})=\\frac1m\\sum\\limits_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum\\limits_{l=1}^L||W^{[l]}||_F^2$`\n- 其中，矩阵的L2范数称为F范数(Frobenius范数)，`$||W^{[l]}||_F^2=\\sum_{i=1}^{n^{[l]}}\\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2$`。\n- 正则化后的梯度下降法：\n - $dW^{[l]}=dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]}$\n - $W^{[l]} =W^{[l]}-\\alpha dW^{[l]}$\n\n**L2正则化也被称作权重衰减(weight decay)**。原因如下：\n- $$\n\\begin{eqnarray}W^{[l]} &:=&W^{[l]}-\\alpha\\cdot dW^{[l]}\\\\ &=&W^{[l]}-\\alpha\\cdot(dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]})\\\\ &=&(1-\\alpha\\frac{\\lambda}{m})W^{[l]}-\\alpha\\cdot dW^{[l]}_{before} \\end{eqnarray}\n$$\n- 其中，$(1-\\alpha\\frac{\\lambda}{m})<1$。加上L2正则化项后，$W^{[l]}$的每次更新，都会乘以一个小于1的项。即每次迭代更新，都使得$W^{[l]}$不断地减小，故L2正则化又被称为权重衰减。\n\n### **为什么正则化可以减轻过拟合**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%881.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例一：\n- 假设由于选择了非常复杂的神经网络模型，因而存在过拟合，如上图左上角所示。\n- 加上正则化项后，若将正则化参数$\\lambda$设置的很大，那么参数$ W^{[l]}\\approx0$，参数$W$中的很多数接近于0，这相当于网络中的很多神经元不起作用，这样原本过于复杂的神经网络模型就变得简单化了，故减轻了过拟合。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%882.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例二：\n- 假设激活函数是`tanh`函数。`tanh`函数的特点是在$|z|$较小的区域，函数是近似线性的，而当$|z|$稍大的时候，才会展现出非线性能力。\n- 若加入正则化，使$\\lambda$较大，即对权重$W^{[l]}$的惩罚较大，使得$W^{[l]}$较小。\n- 因为$z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}$。当$W^{[l]}$较小，$z^{[l]}$也较小。当$z^{[l]}$在较小范围内时，激活函数$g(z)$就会近似于线性函数。因此每一层几乎都是线性的，当隐藏曾的激活函数是线性函数的时候，再多隐藏层也只是计算线性函数。故网络不能拟合复杂的非线性函数，便不容易过拟合了。\n\n### **Dropout正则化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-1.JPG\" width=\"70%\" height=\"70%\"> 除了正则化外，还有另外一种防止过拟合的有效方法：Dropout(随机失活)：\n- Dropout：在神经网络的训练过程中，每一次迭代，按照一定的概率随机地将其暂时从网络中丢弃。\n- 也就是说，每一次迭代，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-2.JPG\" width=\"50%\" height=\"50%\"> Dropout有不同的实现方法，Inverted dropout(反向失活)是目前最常用的实现方法：\n- 假设对于第$l=3$层神经元，设定保留神经元比例概率`keep_prob=0.8`。在Python中，Inverted dropout可实现如下：\n```Python\nd3 = np.random.rand(a3.shape[0],a3.shape[1]) < keep_prob\na3 = np.multiply(a3,d3) #逐元素相乘，也可以写成 a3 *= d3\na3 /= keep_prob         #保持a3的期望值不变。这样在测试阶段也不用再对a3值进行缩放\n```\n - 最后一步解释：例如`keep_prob=0.5`，该层将有一般的神经元被关闭，故该层的输出将被0.5缩放，因为只有剩下的一半神经元为计算输出做贡献。除以0.5等价于乘以2。因此输出有了相同的期望值。\n- 反向传播过程：\n```Python\nda3 = np.multiply(da3,d3) #前向传播中关闭了某些神经元，反向传播中也关闭\nda3 /= keep_prob          #a3缩放了keep_prob尺度，根据微积分的性质，则它的梯度也要缩放\n```\n\n注：Dropout仅在训练阶段使用，在测试阶段，不使用Dropout。\n### **理解Dropout**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-3.JPG\" width=\"50%\" height=\"50%\">如图，对于网络中的某一神经元，若采用了dropout，对于每个不同的样本，它的输入特征被消除的特征都不同，因此该神经元不能依靠任一输入特征，故最终网络会分散权重，即所有的权重都不会过大。\n使用Dropout的时候的几个注意点：\n- 可为不同网络层设置不同的`keep_prob`，但该做法的缺点是引入了更多的超参数。可将神经元较多(更容易过拟合)的隐藏层，`keep_out`设置得较小，如0.5；神经元越少的隐藏层，`keep_out`设置得较大，例如0.7。`keep_out`设置为1，表示全部保留，不使用Dropout。\n- 不建议对输入层进行Dropout，如果输入层维度很大，例如图片，那么可以设置Dropout，但`keep_out`应设置的大一些，例如0.8，0.9。\n- Dropout在计算机视觉领域中应用广泛（实际从AlextNet中提出），因为输入层(图像)维度较大，且通常没有足够多的训练样本。\n- Dropout是一种正则化技巧，用来防止过拟合，只有在确认模型过拟合后，再使用它。\n- Dropout的一大缺点是代价函数$J$不再被明确定义，每次迭代都会随机移除一些神经元。故失去了检查梯度下降这一项调式工具，即通过绘图检查代价函数$J$是否随着迭代次数而减小（定义明确的代价函数$J$，在每次迭代后都会下降）。故应关闭Dropout(`keep_out`设置为1)，再进行梯度下降检查。\n\n### **其他正则化方法**\n除了L2正则化和dropout之外，还有其它的正则化方法，如:数据增强，提前终止(early stopping)。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%951.JPG\" width=\"60%\" height=\"60%\">数据增强是对已有的训练样本进行一些处理来“制造”出更多的样本。\n- 例如图片识别问题中，数据增强是通过对已有的图片进行水平翻转、随机剪裁等方式制造出训练样本。\n- 虽然这些新样本是基于原有样本的，可能新的训练集有些冗余，但是相对于重新搜集全新独立的数据，数据增强不需要成本。\n- 因为增加了训练数据，能起到减轻过拟合的作用，故算过正则化方法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%952.JPG\" width=\"80%\" height=\"80%\">另外一种正则化方法early stopping：如图，根据训练集误差曲线(或$J$的曲线)和开发集误差曲线(或$J$的曲线)随着迭代次数的变化趋势，选择使得开发集误差最小的迭代次数，停止训练，即early stopping。\n- 直观解释：神经网络训练前,$W$的值趋近于0,随着训练的进行，$W$越来越大。early stopping相当于选取了一个不大不小的$W$，类似于$||w||_F$的效果，从而希望此时神经网络的过拟合不严重。\n\nearly stopping的缺点：\n- 通常来说，机器学习训练模型有两个目标：一是优化代价函数，即减小$J$；二是防止过拟合。这两个任务是分开进行的。把这二者之间的关系称为正交化(orthogonalization)，后面课程会进一步讲解。\n- early stopping的做法相当于将两个任务合在一起执行，减少迭代次数停止训练时，$J$就不会足够小，且希望此时不过拟合。\n\nearly stopping的优点：\n- 相比与L2正则化，early stopping不用选择超参数$\\lambda$。\n\n吴恩达的做法：\n- 偶尔用early stopping，一般只用L2正则化。\n\n## 1.3 **设置优化问题**\n### **归一化输入**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A51.JPG\" width=\"80%\" height=\"80%\"> 在训练神经网络时，**归一化(normalize)输入**可以**加速训练过程($J$的优化过程)**。\n归一化输入就是将原始数据减去其均值$\\mu$后，再除以其方差$\\sigma^2$：\n- $\\mu=\\frac1m\\sum_{i=1}^m x^{(i)}$\n- $x = x-\\mu$\n- $\\sigma^2=\\frac1m\\sum_{i=1}^m x^{(i)}**2$\n- $x = x/ \\sqrt{\\sigma^2}$\n- 注：对于训练集和测试集，应使用同样的$\\mu$和$\\sigma^2$进行归一化处理，即均使用训练集计算出的$\\mu$和$\\sigma^2$进行归一化处理。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A52.JPG\" width=\"75%\" height=\"75%\"> 上图以二维输入特征为例，解释了为什么归一化输入可以加速训练过程：\n- 假设输入特征为二维，且$x_1$的范围是[1,1000]，$x_2$的范围是[0,1]。  \n- 如图左下所示，若不归一化输入，$x_1$与$x_2$之间分布极不平衡，代价函数$J$与$x_1$和$x_2$的等高线是一个细长的椭圆形。对其进行梯度下降算法时，容易发生振荡，且需选择很小的学习速率$\\alpha$，来避免$J$发生振荡，一旦$\\alpha$较大，必然发生振荡，故学习过程很慢。\n- 如图右下所示，若归一化输入，$x_1$与$x_2$分布均匀，代价函数$J$与$x_1$和$x_2$的等高线是一个圆形。对其进行梯度下降算法时， 可选取较大的步长$\\alpha$，且$J$不易发生振荡，故学习过程较快。\n- 注意：如果输入特征的尺度非常不同，比如有些特征取值为[0,1]，有些是[1,1000]，那对输入进行归一化就很重要。而如果输入特征本来尺度就相近，那么这一步就不那么重要。\n- 吴恩达的做法：因为归一化输入的步骤几乎从来没有任何害处，所以无论如何总是进行归一化，尽管不确定它是否会让训练变得更快。\n\n### **梯度消失与梯度爆炸**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8.JPG\" width=\"75%\" height=\"75%\"> 当训练深层神经网络时，会出现梯度消失和梯度爆炸问题。如图：\n- 为便于分析，令各层的激活函数为线性函数，即$g(z)=z$，且令$b=0$。那么，该网络的预测输出$\\hat y$为：\n - $\\hat y=W^{[L]}W^{[L-1]}W^{[L-2]}\\cdots W^{[3]}W^{[2]}W^{[1]}x $\n- 如果各层权重$W^{[l]}$只比1或单位矩阵稍大一点（如1.5），深层神经网络的激活函数将作为层数$l$的函数指数级增长。\n- 如果各层权重$W^{[l]}$只比1或单位矩阵稍小一点（如0.9），深层神经网络的激活函数将作为层数$l$的函数指数级递减。\n- 虽然上图只论述了激活函数作为层数$l$的函数指数级增加或减少，同样可以论证表明，计算出的导数或梯度，也会指数级增加或指数级减少。\n- 在一个非常深的神经网络（如150层）中，如果激活函数或梯度作为$l$的函数指数级的增大或减小，这些值会变得非常大或非常小，这会让训练变得非常困难。尤其是如果梯度作为$l$的函数指数级减小，梯度下降会用很小很小的步子走，梯度下降会用很长时间才能完成学习。\n\n### **深层网络的权重初始化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%B1%82%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96.JPG\" width=\"80%\" height=\"80%\"> 针对梯度消失和梯度爆炸，有一种部分解决方法，虽然不能完全解决它，但帮助很大，即更小心地随机初始化神经网络。\n如图，以初始化单个神经元为例，然后再把它应用到深层网络中：\n- $z=w_1x_1+w_2x_2+...+w_nx_n$\n- 为了让$z$不会过大或者过小，思路是让$w$与$n$有关，且$n$越大，$w$应该越小才好。这样能够保证$z$不会过大。\n- 如果激活函数是`tanh`，一般在初始化$w$时，令其方差为$\\frac1n$，即$Var(w)=\\frac1n$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{1}{n^{[l-1]}})$\n - 解释：第$l$层中的每个神经元都有$n^{[l-1]}$个输入。标准正态分布均值为0，方差为1，乘以$np.sqrt(\\frac{1}{n^{[l-1]}})$，那么$w$的方差便为$\\frac{1}{n^{[l-1]}}$\n 方差性质：$C$为常数，$D(CX) = C^2D(X)$\n - 该初始化方法也称为“Xavier initialization”。\n- 如果激活函数是`ReLU`，一般在初始化$w$时，令其方差为$\\frac2n$，即$Var(w)=\\frac2n$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}})$\n - 该初始化方法也称为“He initialization”。\n- 除此之外，Yoshua Bengio提出了另外一种初始化$w$的方法，令其方差为$\\frac{2}{n^{[l-1]}+n^{[l]}}$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}+n^{[l]}})$\n- 注：视频中3：15秒处，还有一段关于解释该做法可以有效减缓梯度消失/梯度爆炸的原因，没听懂，待理解。\n\n### **梯度的数值逼近**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91.JPG\" width=\"80%\" height=\"80%\"> 对于神经网络的反向传播，有一项重要的测试——梯度检验(gradient checking)。该节先介绍梯度的数值逼近：\n- 采用双边差分公式进行数值逼近：$f'(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta-\\varepsilon)}{2\\varepsilon}$\n- 如$f(\\theta)=theta^3$，当$\\theta$为1，$\\varepsilon$为0.01时，逼近误差为：0.0001\n- 注意：不采用单边差分公式：$f'(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta)}{\\varepsilon}$进行梯度的数值逼近的原因是：\n - 单边差分公式的逼近误差是$O(\\varepsilon)$。\n - 双边差分公式的逼近误差是$O(\\varepsilon^2)$，逼近误差更小，故本课程采用此方法。\n- 即利用的是该导数定义：$$ f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta - \\varepsilon)}{2 \\varepsilon} $$，而不是该导数定义：$$f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta)}{\\varepsilon}$$\n\n### **梯度检验**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C1.JPG\" width=\"75%\" height=\"75%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C2.JPG\" width=\"75%\" height=\"75%\"> 进行梯度检验，可验证代码中的反向传播是否有错误：\n- 首先，将$W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]}$ 这些矩阵逐个转变为一维向量，然后连接成一个大的一维向量$\\theta$。这样$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})$ 就可表示成$J(\\theta)$。\n- 然后，将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\\cdots,dW^{[L]},db^{[L]}$同上一步骤一样构造成一个大的一维向量 $d\\theta$。注意到，$d\\theta$的维度与$\\theta$是一致的。\n- 接着，对$\\theta$中的每个元素$\\theta_i$，计算近似梯度：\n$$d\\theta_{approx}[i]=\\frac{J(\\theta_1,\\theta_2,\\cdots,\\theta_i+\\varepsilon,\\cdots)-J(\\theta_1,\\theta_2,\\cdots,\\theta_i-\\varepsilon,\\cdots)}{2\\varepsilon}$$\n- 最终，得到$d\\theta_{approx}$。\n- 将`$d\\theta_{approx}$`与`$d\\theta$`相比较，检查是否一致，即是否`$d\\theta_{approx} \\approx d\\theta $`，也即是否每一元素`$d\\theta_{approx}[i] \\approx d\\theta[i] $`。\n- 检验相似度的标准如下：\n$$\\frac{||d\\theta_{approx}-d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}$$\n - 解释：首先计算`$d\\theta_{approx}$`与`$d\\theta$`的欧氏距离，即差值的L2范数。然后根据向量的长度将其归一化，即除以两个向量的欧几里德长度和，除以该分母的原因是：防止分子过大或过小，这样整个式子就成了一个比值。\n - 在实际中，选用$\\varepsilon=10^{-7}$：\n - 如果相似度的值小于$10^{-7}$，表明梯度逼近误差极小，通过梯度检查，代码是对的。\n - 如果相似度在$10^{-5}$左右，代码可能是对的，但还是会逐个检查向量`$d\\theta_{approx}$`与`$d\\theta$`的每一项，看是否有某一项过大。则该处代码可能存在错误，下节会稍详细讲解此点。\n - 如果相似度在$10^{-3}$左右，代码中一定有错误。\n\n### **运用梯度检验的注意事项**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.JPG\" width=\"75%\" height=\"75%\"> 在运用梯度检查时有几点注意事项：\n\n- 一旦确定反向传播正确，即关闭梯度检验，否则训练过程会极慢。\n - 解释：梯度检验很慢,故不在训练的每一次迭代中都使用。只要确定反向传播代码正确, 就关闭它。\n- 如果梯度检验出现错误，找到对应出错项，尝试识别出bug位置：\n - 解释：逐个对比向量`$d\\theta_{approx}$`与`$d\\theta$`的每一项，看是否有某一项`$d\\theta[i]$`过大。例如，过大项`$d\\theta[i]$`属于$dw^{[l]}$，而同一层的$db^{[l]}$未出错，则可能bug在关于$dw^{[l]}$的代码中。\n - 有时这样的分析虽然无法帮助精确定位出bug位置，但可以帮助我们猜测bug的位置。\n- 如果进行了正则化，则计算近似梯度$d\\theta_{approx}$的时候要包括进去。\n- 梯度检验时关闭dropout，梯度检验完毕后再打开dropout。\n - 解释：dropout使得$J$没有精确的定义，无法进行$d\\theta_{approx}$的计算。故先梯度检验，通过后，再开启dropout。\n- 随机初始化时运行梯度检验，经过一些训练后再次进行梯度检验（不常用）。\n - 为了预防你的反向传播算法在$w$和$b$在接近0的时候是正确的，但当$w$和$b$变大时，算法精度有所下降。\n - 故在一些迭代后，当$w$和$b$变大时，再次进行梯度检验。\n\n# 2.优化算法\n## 2.1 优化算法\n### 小批量梯度下降法\n开篇即说过，机器学习应用是一个高度依赖经验的需要大量迭代的过程。优化算法可以加快神经网络的训练速度，从而提高效率。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%951.JPG\" width=\"80%\" height=\"80%\"> 批量梯度下降法(batch gradient descent)：\n- 每次迭代，对所有样本进行训练，故其训练速度很慢。\n\n小批量梯度下降法(mini-batch gradient descent)：\n- 将$m$个训练样本分成若干个子集，称为mini-batch。\n- 然后每次迭代，在单一子集(mini-batch)上进行神经网络训练，每次迭代所需时间大幅减少。\n\n如图中示例：\n- 总的训练样本$X_{(n_x,m)}=[x^{{1}},x^{(2)},...,x^{(m)}]$，其中$m=5,000,000$。\n- 总的训练样本的标签$Y_{(1,m)}=[y^{{1}},y^{(2)},...,y^{(m)}]$，其中$m=5,000,000$。\n- 将$X$分成5000个mini-batch，每mini-batch含1000个样本，将每个mini-batch记为`$X^{\\{t\\}}$` ，其维度为`$(n_x,1000)$`,且`$t=1,2,\\cdots,5000$`。\n- 每个mini-batch对应的标签记为`$Y^{\\{t\\}}$`，其维度为`$(1,1000)$`，且`$t=1,2,\\cdots,5000$`。\n\n总结一下遇到的神经网络中几类字母的上标含义：\n- $x^{(i)}$ ：第$i$个样本\n- $z^{[l]}$ ：神经网络第$l$层网络的线性输出\n- `$X^{\\{t\\}},Y^{\\{t\\}}$`：第$t$个mini-batch\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 如图：\n- 对于小批量梯度下降法来说，一个周期(epoch)是指：将所有mini_batch（`$X^{\\{t\\}},Y^{\\{t\\}}$`）训练一次(前向传播、计算$J$、反向传播、参数更新)，即遍历一次总体训练集。\n- 对于批量梯度下降法，一个周期只进行一次梯度下降步骤；而对于小批量梯度下降法，一个周期会进行$T$次梯度下降步骤。\n- 通常，会多次遍历训练集(一个显式的for循环)直到收敛到某个值。\n\n### 理解小批量梯度下降法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\">\n- 使用批量梯度下降法，每次迭代将遍历整个训练集，$J$都会减小，若没有减小，则一定是某处错了。\n- 使用小批量梯度下降法，每次迭代是在不同的mini-batch上训练，其代价函数$J$和迭代次数(也即mini-batch/t)的曲线存在噪声，上下振荡，但整体的趋势是下降的。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 对于mini-batch尺寸的选择：\n- 如果mini-batch尺寸为m：即为批量梯度下降((Batch) Gradient Descent)。`$X^{\\{t\\}},Y^{\\{t\\}}=(X,Y)$`\n- 如果mini-batch尺寸为1：即为随机梯度下降(Stochastic Gradient Descent, SGD)。每个样本都是一个mini-batch。\n- 实际操作中：mini-batch尺寸的选择在1到m之间。\n\n如图，比较各梯度下降方法的代价函数的等高线图：\n- 蓝色曲线代表批量梯度下降：\n - 它的噪声相对较小。\n - 每一步相对较大。\n - 并且最终可以达到最小值。\n - 缺点：每次迭代所需时间太长。\n- 紫色曲线代表随机梯度下降：\n - 对于每一次迭代，就在一个样本上做梯度下降，噪声非常大。\n - 一般来说它会沿着正确的方向，但有时也会指向错误的方向。\n - 最后也不会收敛到一个点，它一般会在最低点附近摆动，但是不会达到并且停在那里。 \n - 缺点：失去了通过向量化来加速计算这个工具。\n- 绿色曲线代表实际中mini-batch尺寸为1~m之间的梯度下降：\n - 优点：有着最快的学习速度：1.可在每一个mini-batch运用向量化。2.每次迭代所需时间少。\n  \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"75%\" height=\"75%\">\n- 如果总体样本数量$m$($m\\leq2000$)，建议直接使用批量梯度下降。\n- 如果总体样本数量$m$很大时，建议将样本分成许多mini-batch。\n- 推荐常用的mini-batch 尺寸为64,128,256,512(这些都是2的幂。之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度)。\n- 但要确保每一个mini-batch（`$X^{\\{t\\}},Y^{\\{t\\}}$`）能装进CPU/GPU。\n- 在实践中，要得到不同的mini-batches，需要两个步骤：1.对数据集洗牌(shuffle)；2.分割(partition)。\n\n### 指数加权平均\n接下来介绍几个优化算法，它们比梯度下降更快，为了理解这些算法，需要用到一种叫指数加权平均(exponentially weighted average)的操作，在统计学上也被称为指数加权滑动平均。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 如图，通过指数加权平均来计算最近10天的温度：\n- 设$V_0=0$，当成第0天的气温值\n- 第一天的气温与第0天的气温有关：$V_1=0.9V_0+0.1\\theta_1$\n- 第二天的气温与第一天的气温有关：$V_2=0.9V_1+0.1\\theta_2$\n- 第$t$天与第$t-1$天的气温迭代关系为：`$V_t = 0.9V_{t-1}+0.1\\theta_t$`\n- 经过指数加权平均得到的气温如图中红色曲线所示。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\"> 指数加权平均的一般形式为：\n- `$V_t=\\beta V_{t-1}+(1-\\beta)\\theta_t$`\n- `$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值。\n- 当$\\beta=0.5$，则$\\frac{1}{1-\\beta}=2$，表示将前2天进行指数加权平均。由于仅仅平均两天的气温，即只在很小的窗口内计算平均。得到结果中会有更多的噪声，更容易受到异常值的影响，但它可以更快地适应温度变化。如图中黄色曲线所示。\n- 当$\\beta=0.9$，则$\\frac{1}{1-\\beta}=10$，表示将前10天进行指数加权平均。如图中红色曲线所示。\n- 当$\\beta=0.98$，则$\\frac{1}{1-\\beta}=50$，表示将前50天进行指数加权平均。如图中绿色曲线所示。\n- $\\beta$值越大，则指数加权平均的天数越多，平均后的曲线则更平滑，但是同时曲线会右移，因为在一个更大的窗口内计算平均温度，在温度变化时，适应地更加缓慢，这就造成了一些延迟。\n- 可将$\\beta$视为一个超参数，通过调整这个参数，就可以得到略微不同的收效。通常取中间的某个值效果最好，也就是这里的红色的曲线。\n\n### 理解指数加权平均\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 上图解释了为什么指数加权平均的结果`$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值：\n- 准确来说，指数加权平均算法跟之前所有天的数值都有关系，如图中的推导公式:\n - $$\\begin{eqnarray}V_{100} &=& 0.1\\theta_{100}+ 0.1\\cdot0.9\\theta_{99}+  0.1\\cdot0.9^{2}\\theta_{98}+ 0.1\\cdot0.9^{3}\\theta_{97} + 0.1\\cdot0.9^{4}\\theta_{96}+ ... \\end{eqnarray}$$\n- 其中每一$\\theta_{i}$项都是指数衰减的，一般认为衰减到原始的$\\frac1e$就可以忽略不计了。\n- $\\beta^{\\frac{1}{1-\\beta}}=\\frac1e$，例如，此处$\\beta=0.9$，$0.9^{10}\\approx 0.35\\approx \\frac{1}{e}$。\n- 故`$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\">  实际应用中，使用这样的语句来实现指数加权平均算法：\n`$V_{\\theta}=0$`\n`$Repeat\\ \\{$`\n`$\\ \\ \\ \\ Get\\ next\\ \\theta_t$`\n`$\\ \\ \\ \\ V_{\\theta}:=\\beta V_{\\theta}+(1-\\beta)\\theta_t$`\n`$\\}$`\n\n### 指数加权平均中的偏差修正\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E7%9A%84%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3.JPG\" width=\"80%\" height=\"80%\">\n- 上文中提到当$\\beta=0.98$时，指数加权平均结果如下图绿色曲线所示。但是实际上，得不到绿色曲线，真实曲线如紫色曲线所示。\n- 紫色曲线与绿色曲线的区别是：紫色曲线开始的时候相对较低一些。这是因为设置$V_0=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常:\n - $V_0=0$\n - $V_1 = 0.98V_0+0.02\\theta_1$\n - $V_2 = 0.98V_1+0.02\\theta_2=0.98 \\cdot 0.02\\theta_1+0.02\\theta_2=0.0196\\theta_1+0.02\\theta_2$\n \n修正这种问题的方法是进行偏移修正(bias correction):\n- 将$V_t$取值变为$\\frac{V_t}{1-\\beta^t}$\n- 在刚开始的时候，$t$比较小，$(1-\\beta^t)<1$，这样就将$V_t$修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。\n- 随着$t$增大，$(1-\\beta^t)\\approx1$，$V_t$基本不变，紫色曲线与绿色曲线依然重合。\n- 这样就实现了简单的偏移校正，得到我们希望的绿色曲线。\n- 在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个稍带偏差的值进行运算。\n- 不过，如果在初始阶段就开始考虑偏差，指数加权移动均指仍处于预热阶段，偏差修正可以帮你尽早做出更好的估计。\n\n### 动量梯度下降法\n有一种算法叫做动量(Momentum)梯度下降算法，它几乎总会比标准的梯度下降算法更快。算法的主要思想是：计算梯度的指数加权平均，然后使用这个梯度来更新权重。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\">\n- 假设要优化一个代价函数，如图中的等高线图,红色的点表示最小值的位置。\n- 无论是批量梯度下降或小批量梯度下降，梯度下降算法会向着最小值缓慢地振荡前进。这种上下的振荡会减慢梯度下降的速度，同时也让你无法使用较大的学习率。如果你使用的学习率很大，可能会超调(overshoot)，发散出去。因此为了避免振荡过大，你只能使用比较小的学习率。如图1中的蓝色曲线所示。\n- 因此，在垂直方向上，希望学习慢一点，因为你不希望有这些振荡；但是在水平方向上，你希望加快学习速度。 \n\n动量梯度下降算法的过程如下:\n`$V_{dW}=0,V_{db}=0$`\n`$On\\ iteration\\$`\n`$\\ \\ \\ \\ Compute\\ dW,\\ db\\ on\\ the\\ current\\ mini-batch$`\n`$\\ \\ \\ \\ V_{dW}=\\beta V_{dW}+(1-\\beta)dW$`\n`$\\ \\ \\ \\ V_{db}=\\beta V_{db}+(1-\\beta)db$`\n`$\\ \\ \\ \\ W=W-\\alpha V_{dW},\\ b=b-\\alpha V_{db}$`\n\n- 使用`$v_{dW}$`更新权重，而不是`$dW$`。同样地用`$v_{db}$`更新`$b$`，而不是`$db$`。\n- $v_{dW}$是在近10个$dW$上的指数加权平均，故**在垂直方向上，其平均值接近于0**。然而**在水平方向上，所有导数都指向水平方向的右边，所以水平方向的平均值仍然较大**。\n- 因此，**动量梯度下降算法的每一步，在垂直方向上的振荡非常小，且在水平方向上运动得更快**。这会让你的算法选择更加直接的路径，或者说减弱了前往最小值的路径上的振荡，如图1中红色曲线所示。 \n\n另外：\n- 使用动量梯度下降法有两个超参数：$\\alpha$和$\\beta$。$\\beta$最常用的取值是0.9，就像之前计算最近10天气温的平均值，这里就是计算前10次迭代的梯度的平均值。在实践中，使用$\\beta=0.9$效果很好，你也可以尝试不同的值，做一些超参数搜索，但是0.9是非常稳健的参数值。\n- 至于偏差修正，即是否需要让`$v_{dW}$`或`$v_{db}$`除以`$1-\\beta^t$`。实际上，通常人们不会这么做，因为在10次迭代之后，滑动平均值就不再是一个偏差估计，所以在实现梯度下降或动量梯度下降时，不用做偏差修正。\n\n### RMSprop\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/RMSprop.JPG\" width=\"80%\" height=\"80%\"> RMSprop的算法的全称为均方根传递(Root Mean Square prop)，它同动量梯度下降法一样，也可以加速梯度下降：\n- 批量梯度下降或小批量梯度下降在实现梯度下降时，可能会在垂直方向上出现巨大的振荡，即使它试图在水平方向上前进。\n- 假设垂直方向代表参数$b$，水平方向代表参数$W$，当然这里也可以是$W_1$和$W_2$等其他参数，使用$b$和$W$是为了便于标记解释。 \n- 你希望减慢$b$方向的学习，也就是垂直方向，同时加速或至少不减慢水平方向的学习，这就是RMSprop算法要做的。\n- RMSprop算法步骤：\n`$S_{dW},\\ S_{db}=0$`\n`$On\\ iteration\\ t:$`\n`$\\ \\ \\ \\ Compute\\ dW,\\ db \\ on \\ current \\ mini-batch$`\n`$S_{dw}=\\beta S_{dW}+(1-\\beta)dW^2$`\n`$S_{db}=\\beta S_{db}+(1-\\beta)db^2$`\n`$W:=W-\\alpha \\frac{dW}{\\sqrt{S_{dw}+\\varepsilon}},\\ b:=b-\\alpha \\frac{db}{\\sqrt{S_{db}+\\varepsilon}}$`\n - 其中，$dW^2$和$db^2$是逐元素平方。\n - 其中，$\\varepsilon=10^{-8}$。为了防止除以0。$\\epsilon$的值取多少并不重要，$10^{-8}$是一个合理的默认值，能轻微提高数值稳定性。\n- 从图中蓝色曲线可以看出，$db$很大，而$dW$相对较小，因此，`$S_{dW}$`相对`$S_{db}$`较小。\n- 因此RMSprop中垂直方向的$b$的更新较小，这有助于减弱振荡，垂直方向$W$的更新较大。另一个收效是：可以使用更大的学习率$\\alpha$，学习得更快，而不用担心在垂直方向上发散。如图中绿色曲线所示。\n\n### Adam优化算法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam1.JPG\" width=\"90%\" height=\"90%\"> Adam算法（Adaptive Moment Estimation，自适应矩估计)将动量和RMSprop梯度下降结合起来，被广泛使用且已经被证明在很多不同种类的神经网络构架中都是十分有效的。\n- Adam算法流程为： \n`$V_{dW}=0,\\ S_{dW},\\ V_{db}=0,\\ S_{db}=0$`\n`$On\\ iteration\\ t:$`\n`$\\ \\ \\ \\ Cpmpute\\ dW,\\ db \\ on \\ current \\ mini-batch$`\n`$\\ \\ \\ \\ V_{dW}=\\beta_1V_{dW}+(1-\\beta_1)dW,\\ V_{db}=\\beta_1V_{db}+(1-\\beta_1)db$`\n`$\\ \\ \\ \\ S_{dW}=\\beta_2S_{dW}+(1-\\beta_2)dW^2,\\ S_{db}=\\beta_2S_{db}+(1-\\beta_2)db^2$`\n`$\\ \\ \\ \\ V_{dW}^{corrected}=\\frac{V_{dW}}{1-\\beta_1^t},\\ V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}$`\n`$\\ \\ \\ \\ S_{dW}^{corrected}=\\frac{S_{dW}}{1-\\beta_2^t},\\ S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}$`\n`$\\ \\ \\ \\ W:=W-\\alpha\\frac{V_{dW}^{corrected}}{\\sqrt{S_{dW}^{corrected}}+\\varepsilon},\\ b:=b-\\alpha\\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\varepsilon}$`\n - 注意到：在构建Adam算法的过程中需要进行偏差修正。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam2.JPG\" width=\"80%\" height=\"80%\">\n- Adam算法中的超参数：$\\alpha$，$\\beta_1$，$\\beta_2$，$\\varepsilon$。\n- 超参数$\\beta_1$的默认值设置为0.9，这是关于动量算法的$dW$的加权平均计算。\n- 对于超参数$\\beta_2$，Adam算法论文的作者推荐使用0.999，这是关于$dW^2$的加权平均计算。\n- 超参数$\\varepsilon$，如何选择影响都不大，Adam论文的作者推荐使用$10^{-8}$作为默认值。\n- 在使用Adam算法的时候，业内通常对$\\beta_1$、$\\beta_2$以及$\\varepsilon$都直接使用默认值，然后尝试不同的学习率$\\alpha$来以获得最好的训练效果。\n\n### 学习速率衰减\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F1.JPG\" width=\"80%\" height=\"80%\"> 学习速率衰减，即逐渐地减小学习率，可使得学习算法运行更快：\n- 如图，当采用小批量梯度下降法进行迭代时：\n - 当学习率$\\alpha$采用固定值，会逐步向最小值靠近，但不会完全收敛到这点。如图中蓝色曲线所示。\n - 当采用学习率衰减，那么在初始阶段，因为学习率$\\alpha$取值还比较大，学习速度仍然可以比较快。但随着学习率降低$\\alpha$变小，步长也会渐渐变小。所以，最终将围绕着离极小值点更近的区域摆动，即使继续训练下去也不会漂游远离。如图中绿色曲线所示。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F2.JPG\" width=\"80%\" height=\"80%\">\n- 如图所示，可由以下公式，实现学习率衰减：\n - $$\\alpha=\\frac{1}{1+decay \\_ rate*epoch}\\alpha_0$$\n - 其中，deacy_rate是参数（可调），epoch是周期数。随着epoch增加，$\\alpha$会不断变小。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F3.JPG\" width=\"50%\" height=\"50%\"> 实现学习率衰减还有其它可供选择的计算公式，如图所示:\n- $\\alpha=0.95^{epoch}\\cdot \\alpha_0$\n- $\\alpha=\\frac{k}{\\sqrt{epoch}}\\cdot \\alpha_0\\ \\ \\ \\ or\\ \\ \\ \\ \\frac{k}{\\sqrt{t}}\\cdot \\alpha_0$\n- 离散阶梯衰减。\n- 手动衰减。\n\n另外：\n- **学习率衰减的确可以帮助加速训练，但学习率衰减通常位于应该尝试的事情中比较靠后的位置**。\n- **设置一个固定数值的$\\alpha_0$，且使得优化良好，对结果有着巨大影响**。\n- 下周，将对超参数进行系统地讲解。\n\n### 局部最优解的问题\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A31.JPG\" width=\"80%\" height=\"80%\">\n- 在深度学习的早期阶段，人们常常担心优化算法会陷入糟糕的局部最优解(Local Optima)之中。但随着深度学习理论的发展，我们对局部最优的理解也在改变。\n- 在使用梯度下降算法不断减小代价函数时，可能会得到局部最优解而不是全局最优解。之前我们对局部最优解的理解是如上图左边所示。\n- 但对于神经网络，其参数维数很高，梯度为零的点，在每个方向上，有可能是凸函数，有可能是凹函数。因此，梯度为零的点很可能都是右边所示的马鞍状的鞍点。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A32.JPG\" width=\"80%\" height=\"80%\"> 总结：\n- 局部最优不是问题，不太可能陷入极差的局部最优问题中（只要训练的是一个较大的神经网络，即有很多参数，代价函数$J$定义在一个相对高维的空间上时）。\n-  停滞区让学习过程变得相当慢。\n - 解释：停滞区指的是导数长时间接近于零的一段区域，因为梯度为零或接近于零，曲面很平。在离开停滞区继续下降之前，需要花费很长的时间，缓慢地渡过在停滞区。\n - 解决方法：更复杂的算法，比如Adam算法，可以加快沿停滞区向下移动然后离开停滞区的速度。\n \n# 3.超参数调试、批量归一化以及编程框架\n## 3.1 超参数调试\n### 调试过程\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"> 深度神经网络需要调试的超参数较多，包括：\n- $\\alpha$ ：学习速率\n- $\\beta$ ：动量梯度下降因子\n- $\\beta_1,\\beta_2,\\varepsilon$ ：Adam算法参数\n- \\#layers：神经网络层数\n- \\#hidden units：各隐藏层神经元个数\n- learning rate decay：学习速率衰减参数\n- mini-batch size：每一mini-batch包含的样本个数\n\n对于以上超参数的优先级：\n- 优先级1：学习速率$\\alpha$需要调试的超参数中最重要的一个，没有之一。\n- 优先级2：接下来会调整动量梯度下降参数$\\beta$，0.9是不错的默认值；还会调整Mini-Batch的大小，来保证最优化算法的运行效率；还经常调试隐藏单元数量。这三个超参数的重要性仅次于学习速率$\\alpha$。\n- \n优先级3：网络层数有时候对结果起到重要作用，学习率衰减有时也一样。\n- 优先级4：当使用Adam优化算法时，几乎不调节$\\beta_1,\\beta_2,\\varepsilon$，几乎都是用0.9，0.999和$10^{-8}$。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 当调整超参数时，对于超参数值的组合：\n- 在早期的机器学习算法中，如果有两个超参数（超参数1和超参数2），人们经常会像这样：在一个网格中对点进行规则抽样，然后系统化地尝试这些点所代表的值。如在图中5*5的网格中采样25个点后，选择最优的超参数。当超参数的数量相对较少时，这样的取参方法较为实用。 \n- 但在深度学习中，推荐采取另一种方法：在网格中进行随机抽样，无论最重要的超参数是哪个，将帮助你更充分地为最重要的超参数尝试尽可能多的值的组合。超参数值域的随机抽样，能更有效地搜索超参数空间。如图中，随机采样25个点，然后在这些随机选取的点中，尝试所有的超参数。对于多维情况，也是如此在多维空间中进行随机采样，然后尝试多个超参数的组合值。\n - 这样做的原因：事先很难知道，哪一个超参数对于你的模型更重要。  \n - 解释：假设超参数1是学习速率$\\alpha$，超参数2是Adam优化算法中的$\\varepsilon$。若在网格中取样，因为$\\varepsilon$对结果没有什么影响，所以训练了25个模型，但是只相当于尝试了5个有用的α的值；相比较而言，如果在网格中随机取样 那么将获得25个不同的学习速率$\\alpha$，因此你找到理想值的概率也就变得更大。 \n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%953.JPG\" width=\"80%\" height=\"80%\"> 由粗糙到精细的搜索策略：\n- 继续以二维空间为例，当在此空间进行完随机采样后，发现在某些点能产生最好的结果，大体能确定这个区域内取的值能产生最优结果，即最理想的超参数来自于这个区域。即在对整个框定范围进行粗略的抽样后，结果会引导你集中在一个更小的区域内。\n- 然后，继续采用区域定位的抽样方案：即在这个更小的区域内进行密度更高的随机抽样。\n\n### 用合适的尺度去选择超参数\n上一节讲解的超参数值域的随机抽样，能帮助更有效地搜索超参数空间。但随机抽样并不意味着在有效值范围内的均匀随机抽样(sampleing uniformly at random)。相反，更重要的是选取适当的尺度(scale)，用以研究这些超参数。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A61.JPG\" width=\"80%\" height=\"80%\">\n- 对于超参数#layers和#hidden units，采用均匀随机抽样是合理的方案，但它并不是对所有的超参数都适用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A62.JPG\" width=\"80%\" height=\"80%\">\n- 对于超参数学习率$\\alpha$，待调范围是$[0.0001, 1]$。如果使用均匀随机抽样，那么有90%的采样点分布在$[0.1, 1]$之间，只有10%分布在$[0.0001, 0.1]$之间，并不合理。\n- 更合理的方法：在对数尺度(log scale)上进行采样，而不是用线性尺度(linear scale)。即分为$[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]$这几个区间。\n- 一般解法是，如果线性区间为$[a,b]$，令$m=log(a)$，$n=log(b)$，则对应的$log$区间为$[m,n]$。对$log$区间的$[m,n]$进行随机均匀采样，然后得到的采样值$r$，最后反推到线性区间，即$10^r$。$10^r$就是最终采样的超参数。相应的Python代码为：\n```Python\nm = np.log10(a)\nn = np.log10(b)\nr = np.random.rand() #[0,1)\nr = m + (n-m)*r #[m,n)\nr = np.power(10,r)\n```\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A63.JPG\" width=\"80%\" height=\"80%\">\n- 除了$\\alpha$之外，动量梯度下降法中的参数$\\beta$在超参数调试时，同样应在对数尺度上进行采样。\n- 一般$\\beta$的取值范围在$[0.9, 0.999]$之间，那么$1-\\beta$的取值范围就在$[0.001, 0.1]$之间。那么直接对$1-\\beta$在$[0.001, 0.1]$区间内进行对数尺度采样(即$10^r$)，然后再推出$\\beta$(即$1-10^r$)即可。\n- 为什么$\\beta$也需要向$\\alpha$那样做非均匀采样:公式$\\frac{1}{1-\\beta}$在当$\\beta$趋于1时，它对$\\beta$的值的改变非常敏感。\n\n最后：\n- 如果对于某个超参数你选择的尺度是不对的，或即使在存在更优尺度的情况下，你依然选择了均匀尺度(uniform scale) 你仍然可能得到不错的结果，尤其是如果你采取从粗到精(coarse to fine)的搜索策略。\n\n### 实践中的超参数调试：Pandas vs. Caviar\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\">\n- 经过调试选择完最佳的超参数并不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况（如数据集改变、有了更先进的服务器等），再次调试超参数，以获得实时的最佳模型。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\">\n- 精心照料一个模型(\"Panda\" approach)：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。 \n- 并行训练多个模型(\"Caviar\" approach)：可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。\n\n## 3.2 批量归一化 \n### 归一化网络的激活函数\n在深度学习不断兴起的过程中,最重要的创新之一是一种叫批量归一化(Batch Normalization)的算法，可让超参搜索变得很简单，让神经网络对于超参数的选择上不再那么敏感，并且可以更容易地训练非常深的网络 。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"> 批量归一化原理：\n- 对于单一逻辑回归神经元，归一化输入的操作：$X=\\frac{X-\\mu}{\\sqrt{\\sigma^2}}$，提高模型的训练速度。\n- 批量归一化：对$A^{[l-1]}$进行归一化处理，提高$W^{[l]}$和$b^{[l]}$的训练速度。\n- 批量归一化在实际操作时，归一化的不是$A^{[i]}$，而是$Z^{[i]}$，即激活函数前的值。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"> 单隐藏层的批量归一化的实现：\n- 对第$l$层隐藏层的输入`$Z^{[l-1]}=[z^{[l-1](1)},z^{[l-1](2)},...,z^{[l-1](m)}]$`做如下归一化处理，忽略上标$[l-1]$：\n - $\\mu=\\frac1m\\sum_iz^{(i)}$\n - $\\sigma^2=\\frac1m\\sum_i(z_i-\\mu)^2$\n - $z^{(i)}_{norm}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$\n - 其中，$m$是单个mini-batch包含样本个数，$\\varepsilon$是为了防止分母为零，可取值$10^{-8}$。这样，使得该隐藏层的所有输入 $z^{(i)}$均值为0，方差为1。\n- 但是，大部分情况下并不希望所有的$z^{(i)}$均值都为0，方差都为1，也不太合理。通常需要对$z^{(i)}$进行进一步处理：\n - $\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$\n - 式中，$\\gamma$和$\\beta$是可学习的参数，类似于$W$和$b$一样，可以通过梯度下降等算法求得。这里，$\\gamma$和$\\beta$的作用是让$\\tilde z^{(i)}$的均值和方差为任意值，只需调整其值就可以了。\n - 例如，令：$\\gamma=\\sqrt{\\sigma^2+\\varepsilon}$,$\\beta=\\mu$，则$\\tilde z^{(i)}=z^{(i)}$。可见，设置$\\gamma$和$\\beta$为不同的值，可以得到任意的均值和方差。\n- 这样，通过批量归一化，对隐藏层的各个`$z^{[l](i)}$`进行归一化处理，得到`$\\tilde z^{[l](i)}$`，替代`$z^{[l](i)}$`。\n- 值得注意的是，**输入层的归一化处理和隐藏层的归一化处理是有区别的**。**归一化输入使所有输入的均值为0，方差为1**。而**隐藏层的归一化处理可使各隐藏层输入的均值和方差为任意值**。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，则无法更好的利用激活函数非线性的特性，而不是所有的值都集中在线性区域。这就是为什么通过设置$\\gamma$和$\\beta$来控制`$z^{[l](i)}$`在希望的范围内，或者说**批量归一化真正实现的是通过两个参数$\\gamma$和$\\beta$来让隐藏单元有可控的均值和方差**。\n\n### 将批量归一化用于神经网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 对于$L$层神经网络，实施批量归一化的整体流程如下：\n- <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B.jpg\" width=\"100%\" height=\"100%\">\n- 其中，参数为$W^{[1]}$,$b^{[1]}$,$W^{[2]}$,$b^{[2]}$,...,$W^{[L]}$,$b^{[L]}$以及$\\beta^{[1]}$,$\\gamma^{[1]}$,$\\beta^{[2]}$,$\\gamma^{[2]}$,...,$\\beta^{[L]}$,$\\gamma^{[L]}$。$\\beta^{[l]}$与$\\gamma^{[l]}$的学习同$W^{[l]}$与$b^{[l]}$一样，采用梯度下降法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在mini-batch上应用批量归一化：\n- 分别用每个mini-batch的数据(均值和方差)进行批量归一化。\n- 因为批量归一化对各隐藏层$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$有去均值的操作，所以这里的常数项$b^{[l]}$可以消去，其数值效果完全可以由$\\tilde Z^{[l]}$中的$\\beta^{[l]}$来实现。因此，我们在使用批量归一化的时候，可以忽略各隐藏层的常数项$b^{[l]}$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B03.JPG\" width=\"80%\" height=\"80%\"> 概述了应用批量归一化时，梯度下降(或动量或RMSprop或Adam)的整个过程。\n\n### 批量归一化为什么有效\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%881.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%882.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%883.JPG\" width=\"80%\" height=\"80%\">\n- 解释1：归一化输入，使得输入$X$的均值为0，方差为1，大幅加速学习过程。批量归一化同理。\n- 解释2：批量归一化使得网络的每一层相对独立。\n- 解释3：批量归一化具有轻微的正则化效果。\n\n### 在测试阶段使用批量归一化\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8BatchNorm.JPG\" width=\"50%\" height=\"50%\"> \n- 首先，回顾批量归一化在训练过程中，在每一mini-batch，在网络的每一层中，做如下操作：\n - $\\mu=\\frac1m\\sum_iz^{(i)}$\n - $\\sigma^2=\\frac1m\\sum_i(z^{(i)}-\\mu)^2$\n - $z_{norm}^{(i)}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$\n - $\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$ \n - 其中，$\\mu$和$\\sigma^2$是对单个mini-batch中所有$m$个样本求得的。\n- 在测试阶段，如果只有一个样本，求其均值和方差是没有意义的，就需要对$\\mu$和$\\sigma^2$进行估计。实际应用中一般采用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的$\\mu$和$\\sigma^2$：\n - 指数加权平均的做法:对于第$l$层隐藏层，考虑所有mini-batch在该隐藏层下的$\\mu^{[l]}$和$\\sigma^{2[l]}$，然后用指数加权平均的方式来预测得到当前单个样本的$\\mu^{[l]}$和$\\sigma^{2[l]}$。这样就实现了对测试过程单个样本的均值和方差估计。\n - 最后，再利用训练过程得到的$\\gamma$和$\\beta$值计算出各层的$\\tilde z^{(i)}$值。\n\n## 3.3 多类别分类\n### Softmax回归\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax1.JPG\" width=\"80%\" height=\"80%\"> \n- 用神经网络进行多分类，`$C=\\#class=4$`，0为其他，1为猫，2为狗，3为小鸡。\n- 对于单个输入样本$x$，网络的最后一层(第$L$层)为Softmax层，$\\hat{y}=a^{[L]}$，维度为$(4,1)$。\n- Softmax层中各神经元的输出依次代表$P(other|x)$，$P(cat|x)$，$P(dog|x)$，$P(baby \\ chicks|x)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax2.JPG\" width=\"80%\" height=\"80%\">\n- Softmax层的激活函数计算过程如下：\n - `$z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}$`\n - `$t=e^{(z^{[L]})}$`\n - `$a^{[L]}=\\frac{e^{z^{[L]}}}{\\sum_{i=1}^C t_i}$`\n - `$a^{[L]}_i=\\frac{t_i}{\\sum_{i=1}^C t_i}$`\n - 也可看成是$a^{[L]}=g^{[L]}(z^{[L]})$，只不是该激活函数的输入是向量，输入也是向量。\n - 其中，Softmax层每个神经元的输出`$a^{[L]}_i$`对应属于该类的概率，满足：`$\\sum_{i=1}^Ca^{[L]}_i=1$`\n - `$a^{[L]}= \\hat{y}$`，维度为$(C, 1)$。\n- 具体计算示例如图。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax3.JPG\" width=\"80%\" height=\"80%\">\n- 上图为没有隐藏层，只有单一Softmax层的神经网络，其经Softmax分类的效果如图所示，为线性多分类效果，各两类之间的决策边界均为线性。\n- 当网络具有很多隐藏层，可构成更复杂的非线性决策边界。\n\n### 训练一个softmax分类器\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A81.JPG\" width=\"80%\" height=\"80%\"> 理解Softmax：\n- Softmax回归是Logistic回归向多类别的泛化。\n- 当$C=2$时，Softmax回归将简化成Logistic回归。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A82.JPG\" width=\"80%\" height=\"80%\">\n- 假设$C=4$，某个样本的预测输出$\\hat y$和目标输出(真实值标签)$y$为：\n - $$\\hat y=\\left[ \\begin{matrix} 0.3 \\\\ 0.2 \\\\ 0.1 \\\\ 0.4 \\end{matrix} \\right]$$\n - $$y=\\left[ \\begin{matrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{matrix} \\right]$$\n- Loss function：$L(\\hat y,y)=-\\sum_{j=1}^4y_j\\cdot log\\ \\hat y_j$\n - 然而，由于只有当$j=2$时，$y_2=1$，其它情况下，$y_j=0$。所以，上式中的$L(\\hat y,y)$可以简化为：$L(\\hat y,y)=-y_2\\cdot log\\ \\hat y_2=-log\\ \\hat y_2$\n - 要让$L(\\hat y,y)$更小，就应该让$\\hat y_2$越大越好。$\\hat y_2$反映的是概率，完全符合我们之前的定义。 \n- Cost function：$J(W^{[1]},b^{[1]},...)=\\frac1m\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})$\n- 若对于m个样本，其预测输出向量$A^{[L]}$即$\\hat Y$的维度为$(4, m)$，样本标签$Y$的维度也为$(4, m)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A83.JPG\" width=\"80%\" height=\"80%\"> 梯度下降的过程中，输出层Softmax的梯度推导，即$dZ^{[L]}$的推导：\n- $$da^{[L]}=-\\frac{1}{a^{[L]}}$$\n- $$\\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=\\frac{\\partial}{\\partial z^{[L]}}\\cdot (\\frac{e^{z^{[L]}_i}}{\\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\\cdot (1-a^{[L]})$$\n- $$dz^{[L]}= \\frac{\\partial J}{\\partial z^{[L]}}= da^{[L]}\\cdot \\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=a^{[L]}-1=a^{[L]}-y$$\n- 对于所有$m$个训练样本：$$dZ^{[L]}=A^{[L]}-Y$$\n- 可见$dZ^{[L]}$的表达式与二元分类结果是一致的，虽然推导过程不太一样。然后就可以继续进行反向传播过程的梯度下降算法了，推导过程与二元分类神经网络完全一致。\n\n## 3.4 编程框架介绍\n### 深度学习框架\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.JPG\" width=\"80%\" height=\"80%\"> 如图，介绍了目前的深度学习框架，和选择深度学习框架的标准。\n\n### TensorFlow\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow2.JPG\" width=\"80%\" height=\"80%\"> 本节介绍TensorFlow程序的典型结构。\n\n举个例子来说明，代价函数是参数`w`的函数：$J=w^2-10w+25$。\n如果使用TensorFlow对代价函数进行优化，求出最小值对应的`w`，程序如下：\n```Python\nimport numpy as np\nimport tensorflow as tf\n\nw = tf.Variable(0,dtype=tf.float32)\n#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)\ncost = w**2 - 10*w +25\ntrain = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n\ninit = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n`>>0.0`\n```Python\nsession.run(train)\nprint(session.run(w))\n```\n`>>0.1`\n```Python\nfor i in range(1000):\n    session.run(train)\nprint(session.run(w))\n```\n`>>4.99999`\nTensorFlow框架内可以直接调用梯度下降优化算法。在运行1000次梯度下降算法后，`w`的解为4.99999，已经非常接近`w`的最优值5了。\n针对上面这个例子，如果对`w`前的系数用变量`x`来代替，程序如下：\n```Python\nimport numpy as np\nimport tensorflow as tf\n\ncofficients = np.array([[1.],[-10.],[25.]])\n\nw = tf.Variable(0,dtype=tf.float32)\nx = tf.placeholder(tf.float32,[3,1])\n#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)\n#cost = w**2 - 10*w +25\ncost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\ntrain = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n\ninit = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n`>>0.0`\n```Python\nsession.run(train, feed_dict=(x:coefficients))\nprint(session.run(w))\n```\n`>>0.1`\n```Python\nfor i in range(1000):\n    session.run(train, feed_dict=(x:coefficients))\nprint(session.run(w))\n```\n`>>4.99999`\n结果跟之前是一样的。除此之外，我们还可以更改`x`即`cofficients`的值，而得到不同的优化结果`w`。\n另外，上段程序中的：\n```\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n有另外一种写法：\n```Python\nwith tf.Session() as session:\n    session.run(init)\n    print(session.run(w))\n```\nTensorFlow的最大优点就是采用数据流图(data flow graphs)来进行数值运算。图中的节点(Nodes)表示数学操作，图中的线(edges)则表示在节点间相互联系的多维数据数组，即张量(tensor)。而且它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU(或GPU)，服务器，移动设备等。\n ","source":"_posts/深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化.md","raw":"---\ntitle: 深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化\nmathjax: true\ndate: 2017-12-27 15:49:50\ncategories: \n- 深度学习\ntags:\n---\n# **1.深度学习的实用层面**\n## **1.1 建立机器学习应用**\n### **训练/开发/测试集**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%861.JPG\" width=\"70%\" height=\"70%\">在实际中应用机器学习是一个高度迭代的过程：\n- 在构建一个神经网络的时，需要设置许多超参数，例如神经网络的层数、每个隐藏层包含的神经元个数、学习速率、激活函数的选择等。实际上很难在第一次设置的时候就选择到这些最佳的参数，而是需要通过不断地迭代更新来获得。\n- 迭代的过程如下：先有个想法，先选择初始的参数值，构建神经网络模型结构；然后通过代码实现；最后，通过实验验证。根据实验结果，对参数进行适当的调整优化，再进行下一次的Idea->Code->Experiment循环。\n- 恰当的将数据分为训练/开发/测试集，可使得迭代效率更高。\n\n<!-- more --> \n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%862.JPG\" width=\"90%\" height=\"90%\">一般地，将所有的样本数据分成三个部分：训练(Train)/开发(Dev)/测试(Test)集：\n- 训练集用来训练你的模型；\n- 开发集又称交叉验证集(cross validation set)，用来验证不同算法的表现情况，从中选择最好的模型；\n- 测试集用来测试最好模型的实际表现，给出该模型的无偏估计。\n\n关于数据集的比例划分，在以前，可获得的数据量不是很大的情况：\n- 通常设置训练集和测试集的数量比例为70%和30%。如果有开发集，则设置比例为60%、20%、20%，分别对应训练/测试/开发集。\n- 这种比例分配在样本数量不是很大的情况下，例如100,1000,10000，是比较科学的。\n \n关于数据集的比例划分，在如今，大数据的时代：\n- 如果数据量很大的时候，例如数据量达100万，70%/30%或60%/20%/20%的比例分配是不合理的。\n- 因为开发集的目的是用来比较验证不同模型的优劣，从而选择更好的模型。因此，通常不需要所有样本的20%这么多的数据来进行验证。例如对于100万的样本，往往只需要10000个样本来做验证就够了。测试集的目的是给出已选定最优模型的无偏估计。对于100万的样本，往往也只需要10000个样本就够了。\n- 科学的做法是要将开发集和测试集的比例设置得很低。因此，对于大数据样本，训练/开发/测试集的比例通常可以设置为98%/1%/1%，或者99%/0.5%/0.5%。样本数据量越大，相应的开发/测试集的比例可以设置的越低一些。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%863.JPG\" width=\"80%\" height=\"80%\">现代深度学习还有个重要的问题就是训练集和测试集的分布不匹配，意为是训练集和测试集来自于不同的分布。例如：\n- 对于一个手机app，可以让用户上传图片，然后app识别出猫的图片。该应用中，训练集可能是从网络抓取的图片，而开发和测试集可能来自不同用户的上传的猫的照片。\n- 从网络抓取的图片可能像素较高且拍摄专业等等，而用户上传的图片可能像素较低且模糊等等。因此，训练集和验证/测试集可能来自不同的分布。\n- **解决方法：保证开发集和测试集来自于同一分布。**\n\n注意：\n- 如果不需要对最终选定的神经网络做出无偏估计，可以没有测试集，只有训练/开发集（也有人说成只有训练/测试集，都可以）。\n\n### **偏差/方差**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 对于只有$x_1$和$x_2$两个特征的二维数据集，可以绘制数据，可视化偏差和方差。如上图所示：\n- 左：高偏差，欠拟合\n- 中：恰好\n- 右：高方差，过拟合\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"80%\" height=\"80%\"> 对于高维数据，无法绘制数据以及可视化决策边界。但可通过几个指标来理解偏差和方差。\n基于人工误差（或贝叶斯误差或最优误差)非常低（约为0%）并且训练集和开发集都来自于同一分布这两个假设，如上图所示：\n- 训练集误差为1%/开发集误差11%，结合两者说明该算法在训练集上过拟合，导致在开发集上的泛化性能不好，推出高方差。\n- 训练集误差为15%，在训练集上欠拟合，推出高偏差。开发集误差16%，相比于训练集误差只高1%，并不存在高方差。\n- 训练集误差为15%，推出高偏差。开发集误差30%，相比于训练集误差高15%，推出高方差。\n- 训练集误差为0.5%，低偏差。开发集误差1%，相比于训练集误差只高0.5%，低方差。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"70%\" height=\"70%\"> 上图展示了高偏差和高方差同时存在的可视化情形：\n- 决策边界为线性，欠拟合，高偏差\n- 在局部发生过拟合，高方差\n- 该情形在二维情况下看起来不自然，但对于高维数据，这种情况是容易发生的。\n\n### **机器学习的基本准则**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99.JPG\" width=\"70%\" height=\"70%\"> 当训练好最初的神经网络时：\n- 高偏差？通过训练集表现来确定，若存在高偏差，则可通过更大的网络或训练更长时间来解决。\n- 高方差？通过开发集表现来确定，若存在高方差，则可通过获取更多数据及正则化来解决。\n- 直到找到低偏差且低方差的网络。\n\n关于偏差和方差的权衡：\n- 在早期的机器学习时代，有很多关于偏差和方差的权衡的讨论，因为当时没有能够单独减小偏差和单独减小方差的工具。\n- 而在如今的深度学习和大数据时代，通过扩大网络几乎总是能够较小偏差而不增大方差（只要用恰当的方式正则化）；通过获得更多数据几乎总是能够减小方差而不增大偏差。因此，这也解释了为何深度学习在监督学习中如此有效。\n\n## **1.2 正则化神经网络**\n### **正则化**\n获得更多数据和正则化都是解决过拟合(高方差)的有效方法，但很多时候并不能总是获得更多数据或者获得更多数据的代价太高。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%AD%A3%E5%88%99%E5%8C%96-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.JPG\" width=\"80%\" height=\"80%\">先介绍在逻辑回归中应用正则化，如图：\n- 逻辑回归：$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})$\n- 参数：$w \\in R^{n_x}$，$b\\in R$\n- 目的：$\\min\\limits_{w,b} J(w,b)$；\n- $J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_2^2$\n - L2正则化：`$||w||_2^2=\\sum_{j=1}^{n_x}w_j^2=w^Tw$`，其中$\\lambda$是正则化参数\n- $J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_1$\n - L1正则化：`$||w||_1=\\sum_{j=1}^{n_x}|w_j|$`，其中$\\lambda$是正则化参数\n- 若使用L1正则化，$w$最后会变得稀疏，即$w$中会有很多0。有人认为这有助于压缩模型，因为有一部分参数是0，只需较少的内存来存储模型。\n然而在实践中发现，通过L1正则化让模型变得稀疏带来的收效甚微。故吴恩达觉得至少在压缩模型的目标上，它的作用不大。\n总之，在训练神经网络中，L2正则化应用地更频繁。\n- 只正则化参数$w$，而省略正则化参数$b$的原因是：$w$是高维矢量参数，$b$只是一个标量，几乎所有的参数都集中在$w$中，$b$只是大量参数中的一个，故可省略。\n- 注意，在python中，由于`lambda`是保留字，为了避免冲突，故在编程练习中使用`lambd`来表示$\\lambda$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"50%\" height=\"50%\"> 在神经网络中应用正则化，如图：\n- 代价函数：`$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})=\\frac1m\\sum\\limits_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum\\limits_{l=1}^L||W^{[l]}||_F^2$`\n- 其中，矩阵的L2范数称为F范数(Frobenius范数)，`$||W^{[l]}||_F^2=\\sum_{i=1}^{n^{[l]}}\\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2$`。\n- 正则化后的梯度下降法：\n - $dW^{[l]}=dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]}$\n - $W^{[l]} =W^{[l]}-\\alpha dW^{[l]}$\n\n**L2正则化也被称作权重衰减(weight decay)**。原因如下：\n- $$\n\\begin{eqnarray}W^{[l]} &:=&W^{[l]}-\\alpha\\cdot dW^{[l]}\\\\ &=&W^{[l]}-\\alpha\\cdot(dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]})\\\\ &=&(1-\\alpha\\frac{\\lambda}{m})W^{[l]}-\\alpha\\cdot dW^{[l]}_{before} \\end{eqnarray}\n$$\n- 其中，$(1-\\alpha\\frac{\\lambda}{m})<1$。加上L2正则化项后，$W^{[l]}$的每次更新，都会乘以一个小于1的项。即每次迭代更新，都使得$W^{[l]}$不断地减小，故L2正则化又被称为权重衰减。\n\n### **为什么正则化可以减轻过拟合**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%881.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例一：\n- 假设由于选择了非常复杂的神经网络模型，因而存在过拟合，如上图左上角所示。\n- 加上正则化项后，若将正则化参数$\\lambda$设置的很大，那么参数$ W^{[l]}\\approx0$，参数$W$中的很多数接近于0，这相当于网络中的很多神经元不起作用，这样原本过于复杂的神经网络模型就变得简单化了，故减轻了过拟合。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%882.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例二：\n- 假设激活函数是`tanh`函数。`tanh`函数的特点是在$|z|$较小的区域，函数是近似线性的，而当$|z|$稍大的时候，才会展现出非线性能力。\n- 若加入正则化，使$\\lambda$较大，即对权重$W^{[l]}$的惩罚较大，使得$W^{[l]}$较小。\n- 因为$z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}$。当$W^{[l]}$较小，$z^{[l]}$也较小。当$z^{[l]}$在较小范围内时，激活函数$g(z)$就会近似于线性函数。因此每一层几乎都是线性的，当隐藏曾的激活函数是线性函数的时候，再多隐藏层也只是计算线性函数。故网络不能拟合复杂的非线性函数，便不容易过拟合了。\n\n### **Dropout正则化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-1.JPG\" width=\"70%\" height=\"70%\"> 除了正则化外，还有另外一种防止过拟合的有效方法：Dropout(随机失活)：\n- Dropout：在神经网络的训练过程中，每一次迭代，按照一定的概率随机地将其暂时从网络中丢弃。\n- 也就是说，每一次迭代，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-2.JPG\" width=\"50%\" height=\"50%\"> Dropout有不同的实现方法，Inverted dropout(反向失活)是目前最常用的实现方法：\n- 假设对于第$l=3$层神经元，设定保留神经元比例概率`keep_prob=0.8`。在Python中，Inverted dropout可实现如下：\n```Python\nd3 = np.random.rand(a3.shape[0],a3.shape[1]) < keep_prob\na3 = np.multiply(a3,d3) #逐元素相乘，也可以写成 a3 *= d3\na3 /= keep_prob         #保持a3的期望值不变。这样在测试阶段也不用再对a3值进行缩放\n```\n - 最后一步解释：例如`keep_prob=0.5`，该层将有一般的神经元被关闭，故该层的输出将被0.5缩放，因为只有剩下的一半神经元为计算输出做贡献。除以0.5等价于乘以2。因此输出有了相同的期望值。\n- 反向传播过程：\n```Python\nda3 = np.multiply(da3,d3) #前向传播中关闭了某些神经元，反向传播中也关闭\nda3 /= keep_prob          #a3缩放了keep_prob尺度，根据微积分的性质，则它的梯度也要缩放\n```\n\n注：Dropout仅在训练阶段使用，在测试阶段，不使用Dropout。\n### **理解Dropout**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-3.JPG\" width=\"50%\" height=\"50%\">如图，对于网络中的某一神经元，若采用了dropout，对于每个不同的样本，它的输入特征被消除的特征都不同，因此该神经元不能依靠任一输入特征，故最终网络会分散权重，即所有的权重都不会过大。\n使用Dropout的时候的几个注意点：\n- 可为不同网络层设置不同的`keep_prob`，但该做法的缺点是引入了更多的超参数。可将神经元较多(更容易过拟合)的隐藏层，`keep_out`设置得较小，如0.5；神经元越少的隐藏层，`keep_out`设置得较大，例如0.7。`keep_out`设置为1，表示全部保留，不使用Dropout。\n- 不建议对输入层进行Dropout，如果输入层维度很大，例如图片，那么可以设置Dropout，但`keep_out`应设置的大一些，例如0.8，0.9。\n- Dropout在计算机视觉领域中应用广泛（实际从AlextNet中提出），因为输入层(图像)维度较大，且通常没有足够多的训练样本。\n- Dropout是一种正则化技巧，用来防止过拟合，只有在确认模型过拟合后，再使用它。\n- Dropout的一大缺点是代价函数$J$不再被明确定义，每次迭代都会随机移除一些神经元。故失去了检查梯度下降这一项调式工具，即通过绘图检查代价函数$J$是否随着迭代次数而减小（定义明确的代价函数$J$，在每次迭代后都会下降）。故应关闭Dropout(`keep_out`设置为1)，再进行梯度下降检查。\n\n### **其他正则化方法**\n除了L2正则化和dropout之外，还有其它的正则化方法，如:数据增强，提前终止(early stopping)。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%951.JPG\" width=\"60%\" height=\"60%\">数据增强是对已有的训练样本进行一些处理来“制造”出更多的样本。\n- 例如图片识别问题中，数据增强是通过对已有的图片进行水平翻转、随机剪裁等方式制造出训练样本。\n- 虽然这些新样本是基于原有样本的，可能新的训练集有些冗余，但是相对于重新搜集全新独立的数据，数据增强不需要成本。\n- 因为增加了训练数据，能起到减轻过拟合的作用，故算过正则化方法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%952.JPG\" width=\"80%\" height=\"80%\">另外一种正则化方法early stopping：如图，根据训练集误差曲线(或$J$的曲线)和开发集误差曲线(或$J$的曲线)随着迭代次数的变化趋势，选择使得开发集误差最小的迭代次数，停止训练，即early stopping。\n- 直观解释：神经网络训练前,$W$的值趋近于0,随着训练的进行，$W$越来越大。early stopping相当于选取了一个不大不小的$W$，类似于$||w||_F$的效果，从而希望此时神经网络的过拟合不严重。\n\nearly stopping的缺点：\n- 通常来说，机器学习训练模型有两个目标：一是优化代价函数，即减小$J$；二是防止过拟合。这两个任务是分开进行的。把这二者之间的关系称为正交化(orthogonalization)，后面课程会进一步讲解。\n- early stopping的做法相当于将两个任务合在一起执行，减少迭代次数停止训练时，$J$就不会足够小，且希望此时不过拟合。\n\nearly stopping的优点：\n- 相比与L2正则化，early stopping不用选择超参数$\\lambda$。\n\n吴恩达的做法：\n- 偶尔用early stopping，一般只用L2正则化。\n\n## 1.3 **设置优化问题**\n### **归一化输入**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A51.JPG\" width=\"80%\" height=\"80%\"> 在训练神经网络时，**归一化(normalize)输入**可以**加速训练过程($J$的优化过程)**。\n归一化输入就是将原始数据减去其均值$\\mu$后，再除以其方差$\\sigma^2$：\n- $\\mu=\\frac1m\\sum_{i=1}^m x^{(i)}$\n- $x = x-\\mu$\n- $\\sigma^2=\\frac1m\\sum_{i=1}^m x^{(i)}**2$\n- $x = x/ \\sqrt{\\sigma^2}$\n- 注：对于训练集和测试集，应使用同样的$\\mu$和$\\sigma^2$进行归一化处理，即均使用训练集计算出的$\\mu$和$\\sigma^2$进行归一化处理。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A52.JPG\" width=\"75%\" height=\"75%\"> 上图以二维输入特征为例，解释了为什么归一化输入可以加速训练过程：\n- 假设输入特征为二维，且$x_1$的范围是[1,1000]，$x_2$的范围是[0,1]。  \n- 如图左下所示，若不归一化输入，$x_1$与$x_2$之间分布极不平衡，代价函数$J$与$x_1$和$x_2$的等高线是一个细长的椭圆形。对其进行梯度下降算法时，容易发生振荡，且需选择很小的学习速率$\\alpha$，来避免$J$发生振荡，一旦$\\alpha$较大，必然发生振荡，故学习过程很慢。\n- 如图右下所示，若归一化输入，$x_1$与$x_2$分布均匀，代价函数$J$与$x_1$和$x_2$的等高线是一个圆形。对其进行梯度下降算法时， 可选取较大的步长$\\alpha$，且$J$不易发生振荡，故学习过程较快。\n- 注意：如果输入特征的尺度非常不同，比如有些特征取值为[0,1]，有些是[1,1000]，那对输入进行归一化就很重要。而如果输入特征本来尺度就相近，那么这一步就不那么重要。\n- 吴恩达的做法：因为归一化输入的步骤几乎从来没有任何害处，所以无论如何总是进行归一化，尽管不确定它是否会让训练变得更快。\n\n### **梯度消失与梯度爆炸**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8.JPG\" width=\"75%\" height=\"75%\"> 当训练深层神经网络时，会出现梯度消失和梯度爆炸问题。如图：\n- 为便于分析，令各层的激活函数为线性函数，即$g(z)=z$，且令$b=0$。那么，该网络的预测输出$\\hat y$为：\n - $\\hat y=W^{[L]}W^{[L-1]}W^{[L-2]}\\cdots W^{[3]}W^{[2]}W^{[1]}x $\n- 如果各层权重$W^{[l]}$只比1或单位矩阵稍大一点（如1.5），深层神经网络的激活函数将作为层数$l$的函数指数级增长。\n- 如果各层权重$W^{[l]}$只比1或单位矩阵稍小一点（如0.9），深层神经网络的激活函数将作为层数$l$的函数指数级递减。\n- 虽然上图只论述了激活函数作为层数$l$的函数指数级增加或减少，同样可以论证表明，计算出的导数或梯度，也会指数级增加或指数级减少。\n- 在一个非常深的神经网络（如150层）中，如果激活函数或梯度作为$l$的函数指数级的增大或减小，这些值会变得非常大或非常小，这会让训练变得非常困难。尤其是如果梯度作为$l$的函数指数级减小，梯度下降会用很小很小的步子走，梯度下降会用很长时间才能完成学习。\n\n### **深层网络的权重初始化**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%B1%82%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96.JPG\" width=\"80%\" height=\"80%\"> 针对梯度消失和梯度爆炸，有一种部分解决方法，虽然不能完全解决它，但帮助很大，即更小心地随机初始化神经网络。\n如图，以初始化单个神经元为例，然后再把它应用到深层网络中：\n- $z=w_1x_1+w_2x_2+...+w_nx_n$\n- 为了让$z$不会过大或者过小，思路是让$w$与$n$有关，且$n$越大，$w$应该越小才好。这样能够保证$z$不会过大。\n- 如果激活函数是`tanh`，一般在初始化$w$时，令其方差为$\\frac1n$，即$Var(w)=\\frac1n$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{1}{n^{[l-1]}})$\n - 解释：第$l$层中的每个神经元都有$n^{[l-1]}$个输入。标准正态分布均值为0，方差为1，乘以$np.sqrt(\\frac{1}{n^{[l-1]}})$，那么$w$的方差便为$\\frac{1}{n^{[l-1]}}$\n 方差性质：$C$为常数，$D(CX) = C^2D(X)$\n - 该初始化方法也称为“Xavier initialization”。\n- 如果激活函数是`ReLU`，一般在初始化$w$时，令其方差为$\\frac2n$，即$Var(w)=\\frac2n$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}})$\n - 该初始化方法也称为“He initialization”。\n- 除此之外，Yoshua Bengio提出了另外一种初始化$w$的方法，令其方差为$\\frac{2}{n^{[l-1]}+n^{[l]}}$：\n - 公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}+n^{[l]}})$\n- 注：视频中3：15秒处，还有一段关于解释该做法可以有效减缓梯度消失/梯度爆炸的原因，没听懂，待理解。\n\n### **梯度的数值逼近**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91.JPG\" width=\"80%\" height=\"80%\"> 对于神经网络的反向传播，有一项重要的测试——梯度检验(gradient checking)。该节先介绍梯度的数值逼近：\n- 采用双边差分公式进行数值逼近：$f'(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta-\\varepsilon)}{2\\varepsilon}$\n- 如$f(\\theta)=theta^3$，当$\\theta$为1，$\\varepsilon$为0.01时，逼近误差为：0.0001\n- 注意：不采用单边差分公式：$f'(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta)}{\\varepsilon}$进行梯度的数值逼近的原因是：\n - 单边差分公式的逼近误差是$O(\\varepsilon)$。\n - 双边差分公式的逼近误差是$O(\\varepsilon^2)$，逼近误差更小，故本课程采用此方法。\n- 即利用的是该导数定义：$$ f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta - \\varepsilon)}{2 \\varepsilon} $$，而不是该导数定义：$$f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta)}{\\varepsilon}$$\n\n### **梯度检验**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C1.JPG\" width=\"75%\" height=\"75%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C2.JPG\" width=\"75%\" height=\"75%\"> 进行梯度检验，可验证代码中的反向传播是否有错误：\n- 首先，将$W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]}$ 这些矩阵逐个转变为一维向量，然后连接成一个大的一维向量$\\theta$。这样$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})$ 就可表示成$J(\\theta)$。\n- 然后，将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\\cdots,dW^{[L]},db^{[L]}$同上一步骤一样构造成一个大的一维向量 $d\\theta$。注意到，$d\\theta$的维度与$\\theta$是一致的。\n- 接着，对$\\theta$中的每个元素$\\theta_i$，计算近似梯度：\n$$d\\theta_{approx}[i]=\\frac{J(\\theta_1,\\theta_2,\\cdots,\\theta_i+\\varepsilon,\\cdots)-J(\\theta_1,\\theta_2,\\cdots,\\theta_i-\\varepsilon,\\cdots)}{2\\varepsilon}$$\n- 最终，得到$d\\theta_{approx}$。\n- 将`$d\\theta_{approx}$`与`$d\\theta$`相比较，检查是否一致，即是否`$d\\theta_{approx} \\approx d\\theta $`，也即是否每一元素`$d\\theta_{approx}[i] \\approx d\\theta[i] $`。\n- 检验相似度的标准如下：\n$$\\frac{||d\\theta_{approx}-d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}$$\n - 解释：首先计算`$d\\theta_{approx}$`与`$d\\theta$`的欧氏距离，即差值的L2范数。然后根据向量的长度将其归一化，即除以两个向量的欧几里德长度和，除以该分母的原因是：防止分子过大或过小，这样整个式子就成了一个比值。\n - 在实际中，选用$\\varepsilon=10^{-7}$：\n - 如果相似度的值小于$10^{-7}$，表明梯度逼近误差极小，通过梯度检查，代码是对的。\n - 如果相似度在$10^{-5}$左右，代码可能是对的，但还是会逐个检查向量`$d\\theta_{approx}$`与`$d\\theta$`的每一项，看是否有某一项过大。则该处代码可能存在错误，下节会稍详细讲解此点。\n - 如果相似度在$10^{-3}$左右，代码中一定有错误。\n\n### **运用梯度检验的注意事项**\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.JPG\" width=\"75%\" height=\"75%\"> 在运用梯度检查时有几点注意事项：\n\n- 一旦确定反向传播正确，即关闭梯度检验，否则训练过程会极慢。\n - 解释：梯度检验很慢,故不在训练的每一次迭代中都使用。只要确定反向传播代码正确, 就关闭它。\n- 如果梯度检验出现错误，找到对应出错项，尝试识别出bug位置：\n - 解释：逐个对比向量`$d\\theta_{approx}$`与`$d\\theta$`的每一项，看是否有某一项`$d\\theta[i]$`过大。例如，过大项`$d\\theta[i]$`属于$dw^{[l]}$，而同一层的$db^{[l]}$未出错，则可能bug在关于$dw^{[l]}$的代码中。\n - 有时这样的分析虽然无法帮助精确定位出bug位置，但可以帮助我们猜测bug的位置。\n- 如果进行了正则化，则计算近似梯度$d\\theta_{approx}$的时候要包括进去。\n- 梯度检验时关闭dropout，梯度检验完毕后再打开dropout。\n - 解释：dropout使得$J$没有精确的定义，无法进行$d\\theta_{approx}$的计算。故先梯度检验，通过后，再开启dropout。\n- 随机初始化时运行梯度检验，经过一些训练后再次进行梯度检验（不常用）。\n - 为了预防你的反向传播算法在$w$和$b$在接近0的时候是正确的，但当$w$和$b$变大时，算法精度有所下降。\n - 故在一些迭代后，当$w$和$b$变大时，再次进行梯度检验。\n\n# 2.优化算法\n## 2.1 优化算法\n### 小批量梯度下降法\n开篇即说过，机器学习应用是一个高度依赖经验的需要大量迭代的过程。优化算法可以加快神经网络的训练速度，从而提高效率。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%951.JPG\" width=\"80%\" height=\"80%\"> 批量梯度下降法(batch gradient descent)：\n- 每次迭代，对所有样本进行训练，故其训练速度很慢。\n\n小批量梯度下降法(mini-batch gradient descent)：\n- 将$m$个训练样本分成若干个子集，称为mini-batch。\n- 然后每次迭代，在单一子集(mini-batch)上进行神经网络训练，每次迭代所需时间大幅减少。\n\n如图中示例：\n- 总的训练样本$X_{(n_x,m)}=[x^{{1}},x^{(2)},...,x^{(m)}]$，其中$m=5,000,000$。\n- 总的训练样本的标签$Y_{(1,m)}=[y^{{1}},y^{(2)},...,y^{(m)}]$，其中$m=5,000,000$。\n- 将$X$分成5000个mini-batch，每mini-batch含1000个样本，将每个mini-batch记为`$X^{\\{t\\}}$` ，其维度为`$(n_x,1000)$`,且`$t=1,2,\\cdots,5000$`。\n- 每个mini-batch对应的标签记为`$Y^{\\{t\\}}$`，其维度为`$(1,1000)$`，且`$t=1,2,\\cdots,5000$`。\n\n总结一下遇到的神经网络中几类字母的上标含义：\n- $x^{(i)}$ ：第$i$个样本\n- $z^{[l]}$ ：神经网络第$l$层网络的线性输出\n- `$X^{\\{t\\}},Y^{\\{t\\}}$`：第$t$个mini-batch\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 如图：\n- 对于小批量梯度下降法来说，一个周期(epoch)是指：将所有mini_batch（`$X^{\\{t\\}},Y^{\\{t\\}}$`）训练一次(前向传播、计算$J$、反向传播、参数更新)，即遍历一次总体训练集。\n- 对于批量梯度下降法，一个周期只进行一次梯度下降步骤；而对于小批量梯度下降法，一个周期会进行$T$次梯度下降步骤。\n- 通常，会多次遍历训练集(一个显式的for循环)直到收敛到某个值。\n\n### 理解小批量梯度下降法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\">\n- 使用批量梯度下降法，每次迭代将遍历整个训练集，$J$都会减小，若没有减小，则一定是某处错了。\n- 使用小批量梯度下降法，每次迭代是在不同的mini-batch上训练，其代价函数$J$和迭代次数(也即mini-batch/t)的曲线存在噪声，上下振荡，但整体的趋势是下降的。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 对于mini-batch尺寸的选择：\n- 如果mini-batch尺寸为m：即为批量梯度下降((Batch) Gradient Descent)。`$X^{\\{t\\}},Y^{\\{t\\}}=(X,Y)$`\n- 如果mini-batch尺寸为1：即为随机梯度下降(Stochastic Gradient Descent, SGD)。每个样本都是一个mini-batch。\n- 实际操作中：mini-batch尺寸的选择在1到m之间。\n\n如图，比较各梯度下降方法的代价函数的等高线图：\n- 蓝色曲线代表批量梯度下降：\n - 它的噪声相对较小。\n - 每一步相对较大。\n - 并且最终可以达到最小值。\n - 缺点：每次迭代所需时间太长。\n- 紫色曲线代表随机梯度下降：\n - 对于每一次迭代，就在一个样本上做梯度下降，噪声非常大。\n - 一般来说它会沿着正确的方向，但有时也会指向错误的方向。\n - 最后也不会收敛到一个点，它一般会在最低点附近摆动，但是不会达到并且停在那里。 \n - 缺点：失去了通过向量化来加速计算这个工具。\n- 绿色曲线代表实际中mini-batch尺寸为1~m之间的梯度下降：\n - 优点：有着最快的学习速度：1.可在每一个mini-batch运用向量化。2.每次迭代所需时间少。\n  \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"75%\" height=\"75%\">\n- 如果总体样本数量$m$($m\\leq2000$)，建议直接使用批量梯度下降。\n- 如果总体样本数量$m$很大时，建议将样本分成许多mini-batch。\n- 推荐常用的mini-batch 尺寸为64,128,256,512(这些都是2的幂。之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度)。\n- 但要确保每一个mini-batch（`$X^{\\{t\\}},Y^{\\{t\\}}$`）能装进CPU/GPU。\n- 在实践中，要得到不同的mini-batches，需要两个步骤：1.对数据集洗牌(shuffle)；2.分割(partition)。\n\n### 指数加权平均\n接下来介绍几个优化算法，它们比梯度下降更快，为了理解这些算法，需要用到一种叫指数加权平均(exponentially weighted average)的操作，在统计学上也被称为指数加权滑动平均。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 如图，通过指数加权平均来计算最近10天的温度：\n- 设$V_0=0$，当成第0天的气温值\n- 第一天的气温与第0天的气温有关：$V_1=0.9V_0+0.1\\theta_1$\n- 第二天的气温与第一天的气温有关：$V_2=0.9V_1+0.1\\theta_2$\n- 第$t$天与第$t-1$天的气温迭代关系为：`$V_t = 0.9V_{t-1}+0.1\\theta_t$`\n- 经过指数加权平均得到的气温如图中红色曲线所示。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\"> 指数加权平均的一般形式为：\n- `$V_t=\\beta V_{t-1}+(1-\\beta)\\theta_t$`\n- `$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值。\n- 当$\\beta=0.5$，则$\\frac{1}{1-\\beta}=2$，表示将前2天进行指数加权平均。由于仅仅平均两天的气温，即只在很小的窗口内计算平均。得到结果中会有更多的噪声，更容易受到异常值的影响，但它可以更快地适应温度变化。如图中黄色曲线所示。\n- 当$\\beta=0.9$，则$\\frac{1}{1-\\beta}=10$，表示将前10天进行指数加权平均。如图中红色曲线所示。\n- 当$\\beta=0.98$，则$\\frac{1}{1-\\beta}=50$，表示将前50天进行指数加权平均。如图中绿色曲线所示。\n- $\\beta$值越大，则指数加权平均的天数越多，平均后的曲线则更平滑，但是同时曲线会右移，因为在一个更大的窗口内计算平均温度，在温度变化时，适应地更加缓慢，这就造成了一些延迟。\n- 可将$\\beta$视为一个超参数，通过调整这个参数，就可以得到略微不同的收效。通常取中间的某个值效果最好，也就是这里的红色的曲线。\n\n### 理解指数加权平均\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 上图解释了为什么指数加权平均的结果`$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值：\n- 准确来说，指数加权平均算法跟之前所有天的数值都有关系，如图中的推导公式:\n - $$\\begin{eqnarray}V_{100} &=& 0.1\\theta_{100}+ 0.1\\cdot0.9\\theta_{99}+  0.1\\cdot0.9^{2}\\theta_{98}+ 0.1\\cdot0.9^{3}\\theta_{97} + 0.1\\cdot0.9^{4}\\theta_{96}+ ... \\end{eqnarray}$$\n- 其中每一$\\theta_{i}$项都是指数衰减的，一般认为衰减到原始的$\\frac1e$就可以忽略不计了。\n- $\\beta^{\\frac{1}{1-\\beta}}=\\frac1e$，例如，此处$\\beta=0.9$，$0.9^{10}\\approx 0.35\\approx \\frac{1}{e}$。\n- 故`$V_t$`是在约`$\\frac{1}{1-\\beta}$`天的温度上的平均的近似值。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\">  实际应用中，使用这样的语句来实现指数加权平均算法：\n`$V_{\\theta}=0$`\n`$Repeat\\ \\{$`\n`$\\ \\ \\ \\ Get\\ next\\ \\theta_t$`\n`$\\ \\ \\ \\ V_{\\theta}:=\\beta V_{\\theta}+(1-\\beta)\\theta_t$`\n`$\\}$`\n\n### 指数加权平均中的偏差修正\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E7%9A%84%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3.JPG\" width=\"80%\" height=\"80%\">\n- 上文中提到当$\\beta=0.98$时，指数加权平均结果如下图绿色曲线所示。但是实际上，得不到绿色曲线，真实曲线如紫色曲线所示。\n- 紫色曲线与绿色曲线的区别是：紫色曲线开始的时候相对较低一些。这是因为设置$V_0=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常:\n - $V_0=0$\n - $V_1 = 0.98V_0+0.02\\theta_1$\n - $V_2 = 0.98V_1+0.02\\theta_2=0.98 \\cdot 0.02\\theta_1+0.02\\theta_2=0.0196\\theta_1+0.02\\theta_2$\n \n修正这种问题的方法是进行偏移修正(bias correction):\n- 将$V_t$取值变为$\\frac{V_t}{1-\\beta^t}$\n- 在刚开始的时候，$t$比较小，$(1-\\beta^t)<1$，这样就将$V_t$修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。\n- 随着$t$增大，$(1-\\beta^t)\\approx1$，$V_t$基本不变，紫色曲线与绿色曲线依然重合。\n- 这样就实现了简单的偏移校正，得到我们希望的绿色曲线。\n- 在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个稍带偏差的值进行运算。\n- 不过，如果在初始阶段就开始考虑偏差，指数加权移动均指仍处于预热阶段，偏差修正可以帮你尽早做出更好的估计。\n\n### 动量梯度下降法\n有一种算法叫做动量(Momentum)梯度下降算法，它几乎总会比标准的梯度下降算法更快。算法的主要思想是：计算梯度的指数加权平均，然后使用这个梯度来更新权重。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\">\n- 假设要优化一个代价函数，如图中的等高线图,红色的点表示最小值的位置。\n- 无论是批量梯度下降或小批量梯度下降，梯度下降算法会向着最小值缓慢地振荡前进。这种上下的振荡会减慢梯度下降的速度，同时也让你无法使用较大的学习率。如果你使用的学习率很大，可能会超调(overshoot)，发散出去。因此为了避免振荡过大，你只能使用比较小的学习率。如图1中的蓝色曲线所示。\n- 因此，在垂直方向上，希望学习慢一点，因为你不希望有这些振荡；但是在水平方向上，你希望加快学习速度。 \n\n动量梯度下降算法的过程如下:\n`$V_{dW}=0,V_{db}=0$`\n`$On\\ iteration\\$`\n`$\\ \\ \\ \\ Compute\\ dW,\\ db\\ on\\ the\\ current\\ mini-batch$`\n`$\\ \\ \\ \\ V_{dW}=\\beta V_{dW}+(1-\\beta)dW$`\n`$\\ \\ \\ \\ V_{db}=\\beta V_{db}+(1-\\beta)db$`\n`$\\ \\ \\ \\ W=W-\\alpha V_{dW},\\ b=b-\\alpha V_{db}$`\n\n- 使用`$v_{dW}$`更新权重，而不是`$dW$`。同样地用`$v_{db}$`更新`$b$`，而不是`$db$`。\n- $v_{dW}$是在近10个$dW$上的指数加权平均，故**在垂直方向上，其平均值接近于0**。然而**在水平方向上，所有导数都指向水平方向的右边，所以水平方向的平均值仍然较大**。\n- 因此，**动量梯度下降算法的每一步，在垂直方向上的振荡非常小，且在水平方向上运动得更快**。这会让你的算法选择更加直接的路径，或者说减弱了前往最小值的路径上的振荡，如图1中红色曲线所示。 \n\n另外：\n- 使用动量梯度下降法有两个超参数：$\\alpha$和$\\beta$。$\\beta$最常用的取值是0.9，就像之前计算最近10天气温的平均值，这里就是计算前10次迭代的梯度的平均值。在实践中，使用$\\beta=0.9$效果很好，你也可以尝试不同的值，做一些超参数搜索，但是0.9是非常稳健的参数值。\n- 至于偏差修正，即是否需要让`$v_{dW}$`或`$v_{db}$`除以`$1-\\beta^t$`。实际上，通常人们不会这么做，因为在10次迭代之后，滑动平均值就不再是一个偏差估计，所以在实现梯度下降或动量梯度下降时，不用做偏差修正。\n\n### RMSprop\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/RMSprop.JPG\" width=\"80%\" height=\"80%\"> RMSprop的算法的全称为均方根传递(Root Mean Square prop)，它同动量梯度下降法一样，也可以加速梯度下降：\n- 批量梯度下降或小批量梯度下降在实现梯度下降时，可能会在垂直方向上出现巨大的振荡，即使它试图在水平方向上前进。\n- 假设垂直方向代表参数$b$，水平方向代表参数$W$，当然这里也可以是$W_1$和$W_2$等其他参数，使用$b$和$W$是为了便于标记解释。 \n- 你希望减慢$b$方向的学习，也就是垂直方向，同时加速或至少不减慢水平方向的学习，这就是RMSprop算法要做的。\n- RMSprop算法步骤：\n`$S_{dW},\\ S_{db}=0$`\n`$On\\ iteration\\ t:$`\n`$\\ \\ \\ \\ Compute\\ dW,\\ db \\ on \\ current \\ mini-batch$`\n`$S_{dw}=\\beta S_{dW}+(1-\\beta)dW^2$`\n`$S_{db}=\\beta S_{db}+(1-\\beta)db^2$`\n`$W:=W-\\alpha \\frac{dW}{\\sqrt{S_{dw}+\\varepsilon}},\\ b:=b-\\alpha \\frac{db}{\\sqrt{S_{db}+\\varepsilon}}$`\n - 其中，$dW^2$和$db^2$是逐元素平方。\n - 其中，$\\varepsilon=10^{-8}$。为了防止除以0。$\\epsilon$的值取多少并不重要，$10^{-8}$是一个合理的默认值，能轻微提高数值稳定性。\n- 从图中蓝色曲线可以看出，$db$很大，而$dW$相对较小，因此，`$S_{dW}$`相对`$S_{db}$`较小。\n- 因此RMSprop中垂直方向的$b$的更新较小，这有助于减弱振荡，垂直方向$W$的更新较大。另一个收效是：可以使用更大的学习率$\\alpha$，学习得更快，而不用担心在垂直方向上发散。如图中绿色曲线所示。\n\n### Adam优化算法\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam1.JPG\" width=\"90%\" height=\"90%\"> Adam算法（Adaptive Moment Estimation，自适应矩估计)将动量和RMSprop梯度下降结合起来，被广泛使用且已经被证明在很多不同种类的神经网络构架中都是十分有效的。\n- Adam算法流程为： \n`$V_{dW}=0,\\ S_{dW},\\ V_{db}=0,\\ S_{db}=0$`\n`$On\\ iteration\\ t:$`\n`$\\ \\ \\ \\ Cpmpute\\ dW,\\ db \\ on \\ current \\ mini-batch$`\n`$\\ \\ \\ \\ V_{dW}=\\beta_1V_{dW}+(1-\\beta_1)dW,\\ V_{db}=\\beta_1V_{db}+(1-\\beta_1)db$`\n`$\\ \\ \\ \\ S_{dW}=\\beta_2S_{dW}+(1-\\beta_2)dW^2,\\ S_{db}=\\beta_2S_{db}+(1-\\beta_2)db^2$`\n`$\\ \\ \\ \\ V_{dW}^{corrected}=\\frac{V_{dW}}{1-\\beta_1^t},\\ V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}$`\n`$\\ \\ \\ \\ S_{dW}^{corrected}=\\frac{S_{dW}}{1-\\beta_2^t},\\ S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}$`\n`$\\ \\ \\ \\ W:=W-\\alpha\\frac{V_{dW}^{corrected}}{\\sqrt{S_{dW}^{corrected}}+\\varepsilon},\\ b:=b-\\alpha\\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\varepsilon}$`\n - 注意到：在构建Adam算法的过程中需要进行偏差修正。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam2.JPG\" width=\"80%\" height=\"80%\">\n- Adam算法中的超参数：$\\alpha$，$\\beta_1$，$\\beta_2$，$\\varepsilon$。\n- 超参数$\\beta_1$的默认值设置为0.9，这是关于动量算法的$dW$的加权平均计算。\n- 对于超参数$\\beta_2$，Adam算法论文的作者推荐使用0.999，这是关于$dW^2$的加权平均计算。\n- 超参数$\\varepsilon$，如何选择影响都不大，Adam论文的作者推荐使用$10^{-8}$作为默认值。\n- 在使用Adam算法的时候，业内通常对$\\beta_1$、$\\beta_2$以及$\\varepsilon$都直接使用默认值，然后尝试不同的学习率$\\alpha$来以获得最好的训练效果。\n\n### 学习速率衰减\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F1.JPG\" width=\"80%\" height=\"80%\"> 学习速率衰减，即逐渐地减小学习率，可使得学习算法运行更快：\n- 如图，当采用小批量梯度下降法进行迭代时：\n - 当学习率$\\alpha$采用固定值，会逐步向最小值靠近，但不会完全收敛到这点。如图中蓝色曲线所示。\n - 当采用学习率衰减，那么在初始阶段，因为学习率$\\alpha$取值还比较大，学习速度仍然可以比较快。但随着学习率降低$\\alpha$变小，步长也会渐渐变小。所以，最终将围绕着离极小值点更近的区域摆动，即使继续训练下去也不会漂游远离。如图中绿色曲线所示。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F2.JPG\" width=\"80%\" height=\"80%\">\n- 如图所示，可由以下公式，实现学习率衰减：\n - $$\\alpha=\\frac{1}{1+decay \\_ rate*epoch}\\alpha_0$$\n - 其中，deacy_rate是参数（可调），epoch是周期数。随着epoch增加，$\\alpha$会不断变小。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F3.JPG\" width=\"50%\" height=\"50%\"> 实现学习率衰减还有其它可供选择的计算公式，如图所示:\n- $\\alpha=0.95^{epoch}\\cdot \\alpha_0$\n- $\\alpha=\\frac{k}{\\sqrt{epoch}}\\cdot \\alpha_0\\ \\ \\ \\ or\\ \\ \\ \\ \\frac{k}{\\sqrt{t}}\\cdot \\alpha_0$\n- 离散阶梯衰减。\n- 手动衰减。\n\n另外：\n- **学习率衰减的确可以帮助加速训练，但学习率衰减通常位于应该尝试的事情中比较靠后的位置**。\n- **设置一个固定数值的$\\alpha_0$，且使得优化良好，对结果有着巨大影响**。\n- 下周，将对超参数进行系统地讲解。\n\n### 局部最优解的问题\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A31.JPG\" width=\"80%\" height=\"80%\">\n- 在深度学习的早期阶段，人们常常担心优化算法会陷入糟糕的局部最优解(Local Optima)之中。但随着深度学习理论的发展，我们对局部最优的理解也在改变。\n- 在使用梯度下降算法不断减小代价函数时，可能会得到局部最优解而不是全局最优解。之前我们对局部最优解的理解是如上图左边所示。\n- 但对于神经网络，其参数维数很高，梯度为零的点，在每个方向上，有可能是凸函数，有可能是凹函数。因此，梯度为零的点很可能都是右边所示的马鞍状的鞍点。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A32.JPG\" width=\"80%\" height=\"80%\"> 总结：\n- 局部最优不是问题，不太可能陷入极差的局部最优问题中（只要训练的是一个较大的神经网络，即有很多参数，代价函数$J$定义在一个相对高维的空间上时）。\n-  停滞区让学习过程变得相当慢。\n - 解释：停滞区指的是导数长时间接近于零的一段区域，因为梯度为零或接近于零，曲面很平。在离开停滞区继续下降之前，需要花费很长的时间，缓慢地渡过在停滞区。\n - 解决方法：更复杂的算法，比如Adam算法，可以加快沿停滞区向下移动然后离开停滞区的速度。\n \n# 3.超参数调试、批量归一化以及编程框架\n## 3.1 超参数调试\n### 调试过程\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"> 深度神经网络需要调试的超参数较多，包括：\n- $\\alpha$ ：学习速率\n- $\\beta$ ：动量梯度下降因子\n- $\\beta_1,\\beta_2,\\varepsilon$ ：Adam算法参数\n- \\#layers：神经网络层数\n- \\#hidden units：各隐藏层神经元个数\n- learning rate decay：学习速率衰减参数\n- mini-batch size：每一mini-batch包含的样本个数\n\n对于以上超参数的优先级：\n- 优先级1：学习速率$\\alpha$需要调试的超参数中最重要的一个，没有之一。\n- 优先级2：接下来会调整动量梯度下降参数$\\beta$，0.9是不错的默认值；还会调整Mini-Batch的大小，来保证最优化算法的运行效率；还经常调试隐藏单元数量。这三个超参数的重要性仅次于学习速率$\\alpha$。\n- \n优先级3：网络层数有时候对结果起到重要作用，学习率衰减有时也一样。\n- 优先级4：当使用Adam优化算法时，几乎不调节$\\beta_1,\\beta_2,\\varepsilon$，几乎都是用0.9，0.999和$10^{-8}$。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 当调整超参数时，对于超参数值的组合：\n- 在早期的机器学习算法中，如果有两个超参数（超参数1和超参数2），人们经常会像这样：在一个网格中对点进行规则抽样，然后系统化地尝试这些点所代表的值。如在图中5*5的网格中采样25个点后，选择最优的超参数。当超参数的数量相对较少时，这样的取参方法较为实用。 \n- 但在深度学习中，推荐采取另一种方法：在网格中进行随机抽样，无论最重要的超参数是哪个，将帮助你更充分地为最重要的超参数尝试尽可能多的值的组合。超参数值域的随机抽样，能更有效地搜索超参数空间。如图中，随机采样25个点，然后在这些随机选取的点中，尝试所有的超参数。对于多维情况，也是如此在多维空间中进行随机采样，然后尝试多个超参数的组合值。\n - 这样做的原因：事先很难知道，哪一个超参数对于你的模型更重要。  \n - 解释：假设超参数1是学习速率$\\alpha$，超参数2是Adam优化算法中的$\\varepsilon$。若在网格中取样，因为$\\varepsilon$对结果没有什么影响，所以训练了25个模型，但是只相当于尝试了5个有用的α的值；相比较而言，如果在网格中随机取样 那么将获得25个不同的学习速率$\\alpha$，因此你找到理想值的概率也就变得更大。 \n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%953.JPG\" width=\"80%\" height=\"80%\"> 由粗糙到精细的搜索策略：\n- 继续以二维空间为例，当在此空间进行完随机采样后，发现在某些点能产生最好的结果，大体能确定这个区域内取的值能产生最优结果，即最理想的超参数来自于这个区域。即在对整个框定范围进行粗略的抽样后，结果会引导你集中在一个更小的区域内。\n- 然后，继续采用区域定位的抽样方案：即在这个更小的区域内进行密度更高的随机抽样。\n\n### 用合适的尺度去选择超参数\n上一节讲解的超参数值域的随机抽样，能帮助更有效地搜索超参数空间。但随机抽样并不意味着在有效值范围内的均匀随机抽样(sampleing uniformly at random)。相反，更重要的是选取适当的尺度(scale)，用以研究这些超参数。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A61.JPG\" width=\"80%\" height=\"80%\">\n- 对于超参数#layers和#hidden units，采用均匀随机抽样是合理的方案，但它并不是对所有的超参数都适用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A62.JPG\" width=\"80%\" height=\"80%\">\n- 对于超参数学习率$\\alpha$，待调范围是$[0.0001, 1]$。如果使用均匀随机抽样，那么有90%的采样点分布在$[0.1, 1]$之间，只有10%分布在$[0.0001, 0.1]$之间，并不合理。\n- 更合理的方法：在对数尺度(log scale)上进行采样，而不是用线性尺度(linear scale)。即分为$[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]$这几个区间。\n- 一般解法是，如果线性区间为$[a,b]$，令$m=log(a)$，$n=log(b)$，则对应的$log$区间为$[m,n]$。对$log$区间的$[m,n]$进行随机均匀采样，然后得到的采样值$r$，最后反推到线性区间，即$10^r$。$10^r$就是最终采样的超参数。相应的Python代码为：\n```Python\nm = np.log10(a)\nn = np.log10(b)\nr = np.random.rand() #[0,1)\nr = m + (n-m)*r #[m,n)\nr = np.power(10,r)\n```\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A63.JPG\" width=\"80%\" height=\"80%\">\n- 除了$\\alpha$之外，动量梯度下降法中的参数$\\beta$在超参数调试时，同样应在对数尺度上进行采样。\n- 一般$\\beta$的取值范围在$[0.9, 0.999]$之间，那么$1-\\beta$的取值范围就在$[0.001, 0.1]$之间。那么直接对$1-\\beta$在$[0.001, 0.1]$区间内进行对数尺度采样(即$10^r$)，然后再推出$\\beta$(即$1-10^r$)即可。\n- 为什么$\\beta$也需要向$\\alpha$那样做非均匀采样:公式$\\frac{1}{1-\\beta}$在当$\\beta$趋于1时，它对$\\beta$的值的改变非常敏感。\n\n最后：\n- 如果对于某个超参数你选择的尺度是不对的，或即使在存在更优尺度的情况下，你依然选择了均匀尺度(uniform scale) 你仍然可能得到不错的结果，尤其是如果你采取从粗到精(coarse to fine)的搜索策略。\n\n### 实践中的超参数调试：Pandas vs. Caviar\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\">\n- 经过调试选择完最佳的超参数并不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况（如数据集改变、有了更先进的服务器等），再次调试超参数，以获得实时的最佳模型。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\">\n- 精心照料一个模型(\"Panda\" approach)：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。 \n- 并行训练多个模型(\"Caviar\" approach)：可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。\n\n## 3.2 批量归一化 \n### 归一化网络的激活函数\n在深度学习不断兴起的过程中,最重要的创新之一是一种叫批量归一化(Batch Normalization)的算法，可让超参搜索变得很简单，让神经网络对于超参数的选择上不再那么敏感，并且可以更容易地训练非常深的网络 。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"> 批量归一化原理：\n- 对于单一逻辑回归神经元，归一化输入的操作：$X=\\frac{X-\\mu}{\\sqrt{\\sigma^2}}$，提高模型的训练速度。\n- 批量归一化：对$A^{[l-1]}$进行归一化处理，提高$W^{[l]}$和$b^{[l]}$的训练速度。\n- 批量归一化在实际操作时，归一化的不是$A^{[i]}$，而是$Z^{[i]}$，即激活函数前的值。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"> 单隐藏层的批量归一化的实现：\n- 对第$l$层隐藏层的输入`$Z^{[l-1]}=[z^{[l-1](1)},z^{[l-1](2)},...,z^{[l-1](m)}]$`做如下归一化处理，忽略上标$[l-1]$：\n - $\\mu=\\frac1m\\sum_iz^{(i)}$\n - $\\sigma^2=\\frac1m\\sum_i(z_i-\\mu)^2$\n - $z^{(i)}_{norm}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$\n - 其中，$m$是单个mini-batch包含样本个数，$\\varepsilon$是为了防止分母为零，可取值$10^{-8}$。这样，使得该隐藏层的所有输入 $z^{(i)}$均值为0，方差为1。\n- 但是，大部分情况下并不希望所有的$z^{(i)}$均值都为0，方差都为1，也不太合理。通常需要对$z^{(i)}$进行进一步处理：\n - $\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$\n - 式中，$\\gamma$和$\\beta$是可学习的参数，类似于$W$和$b$一样，可以通过梯度下降等算法求得。这里，$\\gamma$和$\\beta$的作用是让$\\tilde z^{(i)}$的均值和方差为任意值，只需调整其值就可以了。\n - 例如，令：$\\gamma=\\sqrt{\\sigma^2+\\varepsilon}$,$\\beta=\\mu$，则$\\tilde z^{(i)}=z^{(i)}$。可见，设置$\\gamma$和$\\beta$为不同的值，可以得到任意的均值和方差。\n- 这样，通过批量归一化，对隐藏层的各个`$z^{[l](i)}$`进行归一化处理，得到`$\\tilde z^{[l](i)}$`，替代`$z^{[l](i)}$`。\n- 值得注意的是，**输入层的归一化处理和隐藏层的归一化处理是有区别的**。**归一化输入使所有输入的均值为0，方差为1**。而**隐藏层的归一化处理可使各隐藏层输入的均值和方差为任意值**。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，则无法更好的利用激活函数非线性的特性，而不是所有的值都集中在线性区域。这就是为什么通过设置$\\gamma$和$\\beta$来控制`$z^{[l](i)}$`在希望的范围内，或者说**批量归一化真正实现的是通过两个参数$\\gamma$和$\\beta$来让隐藏单元有可控的均值和方差**。\n\n### 将批量归一化用于神经网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 对于$L$层神经网络，实施批量归一化的整体流程如下：\n- <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B.jpg\" width=\"100%\" height=\"100%\">\n- 其中，参数为$W^{[1]}$,$b^{[1]}$,$W^{[2]}$,$b^{[2]}$,...,$W^{[L]}$,$b^{[L]}$以及$\\beta^{[1]}$,$\\gamma^{[1]}$,$\\beta^{[2]}$,$\\gamma^{[2]}$,...,$\\beta^{[L]}$,$\\gamma^{[L]}$。$\\beta^{[l]}$与$\\gamma^{[l]}$的学习同$W^{[l]}$与$b^{[l]}$一样，采用梯度下降法。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在mini-batch上应用批量归一化：\n- 分别用每个mini-batch的数据(均值和方差)进行批量归一化。\n- 因为批量归一化对各隐藏层$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$有去均值的操作，所以这里的常数项$b^{[l]}$可以消去，其数值效果完全可以由$\\tilde Z^{[l]}$中的$\\beta^{[l]}$来实现。因此，我们在使用批量归一化的时候，可以忽略各隐藏层的常数项$b^{[l]}$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B03.JPG\" width=\"80%\" height=\"80%\"> 概述了应用批量归一化时，梯度下降(或动量或RMSprop或Adam)的整个过程。\n\n### 批量归一化为什么有效\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%881.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%882.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%883.JPG\" width=\"80%\" height=\"80%\">\n- 解释1：归一化输入，使得输入$X$的均值为0，方差为1，大幅加速学习过程。批量归一化同理。\n- 解释2：批量归一化使得网络的每一层相对独立。\n- 解释3：批量归一化具有轻微的正则化效果。\n\n### 在测试阶段使用批量归一化\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8BatchNorm.JPG\" width=\"50%\" height=\"50%\"> \n- 首先，回顾批量归一化在训练过程中，在每一mini-batch，在网络的每一层中，做如下操作：\n - $\\mu=\\frac1m\\sum_iz^{(i)}$\n - $\\sigma^2=\\frac1m\\sum_i(z^{(i)}-\\mu)^2$\n - $z_{norm}^{(i)}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$\n - $\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$ \n - 其中，$\\mu$和$\\sigma^2$是对单个mini-batch中所有$m$个样本求得的。\n- 在测试阶段，如果只有一个样本，求其均值和方差是没有意义的，就需要对$\\mu$和$\\sigma^2$进行估计。实际应用中一般采用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的$\\mu$和$\\sigma^2$：\n - 指数加权平均的做法:对于第$l$层隐藏层，考虑所有mini-batch在该隐藏层下的$\\mu^{[l]}$和$\\sigma^{2[l]}$，然后用指数加权平均的方式来预测得到当前单个样本的$\\mu^{[l]}$和$\\sigma^{2[l]}$。这样就实现了对测试过程单个样本的均值和方差估计。\n - 最后，再利用训练过程得到的$\\gamma$和$\\beta$值计算出各层的$\\tilde z^{(i)}$值。\n\n## 3.3 多类别分类\n### Softmax回归\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax1.JPG\" width=\"80%\" height=\"80%\"> \n- 用神经网络进行多分类，`$C=\\#class=4$`，0为其他，1为猫，2为狗，3为小鸡。\n- 对于单个输入样本$x$，网络的最后一层(第$L$层)为Softmax层，$\\hat{y}=a^{[L]}$，维度为$(4,1)$。\n- Softmax层中各神经元的输出依次代表$P(other|x)$，$P(cat|x)$，$P(dog|x)$，$P(baby \\ chicks|x)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax2.JPG\" width=\"80%\" height=\"80%\">\n- Softmax层的激活函数计算过程如下：\n - `$z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}$`\n - `$t=e^{(z^{[L]})}$`\n - `$a^{[L]}=\\frac{e^{z^{[L]}}}{\\sum_{i=1}^C t_i}$`\n - `$a^{[L]}_i=\\frac{t_i}{\\sum_{i=1}^C t_i}$`\n - 也可看成是$a^{[L]}=g^{[L]}(z^{[L]})$，只不是该激活函数的输入是向量，输入也是向量。\n - 其中，Softmax层每个神经元的输出`$a^{[L]}_i$`对应属于该类的概率，满足：`$\\sum_{i=1}^Ca^{[L]}_i=1$`\n - `$a^{[L]}= \\hat{y}$`，维度为$(C, 1)$。\n- 具体计算示例如图。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax3.JPG\" width=\"80%\" height=\"80%\">\n- 上图为没有隐藏层，只有单一Softmax层的神经网络，其经Softmax分类的效果如图所示，为线性多分类效果，各两类之间的决策边界均为线性。\n- 当网络具有很多隐藏层，可构成更复杂的非线性决策边界。\n\n### 训练一个softmax分类器\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A81.JPG\" width=\"80%\" height=\"80%\"> 理解Softmax：\n- Softmax回归是Logistic回归向多类别的泛化。\n- 当$C=2$时，Softmax回归将简化成Logistic回归。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A82.JPG\" width=\"80%\" height=\"80%\">\n- 假设$C=4$，某个样本的预测输出$\\hat y$和目标输出(真实值标签)$y$为：\n - $$\\hat y=\\left[ \\begin{matrix} 0.3 \\\\ 0.2 \\\\ 0.1 \\\\ 0.4 \\end{matrix} \\right]$$\n - $$y=\\left[ \\begin{matrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{matrix} \\right]$$\n- Loss function：$L(\\hat y,y)=-\\sum_{j=1}^4y_j\\cdot log\\ \\hat y_j$\n - 然而，由于只有当$j=2$时，$y_2=1$，其它情况下，$y_j=0$。所以，上式中的$L(\\hat y,y)$可以简化为：$L(\\hat y,y)=-y_2\\cdot log\\ \\hat y_2=-log\\ \\hat y_2$\n - 要让$L(\\hat y,y)$更小，就应该让$\\hat y_2$越大越好。$\\hat y_2$反映的是概率，完全符合我们之前的定义。 \n- Cost function：$J(W^{[1]},b^{[1]},...)=\\frac1m\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})$\n- 若对于m个样本，其预测输出向量$A^{[L]}$即$\\hat Y$的维度为$(4, m)$，样本标签$Y$的维度也为$(4, m)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A83.JPG\" width=\"80%\" height=\"80%\"> 梯度下降的过程中，输出层Softmax的梯度推导，即$dZ^{[L]}$的推导：\n- $$da^{[L]}=-\\frac{1}{a^{[L]}}$$\n- $$\\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=\\frac{\\partial}{\\partial z^{[L]}}\\cdot (\\frac{e^{z^{[L]}_i}}{\\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\\cdot (1-a^{[L]})$$\n- $$dz^{[L]}= \\frac{\\partial J}{\\partial z^{[L]}}= da^{[L]}\\cdot \\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=a^{[L]}-1=a^{[L]}-y$$\n- 对于所有$m$个训练样本：$$dZ^{[L]}=A^{[L]}-Y$$\n- 可见$dZ^{[L]}$的表达式与二元分类结果是一致的，虽然推导过程不太一样。然后就可以继续进行反向传播过程的梯度下降算法了，推导过程与二元分类神经网络完全一致。\n\n## 3.4 编程框架介绍\n### 深度学习框架\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.JPG\" width=\"80%\" height=\"80%\"> 如图，介绍了目前的深度学习框架，和选择深度学习框架的标准。\n\n### TensorFlow\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow2.JPG\" width=\"80%\" height=\"80%\"> 本节介绍TensorFlow程序的典型结构。\n\n举个例子来说明，代价函数是参数`w`的函数：$J=w^2-10w+25$。\n如果使用TensorFlow对代价函数进行优化，求出最小值对应的`w`，程序如下：\n```Python\nimport numpy as np\nimport tensorflow as tf\n\nw = tf.Variable(0,dtype=tf.float32)\n#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)\ncost = w**2 - 10*w +25\ntrain = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n\ninit = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n`>>0.0`\n```Python\nsession.run(train)\nprint(session.run(w))\n```\n`>>0.1`\n```Python\nfor i in range(1000):\n    session.run(train)\nprint(session.run(w))\n```\n`>>4.99999`\nTensorFlow框架内可以直接调用梯度下降优化算法。在运行1000次梯度下降算法后，`w`的解为4.99999，已经非常接近`w`的最优值5了。\n针对上面这个例子，如果对`w`前的系数用变量`x`来代替，程序如下：\n```Python\nimport numpy as np\nimport tensorflow as tf\n\ncofficients = np.array([[1.],[-10.],[25.]])\n\nw = tf.Variable(0,dtype=tf.float32)\nx = tf.placeholder(tf.float32,[3,1])\n#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)\n#cost = w**2 - 10*w +25\ncost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\ntrain = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n\ninit = tf.global_variables_initializer()\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n`>>0.0`\n```Python\nsession.run(train, feed_dict=(x:coefficients))\nprint(session.run(w))\n```\n`>>0.1`\n```Python\nfor i in range(1000):\n    session.run(train, feed_dict=(x:coefficients))\nprint(session.run(w))\n```\n`>>4.99999`\n结果跟之前是一样的。除此之外，我们还可以更改`x`即`cofficients`的值，而得到不同的优化结果`w`。\n另外，上段程序中的：\n```\nsession = tf.Session()\nsession.run(init)\nprint(session.run(w))\n```\n有另外一种写法：\n```Python\nwith tf.Session() as session:\n    session.run(init)\n    print(session.run(w))\n```\nTensorFlow的最大优点就是采用数据流图(data flow graphs)来进行数值运算。图中的节点(Nodes)表示数学操作，图中的线(edges)则表示在节点间相互联系的多维数据数组，即张量(tensor)。而且它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU(或GPU)，服务器，移动设备等。\n ","slug":"深度学习课程(二)优化深层神经网络：超参数调试、正则化和最优化","published":1,"updated":"2018-01-30T07:16:10.529Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w49006dqslp0wnse0yl","content":"<h1 id=\"1-深度学习的实用层面\"><a href=\"#1-深度学习的实用层面\" class=\"headerlink\" title=\"1.深度学习的实用层面\"></a><strong>1.深度学习的实用层面</strong></h1><h2 id=\"1-1-建立机器学习应用\"><a href=\"#1-1-建立机器学习应用\" class=\"headerlink\" title=\"1.1 建立机器学习应用\"></a><strong>1.1 建立机器学习应用</strong></h2><h3 id=\"训练-开发-测试集\"><a href=\"#训练-开发-测试集\" class=\"headerlink\" title=\"训练/开发/测试集\"></a><strong>训练/开发/测试集</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%861.JPG\" width=\"70%\" height=\"70%\">在实际中应用机器学习是一个高度迭代的过程：</p>\n<ul>\n<li>在构建一个神经网络的时，需要设置许多超参数，例如神经网络的层数、每个隐藏层包含的神经元个数、学习速率、激活函数的选择等。实际上很难在第一次设置的时候就选择到这些最佳的参数，而是需要通过不断地迭代更新来获得。</li>\n<li>迭代的过程如下：先有个想法，先选择初始的参数值，构建神经网络模型结构；然后通过代码实现；最后，通过实验验证。根据实验结果，对参数进行适当的调整优化，再进行下一次的Idea-&gt;Code-&gt;Experiment循环。</li>\n<li>恰当的将数据分为训练/开发/测试集，可使得迭代效率更高。</li>\n</ul>\n<a id=\"more\"></a> \n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%862.JPG\" width=\"90%\" height=\"90%\">一般地，将所有的样本数据分成三个部分：训练(Train)/开发(Dev)/测试(Test)集：</p>\n<ul>\n<li>训练集用来训练你的模型；</li>\n<li>开发集又称交叉验证集(cross validation set)，用来验证不同算法的表现情况，从中选择最好的模型；</li>\n<li>测试集用来测试最好模型的实际表现，给出该模型的无偏估计。</li>\n</ul>\n<p>关于数据集的比例划分，在以前，可获得的数据量不是很大的情况：</p>\n<ul>\n<li>通常设置训练集和测试集的数量比例为70%和30%。如果有开发集，则设置比例为60%、20%、20%，分别对应训练/测试/开发集。</li>\n<li>这种比例分配在样本数量不是很大的情况下，例如100,1000,10000，是比较科学的。</li>\n</ul>\n<p>关于数据集的比例划分，在如今，大数据的时代：</p>\n<ul>\n<li>如果数据量很大的时候，例如数据量达100万，70%/30%或60%/20%/20%的比例分配是不合理的。</li>\n<li>因为开发集的目的是用来比较验证不同模型的优劣，从而选择更好的模型。因此，通常不需要所有样本的20%这么多的数据来进行验证。例如对于100万的样本，往往只需要10000个样本来做验证就够了。测试集的目的是给出已选定最优模型的无偏估计。对于100万的样本，往往也只需要10000个样本就够了。</li>\n<li>科学的做法是要将开发集和测试集的比例设置得很低。因此，对于大数据样本，训练/开发/测试集的比例通常可以设置为98%/1%/1%，或者99%/0.5%/0.5%。样本数据量越大，相应的开发/测试集的比例可以设置的越低一些。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%863.JPG\" width=\"80%\" height=\"80%\">现代深度学习还有个重要的问题就是训练集和测试集的分布不匹配，意为是训练集和测试集来自于不同的分布。例如：</p>\n<ul>\n<li>对于一个手机app，可以让用户上传图片，然后app识别出猫的图片。该应用中，训练集可能是从网络抓取的图片，而开发和测试集可能来自不同用户的上传的猫的照片。</li>\n<li>从网络抓取的图片可能像素较高且拍摄专业等等，而用户上传的图片可能像素较低且模糊等等。因此，训练集和验证/测试集可能来自不同的分布。</li>\n<li><strong>解决方法：保证开发集和测试集来自于同一分布。</strong></li>\n</ul>\n<p>注意：</p>\n<ul>\n<li>如果不需要对最终选定的神经网络做出无偏估计，可以没有测试集，只有训练/开发集（也有人说成只有训练/测试集，都可以）。</li>\n</ul>\n<h3 id=\"偏差-方差\"><a href=\"#偏差-方差\" class=\"headerlink\" title=\"偏差/方差\"></a><strong>偏差/方差</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 对于只有$x_1$和$x_2$两个特征的二维数据集，可以绘制数据，可视化偏差和方差。如上图所示：</p>\n<ul>\n<li>左：高偏差，欠拟合</li>\n<li>中：恰好</li>\n<li>右：高方差，过拟合</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"80%\" height=\"80%\"> 对于高维数据，无法绘制数据以及可视化决策边界。但可通过几个指标来理解偏差和方差。<br>基于人工误差（或贝叶斯误差或最优误差)非常低（约为0%）并且训练集和开发集都来自于同一分布这两个假设，如上图所示：</p>\n<ul>\n<li>训练集误差为1%/开发集误差11%，结合两者说明该算法在训练集上过拟合，导致在开发集上的泛化性能不好，推出高方差。</li>\n<li>训练集误差为15%，在训练集上欠拟合，推出高偏差。开发集误差16%，相比于训练集误差只高1%，并不存在高方差。</li>\n<li>训练集误差为15%，推出高偏差。开发集误差30%，相比于训练集误差高15%，推出高方差。</li>\n<li>训练集误差为0.5%，低偏差。开发集误差1%，相比于训练集误差只高0.5%，低方差。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"70%\" height=\"70%\"> 上图展示了高偏差和高方差同时存在的可视化情形：</p>\n<ul>\n<li>决策边界为线性，欠拟合，高偏差</li>\n<li>在局部发生过拟合，高方差</li>\n<li>该情形在二维情况下看起来不自然，但对于高维数据，这种情况是容易发生的。</li>\n</ul>\n<h3 id=\"机器学习的基本准则\"><a href=\"#机器学习的基本准则\" class=\"headerlink\" title=\"机器学习的基本准则\"></a><strong>机器学习的基本准则</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99.JPG\" width=\"70%\" height=\"70%\"> 当训练好最初的神经网络时：</p>\n<ul>\n<li>高偏差？通过训练集表现来确定，若存在高偏差，则可通过更大的网络或训练更长时间来解决。</li>\n<li>高方差？通过开发集表现来确定，若存在高方差，则可通过获取更多数据及正则化来解决。</li>\n<li>直到找到低偏差且低方差的网络。</li>\n</ul>\n<p>关于偏差和方差的权衡：</p>\n<ul>\n<li>在早期的机器学习时代，有很多关于偏差和方差的权衡的讨论，因为当时没有能够单独减小偏差和单独减小方差的工具。</li>\n<li>而在如今的深度学习和大数据时代，通过扩大网络几乎总是能够较小偏差而不增大方差（只要用恰当的方式正则化）；通过获得更多数据几乎总是能够减小方差而不增大偏差。因此，这也解释了为何深度学习在监督学习中如此有效。</li>\n</ul>\n<h2 id=\"1-2-正则化神经网络\"><a href=\"#1-2-正则化神经网络\" class=\"headerlink\" title=\"1.2 正则化神经网络\"></a><strong>1.2 正则化神经网络</strong></h2><h3 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a><strong>正则化</strong></h3><p>获得更多数据和正则化都是解决过拟合(高方差)的有效方法，但很多时候并不能总是获得更多数据或者获得更多数据的代价太高。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%AD%A3%E5%88%99%E5%8C%96-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.JPG\" width=\"80%\" height=\"80%\">先介绍在逻辑回归中应用正则化，如图：</p>\n<ul>\n<li>逻辑回归：$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})$</li>\n<li>参数：$w \\in R^{n_x}$，$b\\in R$</li>\n<li>目的：$\\min\\limits_{w,b} J(w,b)$；</li>\n<li>$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_2^2$<ul>\n<li>L2正则化：<script type=\"math/tex\">||w||_2^2=\\sum_{j=1}^{n_x}w_j^2=w^Tw</script>，其中$\\lambda$是正则化参数</li>\n</ul>\n</li>\n<li>$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_1$<ul>\n<li>L1正则化：<script type=\"math/tex\">||w||_1=\\sum_{j=1}^{n_x}|w_j|</script>，其中$\\lambda$是正则化参数</li>\n</ul>\n</li>\n<li>若使用L1正则化，$w$最后会变得稀疏，即$w$中会有很多0。有人认为这有助于压缩模型，因为有一部分参数是0，只需较少的内存来存储模型。<br>然而在实践中发现，通过L1正则化让模型变得稀疏带来的收效甚微。故吴恩达觉得至少在压缩模型的目标上，它的作用不大。<br>总之，在训练神经网络中，L2正则化应用地更频繁。</li>\n<li>只正则化参数$w$，而省略正则化参数$b$的原因是：$w$是高维矢量参数，$b$只是一个标量，几乎所有的参数都集中在$w$中，$b$只是大量参数中的一个，故可省略。</li>\n<li>注意，在python中，由于<code>lambda</code>是保留字，为了避免冲突，故在编程练习中使用<code>lambd</code>来表示$\\lambda$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"50%\" height=\"50%\"> 在神经网络中应用正则化，如图：</p>\n<ul>\n<li>代价函数：<script type=\"math/tex\">J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})=\\frac1m\\sum\\limits_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum\\limits_{l=1}^L||W^{[l]}||_F^2</script></li>\n<li>其中，矩阵的L2范数称为F范数(Frobenius范数)，<script type=\"math/tex\">||W^{[l]}||_F^2=\\sum_{i=1}^{n^{[l]}}\\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2</script>。</li>\n<li>正则化后的梯度下降法：<ul>\n<li>$dW^{[l]}=dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]}$</li>\n<li>$W^{[l]} =W^{[l]}-\\alpha dW^{[l]}$</li>\n</ul>\n</li>\n</ul>\n<p><strong>L2正则化也被称作权重衰减(weight decay)</strong>。原因如下：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\begin{eqnarray}W^{[l]} &:=&W^{[l]}-\\alpha\\cdot dW^{[l]}\\\\ &=&W^{[l]}-\\alpha\\cdot(dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]})\\\\ &=&(1-\\alpha\\frac{\\lambda}{m})W^{[l]}-\\alpha\\cdot dW^{[l]}_{before} \\end{eqnarray}</script></li>\n<li>其中，$(1-\\alpha\\frac{\\lambda}{m})&lt;1$。加上L2正则化项后，$W^{[l]}$的每次更新，都会乘以一个小于1的项。即每次迭代更新，都使得$W^{[l]}$不断地减小，故L2正则化又被称为权重衰减。</li>\n</ul>\n<h3 id=\"为什么正则化可以减轻过拟合\"><a href=\"#为什么正则化可以减轻过拟合\" class=\"headerlink\" title=\"为什么正则化可以减轻过拟合\"></a><strong>为什么正则化可以减轻过拟合</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%881.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例一：</p>\n<ul>\n<li>假设由于选择了非常复杂的神经网络模型，因而存在过拟合，如上图左上角所示。</li>\n<li>加上正则化项后，若将正则化参数$\\lambda$设置的很大，那么参数$ W^{[l]}\\approx0$，参数$W$中的很多数接近于0，这相当于网络中的很多神经元不起作用，这样原本过于复杂的神经网络模型就变得简单化了，故减轻了过拟合。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%882.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例二：</p>\n<ul>\n<li>假设激活函数是<code>tanh</code>函数。<code>tanh</code>函数的特点是在$|z|$较小的区域，函数是近似线性的，而当$|z|$稍大的时候，才会展现出非线性能力。</li>\n<li>若加入正则化，使$\\lambda$较大，即对权重$W^{[l]}$的惩罚较大，使得$W^{[l]}$较小。</li>\n<li>因为$z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}$。当$W^{[l]}$较小，$z^{[l]}$也较小。当$z^{[l]}$在较小范围内时，激活函数$g(z)$就会近似于线性函数。因此每一层几乎都是线性的，当隐藏曾的激活函数是线性函数的时候，再多隐藏层也只是计算线性函数。故网络不能拟合复杂的非线性函数，便不容易过拟合了。</li>\n</ul>\n<h3 id=\"Dropout正则化\"><a href=\"#Dropout正则化\" class=\"headerlink\" title=\"Dropout正则化\"></a><strong>Dropout正则化</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-1.JPG\" width=\"70%\" height=\"70%\"> 除了正则化外，还有另外一种防止过拟合的有效方法：Dropout(随机失活)：</p>\n<ul>\n<li>Dropout：在神经网络的训练过程中，每一次迭代，按照一定的概率随机地将其暂时从网络中丢弃。</li>\n<li>也就是说，每一次迭代，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-2.JPG\" width=\"50%\" height=\"50%\"> Dropout有不同的实现方法，Inverted dropout(反向失活)是目前最常用的实现方法：</p>\n<ul>\n<li><p>假设对于第$l=3$层神经元，设定保留神经元比例概率<code>keep_prob=0.8</code>。在Python中，Inverted dropout可实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d3 = np.random.rand(a3.shape[<span class=\"number\">0</span>],a3.shape[<span class=\"number\">1</span>]) &lt; keep_prob</span><br><span class=\"line\">a3 = np.multiply(a3,d3) <span class=\"comment\">#逐元素相乘，也可以写成 a3 *= d3</span></span><br><span class=\"line\">a3 /= keep_prob         <span class=\"comment\">#保持a3的期望值不变。这样在测试阶段也不用再对a3值进行缩放</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>最后一步解释：例如<code>keep_prob=0.5</code>，该层将有一般的神经元被关闭，故该层的输出将被0.5缩放，因为只有剩下的一半神经元为计算输出做贡献。除以0.5等价于乘以2。因此输出有了相同的期望值。</li>\n</ul>\n</li>\n<li>反向传播过程：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">da3 = np.multiply(da3,d3) <span class=\"comment\">#前向传播中关闭了某些神经元，反向传播中也关闭</span></span><br><span class=\"line\">da3 /= keep_prob          <span class=\"comment\">#a3缩放了keep_prob尺度，根据微积分的性质，则它的梯度也要缩放</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>注：Dropout仅在训练阶段使用，在测试阶段，不使用Dropout。</p>\n<h3 id=\"理解Dropout\"><a href=\"#理解Dropout\" class=\"headerlink\" title=\"理解Dropout\"></a><strong>理解Dropout</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-3.JPG\" width=\"50%\" height=\"50%\">如图，对于网络中的某一神经元，若采用了dropout，对于每个不同的样本，它的输入特征被消除的特征都不同，因此该神经元不能依靠任一输入特征，故最终网络会分散权重，即所有的权重都不会过大。<br>使用Dropout的时候的几个注意点：</p>\n<ul>\n<li>可为不同网络层设置不同的<code>keep_prob</code>，但该做法的缺点是引入了更多的超参数。可将神经元较多(更容易过拟合)的隐藏层，<code>keep_out</code>设置得较小，如0.5；神经元越少的隐藏层，<code>keep_out</code>设置得较大，例如0.7。<code>keep_out</code>设置为1，表示全部保留，不使用Dropout。</li>\n<li>不建议对输入层进行Dropout，如果输入层维度很大，例如图片，那么可以设置Dropout，但<code>keep_out</code>应设置的大一些，例如0.8，0.9。</li>\n<li>Dropout在计算机视觉领域中应用广泛（实际从AlextNet中提出），因为输入层(图像)维度较大，且通常没有足够多的训练样本。</li>\n<li>Dropout是一种正则化技巧，用来防止过拟合，只有在确认模型过拟合后，再使用它。</li>\n<li>Dropout的一大缺点是代价函数$J$不再被明确定义，每次迭代都会随机移除一些神经元。故失去了检查梯度下降这一项调式工具，即通过绘图检查代价函数$J$是否随着迭代次数而减小（定义明确的代价函数$J$，在每次迭代后都会下降）。故应关闭Dropout(<code>keep_out</code>设置为1)，再进行梯度下降检查。</li>\n</ul>\n<h3 id=\"其他正则化方法\"><a href=\"#其他正则化方法\" class=\"headerlink\" title=\"其他正则化方法\"></a><strong>其他正则化方法</strong></h3><p>除了L2正则化和dropout之外，还有其它的正则化方法，如:数据增强，提前终止(early stopping)。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%951.JPG\" width=\"60%\" height=\"60%\">数据增强是对已有的训练样本进行一些处理来“制造”出更多的样本。</p>\n<ul>\n<li>例如图片识别问题中，数据增强是通过对已有的图片进行水平翻转、随机剪裁等方式制造出训练样本。</li>\n<li>虽然这些新样本是基于原有样本的，可能新的训练集有些冗余，但是相对于重新搜集全新独立的数据，数据增强不需要成本。</li>\n<li>因为增加了训练数据，能起到减轻过拟合的作用，故算过正则化方法。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%952.JPG\" width=\"80%\" height=\"80%\">另外一种正则化方法early stopping：如图，根据训练集误差曲线(或$J$的曲线)和开发集误差曲线(或$J$的曲线)随着迭代次数的变化趋势，选择使得开发集误差最小的迭代次数，停止训练，即early stopping。</p>\n<ul>\n<li>直观解释：神经网络训练前,$W$的值趋近于0,随着训练的进行，$W$越来越大。early stopping相当于选取了一个不大不小的$W$，类似于$||w||_F$的效果，从而希望此时神经网络的过拟合不严重。</li>\n</ul>\n<p>early stopping的缺点：</p>\n<ul>\n<li>通常来说，机器学习训练模型有两个目标：一是优化代价函数，即减小$J$；二是防止过拟合。这两个任务是分开进行的。把这二者之间的关系称为正交化(orthogonalization)，后面课程会进一步讲解。</li>\n<li>early stopping的做法相当于将两个任务合在一起执行，减少迭代次数停止训练时，$J$就不会足够小，且希望此时不过拟合。</li>\n</ul>\n<p>early stopping的优点：</p>\n<ul>\n<li>相比与L2正则化，early stopping不用选择超参数$\\lambda$。</li>\n</ul>\n<p>吴恩达的做法：</p>\n<ul>\n<li>偶尔用early stopping，一般只用L2正则化。</li>\n</ul>\n<h2 id=\"1-3-设置优化问题\"><a href=\"#1-3-设置优化问题\" class=\"headerlink\" title=\"1.3 设置优化问题\"></a>1.3 <strong>设置优化问题</strong></h2><h3 id=\"归一化输入\"><a href=\"#归一化输入\" class=\"headerlink\" title=\"归一化输入\"></a><strong>归一化输入</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A51.JPG\" width=\"80%\" height=\"80%\"> 在训练神经网络时，<strong>归一化(normalize)输入</strong>可以<strong>加速训练过程($J$的优化过程)</strong>。<br>归一化输入就是将原始数据减去其均值$\\mu$后，再除以其方差$\\sigma^2$：</p>\n<ul>\n<li>$\\mu=\\frac1m\\sum_{i=1}^m x^{(i)}$</li>\n<li>$x = x-\\mu$</li>\n<li>$\\sigma^2=\\frac1m\\sum_{i=1}^m x^{(i)}**2$</li>\n<li>$x = x/ \\sqrt{\\sigma^2}$</li>\n<li>注：对于训练集和测试集，应使用同样的$\\mu$和$\\sigma^2$进行归一化处理，即均使用训练集计算出的$\\mu$和$\\sigma^2$进行归一化处理。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A52.JPG\" width=\"75%\" height=\"75%\"> 上图以二维输入特征为例，解释了为什么归一化输入可以加速训练过程：</p>\n<ul>\n<li>假设输入特征为二维，且$x_1$的范围是[1,1000]，$x_2$的范围是[0,1]。  </li>\n<li>如图左下所示，若不归一化输入，$x_1$与$x_2$之间分布极不平衡，代价函数$J$与$x_1$和$x_2$的等高线是一个细长的椭圆形。对其进行梯度下降算法时，容易发生振荡，且需选择很小的学习速率$\\alpha$，来避免$J$发生振荡，一旦$\\alpha$较大，必然发生振荡，故学习过程很慢。</li>\n<li>如图右下所示，若归一化输入，$x_1$与$x_2$分布均匀，代价函数$J$与$x_1$和$x_2$的等高线是一个圆形。对其进行梯度下降算法时， 可选取较大的步长$\\alpha$，且$J$不易发生振荡，故学习过程较快。</li>\n<li>注意：如果输入特征的尺度非常不同，比如有些特征取值为[0,1]，有些是[1,1000]，那对输入进行归一化就很重要。而如果输入特征本来尺度就相近，那么这一步就不那么重要。</li>\n<li>吴恩达的做法：因为归一化输入的步骤几乎从来没有任何害处，所以无论如何总是进行归一化，尽管不确定它是否会让训练变得更快。</li>\n</ul>\n<h3 id=\"梯度消失与梯度爆炸\"><a href=\"#梯度消失与梯度爆炸\" class=\"headerlink\" title=\"梯度消失与梯度爆炸\"></a><strong>梯度消失与梯度爆炸</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8.JPG\" width=\"75%\" height=\"75%\"> 当训练深层神经网络时，会出现梯度消失和梯度爆炸问题。如图：</p>\n<ul>\n<li>为便于分析，令各层的激活函数为线性函数，即$g(z)=z$，且令$b=0$。那么，该网络的预测输出$\\hat y$为：<ul>\n<li>$\\hat y=W^{[L]}W^{[L-1]}W^{[L-2]}\\cdots W^{[3]}W^{[2]}W^{[1]}x $</li>\n</ul>\n</li>\n<li>如果各层权重$W^{[l]}$只比1或单位矩阵稍大一点（如1.5），深层神经网络的激活函数将作为层数$l$的函数指数级增长。</li>\n<li>如果各层权重$W^{[l]}$只比1或单位矩阵稍小一点（如0.9），深层神经网络的激活函数将作为层数$l$的函数指数级递减。</li>\n<li>虽然上图只论述了激活函数作为层数$l$的函数指数级增加或减少，同样可以论证表明，计算出的导数或梯度，也会指数级增加或指数级减少。</li>\n<li>在一个非常深的神经网络（如150层）中，如果激活函数或梯度作为$l$的函数指数级的增大或减小，这些值会变得非常大或非常小，这会让训练变得非常困难。尤其是如果梯度作为$l$的函数指数级减小，梯度下降会用很小很小的步子走，梯度下降会用很长时间才能完成学习。</li>\n</ul>\n<h3 id=\"深层网络的权重初始化\"><a href=\"#深层网络的权重初始化\" class=\"headerlink\" title=\"深层网络的权重初始化\"></a><strong>深层网络的权重初始化</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%B1%82%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96.JPG\" width=\"80%\" height=\"80%\"> 针对梯度消失和梯度爆炸，有一种部分解决方法，虽然不能完全解决它，但帮助很大，即更小心地随机初始化神经网络。<br>如图，以初始化单个神经元为例，然后再把它应用到深层网络中：</p>\n<ul>\n<li>$z=w_1x_1+w_2x_2+…+w_nx_n$</li>\n<li>为了让$z$不会过大或者过小，思路是让$w$与$n$有关，且$n$越大，$w$应该越小才好。这样能够保证$z$不会过大。</li>\n<li>如果激活函数是<code>tanh</code>，一般在初始化$w$时，令其方差为$\\frac1n$，即$Var(w)=\\frac1n$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{1}{n^{[l-1]}})$</li>\n<li>解释：第$l$层中的每个神经元都有$n^{[l-1]}$个输入。标准正态分布均值为0，方差为1，乘以$np.sqrt(\\frac{1}{n^{[l-1]}})$，那么$w$的方差便为$\\frac{1}{n^{[l-1]}}$<br>方差性质：$C$为常数，$D(CX) = C^2D(X)$</li>\n<li>该初始化方法也称为“Xavier initialization”。</li>\n</ul>\n</li>\n<li>如果激活函数是<code>ReLU</code>，一般在初始化$w$时，令其方差为$\\frac2n$，即$Var(w)=\\frac2n$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}})$</li>\n<li>该初始化方法也称为“He initialization”。</li>\n</ul>\n</li>\n<li>除此之外，Yoshua Bengio提出了另外一种初始化$w$的方法，令其方差为$\\frac{2}{n^{[l-1]}+n^{[l]}}$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}+n^{[l]}})$</li>\n</ul>\n</li>\n<li>注：视频中3：15秒处，还有一段关于解释该做法可以有效减缓梯度消失/梯度爆炸的原因，没听懂，待理解。</li>\n</ul>\n<h3 id=\"梯度的数值逼近\"><a href=\"#梯度的数值逼近\" class=\"headerlink\" title=\"梯度的数值逼近\"></a><strong>梯度的数值逼近</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91.JPG\" width=\"80%\" height=\"80%\"> 对于神经网络的反向传播，有一项重要的测试——梯度检验(gradient checking)。该节先介绍梯度的数值逼近：</p>\n<ul>\n<li>采用双边差分公式进行数值逼近：$f’(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta-\\varepsilon)}{2\\varepsilon}$</li>\n<li>如$f(\\theta)=theta^3$，当$\\theta$为1，$\\varepsilon$为0.01时，逼近误差为：0.0001</li>\n<li>注意：不采用单边差分公式：$f’(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta)}{\\varepsilon}$进行梯度的数值逼近的原因是：<ul>\n<li>单边差分公式的逼近误差是$O(\\varepsilon)$。</li>\n<li>双边差分公式的逼近误差是$O(\\varepsilon^2)$，逼近误差更小，故本课程采用此方法。</li>\n</ul>\n</li>\n<li>即利用的是该导数定义：<script type=\"math/tex\">f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta - \\varepsilon)}{2 \\varepsilon}</script>，而不是该导数定义：<script type=\"math/tex\">f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta)}{\\varepsilon}</script></li>\n</ul>\n<h3 id=\"梯度检验\"><a href=\"#梯度检验\" class=\"headerlink\" title=\"梯度检验\"></a><strong>梯度检验</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C1.JPG\" width=\"75%\" height=\"75%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C2.JPG\" width=\"75%\" height=\"75%\"> 进行梯度检验，可验证代码中的反向传播是否有错误：</p>\n<ul>\n<li>首先，将$W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]}$ 这些矩阵逐个转变为一维向量，然后连接成一个大的一维向量$\\theta$。这样$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})$ 就可表示成$J(\\theta)$。</li>\n<li>然后，将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\\cdots,dW^{[L]},db^{[L]}$同上一步骤一样构造成一个大的一维向量 $d\\theta$。注意到，$d\\theta$的维度与$\\theta$是一致的。</li>\n<li>接着，对$\\theta$中的每个元素$\\theta_i$，计算近似梯度：<script type=\"math/tex; mode=display\">d\\theta_{approx}[i]=\\frac{J(\\theta_1,\\theta_2,\\cdots,\\theta_i+\\varepsilon,\\cdots)-J(\\theta_1,\\theta_2,\\cdots,\\theta_i-\\varepsilon,\\cdots)}{2\\varepsilon}</script></li>\n<li>最终，得到$d\\theta_{approx}$。</li>\n<li>将<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>相比较，检查是否一致，即是否<script type=\"math/tex\">d\\theta_{approx} \\approx d\\theta</script>，也即是否每一元素<script type=\"math/tex\">d\\theta_{approx}[i] \\approx d\\theta[i]</script>。</li>\n<li>检验相似度的标准如下：<script type=\"math/tex; mode=display\">\\frac{||d\\theta_{approx}-d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}</script><ul>\n<li>解释：首先计算<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的欧氏距离，即差值的L2范数。然后根据向量的长度将其归一化，即除以两个向量的欧几里德长度和，除以该分母的原因是：防止分子过大或过小，这样整个式子就成了一个比值。</li>\n<li>在实际中，选用$\\varepsilon=10^{-7}$：</li>\n<li>如果相似度的值小于$10^{-7}$，表明梯度逼近误差极小，通过梯度检查，代码是对的。</li>\n<li>如果相似度在$10^{-5}$左右，代码可能是对的，但还是会逐个检查向量<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的每一项，看是否有某一项过大。则该处代码可能存在错误，下节会稍详细讲解此点。</li>\n<li>如果相似度在$10^{-3}$左右，代码中一定有错误。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"运用梯度检验的注意事项\"><a href=\"#运用梯度检验的注意事项\" class=\"headerlink\" title=\"运用梯度检验的注意事项\"></a><strong>运用梯度检验的注意事项</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.JPG\" width=\"75%\" height=\"75%\"> 在运用梯度检查时有几点注意事项：</p>\n<ul>\n<li>一旦确定反向传播正确，即关闭梯度检验，否则训练过程会极慢。<ul>\n<li>解释：梯度检验很慢,故不在训练的每一次迭代中都使用。只要确定反向传播代码正确, 就关闭它。</li>\n</ul>\n</li>\n<li>如果梯度检验出现错误，找到对应出错项，尝试识别出bug位置：<ul>\n<li>解释：逐个对比向量<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的每一项，看是否有某一项<script type=\"math/tex\">d\\theta[i]</script>过大。例如，过大项<script type=\"math/tex\">d\\theta[i]</script>属于$dw^{[l]}$，而同一层的$db^{[l]}$未出错，则可能bug在关于$dw^{[l]}$的代码中。</li>\n<li>有时这样的分析虽然无法帮助精确定位出bug位置，但可以帮助我们猜测bug的位置。</li>\n</ul>\n</li>\n<li>如果进行了正则化，则计算近似梯度$d\\theta_{approx}$的时候要包括进去。</li>\n<li>梯度检验时关闭dropout，梯度检验完毕后再打开dropout。<ul>\n<li>解释：dropout使得$J$没有精确的定义，无法进行$d\\theta_{approx}$的计算。故先梯度检验，通过后，再开启dropout。</li>\n</ul>\n</li>\n<li>随机初始化时运行梯度检验，经过一些训练后再次进行梯度检验（不常用）。<ul>\n<li>为了预防你的反向传播算法在$w$和$b$在接近0的时候是正确的，但当$w$和$b$变大时，算法精度有所下降。</li>\n<li>故在一些迭代后，当$w$和$b$变大时，再次进行梯度检验。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-优化算法\"><a href=\"#2-优化算法\" class=\"headerlink\" title=\"2.优化算法\"></a>2.优化算法</h1><h2 id=\"2-1-优化算法\"><a href=\"#2-1-优化算法\" class=\"headerlink\" title=\"2.1 优化算法\"></a>2.1 优化算法</h2><h3 id=\"小批量梯度下降法\"><a href=\"#小批量梯度下降法\" class=\"headerlink\" title=\"小批量梯度下降法\"></a>小批量梯度下降法</h3><p>开篇即说过，机器学习应用是一个高度依赖经验的需要大量迭代的过程。优化算法可以加快神经网络的训练速度，从而提高效率。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%951.JPG\" width=\"80%\" height=\"80%\"> 批量梯度下降法(batch gradient descent)：</p>\n<ul>\n<li>每次迭代，对所有样本进行训练，故其训练速度很慢。</li>\n</ul>\n<p>小批量梯度下降法(mini-batch gradient descent)：</p>\n<ul>\n<li>将$m$个训练样本分成若干个子集，称为mini-batch。</li>\n<li>然后每次迭代，在单一子集(mini-batch)上进行神经网络训练，每次迭代所需时间大幅减少。</li>\n</ul>\n<p>如图中示例：</p>\n<ul>\n<li>总的训练样本$X_{(n_x,m)}=[x^1,x^{(2)},…,x^{(m)}]$，其中$m=5,000,000$。</li>\n<li>总的训练样本的标签$Y_{(1,m)}=[y^1,y^{(2)},…,y^{(m)}]$，其中$m=5,000,000$。</li>\n<li>将$X$分成5000个mini-batch，每mini-batch含1000个样本，将每个mini-batch记为<script type=\"math/tex\">X^{\\{t\\}}</script> ，其维度为<script type=\"math/tex\">(n_x,1000)</script>,且<script type=\"math/tex\">t=1,2,\\cdots,5000</script>。</li>\n<li>每个mini-batch对应的标签记为<script type=\"math/tex\">Y^{\\{t\\}}</script>，其维度为<script type=\"math/tex\">(1,1000)</script>，且<script type=\"math/tex\">t=1,2,\\cdots,5000</script>。</li>\n</ul>\n<p>总结一下遇到的神经网络中几类字母的上标含义：</p>\n<ul>\n<li>$x^{(i)}$ ：第$i$个样本</li>\n<li>$z^{[l]}$ ：神经网络第$l$层网络的线性输出</li>\n<li><script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>：第$t$个mini-batch</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 如图：</p>\n<ul>\n<li>对于小批量梯度下降法来说，一个周期(epoch)是指：将所有mini_batch（<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>）训练一次(前向传播、计算$J$、反向传播、参数更新)，即遍历一次总体训练集。</li>\n<li>对于批量梯度下降法，一个周期只进行一次梯度下降步骤；而对于小批量梯度下降法，一个周期会进行$T$次梯度下降步骤。</li>\n<li>通常，会多次遍历训练集(一个显式的for循环)直到收敛到某个值。</li>\n</ul>\n<h3 id=\"理解小批量梯度下降法\"><a href=\"#理解小批量梯度下降法\" class=\"headerlink\" title=\"理解小批量梯度下降法\"></a>理解小批量梯度下降法</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>使用批量梯度下降法，每次迭代将遍历整个训练集，$J$都会减小，若没有减小，则一定是某处错了。</li>\n<li>使用小批量梯度下降法，每次迭代是在不同的mini-batch上训练，其代价函数$J$和迭代次数(也即mini-batch/t)的曲线存在噪声，上下振荡，但整体的趋势是下降的。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 对于mini-batch尺寸的选择：</p>\n<ul>\n<li>如果mini-batch尺寸为m：即为批量梯度下降((Batch) Gradient Descent)。<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}=(X,Y)</script></li>\n<li>如果mini-batch尺寸为1：即为随机梯度下降(Stochastic Gradient Descent, SGD)。每个样本都是一个mini-batch。</li>\n<li>实际操作中：mini-batch尺寸的选择在1到m之间。</li>\n</ul>\n<p>如图，比较各梯度下降方法的代价函数的等高线图：</p>\n<ul>\n<li>蓝色曲线代表批量梯度下降：<ul>\n<li>它的噪声相对较小。</li>\n<li>每一步相对较大。</li>\n<li>并且最终可以达到最小值。</li>\n<li>缺点：每次迭代所需时间太长。</li>\n</ul>\n</li>\n<li>紫色曲线代表随机梯度下降：<ul>\n<li>对于每一次迭代，就在一个样本上做梯度下降，噪声非常大。</li>\n<li>一般来说它会沿着正确的方向，但有时也会指向错误的方向。</li>\n<li>最后也不会收敛到一个点，它一般会在最低点附近摆动，但是不会达到并且停在那里。 </li>\n<li>缺点：失去了通过向量化来加速计算这个工具。</li>\n</ul>\n</li>\n<li>绿色曲线代表实际中mini-batch尺寸为1~m之间的梯度下降：<ul>\n<li>优点：有着最快的学习速度：1.可在每一个mini-batch运用向量化。2.每次迭代所需时间少。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"75%\" height=\"75%\"></p>\n<ul>\n<li>如果总体样本数量$m$($m\\leq2000$)，建议直接使用批量梯度下降。</li>\n<li>如果总体样本数量$m$很大时，建议将样本分成许多mini-batch。</li>\n<li>推荐常用的mini-batch 尺寸为64,128,256,512(这些都是2的幂。之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度)。</li>\n<li>但要确保每一个mini-batch（<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>）能装进CPU/GPU。</li>\n<li>在实践中，要得到不同的mini-batches，需要两个步骤：1.对数据集洗牌(shuffle)；2.分割(partition)。</li>\n</ul>\n<h3 id=\"指数加权平均\"><a href=\"#指数加权平均\" class=\"headerlink\" title=\"指数加权平均\"></a>指数加权平均</h3><p>接下来介绍几个优化算法，它们比梯度下降更快，为了理解这些算法，需要用到一种叫指数加权平均(exponentially weighted average)的操作，在统计学上也被称为指数加权滑动平均。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 如图，通过指数加权平均来计算最近10天的温度：</p>\n<ul>\n<li>设$V_0=0$，当成第0天的气温值</li>\n<li>第一天的气温与第0天的气温有关：$V_1=0.9V_0+0.1\\theta_1$</li>\n<li>第二天的气温与第一天的气温有关：$V_2=0.9V_1+0.1\\theta_2$</li>\n<li>第$t$天与第$t-1$天的气温迭代关系为：<script type=\"math/tex\">V_t = 0.9V_{t-1}+0.1\\theta_t</script></li>\n<li>经过指数加权平均得到的气温如图中红色曲线所示。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\"> 指数加权平均的一般形式为：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">V_t=\\beta V_{t-1}+(1-\\beta)\\theta_t</script></li>\n<li><script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值。</li>\n<li>当$\\beta=0.5$，则$\\frac{1}{1-\\beta}=2$，表示将前2天进行指数加权平均。由于仅仅平均两天的气温，即只在很小的窗口内计算平均。得到结果中会有更多的噪声，更容易受到异常值的影响，但它可以更快地适应温度变化。如图中黄色曲线所示。</li>\n<li>当$\\beta=0.9$，则$\\frac{1}{1-\\beta}=10$，表示将前10天进行指数加权平均。如图中红色曲线所示。</li>\n<li>当$\\beta=0.98$，则$\\frac{1}{1-\\beta}=50$，表示将前50天进行指数加权平均。如图中绿色曲线所示。</li>\n<li>$\\beta$值越大，则指数加权平均的天数越多，平均后的曲线则更平滑，但是同时曲线会右移，因为在一个更大的窗口内计算平均温度，在温度变化时，适应地更加缓慢，这就造成了一些延迟。</li>\n<li>可将$\\beta$视为一个超参数，通过调整这个参数，就可以得到略微不同的收效。通常取中间的某个值效果最好，也就是这里的红色的曲线。</li>\n</ul>\n<h3 id=\"理解指数加权平均\"><a href=\"#理解指数加权平均\" class=\"headerlink\" title=\"理解指数加权平均\"></a>理解指数加权平均</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 上图解释了为什么指数加权平均的结果<script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值：</p>\n<ul>\n<li>准确来说，指数加权平均算法跟之前所有天的数值都有关系，如图中的推导公式:<ul>\n<li><script type=\"math/tex; mode=display\">\\begin{eqnarray}V_{100} &=& 0.1\\theta_{100}+ 0.1\\cdot0.9\\theta_{99}+  0.1\\cdot0.9^{2}\\theta_{98}+ 0.1\\cdot0.9^{3}\\theta_{97} + 0.1\\cdot0.9^{4}\\theta_{96}+ ... \\end{eqnarray}</script></li>\n</ul>\n</li>\n<li>其中每一$\\theta_{i}$项都是指数衰减的，一般认为衰减到原始的$\\frac1e$就可以忽略不计了。</li>\n<li>$\\beta^{\\frac{1}{1-\\beta}}=\\frac1e$，例如，此处$\\beta=0.9$，$0.9^{10}\\approx 0.35\\approx \\frac{1}{e}$。</li>\n<li>故<script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\">  实际应用中，使用这样的语句来实现指数加权平均算法：</p>\n<script type=\"math/tex; mode=display\">V_{\\theta}=0</script><script type=\"math/tex; mode=display\">Repeat\\ \\{</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Get\\ next\\ \\theta_t</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{\\theta}:=\\beta V_{\\theta}+(1-\\beta)\\theta_t</script><script type=\"math/tex; mode=display\">\\}</script><h3 id=\"指数加权平均中的偏差修正\"><a href=\"#指数加权平均中的偏差修正\" class=\"headerlink\" title=\"指数加权平均中的偏差修正\"></a>指数加权平均中的偏差修正</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E7%9A%84%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>上文中提到当$\\beta=0.98$时，指数加权平均结果如下图绿色曲线所示。但是实际上，得不到绿色曲线，真实曲线如紫色曲线所示。</li>\n<li>紫色曲线与绿色曲线的区别是：紫色曲线开始的时候相对较低一些。这是因为设置$V_0=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常:<ul>\n<li>$V_0=0$</li>\n<li>$V_1 = 0.98V_0+0.02\\theta_1$</li>\n<li>$V_2 = 0.98V_1+0.02\\theta_2=0.98 \\cdot 0.02\\theta_1+0.02\\theta_2=0.0196\\theta_1+0.02\\theta_2$</li>\n</ul>\n</li>\n</ul>\n<p>修正这种问题的方法是进行偏移修正(bias correction):</p>\n<ul>\n<li>将$V_t$取值变为$\\frac{V_t}{1-\\beta^t}$</li>\n<li>在刚开始的时候，$t$比较小，$(1-\\beta^t)&lt;1$，这样就将$V_t$修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。</li>\n<li>随着$t$增大，$(1-\\beta^t)\\approx1$，$V_t$基本不变，紫色曲线与绿色曲线依然重合。</li>\n<li>这样就实现了简单的偏移校正，得到我们希望的绿色曲线。</li>\n<li>在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个稍带偏差的值进行运算。</li>\n<li>不过，如果在初始阶段就开始考虑偏差，指数加权移动均指仍处于预热阶段，偏差修正可以帮你尽早做出更好的估计。</li>\n</ul>\n<h3 id=\"动量梯度下降法\"><a href=\"#动量梯度下降法\" class=\"headerlink\" title=\"动量梯度下降法\"></a>动量梯度下降法</h3><p>有一种算法叫做动量(Momentum)梯度下降算法，它几乎总会比标准的梯度下降算法更快。算法的主要思想是：计算梯度的指数加权平均，然后使用这个梯度来更新权重。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设要优化一个代价函数，如图中的等高线图,红色的点表示最小值的位置。</li>\n<li>无论是批量梯度下降或小批量梯度下降，梯度下降算法会向着最小值缓慢地振荡前进。这种上下的振荡会减慢梯度下降的速度，同时也让你无法使用较大的学习率。如果你使用的学习率很大，可能会超调(overshoot)，发散出去。因此为了避免振荡过大，你只能使用比较小的学习率。如图1中的蓝色曲线所示。</li>\n<li>因此，在垂直方向上，希望学习慢一点，因为你不希望有这些振荡；但是在水平方向上，你希望加快学习速度。 </li>\n</ul>\n<p>动量梯度下降算法的过程如下:</p>\n<script type=\"math/tex; mode=display\">V_{dW}=0,V_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Compute\\ dW,\\ db\\ on\\ the\\ current\\ mini-batch</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}=\\beta V_{dW}+(1-\\beta)dW</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{db}=\\beta V_{db}+(1-\\beta)db</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ W=W-\\alpha V_{dW},\\ b=b-\\alpha V_{db}</script><ul>\n<li>使用<script type=\"math/tex\">v_{dW}</script>更新权重，而不是<script type=\"math/tex\">dW</script>。同样地用<script type=\"math/tex\">v_{db}</script>更新<script type=\"math/tex\">b</script>，而不是<script type=\"math/tex\">db</script>。</li>\n<li>$v_{dW}$是在近10个$dW$上的指数加权平均，故<strong>在垂直方向上，其平均值接近于0</strong>。然而<strong>在水平方向上，所有导数都指向水平方向的右边，所以水平方向的平均值仍然较大</strong>。</li>\n<li>因此，<strong>动量梯度下降算法的每一步，在垂直方向上的振荡非常小，且在水平方向上运动得更快</strong>。这会让你的算法选择更加直接的路径，或者说减弱了前往最小值的路径上的振荡，如图1中红色曲线所示。 </li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>使用动量梯度下降法有两个超参数：$\\alpha$和$\\beta$。$\\beta$最常用的取值是0.9，就像之前计算最近10天气温的平均值，这里就是计算前10次迭代的梯度的平均值。在实践中，使用$\\beta=0.9$效果很好，你也可以尝试不同的值，做一些超参数搜索，但是0.9是非常稳健的参数值。</li>\n<li>至于偏差修正，即是否需要让<script type=\"math/tex\">v_{dW}</script>或<script type=\"math/tex\">v_{db}</script>除以<script type=\"math/tex\">1-\\beta^t</script>。实际上，通常人们不会这么做，因为在10次迭代之后，滑动平均值就不再是一个偏差估计，所以在实现梯度下降或动量梯度下降时，不用做偏差修正。</li>\n</ul>\n<h3 id=\"RMSprop\"><a href=\"#RMSprop\" class=\"headerlink\" title=\"RMSprop\"></a>RMSprop</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/RMSprop.JPG\" width=\"80%\" height=\"80%\"> RMSprop的算法的全称为均方根传递(Root Mean Square prop)，它同动量梯度下降法一样，也可以加速梯度下降：</p>\n<ul>\n<li>批量梯度下降或小批量梯度下降在实现梯度下降时，可能会在垂直方向上出现巨大的振荡，即使它试图在水平方向上前进。</li>\n<li>假设垂直方向代表参数$b$，水平方向代表参数$W$，当然这里也可以是$W_1$和$W_2$等其他参数，使用$b$和$W$是为了便于标记解释。 </li>\n<li>你希望减慢$b$方向的学习，也就是垂直方向，同时加速或至少不减慢水平方向的学习，这就是RMSprop算法要做的。</li>\n<li>RMSprop算法步骤：<script type=\"math/tex; mode=display\">S_{dW},\\ S_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\ t:</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Compute\\ dW,\\ db \\ on \\ current \\ mini-batch</script><script type=\"math/tex; mode=display\">S_{dw}=\\beta S_{dW}+(1-\\beta)dW^2</script><script type=\"math/tex; mode=display\">S_{db}=\\beta S_{db}+(1-\\beta)db^2</script><script type=\"math/tex; mode=display\">W:=W-\\alpha \\frac{dW}{\\sqrt{S_{dw}+\\varepsilon}},\\ b:=b-\\alpha \\frac{db}{\\sqrt{S_{db}+\\varepsilon}}</script><ul>\n<li>其中，$dW^2$和$db^2$是逐元素平方。</li>\n<li>其中，$\\varepsilon=10^{-8}$。为了防止除以0。$\\epsilon$的值取多少并不重要，$10^{-8}$是一个合理的默认值，能轻微提高数值稳定性。</li>\n</ul>\n</li>\n<li>从图中蓝色曲线可以看出，$db$很大，而$dW$相对较小，因此，<script type=\"math/tex\">S_{dW}</script>相对<script type=\"math/tex\">S_{db}</script>较小。</li>\n<li>因此RMSprop中垂直方向的$b$的更新较小，这有助于减弱振荡，垂直方向$W$的更新较大。另一个收效是：可以使用更大的学习率$\\alpha$，学习得更快，而不用担心在垂直方向上发散。如图中绿色曲线所示。</li>\n</ul>\n<h3 id=\"Adam优化算法\"><a href=\"#Adam优化算法\" class=\"headerlink\" title=\"Adam优化算法\"></a>Adam优化算法</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam1.JPG\" width=\"90%\" height=\"90%\"> Adam算法（Adaptive Moment Estimation，自适应矩估计)将动量和RMSprop梯度下降结合起来，被广泛使用且已经被证明在很多不同种类的神经网络构架中都是十分有效的。</p>\n<ul>\n<li>Adam算法流程为： <script type=\"math/tex; mode=display\">V_{dW}=0,\\ S_{dW},\\ V_{db}=0,\\ S_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\ t:</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Cpmpute\\ dW,\\ db \\ on \\ current \\ mini-batch</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}=\\beta_1V_{dW}+(1-\\beta_1)dW,\\ V_{db}=\\beta_1V_{db}+(1-\\beta_1)db</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ S_{dW}=\\beta_2S_{dW}+(1-\\beta_2)dW^2,\\ S_{db}=\\beta_2S_{db}+(1-\\beta_2)db^2</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}^{corrected}=\\frac{V_{dW}}{1-\\beta_1^t},\\ V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ S_{dW}^{corrected}=\\frac{S_{dW}}{1-\\beta_2^t},\\ S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ W:=W-\\alpha\\frac{V_{dW}^{corrected}}{\\sqrt{S_{dW}^{corrected}}+\\varepsilon},\\ b:=b-\\alpha\\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\varepsilon}</script><ul>\n<li>注意到：在构建Adam算法的过程中需要进行偏差修正。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>Adam算法中的超参数：$\\alpha$，$\\beta_1$，$\\beta_2$，$\\varepsilon$。</li>\n<li>超参数$\\beta_1$的默认值设置为0.9，这是关于动量算法的$dW$的加权平均计算。</li>\n<li>对于超参数$\\beta_2$，Adam算法论文的作者推荐使用0.999，这是关于$dW^2$的加权平均计算。</li>\n<li>超参数$\\varepsilon$，如何选择影响都不大，Adam论文的作者推荐使用$10^{-8}$作为默认值。</li>\n<li>在使用Adam算法的时候，业内通常对$\\beta_1$、$\\beta_2$以及$\\varepsilon$都直接使用默认值，然后尝试不同的学习率$\\alpha$来以获得最好的训练效果。</li>\n</ul>\n<h3 id=\"学习速率衰减\"><a href=\"#学习速率衰减\" class=\"headerlink\" title=\"学习速率衰减\"></a>学习速率衰减</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F1.JPG\" width=\"80%\" height=\"80%\"> 学习速率衰减，即逐渐地减小学习率，可使得学习算法运行更快：</p>\n<ul>\n<li>如图，当采用小批量梯度下降法进行迭代时：<ul>\n<li>当学习率$\\alpha$采用固定值，会逐步向最小值靠近，但不会完全收敛到这点。如图中蓝色曲线所示。</li>\n<li>当采用学习率衰减，那么在初始阶段，因为学习率$\\alpha$取值还比较大，学习速度仍然可以比较快。但随着学习率降低$\\alpha$变小，步长也会渐渐变小。所以，最终将围绕着离极小值点更近的区域摆动，即使继续训练下去也不会漂游远离。如图中绿色曲线所示。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图所示，可由以下公式，实现学习率衰减：<ul>\n<li><script type=\"math/tex; mode=display\">\\alpha=\\frac{1}{1+decay \\_ rate*epoch}\\alpha_0</script></li>\n<li>其中，deacy_rate是参数（可调），epoch是周期数。随着epoch增加，$\\alpha$会不断变小。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F3.JPG\" width=\"50%\" height=\"50%\"> 实现学习率衰减还有其它可供选择的计算公式，如图所示:</p>\n<ul>\n<li>$\\alpha=0.95^{epoch}\\cdot \\alpha_0$</li>\n<li>$\\alpha=\\frac{k}{\\sqrt{epoch}}\\cdot \\alpha_0\\ \\ \\ \\ or\\ \\ \\ \\ \\frac{k}{\\sqrt{t}}\\cdot \\alpha_0$</li>\n<li>离散阶梯衰减。</li>\n<li>手动衰减。</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li><strong>学习率衰减的确可以帮助加速训练，但学习率衰减通常位于应该尝试的事情中比较靠后的位置</strong>。</li>\n<li><strong>设置一个固定数值的$\\alpha_0$，且使得优化良好，对结果有着巨大影响</strong>。</li>\n<li>下周，将对超参数进行系统地讲解。</li>\n</ul>\n<h3 id=\"局部最优解的问题\"><a href=\"#局部最优解的问题\" class=\"headerlink\" title=\"局部最优解的问题\"></a>局部最优解的问题</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A31.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>在深度学习的早期阶段，人们常常担心优化算法会陷入糟糕的局部最优解(Local Optima)之中。但随着深度学习理论的发展，我们对局部最优的理解也在改变。</li>\n<li>在使用梯度下降算法不断减小代价函数时，可能会得到局部最优解而不是全局最优解。之前我们对局部最优解的理解是如上图左边所示。</li>\n<li>但对于神经网络，其参数维数很高，梯度为零的点，在每个方向上，有可能是凸函数，有可能是凹函数。因此，梯度为零的点很可能都是右边所示的马鞍状的鞍点。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A32.JPG\" width=\"80%\" height=\"80%\"> 总结：</p>\n<ul>\n<li>局部最优不是问题，不太可能陷入极差的局部最优问题中（只要训练的是一个较大的神经网络，即有很多参数，代价函数$J$定义在一个相对高维的空间上时）。</li>\n<li>停滞区让学习过程变得相当慢。<ul>\n<li>解释：停滞区指的是导数长时间接近于零的一段区域，因为梯度为零或接近于零，曲面很平。在离开停滞区继续下降之前，需要花费很长的时间，缓慢地渡过在停滞区。</li>\n<li>解决方法：更复杂的算法，比如Adam算法，可以加快沿停滞区向下移动然后离开停滞区的速度。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"3-超参数调试、批量归一化以及编程框架\"><a href=\"#3-超参数调试、批量归一化以及编程框架\" class=\"headerlink\" title=\"3.超参数调试、批量归一化以及编程框架\"></a>3.超参数调试、批量归一化以及编程框架</h1><h2 id=\"3-1-超参数调试\"><a href=\"#3-1-超参数调试\" class=\"headerlink\" title=\"3.1 超参数调试\"></a>3.1 超参数调试</h2><h3 id=\"调试过程\"><a href=\"#调试过程\" class=\"headerlink\" title=\"调试过程\"></a>调试过程</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"> 深度神经网络需要调试的超参数较多，包括：</p>\n<ul>\n<li>$\\alpha$ ：学习速率</li>\n<li>$\\beta$ ：动量梯度下降因子</li>\n<li>$\\beta_1,\\beta_2,\\varepsilon$ ：Adam算法参数</li>\n<li>#layers：神经网络层数</li>\n<li>#hidden units：各隐藏层神经元个数</li>\n<li>learning rate decay：学习速率衰减参数</li>\n<li>mini-batch size：每一mini-batch包含的样本个数</li>\n</ul>\n<p>对于以上超参数的优先级：</p>\n<ul>\n<li>优先级1：学习速率$\\alpha$需要调试的超参数中最重要的一个，没有之一。</li>\n<li>优先级2：接下来会调整动量梯度下降参数$\\beta$，0.9是不错的默认值；还会调整Mini-Batch的大小，来保证最优化算法的运行效率；还经常调试隐藏单元数量。这三个超参数的重要性仅次于学习速率$\\alpha$。</li>\n<li>优先级3：网络层数有时候对结果起到重要作用，学习率衰减有时也一样。</li>\n<li>优先级4：当使用Adam优化算法时，几乎不调节$\\beta_1,\\beta_2,\\varepsilon$，几乎都是用0.9，0.999和$10^{-8}$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 当调整超参数时，对于超参数值的组合：</p>\n<ul>\n<li>在早期的机器学习算法中，如果有两个超参数（超参数1和超参数2），人们经常会像这样：在一个网格中对点进行规则抽样，然后系统化地尝试这些点所代表的值。如在图中5*5的网格中采样25个点后，选择最优的超参数。当超参数的数量相对较少时，这样的取参方法较为实用。 </li>\n<li>但在深度学习中，推荐采取另一种方法：在网格中进行随机抽样，无论最重要的超参数是哪个，将帮助你更充分地为最重要的超参数尝试尽可能多的值的组合。超参数值域的随机抽样，能更有效地搜索超参数空间。如图中，随机采样25个点，然后在这些随机选取的点中，尝试所有的超参数。对于多维情况，也是如此在多维空间中进行随机采样，然后尝试多个超参数的组合值。<ul>\n<li>这样做的原因：事先很难知道，哪一个超参数对于你的模型更重要。  </li>\n<li>解释：假设超参数1是学习速率$\\alpha$，超参数2是Adam优化算法中的$\\varepsilon$。若在网格中取样，因为$\\varepsilon$对结果没有什么影响，所以训练了25个模型，但是只相当于尝试了5个有用的α的值；相比较而言，如果在网格中随机取样 那么将获得25个不同的学习速率$\\alpha$，因此你找到理想值的概率也就变得更大。 </li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%953.JPG\" width=\"80%\" height=\"80%\"> 由粗糙到精细的搜索策略：</p>\n<ul>\n<li>继续以二维空间为例，当在此空间进行完随机采样后，发现在某些点能产生最好的结果，大体能确定这个区域内取的值能产生最优结果，即最理想的超参数来自于这个区域。即在对整个框定范围进行粗略的抽样后，结果会引导你集中在一个更小的区域内。</li>\n<li>然后，继续采用区域定位的抽样方案：即在这个更小的区域内进行密度更高的随机抽样。</li>\n</ul>\n<h3 id=\"用合适的尺度去选择超参数\"><a href=\"#用合适的尺度去选择超参数\" class=\"headerlink\" title=\"用合适的尺度去选择超参数\"></a>用合适的尺度去选择超参数</h3><p>上一节讲解的超参数值域的随机抽样，能帮助更有效地搜索超参数空间。但随机抽样并不意味着在有效值范围内的均匀随机抽样(sampleing uniformly at random)。相反，更重要的是选取适当的尺度(scale)，用以研究这些超参数。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A61.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于超参数#layers和#hidden units，采用均匀随机抽样是合理的方案，但它并不是对所有的超参数都适用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A62.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于超参数学习率$\\alpha$，待调范围是$[0.0001, 1]$。如果使用均匀随机抽样，那么有90%的采样点分布在$[0.1, 1]$之间，只有10%分布在$[0.0001, 0.1]$之间，并不合理。</li>\n<li>更合理的方法：在对数尺度(log scale)上进行采样，而不是用线性尺度(linear scale)。即分为$[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]$这几个区间。</li>\n<li>一般解法是，如果线性区间为$[a,b]$，令$m=log(a)$，$n=log(b)$，则对应的$log$区间为$[m,n]$。对$log$区间的$[m,n]$进行随机均匀采样，然后得到的采样值$r$，最后反推到线性区间，即$10^r$。$10^r$就是最终采样的超参数。相应的Python代码为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">m = np.log10(a)</span><br><span class=\"line\">n = np.log10(b)</span><br><span class=\"line\">r = np.random.rand() <span class=\"comment\">#[0,1)</span></span><br><span class=\"line\">r = m + (n-m)*r <span class=\"comment\">#[m,n)</span></span><br><span class=\"line\">r = np.power(<span class=\"number\">10</span>,r)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A63.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>除了$\\alpha$之外，动量梯度下降法中的参数$\\beta$在超参数调试时，同样应在对数尺度上进行采样。</li>\n<li>一般$\\beta$的取值范围在$[0.9, 0.999]$之间，那么$1-\\beta$的取值范围就在$[0.001, 0.1]$之间。那么直接对$1-\\beta$在$[0.001, 0.1]$区间内进行对数尺度采样(即$10^r$)，然后再推出$\\beta$(即$1-10^r$)即可。</li>\n<li>为什么$\\beta$也需要向$\\alpha$那样做非均匀采样:公式$\\frac{1}{1-\\beta}$在当$\\beta$趋于1时，它对$\\beta$的值的改变非常敏感。</li>\n</ul>\n<p>最后：</p>\n<ul>\n<li>如果对于某个超参数你选择的尺度是不对的，或即使在存在更优尺度的情况下，你依然选择了均匀尺度(uniform scale) 你仍然可能得到不错的结果，尤其是如果你采取从粗到精(coarse to fine)的搜索策略。</li>\n</ul>\n<h3 id=\"实践中的超参数调试：Pandas-vs-Caviar\"><a href=\"#实践中的超参数调试：Pandas-vs-Caviar\" class=\"headerlink\" title=\"实践中的超参数调试：Pandas vs. Caviar\"></a>实践中的超参数调试：Pandas vs. Caviar</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>经过调试选择完最佳的超参数并不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况（如数据集改变、有了更先进的服务器等），再次调试超参数，以获得实时的最佳模型。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>精心照料一个模型(“Panda” approach)：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。 </li>\n<li>并行训练多个模型(“Caviar” approach)：可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。</li>\n</ul>\n<h2 id=\"3-2-批量归一化\"><a href=\"#3-2-批量归一化\" class=\"headerlink\" title=\"3.2 批量归一化\"></a>3.2 批量归一化</h2><h3 id=\"归一化网络的激活函数\"><a href=\"#归一化网络的激活函数\" class=\"headerlink\" title=\"归一化网络的激活函数\"></a>归一化网络的激活函数</h3><p>在深度学习不断兴起的过程中,最重要的创新之一是一种叫批量归一化(Batch Normalization)的算法，可让超参搜索变得很简单，让神经网络对于超参数的选择上不再那么敏感，并且可以更容易地训练非常深的网络 。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"> 批量归一化原理：</p>\n<ul>\n<li>对于单一逻辑回归神经元，归一化输入的操作：$X=\\frac{X-\\mu}{\\sqrt{\\sigma^2}}$，提高模型的训练速度。</li>\n<li>批量归一化：对$A^{[l-1]}$进行归一化处理，提高$W^{[l]}$和$b^{[l]}$的训练速度。</li>\n<li>批量归一化在实际操作时，归一化的不是$A^{[i]}$，而是$Z^{[i]}$，即激活函数前的值。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"> 单隐藏层的批量归一化的实现：</p>\n<ul>\n<li>对第$l$层隐藏层的输入<script type=\"math/tex\">Z^{[l-1]}=[z^{[l-1](1)},z^{[l-1](2)},...,z^{[l-1](m)}]</script>做如下归一化处理，忽略上标$[l-1]$：<ul>\n<li>$\\mu=\\frac1m\\sum_iz^{(i)}$</li>\n<li>$\\sigma^2=\\frac1m\\sum_i(z_i-\\mu)^2$</li>\n<li>$z^{(i)}_{norm}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$</li>\n<li>其中，$m$是单个mini-batch包含样本个数，$\\varepsilon$是为了防止分母为零，可取值$10^{-8}$。这样，使得该隐藏层的所有输入 $z^{(i)}$均值为0，方差为1。</li>\n</ul>\n</li>\n<li>但是，大部分情况下并不希望所有的$z^{(i)}$均值都为0，方差都为1，也不太合理。通常需要对$z^{(i)}$进行进一步处理：<ul>\n<li>$\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$</li>\n<li>式中，$\\gamma$和$\\beta$是可学习的参数，类似于$W$和$b$一样，可以通过梯度下降等算法求得。这里，$\\gamma$和$\\beta$的作用是让$\\tilde z^{(i)}$的均值和方差为任意值，只需调整其值就可以了。</li>\n<li>例如，令：$\\gamma=\\sqrt{\\sigma^2+\\varepsilon}$,$\\beta=\\mu$，则$\\tilde z^{(i)}=z^{(i)}$。可见，设置$\\gamma$和$\\beta$为不同的值，可以得到任意的均值和方差。</li>\n</ul>\n</li>\n<li>这样，通过批量归一化，对隐藏层的各个<script type=\"math/tex\">z^{[l](i)}</script>进行归一化处理，得到<script type=\"math/tex\">\\tilde z^{[l](i)}</script>，替代<script type=\"math/tex\">z^{[l](i)}</script>。</li>\n<li>值得注意的是，<strong>输入层的归一化处理和隐藏层的归一化处理是有区别的</strong>。<strong>归一化输入使所有输入的均值为0，方差为1</strong>。而<strong>隐藏层的归一化处理可使各隐藏层输入的均值和方差为任意值</strong>。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，则无法更好的利用激活函数非线性的特性，而不是所有的值都集中在线性区域。这就是为什么通过设置$\\gamma$和$\\beta$来控制<script type=\"math/tex\">z^{[l](i)}</script>在希望的范围内，或者说<strong>批量归一化真正实现的是通过两个参数$\\gamma$和$\\beta$来让隐藏单元有可控的均值和方差</strong>。</li>\n</ul>\n<h3 id=\"将批量归一化用于神经网络\"><a href=\"#将批量归一化用于神经网络\" class=\"headerlink\" title=\"将批量归一化用于神经网络\"></a>将批量归一化用于神经网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 对于$L$层神经网络，实施批量归一化的整体流程如下：</p>\n<ul>\n<li><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B.jpg\" width=\"100%\" height=\"100%\"></li>\n<li>其中，参数为$W^{[1]}$,$b^{[1]}$,$W^{[2]}$,$b^{[2]}$,…,$W^{[L]}$,$b^{[L]}$以及$\\beta^{[1]}$,$\\gamma^{[1]}$,$\\beta^{[2]}$,$\\gamma^{[2]}$,…,$\\beta^{[L]}$,$\\gamma^{[L]}$。$\\beta^{[l]}$与$\\gamma^{[l]}$的学习同$W^{[l]}$与$b^{[l]}$一样，采用梯度下降法。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在mini-batch上应用批量归一化：</p>\n<ul>\n<li>分别用每个mini-batch的数据(均值和方差)进行批量归一化。</li>\n<li>因为批量归一化对各隐藏层$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$有去均值的操作，所以这里的常数项$b^{[l]}$可以消去，其数值效果完全可以由$\\tilde Z^{[l]}$中的$\\beta^{[l]}$来实现。因此，我们在使用批量归一化的时候，可以忽略各隐藏层的常数项$b^{[l]}$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B03.JPG\" width=\"80%\" height=\"80%\"> 概述了应用批量归一化时，梯度下降(或动量或RMSprop或Adam)的整个过程。</p>\n<h3 id=\"批量归一化为什么有效\"><a href=\"#批量归一化为什么有效\" class=\"headerlink\" title=\"批量归一化为什么有效\"></a>批量归一化为什么有效</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%881.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%882.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%883.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>解释1：归一化输入，使得输入$X$的均值为0，方差为1，大幅加速学习过程。批量归一化同理。</li>\n<li>解释2：批量归一化使得网络的每一层相对独立。</li>\n<li>解释3：批量归一化具有轻微的正则化效果。</li>\n</ul>\n<h3 id=\"在测试阶段使用批量归一化\"><a href=\"#在测试阶段使用批量归一化\" class=\"headerlink\" title=\"在测试阶段使用批量归一化\"></a>在测试阶段使用批量归一化</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8BatchNorm.JPG\" width=\"50%\" height=\"50%\"> </p>\n<ul>\n<li>首先，回顾批量归一化在训练过程中，在每一mini-batch，在网络的每一层中，做如下操作：<ul>\n<li>$\\mu=\\frac1m\\sum_iz^{(i)}$</li>\n<li>$\\sigma^2=\\frac1m\\sum_i(z^{(i)}-\\mu)^2$</li>\n<li>$z_{norm}^{(i)}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$</li>\n<li>$\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$ </li>\n<li>其中，$\\mu$和$\\sigma^2$是对单个mini-batch中所有$m$个样本求得的。</li>\n</ul>\n</li>\n<li>在测试阶段，如果只有一个样本，求其均值和方差是没有意义的，就需要对$\\mu$和$\\sigma^2$进行估计。实际应用中一般采用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的$\\mu$和$\\sigma^2$：<ul>\n<li>指数加权平均的做法:对于第$l$层隐藏层，考虑所有mini-batch在该隐藏层下的$\\mu^{[l]}$和$\\sigma^{2[l]}$，然后用指数加权平均的方式来预测得到当前单个样本的$\\mu^{[l]}$和$\\sigma^{2[l]}$。这样就实现了对测试过程单个样本的均值和方差估计。</li>\n<li>最后，再利用训练过程得到的$\\gamma$和$\\beta$值计算出各层的$\\tilde z^{(i)}$值。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-3-多类别分类\"><a href=\"#3-3-多类别分类\" class=\"headerlink\" title=\"3.3 多类别分类\"></a>3.3 多类别分类</h2><h3 id=\"Softmax回归\"><a href=\"#Softmax回归\" class=\"headerlink\" title=\"Softmax回归\"></a>Softmax回归</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>用神经网络进行多分类，<script type=\"math/tex\">C=\\#class=4</script>，0为其他，1为猫，2为狗，3为小鸡。</li>\n<li>对于单个输入样本$x$，网络的最后一层(第$L$层)为Softmax层，$\\hat{y}=a^{[L]}$，维度为$(4,1)$。</li>\n<li>Softmax层中各神经元的输出依次代表$P(other|x)$，$P(cat|x)$，$P(dog|x)$，$P(baby \\ chicks|x)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>Softmax层的激活函数计算过程如下：<ul>\n<li><script type=\"math/tex; mode=display\">z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}</script></li>\n<li><script type=\"math/tex; mode=display\">t=e^{(z^{[L]})}</script></li>\n<li><script type=\"math/tex; mode=display\">a^{[L]}=\\frac{e^{z^{[L]}}}{\\sum_{i=1}^C t_i}</script></li>\n<li><script type=\"math/tex; mode=display\">a^{[L]}_i=\\frac{t_i}{\\sum_{i=1}^C t_i}</script></li>\n<li>也可看成是$a^{[L]}=g^{[L]}(z^{[L]})$，只不是该激活函数的输入是向量，输入也是向量。</li>\n<li>其中，Softmax层每个神经元的输出<script type=\"math/tex\">a^{[L]}_i</script>对应属于该类的概率，满足：<script type=\"math/tex\">\\sum_{i=1}^Ca^{[L]}_i=1</script></li>\n<li><script type=\"math/tex\">a^{[L]}= \\hat{y}</script>，维度为$(C, 1)$。</li>\n</ul>\n</li>\n<li>具体计算示例如图。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax3.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>上图为没有隐藏层，只有单一Softmax层的神经网络，其经Softmax分类的效果如图所示，为线性多分类效果，各两类之间的决策边界均为线性。</li>\n<li>当网络具有很多隐藏层，可构成更复杂的非线性决策边界。</li>\n</ul>\n<h3 id=\"训练一个softmax分类器\"><a href=\"#训练一个softmax分类器\" class=\"headerlink\" title=\"训练一个softmax分类器\"></a>训练一个softmax分类器</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A81.JPG\" width=\"80%\" height=\"80%\"> 理解Softmax：</p>\n<ul>\n<li>Softmax回归是Logistic回归向多类别的泛化。</li>\n<li>当$C=2$时，Softmax回归将简化成Logistic回归。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A82.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设$C=4$，某个样本的预测输出$\\hat y$和目标输出(真实值标签)$y$为：<ul>\n<li><script type=\"math/tex; mode=display\">\\hat y=\\left[ \\begin{matrix} 0.3 \\\\ 0.2 \\\\ 0.1 \\\\ 0.4 \\end{matrix} \\right]</script></li>\n<li><script type=\"math/tex; mode=display\">y=\\left[ \\begin{matrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{matrix} \\right]</script></li>\n</ul>\n</li>\n<li>Loss function：$L(\\hat y,y)=-\\sum_{j=1}^4y_j\\cdot log\\ \\hat y_j$<ul>\n<li>然而，由于只有当$j=2$时，$y_2=1$，其它情况下，$y_j=0$。所以，上式中的$L(\\hat y,y)$可以简化为：$L(\\hat y,y)=-y_2\\cdot log\\ \\hat y_2=-log\\ \\hat y_2$</li>\n<li>要让$L(\\hat y,y)$更小，就应该让$\\hat y_2$越大越好。$\\hat y_2$反映的是概率，完全符合我们之前的定义。 </li>\n</ul>\n</li>\n<li>Cost function：$J(W^{[1]},b^{[1]},…)=\\frac1m\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})$</li>\n<li>若对于m个样本，其预测输出向量$A^{[L]}$即$\\hat Y$的维度为$(4, m)$，样本标签$Y$的维度也为$(4, m)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A83.JPG\" width=\"80%\" height=\"80%\"> 梯度下降的过程中，输出层Softmax的梯度推导，即$dZ^{[L]}$的推导：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">da^{[L]}=-\\frac{1}{a^{[L]}}</script></li>\n<li><script type=\"math/tex; mode=display\">\\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=\\frac{\\partial}{\\partial z^{[L]}}\\cdot (\\frac{e^{z^{[L]}_i}}{\\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\\cdot (1-a^{[L]})</script></li>\n<li><script type=\"math/tex; mode=display\">dz^{[L]}= \\frac{\\partial J}{\\partial z^{[L]}}= da^{[L]}\\cdot \\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=a^{[L]}-1=a^{[L]}-y</script></li>\n<li>对于所有$m$个训练样本：<script type=\"math/tex\">dZ^{[L]}=A^{[L]}-Y</script></li>\n<li>可见$dZ^{[L]}$的表达式与二元分类结果是一致的，虽然推导过程不太一样。然后就可以继续进行反向传播过程的梯度下降算法了，推导过程与二元分类神经网络完全一致。</li>\n</ul>\n<h2 id=\"3-4-编程框架介绍\"><a href=\"#3-4-编程框架介绍\" class=\"headerlink\" title=\"3.4 编程框架介绍\"></a>3.4 编程框架介绍</h2><h3 id=\"深度学习框架\"><a href=\"#深度学习框架\" class=\"headerlink\" title=\"深度学习框架\"></a>深度学习框架</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.JPG\" width=\"80%\" height=\"80%\"> 如图，介绍了目前的深度学习框架，和选择深度学习框架的标准。</p>\n<h3 id=\"TensorFlow\"><a href=\"#TensorFlow\" class=\"headerlink\" title=\"TensorFlow\"></a>TensorFlow</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow2.JPG\" width=\"80%\" height=\"80%\"> 本节介绍TensorFlow程序的典型结构。</p>\n<p>举个例子来说明，代价函数是参数<code>w</code>的函数：$J=w^2-10w+25$。<br>如果使用TensorFlow对代价函数进行优化，求出最小值对应的<code>w</code>，程序如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">w = tf.Variable(<span class=\"number\">0</span>,dtype=tf.float32)</span><br><span class=\"line\"><span class=\"comment\">#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)</span></span><br><span class=\"line\">cost = w**<span class=\"number\">2</span> - <span class=\"number\">10</span>*w +<span class=\"number\">25</span></span><br><span class=\"line\">train = tf.train.GradientDescentOptimizer(<span class=\"number\">0.01</span>).minimize(cost)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.0</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(train)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    session.run(train)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;4.99999</code><br>TensorFlow框架内可以直接调用梯度下降优化算法。在运行1000次梯度下降算法后，<code>w</code>的解为4.99999，已经非常接近<code>w</code>的最优值5了。<br>针对上面这个例子，如果对<code>w</code>前的系数用变量<code>x</code>来代替，程序如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">cofficients = np.array([[<span class=\"number\">1.</span>],[<span class=\"number\">-10.</span>],[<span class=\"number\">25.</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">w = tf.Variable(<span class=\"number\">0</span>,dtype=tf.float32)</span><br><span class=\"line\">x = tf.placeholder(tf.float32,[<span class=\"number\">3</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"comment\">#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)</span></span><br><span class=\"line\"><span class=\"comment\">#cost = w**2 - 10*w +25</span></span><br><span class=\"line\">cost = x[<span class=\"number\">0</span>][<span class=\"number\">0</span>]*w**<span class=\"number\">2</span> + x[<span class=\"number\">1</span>][<span class=\"number\">0</span>]*w + x[<span class=\"number\">2</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">train = tf.train.GradientDescentOptimizer(<span class=\"number\">0.01</span>).minimize(cost)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.0</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(train, feed_dict=(x:coefficients))</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    session.run(train, feed_dict=(x:coefficients))</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;4.99999</code><br>结果跟之前是一样的。除此之外，我们还可以更改<code>x</code>即<code>cofficients</code>的值，而得到不同的优化结果<code>w</code>。<br>另外，上段程序中的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p>有另外一种写法：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> session:</span><br><span class=\"line\">    session.run(init)</span><br><span class=\"line\">    print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p>TensorFlow的最大优点就是采用数据流图(data flow graphs)来进行数值运算。图中的节点(Nodes)表示数学操作，图中的线(edges)则表示在节点间相互联系的多维数据数组，即张量(tensor)。而且它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU(或GPU)，服务器，移动设备等。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-深度学习的实用层面\"><a href=\"#1-深度学习的实用层面\" class=\"headerlink\" title=\"1.深度学习的实用层面\"></a><strong>1.深度学习的实用层面</strong></h1><h2 id=\"1-1-建立机器学习应用\"><a href=\"#1-1-建立机器学习应用\" class=\"headerlink\" title=\"1.1 建立机器学习应用\"></a><strong>1.1 建立机器学习应用</strong></h2><h3 id=\"训练-开发-测试集\"><a href=\"#训练-开发-测试集\" class=\"headerlink\" title=\"训练/开发/测试集\"></a><strong>训练/开发/测试集</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%861.JPG\" width=\"70%\" height=\"70%\">在实际中应用机器学习是一个高度迭代的过程：</p>\n<ul>\n<li>在构建一个神经网络的时，需要设置许多超参数，例如神经网络的层数、每个隐藏层包含的神经元个数、学习速率、激活函数的选择等。实际上很难在第一次设置的时候就选择到这些最佳的参数，而是需要通过不断地迭代更新来获得。</li>\n<li>迭代的过程如下：先有个想法，先选择初始的参数值，构建神经网络模型结构；然后通过代码实现；最后，通过实验验证。根据实验结果，对参数进行适当的调整优化，再进行下一次的Idea-&gt;Code-&gt;Experiment循环。</li>\n<li>恰当的将数据分为训练/开发/测试集，可使得迭代效率更高。</li>\n</ul>","more":"<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%862.JPG\" width=\"90%\" height=\"90%\">一般地，将所有的样本数据分成三个部分：训练(Train)/开发(Dev)/测试(Test)集：</p>\n<ul>\n<li>训练集用来训练你的模型；</li>\n<li>开发集又称交叉验证集(cross validation set)，用来验证不同算法的表现情况，从中选择最好的模型；</li>\n<li>测试集用来测试最好模型的实际表现，给出该模型的无偏估计。</li>\n</ul>\n<p>关于数据集的比例划分，在以前，可获得的数据量不是很大的情况：</p>\n<ul>\n<li>通常设置训练集和测试集的数量比例为70%和30%。如果有开发集，则设置比例为60%、20%、20%，分别对应训练/测试/开发集。</li>\n<li>这种比例分配在样本数量不是很大的情况下，例如100,1000,10000，是比较科学的。</li>\n</ul>\n<p>关于数据集的比例划分，在如今，大数据的时代：</p>\n<ul>\n<li>如果数据量很大的时候，例如数据量达100万，70%/30%或60%/20%/20%的比例分配是不合理的。</li>\n<li>因为开发集的目的是用来比较验证不同模型的优劣，从而选择更好的模型。因此，通常不需要所有样本的20%这么多的数据来进行验证。例如对于100万的样本，往往只需要10000个样本来做验证就够了。测试集的目的是给出已选定最优模型的无偏估计。对于100万的样本，往往也只需要10000个样本就够了。</li>\n<li>科学的做法是要将开发集和测试集的比例设置得很低。因此，对于大数据样本，训练/开发/测试集的比例通常可以设置为98%/1%/1%，或者99%/0.5%/0.5%。样本数据量越大，相应的开发/测试集的比例可以设置的越低一些。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E8%AE%AD%E7%BB%83%E5%BC%80%E5%8F%91%E6%B5%8B%E8%AF%95%E9%9B%863.JPG\" width=\"80%\" height=\"80%\">现代深度学习还有个重要的问题就是训练集和测试集的分布不匹配，意为是训练集和测试集来自于不同的分布。例如：</p>\n<ul>\n<li>对于一个手机app，可以让用户上传图片，然后app识别出猫的图片。该应用中，训练集可能是从网络抓取的图片，而开发和测试集可能来自不同用户的上传的猫的照片。</li>\n<li>从网络抓取的图片可能像素较高且拍摄专业等等，而用户上传的图片可能像素较低且模糊等等。因此，训练集和验证/测试集可能来自不同的分布。</li>\n<li><strong>解决方法：保证开发集和测试集来自于同一分布。</strong></li>\n</ul>\n<p>注意：</p>\n<ul>\n<li>如果不需要对最终选定的神经网络做出无偏估计，可以没有测试集，只有训练/开发集（也有人说成只有训练/测试集，都可以）。</li>\n</ul>\n<h3 id=\"偏差-方差\"><a href=\"#偏差-方差\" class=\"headerlink\" title=\"偏差/方差\"></a><strong>偏差/方差</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE1.JPG\" width=\"80%\" height=\"80%\"> 对于只有$x_1$和$x_2$两个特征的二维数据集，可以绘制数据，可视化偏差和方差。如上图所示：</p>\n<ul>\n<li>左：高偏差，欠拟合</li>\n<li>中：恰好</li>\n<li>右：高方差，过拟合</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE2.JPG\" width=\"80%\" height=\"80%\"> 对于高维数据，无法绘制数据以及可视化决策边界。但可通过几个指标来理解偏差和方差。<br>基于人工误差（或贝叶斯误差或最优误差)非常低（约为0%）并且训练集和开发集都来自于同一分布这两个假设，如上图所示：</p>\n<ul>\n<li>训练集误差为1%/开发集误差11%，结合两者说明该算法在训练集上过拟合，导致在开发集上的泛化性能不好，推出高方差。</li>\n<li>训练集误差为15%，在训练集上欠拟合，推出高偏差。开发集误差16%，相比于训练集误差只高1%，并不存在高方差。</li>\n<li>训练集误差为15%，推出高偏差。开发集误差30%，相比于训练集误差高15%，推出高方差。</li>\n<li>训练集误差为0.5%，低偏差。开发集误差1%，相比于训练集误差只高0.5%，低方差。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE3.JPG\" width=\"70%\" height=\"70%\"> 上图展示了高偏差和高方差同时存在的可视化情形：</p>\n<ul>\n<li>决策边界为线性，欠拟合，高偏差</li>\n<li>在局部发生过拟合，高方差</li>\n<li>该情形在二维情况下看起来不自然，但对于高维数据，这种情况是容易发生的。</li>\n</ul>\n<h3 id=\"机器学习的基本准则\"><a href=\"#机器学习的基本准则\" class=\"headerlink\" title=\"机器学习的基本准则\"></a><strong>机器学习的基本准则</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99.JPG\" width=\"70%\" height=\"70%\"> 当训练好最初的神经网络时：</p>\n<ul>\n<li>高偏差？通过训练集表现来确定，若存在高偏差，则可通过更大的网络或训练更长时间来解决。</li>\n<li>高方差？通过开发集表现来确定，若存在高方差，则可通过获取更多数据及正则化来解决。</li>\n<li>直到找到低偏差且低方差的网络。</li>\n</ul>\n<p>关于偏差和方差的权衡：</p>\n<ul>\n<li>在早期的机器学习时代，有很多关于偏差和方差的权衡的讨论，因为当时没有能够单独减小偏差和单独减小方差的工具。</li>\n<li>而在如今的深度学习和大数据时代，通过扩大网络几乎总是能够较小偏差而不增大方差（只要用恰当的方式正则化）；通过获得更多数据几乎总是能够减小方差而不增大偏差。因此，这也解释了为何深度学习在监督学习中如此有效。</li>\n</ul>\n<h2 id=\"1-2-正则化神经网络\"><a href=\"#1-2-正则化神经网络\" class=\"headerlink\" title=\"1.2 正则化神经网络\"></a><strong>1.2 正则化神经网络</strong></h2><h3 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a><strong>正则化</strong></h3><p>获得更多数据和正则化都是解决过拟合(高方差)的有效方法，但很多时候并不能总是获得更多数据或者获得更多数据的代价太高。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B1/%E6%AD%A3%E5%88%99%E5%8C%96-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.JPG\" width=\"80%\" height=\"80%\">先介绍在逻辑回归中应用正则化，如图：</p>\n<ul>\n<li>逻辑回归：$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})$</li>\n<li>参数：$w \\in R^{n_x}$，$b\\in R$</li>\n<li>目的：$\\min\\limits_{w,b} J(w,b)$；</li>\n<li>$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_2^2$<ul>\n<li>L2正则化：<script type=\"math/tex\">||w||_2^2=\\sum_{j=1}^{n_x}w_j^2=w^Tw</script>，其中$\\lambda$是正则化参数</li>\n</ul>\n</li>\n<li>$J(w,b)=\\frac1m\\sum_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_1$<ul>\n<li>L1正则化：<script type=\"math/tex\">||w||_1=\\sum_{j=1}^{n_x}|w_j|</script>，其中$\\lambda$是正则化参数</li>\n</ul>\n</li>\n<li>若使用L1正则化，$w$最后会变得稀疏，即$w$中会有很多0。有人认为这有助于压缩模型，因为有一部分参数是0，只需较少的内存来存储模型。<br>然而在实践中发现，通过L1正则化让模型变得稀疏带来的收效甚微。故吴恩达觉得至少在压缩模型的目标上，它的作用不大。<br>总之，在训练神经网络中，L2正则化应用地更频繁。</li>\n<li>只正则化参数$w$，而省略正则化参数$b$的原因是：$w$是高维矢量参数，$b$只是一个标量，几乎所有的参数都集中在$w$中，$b$只是大量参数中的一个，故可省略。</li>\n<li>注意，在python中，由于<code>lambda</code>是保留字，为了避免冲突，故在编程练习中使用<code>lambd</code>来表示$\\lambda$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.JPG\" width=\"50%\" height=\"50%\"> 在神经网络中应用正则化，如图：</p>\n<ul>\n<li>代价函数：<script type=\"math/tex\">J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})=\\frac1m\\sum\\limits_{i=1}^mL(\\hat y^{(i)},y^{(i)})+\\frac{\\lambda}{2m}\\sum\\limits_{l=1}^L||W^{[l]}||_F^2</script></li>\n<li>其中，矩阵的L2范数称为F范数(Frobenius范数)，<script type=\"math/tex\">||W^{[l]}||_F^2=\\sum_{i=1}^{n^{[l]}}\\sum_{j=1}^{n^{[l-1]}}(W_{ij}^{[l]})^2</script>。</li>\n<li>正则化后的梯度下降法：<ul>\n<li>$dW^{[l]}=dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]}$</li>\n<li>$W^{[l]} =W^{[l]}-\\alpha dW^{[l]}$</li>\n</ul>\n</li>\n</ul>\n<p><strong>L2正则化也被称作权重衰减(weight decay)</strong>。原因如下：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\begin{eqnarray}W^{[l]} &:=&W^{[l]}-\\alpha\\cdot dW^{[l]}\\\\ &=&W^{[l]}-\\alpha\\cdot(dW^{[l]}_{before}+\\frac{\\lambda}{m}W^{[l]})\\\\ &=&(1-\\alpha\\frac{\\lambda}{m})W^{[l]}-\\alpha\\cdot dW^{[l]}_{before} \\end{eqnarray}</script></li>\n<li>其中，$(1-\\alpha\\frac{\\lambda}{m})&lt;1$。加上L2正则化项后，$W^{[l]}$的每次更新，都会乘以一个小于1的项。即每次迭代更新，都使得$W^{[l]}$不断地减小，故L2正则化又被称为权重衰减。</li>\n</ul>\n<h3 id=\"为什么正则化可以减轻过拟合\"><a href=\"#为什么正则化可以减轻过拟合\" class=\"headerlink\" title=\"为什么正则化可以减轻过拟合\"></a><strong>为什么正则化可以减轻过拟合</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%881.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例一：</p>\n<ul>\n<li>假设由于选择了非常复杂的神经网络模型，因而存在过拟合，如上图左上角所示。</li>\n<li>加上正则化项后，若将正则化参数$\\lambda$设置的很大，那么参数$ W^{[l]}\\approx0$，参数$W$中的很多数接近于0，这相当于网络中的很多神经元不起作用，这样原本过于复杂的神经网络模型就变得简单化了，故减轻了过拟合。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%AD%A3%E5%88%99%E5%8C%96%E5%87%8F%E8%BD%BB%E8%BF%87%E6%8B%9F%E5%90%882.JPG\" width=\"70%\" height=\"70%\">直观理解，如上图例二：</p>\n<ul>\n<li>假设激活函数是<code>tanh</code>函数。<code>tanh</code>函数的特点是在$|z|$较小的区域，函数是近似线性的，而当$|z|$稍大的时候，才会展现出非线性能力。</li>\n<li>若加入正则化，使$\\lambda$较大，即对权重$W^{[l]}$的惩罚较大，使得$W^{[l]}$较小。</li>\n<li>因为$z^{[l]}=W^{[l]}a^{[l]}+b^{[l]}$。当$W^{[l]}$较小，$z^{[l]}$也较小。当$z^{[l]}$在较小范围内时，激活函数$g(z)$就会近似于线性函数。因此每一层几乎都是线性的，当隐藏曾的激活函数是线性函数的时候，再多隐藏层也只是计算线性函数。故网络不能拟合复杂的非线性函数，便不容易过拟合了。</li>\n</ul>\n<h3 id=\"Dropout正则化\"><a href=\"#Dropout正则化\" class=\"headerlink\" title=\"Dropout正则化\"></a><strong>Dropout正则化</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-1.JPG\" width=\"70%\" height=\"70%\"> 除了正则化外，还有另外一种防止过拟合的有效方法：Dropout(随机失活)：</p>\n<ul>\n<li>Dropout：在神经网络的训练过程中，每一次迭代，按照一定的概率随机地将其暂时从网络中丢弃。</li>\n<li>也就是说，每一次迭代，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-2.JPG\" width=\"50%\" height=\"50%\"> Dropout有不同的实现方法，Inverted dropout(反向失活)是目前最常用的实现方法：</p>\n<ul>\n<li><p>假设对于第$l=3$层神经元，设定保留神经元比例概率<code>keep_prob=0.8</code>。在Python中，Inverted dropout可实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">d3 = np.random.rand(a3.shape[<span class=\"number\">0</span>],a3.shape[<span class=\"number\">1</span>]) &lt; keep_prob</span><br><span class=\"line\">a3 = np.multiply(a3,d3) <span class=\"comment\">#逐元素相乘，也可以写成 a3 *= d3</span></span><br><span class=\"line\">a3 /= keep_prob         <span class=\"comment\">#保持a3的期望值不变。这样在测试阶段也不用再对a3值进行缩放</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>最后一步解释：例如<code>keep_prob=0.5</code>，该层将有一般的神经元被关闭，故该层的输出将被0.5缩放，因为只有剩下的一半神经元为计算输出做贡献。除以0.5等价于乘以2。因此输出有了相同的期望值。</li>\n</ul>\n</li>\n<li>反向传播过程：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">da3 = np.multiply(da3,d3) <span class=\"comment\">#前向传播中关闭了某些神经元，反向传播中也关闭</span></span><br><span class=\"line\">da3 /= keep_prob          <span class=\"comment\">#a3缩放了keep_prob尺度，根据微积分的性质，则它的梯度也要缩放</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>注：Dropout仅在训练阶段使用，在测试阶段，不使用Dropout。</p>\n<h3 id=\"理解Dropout\"><a href=\"#理解Dropout\" class=\"headerlink\" title=\"理解Dropout\"></a><strong>理解Dropout</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/dropout-3.JPG\" width=\"50%\" height=\"50%\">如图，对于网络中的某一神经元，若采用了dropout，对于每个不同的样本，它的输入特征被消除的特征都不同，因此该神经元不能依靠任一输入特征，故最终网络会分散权重，即所有的权重都不会过大。<br>使用Dropout的时候的几个注意点：</p>\n<ul>\n<li>可为不同网络层设置不同的<code>keep_prob</code>，但该做法的缺点是引入了更多的超参数。可将神经元较多(更容易过拟合)的隐藏层，<code>keep_out</code>设置得较小，如0.5；神经元越少的隐藏层，<code>keep_out</code>设置得较大，例如0.7。<code>keep_out</code>设置为1，表示全部保留，不使用Dropout。</li>\n<li>不建议对输入层进行Dropout，如果输入层维度很大，例如图片，那么可以设置Dropout，但<code>keep_out</code>应设置的大一些，例如0.8，0.9。</li>\n<li>Dropout在计算机视觉领域中应用广泛（实际从AlextNet中提出），因为输入层(图像)维度较大，且通常没有足够多的训练样本。</li>\n<li>Dropout是一种正则化技巧，用来防止过拟合，只有在确认模型过拟合后，再使用它。</li>\n<li>Dropout的一大缺点是代价函数$J$不再被明确定义，每次迭代都会随机移除一些神经元。故失去了检查梯度下降这一项调式工具，即通过绘图检查代价函数$J$是否随着迭代次数而减小（定义明确的代价函数$J$，在每次迭代后都会下降）。故应关闭Dropout(<code>keep_out</code>设置为1)，再进行梯度下降检查。</li>\n</ul>\n<h3 id=\"其他正则化方法\"><a href=\"#其他正则化方法\" class=\"headerlink\" title=\"其他正则化方法\"></a><strong>其他正则化方法</strong></h3><p>除了L2正则化和dropout之外，还有其它的正则化方法，如:数据增强，提前终止(early stopping)。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%951.JPG\" width=\"60%\" height=\"60%\">数据增强是对已有的训练样本进行一些处理来“制造”出更多的样本。</p>\n<ul>\n<li>例如图片识别问题中，数据增强是通过对已有的图片进行水平翻转、随机剪裁等方式制造出训练样本。</li>\n<li>虽然这些新样本是基于原有样本的，可能新的训练集有些冗余，但是相对于重新搜集全新独立的数据，数据增强不需要成本。</li>\n<li>因为增加了训练数据，能起到减轻过拟合的作用，故算过正则化方法。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%952.JPG\" width=\"80%\" height=\"80%\">另外一种正则化方法early stopping：如图，根据训练集误差曲线(或$J$的曲线)和开发集误差曲线(或$J$的曲线)随着迭代次数的变化趋势，选择使得开发集误差最小的迭代次数，停止训练，即early stopping。</p>\n<ul>\n<li>直观解释：神经网络训练前,$W$的值趋近于0,随着训练的进行，$W$越来越大。early stopping相当于选取了一个不大不小的$W$，类似于$||w||_F$的效果，从而希望此时神经网络的过拟合不严重。</li>\n</ul>\n<p>early stopping的缺点：</p>\n<ul>\n<li>通常来说，机器学习训练模型有两个目标：一是优化代价函数，即减小$J$；二是防止过拟合。这两个任务是分开进行的。把这二者之间的关系称为正交化(orthogonalization)，后面课程会进一步讲解。</li>\n<li>early stopping的做法相当于将两个任务合在一起执行，减少迭代次数停止训练时，$J$就不会足够小，且希望此时不过拟合。</li>\n</ul>\n<p>early stopping的优点：</p>\n<ul>\n<li>相比与L2正则化，early stopping不用选择超参数$\\lambda$。</li>\n</ul>\n<p>吴恩达的做法：</p>\n<ul>\n<li>偶尔用early stopping，一般只用L2正则化。</li>\n</ul>\n<h2 id=\"1-3-设置优化问题\"><a href=\"#1-3-设置优化问题\" class=\"headerlink\" title=\"1.3 设置优化问题\"></a>1.3 <strong>设置优化问题</strong></h2><h3 id=\"归一化输入\"><a href=\"#归一化输入\" class=\"headerlink\" title=\"归一化输入\"></a><strong>归一化输入</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A51.JPG\" width=\"80%\" height=\"80%\"> 在训练神经网络时，<strong>归一化(normalize)输入</strong>可以<strong>加速训练过程($J$的优化过程)</strong>。<br>归一化输入就是将原始数据减去其均值$\\mu$后，再除以其方差$\\sigma^2$：</p>\n<ul>\n<li>$\\mu=\\frac1m\\sum_{i=1}^m x^{(i)}$</li>\n<li>$x = x-\\mu$</li>\n<li>$\\sigma^2=\\frac1m\\sum_{i=1}^m x^{(i)}**2$</li>\n<li>$x = x/ \\sqrt{\\sigma^2}$</li>\n<li>注：对于训练集和测试集，应使用同样的$\\mu$和$\\sigma^2$进行归一化处理，即均使用训练集计算出的$\\mu$和$\\sigma^2$进行归一化处理。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A0%87%E5%87%86%E5%8C%96%E8%BE%93%E5%85%A52.JPG\" width=\"75%\" height=\"75%\"> 上图以二维输入特征为例，解释了为什么归一化输入可以加速训练过程：</p>\n<ul>\n<li>假设输入特征为二维，且$x_1$的范围是[1,1000]，$x_2$的范围是[0,1]。  </li>\n<li>如图左下所示，若不归一化输入，$x_1$与$x_2$之间分布极不平衡，代价函数$J$与$x_1$和$x_2$的等高线是一个细长的椭圆形。对其进行梯度下降算法时，容易发生振荡，且需选择很小的学习速率$\\alpha$，来避免$J$发生振荡，一旦$\\alpha$较大，必然发生振荡，故学习过程很慢。</li>\n<li>如图右下所示，若归一化输入，$x_1$与$x_2$分布均匀，代价函数$J$与$x_1$和$x_2$的等高线是一个圆形。对其进行梯度下降算法时， 可选取较大的步长$\\alpha$，且$J$不易发生振荡，故学习过程较快。</li>\n<li>注意：如果输入特征的尺度非常不同，比如有些特征取值为[0,1]，有些是[1,1000]，那对输入进行归一化就很重要。而如果输入特征本来尺度就相近，那么这一步就不那么重要。</li>\n<li>吴恩达的做法：因为归一化输入的步骤几乎从来没有任何害处，所以无论如何总是进行归一化，尽管不确定它是否会让训练变得更快。</li>\n</ul>\n<h3 id=\"梯度消失与梯度爆炸\"><a href=\"#梯度消失与梯度爆炸\" class=\"headerlink\" title=\"梯度消失与梯度爆炸\"></a><strong>梯度消失与梯度爆炸</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8.JPG\" width=\"75%\" height=\"75%\"> 当训练深层神经网络时，会出现梯度消失和梯度爆炸问题。如图：</p>\n<ul>\n<li>为便于分析，令各层的激活函数为线性函数，即$g(z)=z$，且令$b=0$。那么，该网络的预测输出$\\hat y$为：<ul>\n<li>$\\hat y=W^{[L]}W^{[L-1]}W^{[L-2]}\\cdots W^{[3]}W^{[2]}W^{[1]}x $</li>\n</ul>\n</li>\n<li>如果各层权重$W^{[l]}$只比1或单位矩阵稍大一点（如1.5），深层神经网络的激活函数将作为层数$l$的函数指数级增长。</li>\n<li>如果各层权重$W^{[l]}$只比1或单位矩阵稍小一点（如0.9），深层神经网络的激活函数将作为层数$l$的函数指数级递减。</li>\n<li>虽然上图只论述了激活函数作为层数$l$的函数指数级增加或减少，同样可以论证表明，计算出的导数或梯度，也会指数级增加或指数级减少。</li>\n<li>在一个非常深的神经网络（如150层）中，如果激活函数或梯度作为$l$的函数指数级的增大或减小，这些值会变得非常大或非常小，这会让训练变得非常困难。尤其是如果梯度作为$l$的函数指数级减小，梯度下降会用很小很小的步子走，梯度下降会用很长时间才能完成学习。</li>\n</ul>\n<h3 id=\"深层网络的权重初始化\"><a href=\"#深层网络的权重初始化\" class=\"headerlink\" title=\"深层网络的权重初始化\"></a><strong>深层网络的权重初始化</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%B1%82%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96.JPG\" width=\"80%\" height=\"80%\"> 针对梯度消失和梯度爆炸，有一种部分解决方法，虽然不能完全解决它，但帮助很大，即更小心地随机初始化神经网络。<br>如图，以初始化单个神经元为例，然后再把它应用到深层网络中：</p>\n<ul>\n<li>$z=w_1x_1+w_2x_2+…+w_nx_n$</li>\n<li>为了让$z$不会过大或者过小，思路是让$w$与$n$有关，且$n$越大，$w$应该越小才好。这样能够保证$z$不会过大。</li>\n<li>如果激活函数是<code>tanh</code>，一般在初始化$w$时，令其方差为$\\frac1n$，即$Var(w)=\\frac1n$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{1}{n^{[l-1]}})$</li>\n<li>解释：第$l$层中的每个神经元都有$n^{[l-1]}$个输入。标准正态分布均值为0，方差为1，乘以$np.sqrt(\\frac{1}{n^{[l-1]}})$，那么$w$的方差便为$\\frac{1}{n^{[l-1]}}$<br>方差性质：$C$为常数，$D(CX) = C^2D(X)$</li>\n<li>该初始化方法也称为“Xavier initialization”。</li>\n</ul>\n</li>\n<li>如果激活函数是<code>ReLU</code>，一般在初始化$w$时，令其方差为$\\frac2n$，即$Var(w)=\\frac2n$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}})$</li>\n<li>该初始化方法也称为“He initialization”。</li>\n</ul>\n</li>\n<li>除此之外，Yoshua Bengio提出了另外一种初始化$w$的方法，令其方差为$\\frac{2}{n^{[l-1]}+n^{[l]}}$：<ul>\n<li>公式表示为：$w^{[l]} = np.random.randn(n^{[l]},n^{[l-1]})*np.sqrt(\\frac{2}{n^{[l-1]}+n^{[l]}})$</li>\n</ul>\n</li>\n<li>注：视频中3：15秒处，还有一段关于解释该做法可以有效减缓梯度消失/梯度爆炸的原因，没听懂，待理解。</li>\n</ul>\n<h3 id=\"梯度的数值逼近\"><a href=\"#梯度的数值逼近\" class=\"headerlink\" title=\"梯度的数值逼近\"></a><strong>梯度的数值逼近</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91.JPG\" width=\"80%\" height=\"80%\"> 对于神经网络的反向传播，有一项重要的测试——梯度检验(gradient checking)。该节先介绍梯度的数值逼近：</p>\n<ul>\n<li>采用双边差分公式进行数值逼近：$f’(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta-\\varepsilon)}{2\\varepsilon}$</li>\n<li>如$f(\\theta)=theta^3$，当$\\theta$为1，$\\varepsilon$为0.01时，逼近误差为：0.0001</li>\n<li>注意：不采用单边差分公式：$f’(\\theta) \\approx \\frac{f(\\theta+\\varepsilon)-f(\\theta)}{\\varepsilon}$进行梯度的数值逼近的原因是：<ul>\n<li>单边差分公式的逼近误差是$O(\\varepsilon)$。</li>\n<li>双边差分公式的逼近误差是$O(\\varepsilon^2)$，逼近误差更小，故本课程采用此方法。</li>\n</ul>\n</li>\n<li>即利用的是该导数定义：<script type=\"math/tex\">f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta - \\varepsilon)}{2 \\varepsilon}</script>，而不是该导数定义：<script type=\"math/tex\">f'(\\theta) = \\lim\\limits_{\\varepsilon \\to 0} \\frac{f(\\theta + \\varepsilon) - f(\\theta)}{\\varepsilon}</script></li>\n</ul>\n<h3 id=\"梯度检验\"><a href=\"#梯度检验\" class=\"headerlink\" title=\"梯度检验\"></a><strong>梯度检验</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C1.JPG\" width=\"75%\" height=\"75%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C2.JPG\" width=\"75%\" height=\"75%\"> 进行梯度检验，可验证代码中的反向传播是否有错误：</p>\n<ul>\n<li>首先，将$W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]}$ 这些矩阵逐个转变为一维向量，然后连接成一个大的一维向量$\\theta$。这样$J(W^{[1]},b^{[1]},\\cdots,W^{[L]},b^{[L]})$ 就可表示成$J(\\theta)$。</li>\n<li>然后，将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\\cdots,dW^{[L]},db^{[L]}$同上一步骤一样构造成一个大的一维向量 $d\\theta$。注意到，$d\\theta$的维度与$\\theta$是一致的。</li>\n<li>接着，对$\\theta$中的每个元素$\\theta_i$，计算近似梯度：<script type=\"math/tex; mode=display\">d\\theta_{approx}[i]=\\frac{J(\\theta_1,\\theta_2,\\cdots,\\theta_i+\\varepsilon,\\cdots)-J(\\theta_1,\\theta_2,\\cdots,\\theta_i-\\varepsilon,\\cdots)}{2\\varepsilon}</script></li>\n<li>最终，得到$d\\theta_{approx}$。</li>\n<li>将<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>相比较，检查是否一致，即是否<script type=\"math/tex\">d\\theta_{approx} \\approx d\\theta</script>，也即是否每一元素<script type=\"math/tex\">d\\theta_{approx}[i] \\approx d\\theta[i]</script>。</li>\n<li>检验相似度的标准如下：<script type=\"math/tex; mode=display\">\\frac{||d\\theta_{approx}-d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}</script><ul>\n<li>解释：首先计算<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的欧氏距离，即差值的L2范数。然后根据向量的长度将其归一化，即除以两个向量的欧几里德长度和，除以该分母的原因是：防止分子过大或过小，这样整个式子就成了一个比值。</li>\n<li>在实际中，选用$\\varepsilon=10^{-7}$：</li>\n<li>如果相似度的值小于$10^{-7}$，表明梯度逼近误差极小，通过梯度检查，代码是对的。</li>\n<li>如果相似度在$10^{-5}$左右，代码可能是对的，但还是会逐个检查向量<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的每一项，看是否有某一项过大。则该处代码可能存在错误，下节会稍详细讲解此点。</li>\n<li>如果相似度在$10^{-3}$左右，代码中一定有错误。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"运用梯度检验的注意事项\"><a href=\"#运用梯度检验的注意事项\" class=\"headerlink\" title=\"运用梯度检验的注意事项\"></a><strong>运用梯度检验的注意事项</strong></h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9.JPG\" width=\"75%\" height=\"75%\"> 在运用梯度检查时有几点注意事项：</p>\n<ul>\n<li>一旦确定反向传播正确，即关闭梯度检验，否则训练过程会极慢。<ul>\n<li>解释：梯度检验很慢,故不在训练的每一次迭代中都使用。只要确定反向传播代码正确, 就关闭它。</li>\n</ul>\n</li>\n<li>如果梯度检验出现错误，找到对应出错项，尝试识别出bug位置：<ul>\n<li>解释：逐个对比向量<script type=\"math/tex\">d\\theta_{approx}</script>与<script type=\"math/tex\">d\\theta</script>的每一项，看是否有某一项<script type=\"math/tex\">d\\theta[i]</script>过大。例如，过大项<script type=\"math/tex\">d\\theta[i]</script>属于$dw^{[l]}$，而同一层的$db^{[l]}$未出错，则可能bug在关于$dw^{[l]}$的代码中。</li>\n<li>有时这样的分析虽然无法帮助精确定位出bug位置，但可以帮助我们猜测bug的位置。</li>\n</ul>\n</li>\n<li>如果进行了正则化，则计算近似梯度$d\\theta_{approx}$的时候要包括进去。</li>\n<li>梯度检验时关闭dropout，梯度检验完毕后再打开dropout。<ul>\n<li>解释：dropout使得$J$没有精确的定义，无法进行$d\\theta_{approx}$的计算。故先梯度检验，通过后，再开启dropout。</li>\n</ul>\n</li>\n<li>随机初始化时运行梯度检验，经过一些训练后再次进行梯度检验（不常用）。<ul>\n<li>为了预防你的反向传播算法在$w$和$b$在接近0的时候是正确的，但当$w$和$b$变大时，算法精度有所下降。</li>\n<li>故在一些迭代后，当$w$和$b$变大时，再次进行梯度检验。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"2-优化算法\"><a href=\"#2-优化算法\" class=\"headerlink\" title=\"2.优化算法\"></a>2.优化算法</h1><h2 id=\"2-1-优化算法\"><a href=\"#2-1-优化算法\" class=\"headerlink\" title=\"2.1 优化算法\"></a>2.1 优化算法</h2><h3 id=\"小批量梯度下降法\"><a href=\"#小批量梯度下降法\" class=\"headerlink\" title=\"小批量梯度下降法\"></a>小批量梯度下降法</h3><p>开篇即说过，机器学习应用是一个高度依赖经验的需要大量迭代的过程。优化算法可以加快神经网络的训练速度，从而提高效率。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%951.JPG\" width=\"80%\" height=\"80%\"> 批量梯度下降法(batch gradient descent)：</p>\n<ul>\n<li>每次迭代，对所有样本进行训练，故其训练速度很慢。</li>\n</ul>\n<p>小批量梯度下降法(mini-batch gradient descent)：</p>\n<ul>\n<li>将$m$个训练样本分成若干个子集，称为mini-batch。</li>\n<li>然后每次迭代，在单一子集(mini-batch)上进行神经网络训练，每次迭代所需时间大幅减少。</li>\n</ul>\n<p>如图中示例：</p>\n<ul>\n<li>总的训练样本$X_{(n_x,m)}=[x^1,x^{(2)},…,x^{(m)}]$，其中$m=5,000,000$。</li>\n<li>总的训练样本的标签$Y_{(1,m)}=[y^1,y^{(2)},…,y^{(m)}]$，其中$m=5,000,000$。</li>\n<li>将$X$分成5000个mini-batch，每mini-batch含1000个样本，将每个mini-batch记为<script type=\"math/tex\">X^{\\{t\\}}</script> ，其维度为<script type=\"math/tex\">(n_x,1000)</script>,且<script type=\"math/tex\">t=1,2,\\cdots,5000</script>。</li>\n<li>每个mini-batch对应的标签记为<script type=\"math/tex\">Y^{\\{t\\}}</script>，其维度为<script type=\"math/tex\">(1,1000)</script>，且<script type=\"math/tex\">t=1,2,\\cdots,5000</script>。</li>\n</ul>\n<p>总结一下遇到的神经网络中几类字母的上标含义：</p>\n<ul>\n<li>$x^{(i)}$ ：第$i$个样本</li>\n<li>$z^{[l]}$ ：神经网络第$l$层网络的线性输出</li>\n<li><script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>：第$t$个mini-batch</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 如图：</p>\n<ul>\n<li>对于小批量梯度下降法来说，一个周期(epoch)是指：将所有mini_batch（<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>）训练一次(前向传播、计算$J$、反向传播、参数更新)，即遍历一次总体训练集。</li>\n<li>对于批量梯度下降法，一个周期只进行一次梯度下降步骤；而对于小批量梯度下降法，一个周期会进行$T$次梯度下降步骤。</li>\n<li>通常，会多次遍历训练集(一个显式的for循环)直到收敛到某个值。</li>\n</ul>\n<h3 id=\"理解小批量梯度下降法\"><a href=\"#理解小批量梯度下降法\" class=\"headerlink\" title=\"理解小批量梯度下降法\"></a>理解小批量梯度下降法</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>使用批量梯度下降法，每次迭代将遍历整个训练集，$J$都会减小，若没有减小，则一定是某处错了。</li>\n<li>使用小批量梯度下降法，每次迭代是在不同的mini-batch上训练，其代价函数$J$和迭代次数(也即mini-batch/t)的曲线存在噪声，上下振荡，但整体的趋势是下降的。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"> 对于mini-batch尺寸的选择：</p>\n<ul>\n<li>如果mini-batch尺寸为m：即为批量梯度下降((Batch) Gradient Descent)。<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}=(X,Y)</script></li>\n<li>如果mini-batch尺寸为1：即为随机梯度下降(Stochastic Gradient Descent, SGD)。每个样本都是一个mini-batch。</li>\n<li>实际操作中：mini-batch尺寸的选择在1到m之间。</li>\n</ul>\n<p>如图，比较各梯度下降方法的代价函数的等高线图：</p>\n<ul>\n<li>蓝色曲线代表批量梯度下降：<ul>\n<li>它的噪声相对较小。</li>\n<li>每一步相对较大。</li>\n<li>并且最终可以达到最小值。</li>\n<li>缺点：每次迭代所需时间太长。</li>\n</ul>\n</li>\n<li>紫色曲线代表随机梯度下降：<ul>\n<li>对于每一次迭代，就在一个样本上做梯度下降，噪声非常大。</li>\n<li>一般来说它会沿着正确的方向，但有时也会指向错误的方向。</li>\n<li>最后也不会收敛到一个点，它一般会在最低点附近摆动，但是不会达到并且停在那里。 </li>\n<li>缺点：失去了通过向量化来加速计算这个工具。</li>\n</ul>\n</li>\n<li>绿色曲线代表实际中mini-batch尺寸为1~m之间的梯度下降：<ul>\n<li>优点：有着最快的学习速度：1.可在每一个mini-batch运用向量化。2.每次迭代所需时间少。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D3.JPG\" width=\"75%\" height=\"75%\"></p>\n<ul>\n<li>如果总体样本数量$m$($m\\leq2000$)，建议直接使用批量梯度下降。</li>\n<li>如果总体样本数量$m$很大时，建议将样本分成许多mini-batch。</li>\n<li>推荐常用的mini-batch 尺寸为64,128,256,512(这些都是2的幂。之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度)。</li>\n<li>但要确保每一个mini-batch（<script type=\"math/tex\">X^{\\{t\\}},Y^{\\{t\\}}</script>）能装进CPU/GPU。</li>\n<li>在实践中，要得到不同的mini-batches，需要两个步骤：1.对数据集洗牌(shuffle)；2.分割(partition)。</li>\n</ul>\n<h3 id=\"指数加权平均\"><a href=\"#指数加权平均\" class=\"headerlink\" title=\"指数加权平均\"></a>指数加权平均</h3><p>接下来介绍几个优化算法，它们比梯度下降更快，为了理解这些算法，需要用到一种叫指数加权平均(exponentially weighted average)的操作，在统计学上也被称为指数加权滑动平均。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 如图，通过指数加权平均来计算最近10天的温度：</p>\n<ul>\n<li>设$V_0=0$，当成第0天的气温值</li>\n<li>第一天的气温与第0天的气温有关：$V_1=0.9V_0+0.1\\theta_1$</li>\n<li>第二天的气温与第一天的气温有关：$V_2=0.9V_1+0.1\\theta_2$</li>\n<li>第$t$天与第$t-1$天的气温迭代关系为：<script type=\"math/tex\">V_t = 0.9V_{t-1}+0.1\\theta_t</script></li>\n<li>经过指数加权平均得到的气温如图中红色曲线所示。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\"> 指数加权平均的一般形式为：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">V_t=\\beta V_{t-1}+(1-\\beta)\\theta_t</script></li>\n<li><script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值。</li>\n<li>当$\\beta=0.5$，则$\\frac{1}{1-\\beta}=2$，表示将前2天进行指数加权平均。由于仅仅平均两天的气温，即只在很小的窗口内计算平均。得到结果中会有更多的噪声，更容易受到异常值的影响，但它可以更快地适应温度变化。如图中黄色曲线所示。</li>\n<li>当$\\beta=0.9$，则$\\frac{1}{1-\\beta}=10$，表示将前10天进行指数加权平均。如图中红色曲线所示。</li>\n<li>当$\\beta=0.98$，则$\\frac{1}{1-\\beta}=50$，表示将前50天进行指数加权平均。如图中绿色曲线所示。</li>\n<li>$\\beta$值越大，则指数加权平均的天数越多，平均后的曲线则更平滑，但是同时曲线会右移，因为在一个更大的窗口内计算平均温度，在温度变化时，适应地更加缓慢，这就造成了一些延迟。</li>\n<li>可将$\\beta$视为一个超参数，通过调整这个参数，就可以得到略微不同的收效。通常取中间的某个值效果最好，也就是这里的红色的曲线。</li>\n</ul>\n<h3 id=\"理解指数加权平均\"><a href=\"#理解指数加权平均\" class=\"headerlink\" title=\"理解指数加权平均\"></a>理解指数加权平均</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%871.JPG\" width=\"80%\" height=\"80%\"> 上图解释了为什么指数加权平均的结果<script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值：</p>\n<ul>\n<li>准确来说，指数加权平均算法跟之前所有天的数值都有关系，如图中的推导公式:<ul>\n<li><script type=\"math/tex; mode=display\">\\begin{eqnarray}V_{100} &=& 0.1\\theta_{100}+ 0.1\\cdot0.9\\theta_{99}+  0.1\\cdot0.9^{2}\\theta_{98}+ 0.1\\cdot0.9^{3}\\theta_{97} + 0.1\\cdot0.9^{4}\\theta_{96}+ ... \\end{eqnarray}</script></li>\n</ul>\n</li>\n<li>其中每一$\\theta_{i}$项都是指数衰减的，一般认为衰减到原始的$\\frac1e$就可以忽略不计了。</li>\n<li>$\\beta^{\\frac{1}{1-\\beta}}=\\frac1e$，例如，此处$\\beta=0.9$，$0.9^{10}\\approx 0.35\\approx \\frac{1}{e}$。</li>\n<li>故<script type=\"math/tex\">V_t</script>是在约<script type=\"math/tex\">\\frac{1}{1-\\beta}</script>天的温度上的平均的近似值。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%90%86%E8%A7%A3%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%872.JPG\" width=\"80%\" height=\"80%\">  实际应用中，使用这样的语句来实现指数加权平均算法：</p>\n<script type=\"math/tex; mode=display\">V_{\\theta}=0</script><script type=\"math/tex; mode=display\">Repeat\\ \\{</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Get\\ next\\ \\theta_t</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{\\theta}:=\\beta V_{\\theta}+(1-\\beta)\\theta_t</script><script type=\"math/tex; mode=display\">\\}</script><h3 id=\"指数加权平均中的偏差修正\"><a href=\"#指数加权平均中的偏差修正\" class=\"headerlink\" title=\"指数加权平均中的偏差修正\"></a>指数加权平均中的偏差修正</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87%E7%9A%84%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>上文中提到当$\\beta=0.98$时，指数加权平均结果如下图绿色曲线所示。但是实际上，得不到绿色曲线，真实曲线如紫色曲线所示。</li>\n<li>紫色曲线与绿色曲线的区别是：紫色曲线开始的时候相对较低一些。这是因为设置$V_0=0$，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常:<ul>\n<li>$V_0=0$</li>\n<li>$V_1 = 0.98V_0+0.02\\theta_1$</li>\n<li>$V_2 = 0.98V_1+0.02\\theta_2=0.98 \\cdot 0.02\\theta_1+0.02\\theta_2=0.0196\\theta_1+0.02\\theta_2$</li>\n</ul>\n</li>\n</ul>\n<p>修正这种问题的方法是进行偏移修正(bias correction):</p>\n<ul>\n<li>将$V_t$取值变为$\\frac{V_t}{1-\\beta^t}$</li>\n<li>在刚开始的时候，$t$比较小，$(1-\\beta^t)&lt;1$，这样就将$V_t$修正得更大一些，效果是把紫色曲线开始部分向上提升一些，与绿色曲线接近重合。</li>\n<li>随着$t$增大，$(1-\\beta^t)\\approx1$，$V_t$基本不变，紫色曲线与绿色曲线依然重合。</li>\n<li>这样就实现了简单的偏移校正，得到我们希望的绿色曲线。</li>\n<li>在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个稍带偏差的值进行运算。</li>\n<li>不过，如果在初始阶段就开始考虑偏差，指数加权移动均指仍处于预热阶段，偏差修正可以帮你尽早做出更好的估计。</li>\n</ul>\n<h3 id=\"动量梯度下降法\"><a href=\"#动量梯度下降法\" class=\"headerlink\" title=\"动量梯度下降法\"></a>动量梯度下降法</h3><p>有一种算法叫做动量(Momentum)梯度下降算法，它几乎总会比标准的梯度下降算法更快。算法的主要思想是：计算梯度的指数加权平均，然后使用这个梯度来更新权重。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设要优化一个代价函数，如图中的等高线图,红色的点表示最小值的位置。</li>\n<li>无论是批量梯度下降或小批量梯度下降，梯度下降算法会向着最小值缓慢地振荡前进。这种上下的振荡会减慢梯度下降的速度，同时也让你无法使用较大的学习率。如果你使用的学习率很大，可能会超调(overshoot)，发散出去。因此为了避免振荡过大，你只能使用比较小的学习率。如图1中的蓝色曲线所示。</li>\n<li>因此，在垂直方向上，希望学习慢一点，因为你不希望有这些振荡；但是在水平方向上，你希望加快学习速度。 </li>\n</ul>\n<p>动量梯度下降算法的过程如下:</p>\n<script type=\"math/tex; mode=display\">V_{dW}=0,V_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Compute\\ dW,\\ db\\ on\\ the\\ current\\ mini-batch</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}=\\beta V_{dW}+(1-\\beta)dW</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{db}=\\beta V_{db}+(1-\\beta)db</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ W=W-\\alpha V_{dW},\\ b=b-\\alpha V_{db}</script><ul>\n<li>使用<script type=\"math/tex\">v_{dW}</script>更新权重，而不是<script type=\"math/tex\">dW</script>。同样地用<script type=\"math/tex\">v_{db}</script>更新<script type=\"math/tex\">b</script>，而不是<script type=\"math/tex\">db</script>。</li>\n<li>$v_{dW}$是在近10个$dW$上的指数加权平均，故<strong>在垂直方向上，其平均值接近于0</strong>。然而<strong>在水平方向上，所有导数都指向水平方向的右边，所以水平方向的平均值仍然较大</strong>。</li>\n<li>因此，<strong>动量梯度下降算法的每一步，在垂直方向上的振荡非常小，且在水平方向上运动得更快</strong>。这会让你的算法选择更加直接的路径，或者说减弱了前往最小值的路径上的振荡，如图1中红色曲线所示。 </li>\n</ul>\n<p>另外：</p>\n<ul>\n<li>使用动量梯度下降法有两个超参数：$\\alpha$和$\\beta$。$\\beta$最常用的取值是0.9，就像之前计算最近10天气温的平均值，这里就是计算前10次迭代的梯度的平均值。在实践中，使用$\\beta=0.9$效果很好，你也可以尝试不同的值，做一些超参数搜索，但是0.9是非常稳健的参数值。</li>\n<li>至于偏差修正，即是否需要让<script type=\"math/tex\">v_{dW}</script>或<script type=\"math/tex\">v_{db}</script>除以<script type=\"math/tex\">1-\\beta^t</script>。实际上，通常人们不会这么做，因为在10次迭代之后，滑动平均值就不再是一个偏差估计，所以在实现梯度下降或动量梯度下降时，不用做偏差修正。</li>\n</ul>\n<h3 id=\"RMSprop\"><a href=\"#RMSprop\" class=\"headerlink\" title=\"RMSprop\"></a>RMSprop</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/RMSprop.JPG\" width=\"80%\" height=\"80%\"> RMSprop的算法的全称为均方根传递(Root Mean Square prop)，它同动量梯度下降法一样，也可以加速梯度下降：</p>\n<ul>\n<li>批量梯度下降或小批量梯度下降在实现梯度下降时，可能会在垂直方向上出现巨大的振荡，即使它试图在水平方向上前进。</li>\n<li>假设垂直方向代表参数$b$，水平方向代表参数$W$，当然这里也可以是$W_1$和$W_2$等其他参数，使用$b$和$W$是为了便于标记解释。 </li>\n<li>你希望减慢$b$方向的学习，也就是垂直方向，同时加速或至少不减慢水平方向的学习，这就是RMSprop算法要做的。</li>\n<li>RMSprop算法步骤：<script type=\"math/tex; mode=display\">S_{dW},\\ S_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\ t:</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Compute\\ dW,\\ db \\ on \\ current \\ mini-batch</script><script type=\"math/tex; mode=display\">S_{dw}=\\beta S_{dW}+(1-\\beta)dW^2</script><script type=\"math/tex; mode=display\">S_{db}=\\beta S_{db}+(1-\\beta)db^2</script><script type=\"math/tex; mode=display\">W:=W-\\alpha \\frac{dW}{\\sqrt{S_{dw}+\\varepsilon}},\\ b:=b-\\alpha \\frac{db}{\\sqrt{S_{db}+\\varepsilon}}</script><ul>\n<li>其中，$dW^2$和$db^2$是逐元素平方。</li>\n<li>其中，$\\varepsilon=10^{-8}$。为了防止除以0。$\\epsilon$的值取多少并不重要，$10^{-8}$是一个合理的默认值，能轻微提高数值稳定性。</li>\n</ul>\n</li>\n<li>从图中蓝色曲线可以看出，$db$很大，而$dW$相对较小，因此，<script type=\"math/tex\">S_{dW}</script>相对<script type=\"math/tex\">S_{db}</script>较小。</li>\n<li>因此RMSprop中垂直方向的$b$的更新较小，这有助于减弱振荡，垂直方向$W$的更新较大。另一个收效是：可以使用更大的学习率$\\alpha$，学习得更快，而不用担心在垂直方向上发散。如图中绿色曲线所示。</li>\n</ul>\n<h3 id=\"Adam优化算法\"><a href=\"#Adam优化算法\" class=\"headerlink\" title=\"Adam优化算法\"></a>Adam优化算法</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam1.JPG\" width=\"90%\" height=\"90%\"> Adam算法（Adaptive Moment Estimation，自适应矩估计)将动量和RMSprop梯度下降结合起来，被广泛使用且已经被证明在很多不同种类的神经网络构架中都是十分有效的。</p>\n<ul>\n<li>Adam算法流程为： <script type=\"math/tex; mode=display\">V_{dW}=0,\\ S_{dW},\\ V_{db}=0,\\ S_{db}=0</script><script type=\"math/tex; mode=display\">On\\ iteration\\ t:</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ Cpmpute\\ dW,\\ db \\ on \\ current \\ mini-batch</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}=\\beta_1V_{dW}+(1-\\beta_1)dW,\\ V_{db}=\\beta_1V_{db}+(1-\\beta_1)db</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ S_{dW}=\\beta_2S_{dW}+(1-\\beta_2)dW^2,\\ S_{db}=\\beta_2S_{db}+(1-\\beta_2)db^2</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ V_{dW}^{corrected}=\\frac{V_{dW}}{1-\\beta_1^t},\\ V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ S_{dW}^{corrected}=\\frac{S_{dW}}{1-\\beta_2^t},\\ S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}</script><script type=\"math/tex; mode=display\">\\ \\ \\ \\ W:=W-\\alpha\\frac{V_{dW}^{corrected}}{\\sqrt{S_{dW}^{corrected}}+\\varepsilon},\\ b:=b-\\alpha\\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\varepsilon}</script><ul>\n<li>注意到：在构建Adam算法的过程中需要进行偏差修正。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Adam2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>Adam算法中的超参数：$\\alpha$，$\\beta_1$，$\\beta_2$，$\\varepsilon$。</li>\n<li>超参数$\\beta_1$的默认值设置为0.9，这是关于动量算法的$dW$的加权平均计算。</li>\n<li>对于超参数$\\beta_2$，Adam算法论文的作者推荐使用0.999，这是关于$dW^2$的加权平均计算。</li>\n<li>超参数$\\varepsilon$，如何选择影响都不大，Adam论文的作者推荐使用$10^{-8}$作为默认值。</li>\n<li>在使用Adam算法的时候，业内通常对$\\beta_1$、$\\beta_2$以及$\\varepsilon$都直接使用默认值，然后尝试不同的学习率$\\alpha$来以获得最好的训练效果。</li>\n</ul>\n<h3 id=\"学习速率衰减\"><a href=\"#学习速率衰减\" class=\"headerlink\" title=\"学习速率衰减\"></a>学习速率衰减</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F1.JPG\" width=\"80%\" height=\"80%\"> 学习速率衰减，即逐渐地减小学习率，可使得学习算法运行更快：</p>\n<ul>\n<li>如图，当采用小批量梯度下降法进行迭代时：<ul>\n<li>当学习率$\\alpha$采用固定值，会逐步向最小值靠近，但不会完全收敛到这点。如图中蓝色曲线所示。</li>\n<li>当采用学习率衰减，那么在初始阶段，因为学习率$\\alpha$取值还比较大，学习速度仍然可以比较快。但随着学习率降低$\\alpha$变小，步长也会渐渐变小。所以，最终将围绕着离极小值点更近的区域摆动，即使继续训练下去也不会漂游远离。如图中绿色曲线所示。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>如图所示，可由以下公式，实现学习率衰减：<ul>\n<li><script type=\"math/tex; mode=display\">\\alpha=\\frac{1}{1+decay \\_ rate*epoch}\\alpha_0</script></li>\n<li>其中，deacy_rate是参数（可调），epoch是周期数。随着epoch增加，$\\alpha$会不断变小。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F3.JPG\" width=\"50%\" height=\"50%\"> 实现学习率衰减还有其它可供选择的计算公式，如图所示:</p>\n<ul>\n<li>$\\alpha=0.95^{epoch}\\cdot \\alpha_0$</li>\n<li>$\\alpha=\\frac{k}{\\sqrt{epoch}}\\cdot \\alpha_0\\ \\ \\ \\ or\\ \\ \\ \\ \\frac{k}{\\sqrt{t}}\\cdot \\alpha_0$</li>\n<li>离散阶梯衰减。</li>\n<li>手动衰减。</li>\n</ul>\n<p>另外：</p>\n<ul>\n<li><strong>学习率衰减的确可以帮助加速训练，但学习率衰减通常位于应该尝试的事情中比较靠后的位置</strong>。</li>\n<li><strong>设置一个固定数值的$\\alpha_0$，且使得优化良好，对结果有着巨大影响</strong>。</li>\n<li>下周，将对超参数进行系统地讲解。</li>\n</ul>\n<h3 id=\"局部最优解的问题\"><a href=\"#局部最优解的问题\" class=\"headerlink\" title=\"局部最优解的问题\"></a>局部最优解的问题</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A31.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>在深度学习的早期阶段，人们常常担心优化算法会陷入糟糕的局部最优解(Local Optima)之中。但随着深度学习理论的发展，我们对局部最优的理解也在改变。</li>\n<li>在使用梯度下降算法不断减小代价函数时，可能会得到局部最优解而不是全局最优解。之前我们对局部最优解的理解是如上图左边所示。</li>\n<li>但对于神经网络，其参数维数很高，梯度为零的点，在每个方向上，有可能是凸函数，有可能是凹函数。因此，梯度为零的点很可能都是右边所示的马鞍状的鞍点。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A32.JPG\" width=\"80%\" height=\"80%\"> 总结：</p>\n<ul>\n<li>局部最优不是问题，不太可能陷入极差的局部最优问题中（只要训练的是一个较大的神经网络，即有很多参数，代价函数$J$定义在一个相对高维的空间上时）。</li>\n<li>停滞区让学习过程变得相当慢。<ul>\n<li>解释：停滞区指的是导数长时间接近于零的一段区域，因为梯度为零或接近于零，曲面很平。在离开停滞区继续下降之前，需要花费很长的时间，缓慢地渡过在停滞区。</li>\n<li>解决方法：更复杂的算法，比如Adam算法，可以加快沿停滞区向下移动然后离开停滞区的速度。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"3-超参数调试、批量归一化以及编程框架\"><a href=\"#3-超参数调试、批量归一化以及编程框架\" class=\"headerlink\" title=\"3.超参数调试、批量归一化以及编程框架\"></a>3.超参数调试、批量归一化以及编程框架</h1><h2 id=\"3-1-超参数调试\"><a href=\"#3-1-超参数调试\" class=\"headerlink\" title=\"3.1 超参数调试\"></a>3.1 超参数调试</h2><h3 id=\"调试过程\"><a href=\"#调试过程\" class=\"headerlink\" title=\"调试过程\"></a>调试过程</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"> 深度神经网络需要调试的超参数较多，包括：</p>\n<ul>\n<li>$\\alpha$ ：学习速率</li>\n<li>$\\beta$ ：动量梯度下降因子</li>\n<li>$\\beta_1,\\beta_2,\\varepsilon$ ：Adam算法参数</li>\n<li>#layers：神经网络层数</li>\n<li>#hidden units：各隐藏层神经元个数</li>\n<li>learning rate decay：学习速率衰减参数</li>\n<li>mini-batch size：每一mini-batch包含的样本个数</li>\n</ul>\n<p>对于以上超参数的优先级：</p>\n<ul>\n<li>优先级1：学习速率$\\alpha$需要调试的超参数中最重要的一个，没有之一。</li>\n<li>优先级2：接下来会调整动量梯度下降参数$\\beta$，0.9是不错的默认值；还会调整Mini-Batch的大小，来保证最优化算法的运行效率；还经常调试隐藏单元数量。这三个超参数的重要性仅次于学习速率$\\alpha$。</li>\n<li>优先级3：网络层数有时候对结果起到重要作用，学习率衰减有时也一样。</li>\n<li>优先级4：当使用Adam优化算法时，几乎不调节$\\beta_1,\\beta_2,\\varepsilon$，几乎都是用0.9，0.999和$10^{-8}$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"> 当调整超参数时，对于超参数值的组合：</p>\n<ul>\n<li>在早期的机器学习算法中，如果有两个超参数（超参数1和超参数2），人们经常会像这样：在一个网格中对点进行规则抽样，然后系统化地尝试这些点所代表的值。如在图中5*5的网格中采样25个点后，选择最优的超参数。当超参数的数量相对较少时，这样的取参方法较为实用。 </li>\n<li>但在深度学习中，推荐采取另一种方法：在网格中进行随机抽样，无论最重要的超参数是哪个，将帮助你更充分地为最重要的超参数尝试尽可能多的值的组合。超参数值域的随机抽样，能更有效地搜索超参数空间。如图中，随机采样25个点，然后在这些随机选取的点中，尝试所有的超参数。对于多维情况，也是如此在多维空间中进行随机采样，然后尝试多个超参数的组合值。<ul>\n<li>这样做的原因：事先很难知道，哪一个超参数对于你的模型更重要。  </li>\n<li>解释：假设超参数1是学习速率$\\alpha$，超参数2是Adam优化算法中的$\\varepsilon$。若在网格中取样，因为$\\varepsilon$对结果没有什么影响，所以训练了25个模型，但是只相当于尝试了5个有用的α的值；相比较而言，如果在网格中随机取样 那么将获得25个不同的学习速率$\\alpha$，因此你找到理想值的概率也就变得更大。 </li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%953.JPG\" width=\"80%\" height=\"80%\"> 由粗糙到精细的搜索策略：</p>\n<ul>\n<li>继续以二维空间为例，当在此空间进行完随机采样后，发现在某些点能产生最好的结果，大体能确定这个区域内取的值能产生最优结果，即最理想的超参数来自于这个区域。即在对整个框定范围进行粗略的抽样后，结果会引导你集中在一个更小的区域内。</li>\n<li>然后，继续采用区域定位的抽样方案：即在这个更小的区域内进行密度更高的随机抽样。</li>\n</ul>\n<h3 id=\"用合适的尺度去选择超参数\"><a href=\"#用合适的尺度去选择超参数\" class=\"headerlink\" title=\"用合适的尺度去选择超参数\"></a>用合适的尺度去选择超参数</h3><p>上一节讲解的超参数值域的随机抽样，能帮助更有效地搜索超参数空间。但随机抽样并不意味着在有效值范围内的均匀随机抽样(sampleing uniformly at random)。相反，更重要的是选取适当的尺度(scale)，用以研究这些超参数。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A61.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于超参数#layers和#hidden units，采用均匀随机抽样是合理的方案，但它并不是对所有的超参数都适用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A62.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于超参数学习率$\\alpha$，待调范围是$[0.0001, 1]$。如果使用均匀随机抽样，那么有90%的采样点分布在$[0.1, 1]$之间，只有10%分布在$[0.0001, 0.1]$之间，并不合理。</li>\n<li>更合理的方法：在对数尺度(log scale)上进行采样，而不是用线性尺度(linear scale)。即分为$[0.0001, 0.001]，[0.001, 0.01]，[0.01, 0.1]，[0.1, 1]$这几个区间。</li>\n<li>一般解法是，如果线性区间为$[a,b]$，令$m=log(a)$，$n=log(b)$，则对应的$log$区间为$[m,n]$。对$log$区间的$[m,n]$进行随机均匀采样，然后得到的采样值$r$，最后反推到线性区间，即$10^r$。$10^r$就是最终采样的超参数。相应的Python代码为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">m = np.log10(a)</span><br><span class=\"line\">n = np.log10(b)</span><br><span class=\"line\">r = np.random.rand() <span class=\"comment\">#[0,1)</span></span><br><span class=\"line\">r = m + (n-m)*r <span class=\"comment\">#[m,n)</span></span><br><span class=\"line\">r = np.power(<span class=\"number\">10</span>,r)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2%E5%B0%BA%E5%BA%A63.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>除了$\\alpha$之外，动量梯度下降法中的参数$\\beta$在超参数调试时，同样应在对数尺度上进行采样。</li>\n<li>一般$\\beta$的取值范围在$[0.9, 0.999]$之间，那么$1-\\beta$的取值范围就在$[0.001, 0.1]$之间。那么直接对$1-\\beta$在$[0.001, 0.1]$区间内进行对数尺度采样(即$10^r$)，然后再推出$\\beta$(即$1-10^r$)即可。</li>\n<li>为什么$\\beta$也需要向$\\alpha$那样做非均匀采样:公式$\\frac{1}{1-\\beta}$在当$\\beta$趋于1时，它对$\\beta$的值的改变非常敏感。</li>\n</ul>\n<p>最后：</p>\n<ul>\n<li>如果对于某个超参数你选择的尺度是不对的，或即使在存在更优尺度的情况下，你依然选择了均匀尺度(uniform scale) 你仍然可能得到不错的结果，尤其是如果你采取从粗到精(coarse to fine)的搜索策略。</li>\n</ul>\n<h3 id=\"实践中的超参数调试：Pandas-vs-Caviar\"><a href=\"#实践中的超参数调试：Pandas-vs-Caviar\" class=\"headerlink\" title=\"实践中的超参数调试：Pandas vs. Caviar\"></a>实践中的超参数调试：Pandas vs. Caviar</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%951.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>经过调试选择完最佳的超参数并不是一成不变的，一段时间之后（例如一个月），需要根据新的数据和实际情况（如数据集改变、有了更先进的服务器等），再次调试超参数，以获得实时的最佳模型。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%952.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>精心照料一个模型(“Panda” approach)：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现。 </li>\n<li>并行训练多个模型(“Caviar” approach)：可以对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。</li>\n</ul>\n<h2 id=\"3-2-批量归一化\"><a href=\"#3-2-批量归一化\" class=\"headerlink\" title=\"3.2 批量归一化\"></a>3.2 批量归一化</h2><h3 id=\"归一化网络的激活函数\"><a href=\"#归一化网络的激活函数\" class=\"headerlink\" title=\"归一化网络的激活函数\"></a>归一化网络的激活函数</h3><p>在深度学习不断兴起的过程中,最重要的创新之一是一种叫批量归一化(Batch Normalization)的算法，可让超参搜索变得很简单，让神经网络对于超参数的选择上不再那么敏感，并且可以更容易地训练非常深的网络 。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%961.JPG\" width=\"80%\" height=\"80%\"> 批量归一化原理：</p>\n<ul>\n<li>对于单一逻辑回归神经元，归一化输入的操作：$X=\\frac{X-\\mu}{\\sqrt{\\sigma^2}}$，提高模型的训练速度。</li>\n<li>批量归一化：对$A^{[l-1]}$进行归一化处理，提高$W^{[l]}$和$b^{[l]}$的训练速度。</li>\n<li>批量归一化在实际操作时，归一化的不是$A^{[i]}$，而是$Z^{[i]}$，即激活函数前的值。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%962.JPG\" width=\"80%\" height=\"80%\"> 单隐藏层的批量归一化的实现：</p>\n<ul>\n<li>对第$l$层隐藏层的输入<script type=\"math/tex\">Z^{[l-1]}=[z^{[l-1](1)},z^{[l-1](2)},...,z^{[l-1](m)}]</script>做如下归一化处理，忽略上标$[l-1]$：<ul>\n<li>$\\mu=\\frac1m\\sum_iz^{(i)}$</li>\n<li>$\\sigma^2=\\frac1m\\sum_i(z_i-\\mu)^2$</li>\n<li>$z^{(i)}_{norm}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$</li>\n<li>其中，$m$是单个mini-batch包含样本个数，$\\varepsilon$是为了防止分母为零，可取值$10^{-8}$。这样，使得该隐藏层的所有输入 $z^{(i)}$均值为0，方差为1。</li>\n</ul>\n</li>\n<li>但是，大部分情况下并不希望所有的$z^{(i)}$均值都为0，方差都为1，也不太合理。通常需要对$z^{(i)}$进行进一步处理：<ul>\n<li>$\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$</li>\n<li>式中，$\\gamma$和$\\beta$是可学习的参数，类似于$W$和$b$一样，可以通过梯度下降等算法求得。这里，$\\gamma$和$\\beta$的作用是让$\\tilde z^{(i)}$的均值和方差为任意值，只需调整其值就可以了。</li>\n<li>例如，令：$\\gamma=\\sqrt{\\sigma^2+\\varepsilon}$,$\\beta=\\mu$，则$\\tilde z^{(i)}=z^{(i)}$。可见，设置$\\gamma$和$\\beta$为不同的值，可以得到任意的均值和方差。</li>\n</ul>\n</li>\n<li>这样，通过批量归一化，对隐藏层的各个<script type=\"math/tex\">z^{[l](i)}</script>进行归一化处理，得到<script type=\"math/tex\">\\tilde z^{[l](i)}</script>，替代<script type=\"math/tex\">z^{[l](i)}</script>。</li>\n<li>值得注意的是，<strong>输入层的归一化处理和隐藏层的归一化处理是有区别的</strong>。<strong>归一化输入使所有输入的均值为0，方差为1</strong>。而<strong>隐藏层的归一化处理可使各隐藏层输入的均值和方差为任意值</strong>。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，则无法更好的利用激活函数非线性的特性，而不是所有的值都集中在线性区域。这就是为什么通过设置$\\gamma$和$\\beta$来控制<script type=\"math/tex\">z^{[l](i)}</script>在希望的范围内，或者说<strong>批量归一化真正实现的是通过两个参数$\\gamma$和$\\beta$来让隐藏单元有可控的均值和方差</strong>。</li>\n</ul>\n<h3 id=\"将批量归一化用于神经网络\"><a href=\"#将批量归一化用于神经网络\" class=\"headerlink\" title=\"将批量归一化用于神经网络\"></a>将批量归一化用于神经网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B01.JPG\" width=\"80%\" height=\"80%\"> 对于$L$层神经网络，实施批量归一化的整体流程如下：</p>\n<ul>\n<li><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B.jpg\" width=\"100%\" height=\"100%\"></li>\n<li>其中，参数为$W^{[1]}$,$b^{[1]}$,$W^{[2]}$,$b^{[2]}$,…,$W^{[L]}$,$b^{[L]}$以及$\\beta^{[1]}$,$\\gamma^{[1]}$,$\\beta^{[2]}$,$\\gamma^{[2]}$,…,$\\beta^{[L]}$,$\\gamma^{[L]}$。$\\beta^{[l]}$与$\\gamma^{[l]}$的学习同$W^{[l]}$与$b^{[l]}$一样，采用梯度下降法。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B02.JPG\" width=\"80%\" height=\"80%\"> 在mini-batch上应用批量归一化：</p>\n<ul>\n<li>分别用每个mini-batch的数据(均值和方差)进行批量归一化。</li>\n<li>因为批量归一化对各隐藏层$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$有去均值的操作，所以这里的常数项$b^{[l]}$可以消去，其数值效果完全可以由$\\tilde Z^{[l]}$中的$\\beta^{[l]}$来实现。因此，我们在使用批量归一化的时候，可以忽略各隐藏层的常数项$b^{[l]}$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84BatchNorm%E5%AE%9E%E7%8E%B03.JPG\" width=\"80%\" height=\"80%\"> 概述了应用批量归一化时，梯度下降(或动量或RMSprop或Adam)的整个过程。</p>\n<h3 id=\"批量归一化为什么有效\"><a href=\"#批量归一化为什么有效\" class=\"headerlink\" title=\"批量归一化为什么有效\"></a>批量归一化为什么有效</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%881.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%882.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%89%B9%E9%87%8F%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%95%883.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>解释1：归一化输入，使得输入$X$的均值为0，方差为1，大幅加速学习过程。批量归一化同理。</li>\n<li>解释2：批量归一化使得网络的每一层相对独立。</li>\n<li>解释3：批量归一化具有轻微的正则化效果。</li>\n</ul>\n<h3 id=\"在测试阶段使用批量归一化\"><a href=\"#在测试阶段使用批量归一化\" class=\"headerlink\" title=\"在测试阶段使用批量归一化\"></a>在测试阶段使用批量归一化</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8BatchNorm.JPG\" width=\"50%\" height=\"50%\"> </p>\n<ul>\n<li>首先，回顾批量归一化在训练过程中，在每一mini-batch，在网络的每一层中，做如下操作：<ul>\n<li>$\\mu=\\frac1m\\sum_iz^{(i)}$</li>\n<li>$\\sigma^2=\\frac1m\\sum_i(z^{(i)}-\\mu)^2$</li>\n<li>$z_{norm}^{(i)}=\\frac{z^{(i)}-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}}$</li>\n<li>$\\tilde z^{(i)}=\\gamma\\cdot z^{(i)}_{norm}+\\beta$ </li>\n<li>其中，$\\mu$和$\\sigma^2$是对单个mini-batch中所有$m$个样本求得的。</li>\n</ul>\n</li>\n<li>在测试阶段，如果只有一个样本，求其均值和方差是没有意义的，就需要对$\\mu$和$\\sigma^2$进行估计。实际应用中一般采用指数加权平均（exponentially weighted average）的方法来预测测试过程单个样本的$\\mu$和$\\sigma^2$：<ul>\n<li>指数加权平均的做法:对于第$l$层隐藏层，考虑所有mini-batch在该隐藏层下的$\\mu^{[l]}$和$\\sigma^{2[l]}$，然后用指数加权平均的方式来预测得到当前单个样本的$\\mu^{[l]}$和$\\sigma^{2[l]}$。这样就实现了对测试过程单个样本的均值和方差估计。</li>\n<li>最后，再利用训练过程得到的$\\gamma$和$\\beta$值计算出各层的$\\tilde z^{(i)}$值。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-3-多类别分类\"><a href=\"#3-3-多类别分类\" class=\"headerlink\" title=\"3.3 多类别分类\"></a>3.3 多类别分类</h2><h3 id=\"Softmax回归\"><a href=\"#Softmax回归\" class=\"headerlink\" title=\"Softmax回归\"></a>Softmax回归</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>用神经网络进行多分类，<script type=\"math/tex\">C=\\#class=4</script>，0为其他，1为猫，2为狗，3为小鸡。</li>\n<li>对于单个输入样本$x$，网络的最后一层(第$L$层)为Softmax层，$\\hat{y}=a^{[L]}$，维度为$(4,1)$。</li>\n<li>Softmax层中各神经元的输出依次代表$P(other|x)$，$P(cat|x)$，$P(dog|x)$，$P(baby \\ chicks|x)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>Softmax层的激活函数计算过程如下：<ul>\n<li><script type=\"math/tex; mode=display\">z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}</script></li>\n<li><script type=\"math/tex; mode=display\">t=e^{(z^{[L]})}</script></li>\n<li><script type=\"math/tex; mode=display\">a^{[L]}=\\frac{e^{z^{[L]}}}{\\sum_{i=1}^C t_i}</script></li>\n<li><script type=\"math/tex; mode=display\">a^{[L]}_i=\\frac{t_i}{\\sum_{i=1}^C t_i}</script></li>\n<li>也可看成是$a^{[L]}=g^{[L]}(z^{[L]})$，只不是该激活函数的输入是向量，输入也是向量。</li>\n<li>其中，Softmax层每个神经元的输出<script type=\"math/tex\">a^{[L]}_i</script>对应属于该类的概率，满足：<script type=\"math/tex\">\\sum_{i=1}^Ca^{[L]}_i=1</script></li>\n<li><script type=\"math/tex\">a^{[L]}= \\hat{y}</script>，维度为$(C, 1)$。</li>\n</ul>\n</li>\n<li>具体计算示例如图。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/Softmax3.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>上图为没有隐藏层，只有单一Softmax层的神经网络，其经Softmax分类的效果如图所示，为线性多分类效果，各两类之间的决策边界均为线性。</li>\n<li>当网络具有很多隐藏层，可构成更复杂的非线性决策边界。</li>\n</ul>\n<h3 id=\"训练一个softmax分类器\"><a href=\"#训练一个softmax分类器\" class=\"headerlink\" title=\"训练一个softmax分类器\"></a>训练一个softmax分类器</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A81.JPG\" width=\"80%\" height=\"80%\"> 理解Softmax：</p>\n<ul>\n<li>Softmax回归是Logistic回归向多类别的泛化。</li>\n<li>当$C=2$时，Softmax回归将简化成Logistic回归。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A82.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>假设$C=4$，某个样本的预测输出$\\hat y$和目标输出(真实值标签)$y$为：<ul>\n<li><script type=\"math/tex; mode=display\">\\hat y=\\left[ \\begin{matrix} 0.3 \\\\ 0.2 \\\\ 0.1 \\\\ 0.4 \\end{matrix} \\right]</script></li>\n<li><script type=\"math/tex; mode=display\">y=\\left[ \\begin{matrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{matrix} \\right]</script></li>\n</ul>\n</li>\n<li>Loss function：$L(\\hat y,y)=-\\sum_{j=1}^4y_j\\cdot log\\ \\hat y_j$<ul>\n<li>然而，由于只有当$j=2$时，$y_2=1$，其它情况下，$y_j=0$。所以，上式中的$L(\\hat y,y)$可以简化为：$L(\\hat y,y)=-y_2\\cdot log\\ \\hat y_2=-log\\ \\hat y_2$</li>\n<li>要让$L(\\hat y,y)$更小，就应该让$\\hat y_2$越大越好。$\\hat y_2$反映的是概率，完全符合我们之前的定义。 </li>\n</ul>\n</li>\n<li>Cost function：$J(W^{[1]},b^{[1]},…)=\\frac1m\\sum_{i=1}^mL(\\hat{y}^{(i)},y^{(i)})$</li>\n<li>若对于m个样本，其预测输出向量$A^{[L]}$即$\\hat Y$的维度为$(4, m)$，样本标签$Y$的维度也为$(4, m)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AASoftmax%E5%88%86%E7%B1%BB%E5%99%A83.JPG\" width=\"80%\" height=\"80%\"> 梯度下降的过程中，输出层Softmax的梯度推导，即$dZ^{[L]}$的推导：</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">da^{[L]}=-\\frac{1}{a^{[L]}}</script></li>\n<li><script type=\"math/tex; mode=display\">\\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=\\frac{\\partial}{\\partial z^{[L]}}\\cdot (\\frac{e^{z^{[L]}_i}}{\\sum_{i=1}^Ce^{z^{[L]}_i}})=a^{[L]}\\cdot (1-a^{[L]})</script></li>\n<li><script type=\"math/tex; mode=display\">dz^{[L]}= \\frac{\\partial J}{\\partial z^{[L]}}= da^{[L]}\\cdot \\frac{\\partial a^{[L]}}{\\partial z^{[L]}}=a^{[L]}-1=a^{[L]}-y</script></li>\n<li>对于所有$m$个训练样本：<script type=\"math/tex\">dZ^{[L]}=A^{[L]}-Y</script></li>\n<li>可见$dZ^{[L]}$的表达式与二元分类结果是一致的，虽然推导过程不太一样。然后就可以继续进行反向传播过程的梯度下降算法了，推导过程与二元分类神经网络完全一致。</li>\n</ul>\n<h2 id=\"3-4-编程框架介绍\"><a href=\"#3-4-编程框架介绍\" class=\"headerlink\" title=\"3.4 编程框架介绍\"></a>3.4 编程框架介绍</h2><h3 id=\"深度学习框架\"><a href=\"#深度学习框架\" class=\"headerlink\" title=\"深度学习框架\"></a>深度学习框架</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.JPG\" width=\"80%\" height=\"80%\"> 如图，介绍了目前的深度学习框架，和选择深度学习框架的标准。</p>\n<h3 id=\"TensorFlow\"><a href=\"#TensorFlow\" class=\"headerlink\" title=\"TensorFlow\"></a>TensorFlow</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow1.JPG\" width=\"80%\" height=\"80%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B2/tensorflow2.JPG\" width=\"80%\" height=\"80%\"> 本节介绍TensorFlow程序的典型结构。</p>\n<p>举个例子来说明，代价函数是参数<code>w</code>的函数：$J=w^2-10w+25$。<br>如果使用TensorFlow对代价函数进行优化，求出最小值对应的<code>w</code>，程序如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">w = tf.Variable(<span class=\"number\">0</span>,dtype=tf.float32)</span><br><span class=\"line\"><span class=\"comment\">#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)</span></span><br><span class=\"line\">cost = w**<span class=\"number\">2</span> - <span class=\"number\">10</span>*w +<span class=\"number\">25</span></span><br><span class=\"line\">train = tf.train.GradientDescentOptimizer(<span class=\"number\">0.01</span>).minimize(cost)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.0</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(train)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    session.run(train)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;4.99999</code><br>TensorFlow框架内可以直接调用梯度下降优化算法。在运行1000次梯度下降算法后，<code>w</code>的解为4.99999，已经非常接近<code>w</code>的最优值5了。<br>针对上面这个例子，如果对<code>w</code>前的系数用变量<code>x</code>来代替，程序如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">cofficients = np.array([[<span class=\"number\">1.</span>],[<span class=\"number\">-10.</span>],[<span class=\"number\">25.</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">w = tf.Variable(<span class=\"number\">0</span>,dtype=tf.float32)</span><br><span class=\"line\">x = tf.placeholder(tf.float32,[<span class=\"number\">3</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\"><span class=\"comment\">#cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)</span></span><br><span class=\"line\"><span class=\"comment\">#cost = w**2 - 10*w +25</span></span><br><span class=\"line\">cost = x[<span class=\"number\">0</span>][<span class=\"number\">0</span>]*w**<span class=\"number\">2</span> + x[<span class=\"number\">1</span>][<span class=\"number\">0</span>]*w + x[<span class=\"number\">2</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">train = tf.train.GradientDescentOptimizer(<span class=\"number\">0.01</span>).minimize(cost)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.0</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session.run(train, feed_dict=(x:coefficients))</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;0.1</code><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>):</span><br><span class=\"line\">    session.run(train, feed_dict=(x:coefficients))</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p><code>&gt;&gt;4.99999</code><br>结果跟之前是一样的。除此之外，我们还可以更改<code>x</code>即<code>cofficients</code>的值，而得到不同的优化结果<code>w</code>。<br>另外，上段程序中的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">session = tf.Session()</span><br><span class=\"line\">session.run(init)</span><br><span class=\"line\">print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p>有另外一种写法：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> session:</span><br><span class=\"line\">    session.run(init)</span><br><span class=\"line\">    print(session.run(w))</span><br></pre></td></tr></table></figure></p>\n<p>TensorFlow的最大优点就是采用数据流图(data flow graphs)来进行数值运算。图中的节点(Nodes)表示数学操作，图中的线(edges)则表示在节点间相互联系的多维数据数组，即张量(tensor)。而且它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU(或GPU)，服务器，移动设备等。</p>"},{"title":"深度学习课程(四)卷积神经网络","mathjax":true,"date":"2018-01-11T09:21:50.000Z","_content":"# 1.卷积神经网络基础\n## 1.1 卷积神经网络\n### 计算机视觉\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%891.JPG\" width=\"50%\" height=\"50%\"> 举了计算机视觉中的几个典型应用：\n- 图像分类\n- 目标检测\n- 风格迁移\n\n<!-- more --> \n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%892.JPG\" width=\"80%\" height=\"80%\"> 在应用计算机视觉时，所面临的一个挑战是数据的输入可能会非常大：\n- 对$64 \\times 64$的小图片，输入特征的维度是$12288(64\\times 64\\times 3)$。\n- 对稍大的$1000\\times 1000$的图片，输入特征的维度是$3million(1000\\times 1000\\times 3)$：\n - 神经网络的输入$x\\in R^{3m}$，假设第一个隐藏层有1000个神经元，则第一层的参数$W^{[1]}$的维度为$(1000,3m)$，即包含30亿个参数。\n - 对于如此大量的参数，难以获取足够多的数据来防止过拟合。\n - 内存需要处理30个参数的神经网络，所需内存太大。\n - 要解决这个问题，需进行卷积操作。\n\n### 边缘检测示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B1.JPG\" width=\"90%\" height=\"90%\"> 以边缘检测为例，说明卷积操作是如何进行的。如图：\n- 卷积神经网络的浅层检测到的是边缘，然后是物体的部件，深层检测到整体。\n- 想要检测图像中的垂直边缘，下图继续。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 介绍卷积操作：\n- $6\\times 6$的图像(灰度图，单通道)与可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器，以步长为1，进行卷积操作，结果如图。\n - $*$ 表示卷积操作。Python中，卷积用函数conv_forward()；tensorflow中，卷积用函数tf.nn.conv2d()；keras中，卷积用函数Conv2D()。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B3.JPG\" width=\"90%\" height=\"90%\"> \n- $6\\times 6$的图像(灰度图，单通道)的左半部分像素强度较大，即较白，右半部分像素强度较小，故较暗（其实灰度图中白为255，黑为0）。\n- 仍是上图中可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器。左侧较白，中间较暗，右侧最暗。\n- 卷积结果如图所示。输出图像像中中间有一条较白的宽带，即垂直边缘。\n - 输出图像中边缘太粗，是因为图像过小，若对$1000\\times 1000$的图像进行卷积，输出图像中的边缘将不会显得这么粗。\n\n### 更多边缘检测内容\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B1.JPG\" width=\"90%\" height=\"90%\"> \n- 图片边缘有两种边缘过渡方式，一种是由明变暗，另一种是由暗变明。从输出图像可看出，该垂直边缘滤波器，可以区别出这两种明暗变化的区别。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B2.JPG\" width=\"90%\" height=\"90%\">\n- 如图，垂直边缘检测和水平边缘检测的滤波器如图所示。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B3.JPG\" width=\"90%\" height=\"90%\">\n- 更经典的Sobel滤波器和Scharr滤波器。\n - Sobel滤波器的优点是增加了中间一行的权重，也就是处在中央的像素点，使得结果更鲁棒一些。\n - 图中为进行垂直边缘检测的形式，翻转90度后即得进行水平边缘检测的形式。\n- 随着深度学习的兴起，我们学习到的事情是：当你想检测出某些复杂图像的边缘，你不一定要去使用那些研究者们手工设计的滤波器。而将滤波器中的数字当作参数，通过神经网络学习这些参数。学习到的滤波器对于数据的统计特性的捕捉能力甚至比任何一个手工设计的滤波器要好。\n\n### 填充\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%851.JPG\" width=\"90%\" height=\"90%\">\n不进行填充(padding)：\n- $n\\times n$的图像与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n-f+1)\\times (n-f+1)$。\n - 理解公式：$1$为卷积核位于图像最后一个位置，即进行一次卷积操作，$(n-f)$表示图像空出最后一个卷积核位置后的尺寸，也即可进行卷积的次数。故总的输出尺寸为$(n-f+1)$。\n - 如$6\\times 6$的图像与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸尺寸为$4\\times 4$。\n- 缺点：每次做卷积操作后：\n - 图像会缩小(图像的高度和宽度都会缩小)。\n - 丢失边缘信息(原图像中处于边缘的像素进行较少次的卷积运算，而处于中间的像素进行较多次的卷积运算)。\n- 解决方法：对图像进行填充后，进行卷积。\n\n进行填充：\n- $n\\times n$的图像,进行$p=padding=p$的填充后，与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n+2p-f+1)\\times (n+2p-f+1)$。\n - 如$6\\times 6$的图像,进行$p=1$的填充后，尺寸为$8\\times 8$。与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸为$6\\times 6$。\n - 通常采用零填充(zero-padding)，即在图像边缘填充的值为0。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%852.JPG\" width=\"90%\" height=\"90%\">\n- \"Valid\" convolution：不进行填充。即$p=0$。 \n- \"Same\" convolution：进行填充，使得输出尺寸和输入尺寸相同(保留图像的高度和宽度。但输入和输出的通道数可以不同)。\n - 进行填充的输出尺寸为：$(n+2p-f+1)\\times (n+2p-f+1)$，原始输入尺寸为：$n\\times n$。令$(n+2p-f+1)=n$，则$p=\\frac{f-1}{2}$。\n- 另外，按照惯例，在计算机视觉中，对于卷积核/滤波器的尺寸$f \\times f$，$f$通常是奇数。\n - 如果$f$是偶数，则只能使用一些不对称的填充。$f$是奇数，才能有自然的填充。\n - 奇数的卷积核/滤波器，会有一个中心位置。在计算机视觉中，有一个中间像素，便于指出卷积核的位置。\n - 大小为$3\\times 3$、$5\\times 5$和$7\\times 7$的卷积核很常见，$1\\times 1$也有意义。稍后讲解。\n \n### 步长\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF1.JPG\" width=\"90%\" height=\"90%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF2.JPG\" width=\"90%\" height=\"90%\">\n- 输入图片尺寸为$n \\times n$，卷积核尺寸为$f \\times f$，填充(padding)为$p$，步长(stride)为$s$。\n - 则输出尺寸为：$$\\lfloor\\frac{n+2p-f}{s}+1\\rfloor\\ \\times \\ \\lfloor\\frac{n+2p-f}{s}+1\\rfloor$$\n - 其中，$\\lfloor z \\rfloor=floor(z)$，为向下取整，地板除法。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF3.JPG\" width=\"90%\" height=\"90%\">\n- 在机器学习或深度学习领域，我们所使用的卷积操作，严格意义上应叫做互相关(cross-correlation)。\n- 在数学或信号处理的教科书中，卷积操作需先对卷积核进行翻转(双重镜像)后，再进行卷积操作。包含对卷积核的反转，可使得卷积运算拥有$(A\\*B)\\*C=A\\*(B\\*C)$的结合律性质。\n- 本课程按照机器学习或深度学习中的惯例，将不包含翻转操作的互相关，称为卷积操作。\n\n### 对体进行卷积操作\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF2.JPG\" width=\"90%\" height=\"90%\">\n- 彩色图像的尺寸为$6 \\times 6 \\times 3$，分别表示图片的高度(height)、宽度(weight)和通道数(#channels)。\n- 卷积核的尺寸为$3 \\times 3 \\times 3$，分别表示卷积核的高度(height)、宽度(weight)和通道数(#channels)。\n- 输出尺寸为$4 \\times 4$。\n - 解释：卷积核置于起始卷积位置(输入图像的左上)，卷积核的各通道与输入图像的各通道做卷积操作，然后3个通道的各个输出(各一个数)相加，得到最终输出(一个数)。卷积核移动，进行下一次卷积。\n- 其中，输入图像的通道数(#channels)与卷积核的通道数必须相等。\n- 其中，通道数(#channels)也称为深度(depth)，但容易与神经网络的深度混淆，本课程只称其为通道数(#channels)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF3.JPG\" width=\"90%\" height=\"90%\">\n- 输入图像的尺寸为$6 \\times 6 \\times 3$\n- 两个卷积核，第一个卷积核用来检测垂直边缘，其尺寸为$3 \\times 3 \\times 3$。第二个卷积核用来检测水平边缘，其尺寸为$3 \\times 3 \\times 3$。\n- 输出尺寸为$4 \\times 4 \\times 2$。\n\n总结，假设$p=0$，$s=1$：\n- 输入尺寸：$n \\times n \\times n_c$\n- 卷积核尺寸：$f \\times f \\times n_c$ \n- 输出尺寸为：$(n-f+1) \\times (n-f+1) \\times n_c^{\\prime}$。\n - 其中$n_c^{\\prime}$为输出尺寸的通道数，等于卷积核个数(#filters)。\n\n### 单层卷积网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1.JPG\" width=\"90%\" height=\"90%\"> \n- 单层卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C4.jpg\" width=\"90%\" height=\"90%\">\n - 相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏置$b$(每个卷积核有一个偏置，例如图中两个卷积核各有一个偏置)。\n - 整个过程与标准的神经网络单层结构非常类似：\n $$Z^{[l]}=W^{[l]}A^{[l-1]}+b$$\n $$A^{[l]}=g^{[l]}(Z^{[l]})$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2.JPG\" width=\"90%\" height=\"90%\"> 单卷积层中的参数：\n- 若一个卷积层有，卷积核个数为10，每个卷积核尺寸为$3 \\times 3 \\times 3$，每个卷积核有1个偏置参数(一个实数)。\n- 则，单卷积层中的参数个数为：$(3\\*3\\*3+1)\\*10=280$个参数。\n- **注意到，无论输入图像的尺寸多大，该卷积层的参数个数始终为280个。即使图片很大，参数依然很少，因此卷积神经网络不容易过拟合(less prone to overfitting)**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3.JPG\" width=\"90%\" height=\"90%\"> **总结CNN中的符号表示**，若第$l$层是卷积层：\n- 符号表示：\n - $f^{[l]} = $卷积核尺寸(filter size)\n - $p^{[l]} = $填充(padding)\n - $s^{[l]} = $步长(stride)\n - $n_c^{[l]} = $卷积核个数(number of filters)\n- 输入尺寸：$n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_c^{[l-1]}$\n- 每个卷积核的尺寸：$f^{[l]} \\times f^{[l]} \\times  n_c^{[l-1]}$\n- 权重尺寸为： $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times  n_c^{[l]}$\n- 偏置尺寸为：$n_c^{[l]}$ 或$(1,1,1,n_c^{[l]})$\n- 输出$a^{[l]}$的尺寸为： $n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$\n- 输出$A^{[l]}$的尺寸为： $m \\times n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$\n - 其中，$$n_H^{[l]}=\\lfloor \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor$$，$$n_W^{[l]}=\\lfloor \\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor$$\n\n### 简单的卷积网络示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\">\n- 该CNN模型各层结构如上图所示。\n- 需要注意的是，$a^{[3]}$的维度是$7 \\times 7 \\times 40$，将$a^{[3]}$排列成1列，维度为$1960 \\times 1$，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 $\\hat y$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> CNN有三种类型的层：\n- 卷积层(Convolution, CONV）\n- 池化层(Pooling, POOL）\n- 全连接层(Fully connected, FC）\n\n### 池化层\n除了卷积层(convolutional layers)，CNN中也经常使用池化层(pooling layers)来减小模型来加速计算，同时让检测到的特征更鲁棒。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%821.JPG\" width=\"100%\" height=\"100%\"> 最大池化(max pooling)，即取滤波器区域内的最大值。对二维矩阵做最大池化：\n- 输入尺寸为$4 \\times 4$\n- 超参数：$f=2$，$s=2$\n- 没有参数。 \n- 输出尺寸为$2 \\times 2$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> 对三维矩阵做最大池化：\n- 输入尺寸为$5 \\times 5 \\times n_c$\n- 超参数：$f=3$，$s=1$\n- 没有参数。 \n- 输出尺寸为$3 \\times 3 \\times n_c$\n - 注意，对每一通道，分别做最大池化，故输出尺寸的通道数等于输入尺寸的通道数。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 平均池化(average pooling)，即计算滤波器区域内的平均值。其它同上。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%824.JPG\" width=\"90%\" height=\"90%\"> 总结：\n- 池化层的超参数：\n - 滤波器尺寸(filter size)：$f$\n - 步长(stride)：$s$\n - 极少使用填充(padding)\n - 最大池化(max pooling)或平均池化(average pooling)。最大池化层更常用。\n- 常用的池化层超参数有$f=2$，$s=2$，相当于将输入尺寸(高度和宽度)缩小一半。也有$f=3$，$s=2$用法。\n- 没有参数！\n - 池化过程中没有参数需要学习。只有需要设置的上述超参数，可能是手工设置，也可能是通过交叉验证设置。\n- 输入尺寸为：$n_H \\times n_W \\times n_c$\n- 输出尺寸为： $\\lfloor \\frac{n_H-f}{s}+1 \\rfloor \\times \\lfloor \\frac{n_W-f}{s}+1 \\rfloor \\times n_c$\n - 注意到，输出尺寸的通道数与输入尺寸的通道数相同。\n\n### 卷积神经网络示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"> 该CNN为了识别0~9的数字。该CNN类似Yann LeCun提出的LeNet-5:\n- 卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B3.jpg\" width=\"100%\" height=\"100%\"> \n- 输入为0~9的数字的图像。\n- 将CONV1和POOL1称为网络的第一层(Layer 1)。\n  - 在CNN相关文献中，一种惯例是将一个卷积层和一个池化层合称为一层；一种惯例是将一个卷积层称为一层，一个池化层称为一层。\n  - 本课程在统计网络层数时，只统计有权重的层，即将CONV1和POOL1作为网络第一层。 \n- 将CONV2和POOL2称为网络的第二层(Layer 2)。然后，将POOL2的输出平整化为维度为$400\\times 1$的向量。\n- 全连接层FC3为网络第三层(Layer 3)。全连接层即为标准神经网络结构。输入的400个单元和该层的120个单元每个都相连接，故称为全连接层。权重$W^{[3]}$的维度为$(120,400)$。偏置$b^{[3]}$的维度为$(120,1)$\n- 全连接层FC4为网络第四层(Layer 4)。\n- 最后的输出层为softmax层，由10个神经元构成(识别0~9的数字)。\n- 注意到，随着网络深度的加深，高度$n_H$和宽度$n_W$会减小，而通道数$n_c$会增加。\n- CNN的另一种常见模式是一个或多个卷积层后面跟一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 展示上图中CNN的各层的激活值维度和参数数量：\n- 池化层没有参数。\n- 卷积层的参数相对较少，许多参数都存在于全连接层。\n- 随着网络的加深，激活函数的尺寸逐渐变小。减小的太快会影响网络性能，故是逐渐减小。\n\n### 为什么使用卷积层？\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%821.JPG\" width=\"90%\" height=\"90%\"> 相比标准神经网络，CNN的优势之一就是参数数目要少得多：\n- 对于一张$32 \\times 32 \\times 3$的图片。卷积层的超参数为$f=5$，卷积核的个数为$n_c=6$。则输出维度为$28 \\times 28 \\times 6$。\n- 输入尺寸为$32 \\times 32 \\times 3=3072$，输出尺寸为$28 \\times 28 \\times 6=4704$。\n- 若采用标准神经网络，则参数$W$的维度为$(4704,3072)$，共$4704 \\times 3072+4704 \\approx 14m$个参数。仅对于$32 \\times 32 \\times 3$的小图片，就有如此多的参数。\n- 而采用卷积层，每个卷积核的参数为$5\\times 5 +1=26$，有6个卷积核，则共有$6 \\times 26= 156$个参数。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> CNN的参数数目少的原因有两个：\n- 参数共享：一个特征检测器（例如垂直边缘检测器）如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。\n- 稀疏连接：每一层的每个输出只与一小部分输入有关。\n - 如图，输出矩阵的左上角的0，只与输入矩阵的左上角的$3\\times 3$的矩阵有关。其他像素值都不会对该输出产生影响。\n- 通过以上两种机制，CNN有较少的参数，允许我们以较小的训练集训练它，从而不易过拟合。\n- 此外，CNN善于捕捉平移不变性(translation invariance)。即CNN进行分类时，不易受物体所处图片位置发生平移的影响，更鲁棒。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 如何训练一个CNN：\n- 为了构建一个猫的检测器。\n- 训练集为$(x^{(1)},y^{(1)})...(x^{(m)},y^{(m)})$，$x^{(i)}$为输入图像，$y^{(i)}$为标签。\n- 如图，若选定了CNN结构：包含输入层，卷积层，池化层，全连接层和softmax输出层。\n- 依然同之前课程一样，定义代价函数$J=\\frac{1}{m}\\sum_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})$。\n- 采用优化算法(如梯度下降/Momentum/RMSprop/Adam)，来优化网络中的所有参数，去减小代价函数$J$。\n\n# 2.深度卷积模型：案例学习\n## 2.1 案例学习\n### 为什么进行案例学习\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0.JPG\" width=\"90%\" height=\"90%\">  \n- 这一周会讲解的经典CNN模型：\n - LeNet-5\n - AlexNet\n - VGG\n- 另外，还会讲解：\n - ResNet\n - Inception \n\n### 经典卷积网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C1.JPG\" width=\"100%\" height=\"100%\"> LeNet-5由Yann LeCun于1998年提出，用于识别0~9的手写数字：\n- 针对灰度图像，故输入图片维度为$32\\times 32\\times 1$\n- 对于卷积层，那时人们不使用填充(padding)，即通常采取\"valid\" convolution。\n- 对于池化层，那时人们更多使用平均池化(现在通常使用最大池化)。\n- 该模型约有6万个参数。\n- 后来沿用的模式一：**随着网络的加深，图像的高度$n_H$和宽度$n_W$在减小，而通道数$n_c$在增加**。\n- 后来沿用的模式二：一个或多个卷积层接一个池化层，一个或多个卷积层接一个池化层，然后是几个全连接层，然后是输出层。\n- 对于激活函数，那时人们使用的是sigmoid/tanh(如今通常使用ReLU，AlexNet提出)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C2.JPG\" width=\"100%\" height=\"100%\"> AlexNet是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton于2012年共同提出，用于识别ImageNet中的1000类图像：\n- AlexNet模型与LeNet-5模型类似，但更大，约有6千万个参数。\n- 对于激活函数，AlexNet使用了ReLU激活函数。\n- 当时，GPU还较慢，AlexNet采用了在两个GPU上并行计算。\n- AlexNet中含有一种特殊的层，叫做局部相应归一化层(Local Response Normalization, LRN)。但后来研究者发现效果有限，故如今并不使用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C3.JPG\" width=\"100%\" height=\"100%\">\n- VGG-16中一个精彩的地方在于，没有那么多的超参数，专注于构建简单的网络结构：\n - 对于卷积层，只使用$f=3$，$s=1$，\"same\"填充。\n - 对于池化层，只使用$f=2$，$s=2$的最大池化层。\n- 每次池化后，图像的高度$n_H$和宽度$n_W$缩小一半。每一组卷积层之后，通道数$n_c$增加一倍，直到512。\n- 缺点：包含1亿三千万个参数，以现在的标准来看，都是非常大的网络，有太多参数需要训练。\n- 优点：VGG-16的结构并不复杂，**结构很规整**，这一点非常吸引研究者。\n- VGG-16中的16指的是包含权重的卷积层、全连接层和输出层(未计没有参数的池化层)。\n- VGG-19的表现与VGG-16差不多，更多的人使用VGG-16。\n\n### ResNets\n由于梯度消失(vanishing gradients)和梯度爆炸(exploding gradients)的原因，非常非常深的网络是难以训练的。这一节学习跳跃连接(skip connection)，它可从某一层网络获取激活值，然后喂给更深的一层网络。通过跳跃连接，即可构建出ResNets(Residual Networks)，让我们可以训练非常非常深的网络。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets1.JPG\" width=\"100%\" height=\"100%\"> ResNet是由残差模块(residual block)构建的，上图介绍残差模块：\n- 残差模块的主路径(main path)为：$a^{[l]}$ -> 线性操作 -> ReLU(得$a^{[l+1]}$) -> 线性操作 -> ReLU(得$a^{[l+2]}$)。\n- 残差模块的捷径(short cut)/跳跃连接为：$a^{[l]}$ 直接隔层与$l+2$层的线性输出相连，与$z^{[l+2]}$共同通过激活函数（ReLU）输出 $a^{[l+2]}$。\n- 具体公式如下：\n - $z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}$\n - $a^{[l+1]}=g(z^{[l+1]})$\n - $z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}$\n - $a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets2.JPG\" width=\"100%\" height=\"100%\"> 通过堆叠许多残差模块在一起，即构建成ResNet：\n- 在ResNet论文中，将非Residual Network称为Plain Network。\n- 在一个Plain Network中，加上捷径/跳跃连接，如图中每两层构成一个残差模块，共5个残差模块。整体即构成一个残差网络(residual network)。\n- 若用优化算法优化一个朴素的网络(plain network)，其效果如图：\n - 理论上：随着网络深度的加深，训练误差应越来越小。\n - 实际上：起初，训练误差会降低。但随着层数的增多，训练误差上升。\n- 若用优化算法优化一个ResNet，其效果如图：\n - 随着网络深度的加深，训练误差越来越小。\n- 跳跃连接确实有助于解决梯度消失和梯度爆炸的问题，让我们在训练十分深层的网络时得到好的性能。\n\n### RestNets为何有效\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%881.JPG\" width=\"100%\" height=\"100%\"> 给一个深度网络，增加了一个残差模块后，网络的深度得到了增加：\n- $a^{[l+2]}$的表达式为：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})$。\n- 注意到，如果使用L2正则化或权重衰减，将会使得$W^{[l+2]}$不断减小。假设$W^{[l+2]}=0$，$b^{[l+2]}=0$（发生梯度消失）。\n- 那么，$$a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}$$（$a^{[l]}$本就大于等于0，再经过ReLU激活函数，还是$a^{[l]}$本身）。\n- 以上结果表明：恒等函数(identity function)对于残差模块来说，非常容易学习。因此，尽管增加了残差模块，一方面没有伤害网络的效率，另一方面还提升了网络的性能。\n- 残差网络有效的原因：\n - 残差模块学习恒等函数非常容易(没有伤害网络的学习效率)。\n - 残差模块的添加起码不会降低网络的表现，很多时候可以提升网络的表现。\n- 另外，残差网络的另一个细节是：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中$z^{[l+2]}$与$a^{[l]}$拥有相同的维度：\n - 故ResNets中使用了许多\"same\"卷积。\n - 若$a^{[l+2]}$与$a^{[l]}$维度不一样，可以引入矩阵$W_s$，使得$W_s \\cdot a^{[l]}$的维度与$a^{[l+2]}$一致，即$$a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})$$。矩阵$W_s$可以设置为通过网络学习的参数矩阵，也可以设置为固定矩阵(如只是给$a^{[l]}$进行零填充)。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%882.JPG\" width=\"100%\" height=\"100%\"> 简单分析ResNets结构特点：\n- ResNets中采用了很多$3\\times 3$的same卷积。\n - same卷积是为了进行$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中的$z^{[l+2]}+a^{[l]}$。\n- 池化层后需调整$W_s$的维度，即进行$$a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})$$。\n- ResNets的网络结构是几个卷积层接一个池化层，然后重复，然后是一个全连接层，然后是softmax输出层。\n\n### Network in NetWork以及1x1卷积\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/netwrok%20in%20network1.JPG\" width=\"100%\" height=\"100%\">\n- 如图上半部分，对于单通道的二维矩阵，进行$1\\times 1$卷积的效果就是乘以一个数字。\n- 如图下半部分，对$6 \\times 6 \\times 32$的体，卷积核为$1 \\times 1 \\times 32$，进行卷积的效果是：\n - 对于输入体的36个切片，每个切片的维度都为(1,1,32)。每一个切片都与卷积核逐元素相乘，然后求和，得到一个实数，即输出矩阵中的一个绿点。\n - 若应用在CNN中，则相当于：输入体中的每一切片逐元素乘以卷积核中的权重，然后求和，加上偏置，然后进行ReLU激活，如输出矩阵中的一个黄点。\n - 若有多个卷积核，则输出结果为多通道。\n- 因此，$1\\times 1$卷积应用在CNN中，则可以理解为：36个切片中的32个单元，与#filters中的每个卷积核进行了全连接，输出维度为$6 \\times 6 \\times n_c^{[l+1]}$，其中$$n_c^{[l+1]}= \\# filters$$。\n- 此方法称为$1\\times 1$卷积或Network in NetWork。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/network%20in%20network2.JPG\" width=\"90%\" height=\"90%\"> $1\\times 1$卷积可以用来缩小通道数量：\n- 输入维度是$28 \\times 28 \\times 192$，通过32个$1\\times 1$卷积核(准确地说，维度为$1\\times 1\\times 192$)，输出为$28 \\times 28 \\times 32$，缩小了通道数。\n\n总结：\n- $1\\times 1$卷积**给网络增加了非线性，可以让网络学习更复杂的函数**。\n- 通过$1\\times 1$卷积，**可减少或保持或增加通道数**。\n\n### Inception Network动机\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA1.JPG\" width=\"90%\" height=\"90%\"> Inception网络的基本思想是：代替人为选择卷积核尺寸以及是否使用池化层，而是将它们都添加进网络，然后将输出串联起来，然后让网络去学习参数，去决定采用哪些组合：\n- 输入维度为$29\\times 28 \\times 192$\n- 通过$1\\times 1$的same卷积，使得输出为$28 \\times 28 \\times 64$\n- 通过$3\\times 3$的same卷积，使得输出为$28 \\times 28 \\times 128$\n- 通过$5\\times 5$的same卷积，使得输出为$28 \\times 28 \\times 32$\n- 通过最大池化层，$s=1$，使用填充，使成为same-pool，使得输出为$28 \\times 28 \\times 32$\n- 将所有输出串联起来，维度为$28 \\times 28 \\times 256$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA2.JPG\" width=\"90%\" height=\"90%\"> 上图中描述的Inception模块中有一个问题，就是计算成本的问题：\n- 集中讨论上图中的$5 \\times 5$的卷积核\n- 进行该卷积计算，需要进行的乘法次数为：\n - 输出个数为：$28\\times 28\\times 32$\n - 每个输出需进行的乘法次数为：$5\\times 5\\times 192$\n - 故需进行的乘法次数为：$(28\\times 28\\times 32)\\times (5\\times 5\\times 192)\\approx 120m$\n- 即使用现代计算机，计算1.2亿次计算，也是相当昂贵的操作。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA3.JPG\" width=\"90%\" height=\"90%\"> 通过$1\\times 1$卷积层，降低计算成本：\n- 结构如图，先通过$1\\times 1$卷积，再进行$5\\times 5$卷积，最终输出和上图相同。\n- 加入$1\\times 1$卷积后，进行两次卷积计算，需要进行的乘法次数为：\n - $1\\times 1$卷积需要的乘法次数：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)$\n - $5\\times 5$卷积需要的乘法次数：$(28\\times 28\\times 32)\\times (5\\times 5\\times 16)$\n - 进行两次卷积计算，需要进行的乘法次数为：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)+(28\\times 28\\times 32)\\times (5\\times 5\\times 16)\\approx 12.4m$\n- 通常我们把该$1\\times 1$卷积层称为“瓶颈层”(bottleneck layer)，因为它是网络中最小的那个部分。**先通过“瓶颈层”缩小网络，然后再扩大网络，显著降低了计算成本**，乘法计算次数从120m减少为12.4m。\n\n### Inception Network\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork1.JPG\" width=\"90%\" height=\"90%\"> 正式介绍Inception模块：\n- 输入为前一层的激活函数。\n- 单独的$1\\times 1$卷积层，输出维度为$28 \\times 28 \\times 64$。\n- 先是$1\\times 1$卷积层，再接$3\\times 3$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 128$。\n- 先是$1\\times 1$卷积层，再接$5\\times 5$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 32$。\n- 先是$f=3$，$s=1$的same最大池化层，再接$1\\times 1$卷积层(为了降低通道数)，输出维度为$28 \\times 28 \\times 32$。\n- 串联(concatenate)所有输出，输出维度为$28 \\times 28 \\times 256$。(Caffe中的concat层，实现此串联操作。)\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetworkk2.JPG\" width=\"100%\" height=\"100%\"> 正式介绍Inception Network，如图：\n- Inception Network由很多Inception模块构成。\n- Inception Network中的另一个细节是：在中间层设置了两个辅助softmax分类器，它们保证了即便是中间层的隐藏神经元计算的特征，在预测图像类别时，表现也不太差。它们在Inception Network起着正则化的效果，帮助防止过拟合。\n- Inception Network也称为GoogleNet。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork3.JPG\" width=\"90%\" height=\"90%\"> \n- Inception Network中“Inception”取自莱昂纳多的电影《Inception》。\n\n## 2.2 使用卷积网络的实用建议\n### 使用开源实现\n- 对于许多经典的神经网络，因为许多细节问题（如超参数的调节，学习率衰减或其它）而很难实现复现。因此，仅靠论文去从零实现，是很困难的。\n- 建议从其他研究者贡献出的开源代码开始研究或使用，如在Github中搜索并获取开源代码。\n\n### 迁移学习\n你如果要做一个计算机视觉应用，相比于从头(随机初始化权重)开始训练权重，如果你下载别人已经训练好的权重，然后把它当做预训练，然后迁移到你感兴趣的任务中，通常能够取得更快的进展。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.JPG\" width=\"100%\" height=\"100%\"> 假设你训练猫分类器，能够分类Tigger，Misty和Neither。\n- 如图第一行，若你没有关于Tigger，Misty大量图片，即训练集很小：\n - 下载经典网络的代码以及权重，删去最后的Softmax层，创建你自己的Softmax层(Tigger/Misty/Neither)。\n - 将你下载的网络，看作是冻结的，冻结该网络的所有参数。将别人训练好的权重，作为初始权重，只训练和你自己的Softmax层有关的参数。\n - 这样，即使你只有一个小的训练集，也能取得好的性能。\n - 加速训练的技巧：由于前面的层都冻结了，即相当于一个不需要改变的固定函数(相当于取输入$X$，然后映射到选用的最后一层的激活函数)。预先计算这个固定函数的得到的特征或是说激活值，然后将它们存到硬盘中（对于每一周期(epoch)，不用重复遍历数据集计算激活值）。然后将它们作为输入，相当于训练一个浅层的softmax模型。\n- 如图第二行，若有一个更大的训练集：\n - 可以冻结更少的层，如图。然后训练后面的所有层（构建自己的Softmax层后）。\n - 也可将未冻结的后面几层全部删去，构建自己的几个隐藏层和Softmax层，然后只训练后面几层。\n - 模式就是：如果有更多的数据，那么你需要冻结的层数就更少，你需要训练的末端的层数就更多。\n- 如图第三行，如果你有足够多的大量的训练集：\n - 将下载的权重作为初始权重(代替随机初始化)，重新训练网络的所有层。\n- 在所有深度学习的应用中，计算机视觉领域是一个经常用到迁移学习的领域。除非你有极其大的数据集和非常大的计算预算，能让你能够自己从头训练所有东西，那么迁移学习总是值得你考虑的方案。\n\n### 数据增强\n数据增强是经常用来提升计算机视觉系统性能的技巧。计算机视觉任务是一项相当复杂的工作，你需要输入图像中的像素值，然后弄清楚图片中有什么，似乎你需要学习一个相当复杂的函数。对于几乎所有的计算机视觉任务，通常的问题是数据远远不够。因此，对于计算机视觉任务，数据增强通常都会有帮助。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA1.JPG\" width=\"100%\" height=\"100%\"> 介绍了常用的数据增强方法：\n- 镜像(mirroring)：以垂直轴为基准，进行镜像。\n- 随机裁剪(random cropping)：裁剪出原图像中的一部分。\n- 理论上，还有一些方法，如旋转(rotation)，剪切(shearing)，local warping(局部弯曲)等。但因为过于复杂，实践中很少使用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA2.JPG\" width=\"50%\" height=\"50%\"> 第二种经常使用的数据增强方法：\n- 色彩转换(color shifting)/色彩失真(color distortion)：分别对图片的RGB通道中的像素值进行增加或者减少，改变图片色彩。\n - 解释：进行色彩转换，希望能让算法对图片的色彩的改变更具鲁棒性。\n - AlexNet论文中采用了“PCA color augmentation”：减少主要色调成分(如R和B通道)的像素值多一点，减少G通道的像素值少点，使得整体的色调保持一致。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA3.JPG\" width=\"90%\" height=\"90%\">\n- 可通过CPU/GPU的不同进程，并行地进行数据增强和训练。\n\n### 计算机视觉的现状\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B61.JPG\" width=\"90%\" height=\"90%\"> \n- 对于图像识别(image recognition)任务，尽管今天我们有很大的数据集，但仍想要更多的数据。\n- 对于目标检测(object detection)任务，我们有着更少的数据，因为标注边框这一步的成本太高。\n\n**学习算法有两个主要的知识来源：一是带标签的数据；二是手工设计的特征或网络结构或其他组件**：\n- 当有大量数据时，人们倾向于使用更简单的算法和更少的手工工程。\n- 而当有较少量的数据时，人们倾向于使用更多的手工工程\n - 解释：但当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的好的途径。\n - 举例：计算机视觉是在试图学习一个非常复杂的函数，因此我们总感觉没有足够的数据来满足我们的需求。在计算机视觉的初期，拥有的数据量很小，所以依赖手工设计的特征。近几年，数据量剧增，但对于计算机视觉还是不够，因此人们设计复杂的网络结构(包含很多超参数)。对于目标检测任务，拥有的数据量比图像识别任务更少，因此人们手工设计了许多组件。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B62.JPG\" width=\"100%\" height=\"100%\"> 在基准数据集或竞赛中取得好成绩的技巧：\n- 集成(ensembling):\n - 独立训练多个(3~15)网络，然后平均它们的输出。\n- 在测试阶段进行多裁剪(multi-crop)：\n - 在测试阶段，对于一张测试图片，通过镜像(mirroring)以及随机裁剪(random cropping)的方式，获得该图像的多个版本。然后平均它们的测试结果。\n- 集成(ensembling)方式占用过多内存且运行速度慢；在测试阶段进行多裁剪(multi-crop)，运行速度慢。因此它们在实际应用中没有意义。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B63.JPG\" width=\"90%\" height=\"90%\"> 若你要建立一个实际系统，采用以下步骤，能让你的应用进行的更快：\n- 从使用文献中的网络结构开始。\n- 使用开源的代码实现。\n - 因为开源代码已经解决了所有的繁琐细节，如学习率衰减或其他超参数。\n- 使用预训练的模型然后用你的数据集微调。\n - 因为其他人可能已经在多个GPU上花了几个星期对超过一百万张图片进行训练后，得到这个模型。\n\n# 3.目标检测\n## 3.1 检测算法\n### 目标定位\n目标定位(object localization)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D1.JPG\" width=\"90%\" height=\"90%\"> 图像分类任务与目标检测任务的区别：\n- 图像分类(Image classification)：对于给定图像，预测出类别（通常只有一个较大物体在图片中央）。\n- 分类且定位(Classification with Localization)：对于给定图像，预测类别，且给出物体在图片中的位置，即标出包围框(bounding box)（通常只有一个较大物体在图片中央）。\n- 检测(Detection)问题：图片中可存在多个属于不同类别的物体，对每个物体分类且定位。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D2.JPG\" width=\"100%\" height=\"100%\"> 分类且定位的实现方法：\n- 图像分类的方式就是构建CNN，然后通过softmax分类层进行分类。\n - softmax层有四个神经元，分别对应行人(pedestrain)，车辆(car)，摩托车(motorcycle)和背景(background)四类。\n- 要实现定位，修改输出层，通过增加神经元，来输出表示包围框的四个数字：`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`。\n - `$b_x$`，`$b_y$`对应包围框的中点，`$b_h$`，`$b_w$`分别对应包围框的高和宽。\n - 本课程约定，以图像的左上角为$(0,0)$点，右下角为$(1,1)$点，横向为$x$方向，纵向为$y$方向。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D3.JPG\" width=\"90%\" height=\"90%\"> 为了用监督学习算法解决分类且定位任务，需要定义训练集$(x,y)$，其中标签$y$该这样定义：\n- $$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ] $$。其中，$$Pc$$表示是否检测到目标，$$Pc=1$$代表图片中检测到目标。$$Pc=0$$代表图片中未检测到目标。\n- 如上图中的左图，检测到目标，$Pc=1$。训练集中应标注标签：$$ \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 如上图中的右图，未检测到目标，$Pc=0$，则$Pc$后面参数都没有意义，都可以忽略。训练集中应标注标签：$$\\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]$$\n\n最后，对于神经网络的损失函数，若全部使用平方误差形式，有两种情况：\n- 若$y_1=1$,即$Pc=1$，那么：$$L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$$\n- 若$y_1=0$,即$Pc=0$，那么：$$L(\\hat y,y)=(\\hat y_1-y_1)^2$$\n- 这里用平方误差简化了描述过程，在实际应用中，可以对$Pc$使用逻辑回归损失，对`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`使用平方误差损失，对于$c_1$，$c_2$，$c_3$使用softmax损失。\n\n### 特征点检测\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.JPG\" width=\"100%\" height=\"100%\"> \n- 上节中，通过让网络输出四个实数(`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`)的方式，指定了想要定位的物体的包围边框。\n- 在更一般的情况下，可以通过神经网络输出图像中关键特征点的$(x,y)$坐标（这些点称作landmarks），来实现对这些关键特征点的检测。\n\n上图中举了两例：\n- 例1：人脸关键特征点检测。\n - 在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人脸特征点的坐标。\n - 如图，在输出层中，第一个神经元代表是否属于人脸，第二个神经原代表特征点1的$x$坐标，第三个神经元代表特征点1的$y$坐标，等等。\n- 例2：人体姿态检测。\n - 在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人体关键特征点的坐标。\n- 想要训练这样的网络，需要一个带标签的训练集$(X,Y)$。\n - 其中在人工标注关键特征点时，对于每一个样本，每一特征点代表的含义顺序，必须一致。如对于人脸特征点检测，特征点1代表左眼角，特征点2代表右眼角等等。对于人体姿态检测，特征点1代表左肩，特征点2代表胸部中点，特征点3代表右肩等等。\n \n### 目标检测\n本节以车辆检测为例，介绍基于滑动窗口的目标检测算法。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B1.JPG\" width=\"100%\" height=\"100%\"> 第一步，构建CNN以进行车辆分类：\n- 对于训练集$(x,y)$，$x$是适当剪切的图片。如上图，$x$为剪切后的汽车图片样本，即剪去其他部分，只有车辆在图片中央并占据了整个图片。\n- 然后即可训练CNN。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 第二步，滑动窗口检测(sliding window detection)：\n- 选择固定大小的矩形窗口，按某个步长，滑动遍历整个图片。滑动窗口每到达一个位置，就将该窗口内的图片送入CNN进行分类。CNN输出1(是汽车)或者0(背景，不是汽车)。\n- 然后选择一个更大的窗口，继续滑动窗口检测操作。\n- 然后再选择一个更大的窗口，继续滑动窗口检测操作。\n\n基于滑动窗口检测目标检测算法的缺点：\n- 计算成本高。滑动窗口到达的每一个位置的图片，都需要用CNN进行处理。\n- 如果选用大步长，窗口数会减少，但会影响性能。\n- 如果选用小步长，窗口数会剧增，计算成本过高。\n\n### 滑动窗口的卷积实现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B01.JPG\" width=\"100%\" height=\"100%\"> **用卷积层替换全连接层**：\n- 上图中第一行是用来进行分类的CNN结构：输入为尺寸为$14\\times 14 \\times 3$的图片，卷积层，池化层，全连接层，全连接层，然后是softmax分类层（含四个结点，每个结点对应一个类别的概率）。\n- 上图中的第二行是将全连接层转换为卷积层后的CNN结构：\n - 首先通过400个$5\\times 5$的卷积核(每个卷积核的尺寸为$5\\times 5\\times 16$)，将输出尺寸变为$1\\times 1\\times 400$。(将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)\n - 然后通过400个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，将输出尺寸变为$1\\times 1\\times 400$。(**将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)\n - 然后通过4个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，输出层的输出尺寸为$1\\times 1\\times 4$，然后进行softmax激活函数，作为最终的输出结果。(将此处输出的$1\\times 1\\times 4$的体，视为原softmax输出层的4个结点。)\n- 用卷积层替换全连接层的目的是为了使得能够输入任意尺寸的图片，而如果存在全连接层，则输入和输出的维度必须是固定的。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B02.JPG\" width=\"100%\" height=\"100%\"> 基于滑动窗口的目标检测算法的卷积实现：\n- 上图中第一行的输入为一个滑动窗口内的图像，即尺寸为$14\\times 14 \\times 3$的体，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$1\\times 1\\times 4$的体，相当于softmax输出层的4个输出结点。\n- 上图中第二行的输入为一张$16\\times 16 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$2\\times 2\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。4个$1\\times 1\\times 4$的体即对应4个滑动窗口的输出结果。\n- 上图中第三行的输入为一张$28\\times 28 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$8\\times 8\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。64个$1\\times 1\\times 4$的体即对应64个滑动窗口的输出结果。\n- 该模型源于OverFeat。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B03.JPG\" width=\"100%\" height=\"100%\"> 总结：\n- 原始的基于滑动窗口的目标检测算法，会分别将每一个滑动窗口内的图像，单独给CNN处理。并且这样会使得很多CNN的处理过程是重复的。\n- 而基于滑动窗口的目标检测算法的卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的窗口图像共享了许多计算。\n- 基于滑动窗口的目标检测算法的卷积实现，极大地提高了效率。但存在一个缺点：不能输出最准确的包围边框。下节解决这个问题。\n\n### 包围边框预测\n上节中基于滑动窗口的目标检测算法的卷积实现，其计算效率很高，但存在不能输出非常准确的包围边框的问题。本节介绍YOLO(You Only Look Once)算法，它可以得到准确的包围边框。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B1JPG.JPG\" width=\"80%\" height=\"80%\"> \n- 基于滑动窗口的目标检测算法，很有可能没有一个合适的滑动窗口，能够完美匹配图中的汽车的位置，即红色包围边框。最接近的，可能只是图中的蓝色窗口。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 介绍YOLO算法：\n- YOLO算法首先将原始图片分割成$n\\times n$网格，每个网格代表一块区域。为简化说明，将图片分成$3 \\times 3$网格。\n - 实际应用中采用更精细的网格，如$19\\times 19$。更精细的网格也可以使得多个物体分配到同一格子的概率减小。\n- 然后，采用本周第一个视频讲述过的图像分类且定位算法(image classification and localization algorithm)，应用在9个格子的每一个格子上。\n- 训练集$(x,y)$的构建：\n - $x$即为输入图像矩阵，例如尺寸为$100 \\times 100 \\times 3$\n - 标签$y$的维度为$3 \\times 3 \\times 8$，即共9个$1 \\times 1 \\times 8$，其中每一个$1 \\times 1 \\times 8$代表着一个格子的标签。\n - 每个格子对应的$1 \\times 1 \\times 8$的标签，同本周第一个视频讲述过的一样。$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$\n - 需强调：将物体分配给哪个格子是由物体的中点$(b_x,b_y)$属于哪个格子决定的。\n - 对于一个格子可能存在多个物体的情况，稍后讨论。\n- 构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 8$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的进行训练。\n\n总结：\n- 该算法和图像分类且定位算法很相似，它显示的输出包围边框的坐标，它能让神经网络输出任意长宽比的坐标，而不收到滑动窗口的步长的限制。因此，该算法能够输出精确的包围边框。\n- 此外，该算法也是卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的网格共享了许多计算。正因为它是卷积实现，因此该算法的效率非常高，运行得非常快，能达到实时目标检测。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B3.JPG\" width=\"100%\" height=\"100%\"> 如何定义包围边框，即如何编码(encode)`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`：\n- 如图，以每个网格的左上角为$(0,0)$点，以右下角为$(1,1)$点。\n- 中心点`$b_x$`，`$b_y$`为距离$(0,0)$点的水平距离和垂直距离相对网格边长的比值。因此，`$b_x$`和`$b_y$`在0~1之间。\n- 高度`$b_h$`和宽度`$b_w$`，为包围边框的高和宽与网格边长的比值。因此，`$b_h$`和`$b_w$`可能大于1。\n- 如图，图中样本$x$对应的标签应该为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ 0.4 \\\\ 0.3 \\\\ 0.9 \\\\ 0.5 \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 当然编码包围框的方式很多，YOLO论文中也交待了其他更复杂的参数化方式。但本课程给出了此种方法是合理且可使用的一种方式。\n\n### 交并比\n交并比(Intersection over Union, IoU)是评价目标定位算法准确性的指标。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%A4%E5%B9%B6%E6%AF%94.JPG\" width=\"100%\" height=\"100%\"> 交并比讲解：\n- 如图，紫色边框为预测边框，红色边框为真实边框。\n- 黄色阴影部分为两边框区域的交集(Intersection)，绿色阴影部分为两边框区域的并集(Union)。\n- 交并比(Intersection over Union, IoU)即为：$$IoU=\\frac{Intersection}{Union}$$\n - 一般人为规定当$IoU \\geq 0.5$时，预测的包围边框是正确的。\n- 更一般的说，IoU衡量了两个包围边框的重叠程度。\n\n### 非极大值抑制\n目标检测算法可能会检测同一个目标多次。非极大值抑制(Non-max Suppression, NMS)可以确保对每个对象只检测一次。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B61.JPG\" width=\"80%\" height=\"80%\"> 如图，以YOLO算法检测汽车为例，对于该图片，会有多个网格对同一汽车做出检测。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B62.JPG\" width=\"100%\" height=\"100%\"> 极大值抑制的效果：\n- 如图，当运行目标检测算法时，最终出现了对同一个对象进行多次检测的情况。\n- 通过非极大值抑制，清理了这些检测结果。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B63.JPG\" width=\"100%\" height=\"100%\"> 非极大值抑制的实现细节：\n- 假设只检测车辆，用YOLO算法检测这张图片后的输出的维度为$19\\times 19 \\times 5$。共$19\\times 19 = 361$个格子，每一个格子的输出为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw  \\end{matrix} \\right ]$$。其中，$p_c$为存在对象的概率，在此处即是车辆的概率。\n- 第一步，丢弃所有$p_c \\leq 0.6$的包围框。\n - 在编程作业中，这一步作为单独的步骤，不在NMS之内。先算得分($p_c$与$c_1$或$c_2$或$c_3$相乘)再取阈值。\n- 第二步，只要有剩余包围框，则一直循环：\n - 选择$p_c$最大的包围框为一个预测包围框。\n - 舍弃所有与上一步中的预测包围框的$IoU\\geq 0.5$的剩余的包围框。\n- 另外，该节只是介绍了只检测车辆这一类目标的情况，如果想要检测三类目标(如行人，车辆，摩托车)，那么每个格子的输出向量就会有额外三个分量($c_1$，$c_2$，$c_3$)。正确的做法是，对每个类别都独立进行一次非极大值抑制，即进行三次非极大值抑制。\n \n### Anchor Boxes\n到目前位置，我们介绍的是每个网格只能包含一个物体，若一个网格包含两个或以上物体，则无法处理。使用anchor boxes可以解决这个问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes1.JPG\" width=\"100%\" height=\"100%\">\n- 如图，对图片采用$3\\times 3$的网格划分。汽车和行人的中点，几乎重叠，都落在一个格子中。\n - 此前每个格子的输出定义为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$，无法描述该情况，只能舍去一个物体，只描述一个物体。\n- 预先定义两个不同形状的anchor box：Anchor box1和Anchor box2。\n - 通常使用更多的anchor box，如5个或更多。这里为了方便讲解，只定义两个。\n- 则上图对应的输出标签应为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$。其中，前8个分量为与Anchor box1相关的输出，后8个分量为与Anchor box2相关的输出。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes2.JPG\" width=\"80%\" height=\"80%\"> Anchor box算法：\n- 在之前(不采用Anchor box时)：我们将每个训练图像中的物体分配给其中点所处的那个网格。输出$y$的维度为$3\\times 3\\times 8$。\n- 采用两个Anchor box后：我们将将每个训练图像中的物体分配给其中点所处的那个网格，以及分配给与该物体包围框的IoU最大的那个Anchor box。输出$y$的维度为$3\\times 3\\times 16$，即$3\\times 3\\times (8\\times 2)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes3.JPG\" width=\"90%\" height=\"90%\"> 示例：\n- 图中一个格子中包含两个物体，其中行人的包围框应该分配给Anchor box1，车辆包围框应该分配给Anchor box2，因此，该图像的输出应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\n- 若某格子，只含一个车辆物体，则其输出应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\n- 当遇到一个格子包含三个或更多物体时，该算法无法处理。当遇到两个物体被分配给同一Anchor box时，该算法也无法处理。\n- 另外，人们通常人工指定Anchor box的形状，可以选择5~10个形状，覆盖你想要检测的对象的各种形状。后期的YOLO论文中介绍了通过$k$均值来自动选择Anchor box的高级方法。\n\n### YOLO算法\n将所有学过的组件组合在一起，构成YOLO目标检测算法。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%951.JPG\" width=\"100%\" height=\"100%\"> 训练阶段：\n- 假设检测三类物体：行人，车辆和摩托车。采用的是$3 \\times 3$的网格划分。采用两个anchor box。\n- 对于训练集$(x,y)$：\n - $x$为输入图像，维度为$100 \\times 100 \\times 3$\n - 标签$y$的维度为$3 \\times 3 \\times 16$，即$3 \\times 3 \\times (2\\times 8)$。每个$1 \\times 1 \\times 16$对应一个网格的目标标签，共9个网格。\n - 例如对于不含物体的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]$$。对于含有车辆（分配给Anchor box2）的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 16$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的对网络进行训练。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%952.JPG\" width=\"100%\" height=\"100%\"> 预测阶段：\n- 将图片$x$输入网络，输出维度为$3 \\times 3 \\times 16$。其中，对于不包含物体的网格，其输出向量应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\end{matrix} \\right ]$$。对于包含车辆的网格，其输出向量应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\"..\"代表网络输出的一些无意义的数字（网络不会输出问号）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%95%E6%B3%953.JPG\" width=\"100%\" height=\"100%\"> 进行极大值抑制：\n- 对每一类，分别独立的进行一次非极大值抑制。即分别对行人，车辆及摩托车分别进行一次极大值抑制。\n- 最后的结果，作为算法的输出结果。\n\n### 区域建议\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE1.JPG\" width=\"100%\" height=\"100%\"> R-CNN：\n- 基于滑动窗口的目标检测算法(无论是原始的，还是卷积实现)，对于整张图片中的每一个滑动窗口，都会通过CNN去检测。对于其中很多的明显没有任务物体的窗口，通过CNN去处理它们是浪费时间的。\n- R-CNN(基于区域的CNN)的做法是尝试选出一些区域，然后通过CNN进行检测。\n - R-CNN给出区域建议(region proposals)的做法是运行图像分割算法(结果如图)，其中一些色块(如2000个)的矩形包围边框，即是给出的区域建议。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE2.JPG\" width=\"80%\" height=\"80%\">\n- R-CNN：给出建议区域(通过图像分割算法)；每次对一个区域进行分类；输出类别标签+包围边框。\n - R-CNN并不是以色块的包围边框为最后的预测包围边框，而是会输出包围边框($b_x,b_y,b_h,b_w$)，因此可以得到精确的包围边框。\n - 缺点：太慢。\n- Fast R-CNN：给出建议区域；通过滑动窗口的卷积实现去分类所有的建议区域（R-CNN一次只对一个建议区域做分类）。\n - 缺点：给出建议区域的步骤仍然过慢。\n- Faster R-CNN：用CNN进行区域建议(RPN网络)。\n - 缺点：比Fast R-CNN快，但仍比YOLO慢很多，达不到实时。\n\n吴恩达的观点：\n- 区域建议(region proposals)的思想，在计算机视觉领域有着相当大的影响，值得去了解这些算法。\n- 但这类方法需要分成两个步骤：先是得到建议区域，然后再进行分类。相比较之下，从长远的角度看，一步到位的YOLO这类算法，才是有发展前景的方向。\n\n# 4.特殊应用：人脸识别和风格迁移\n## 4.1 人脸识别\n### 什么是人脸识别\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.JPG\" width=\"80%\" height=\"80%\"> 人脸验证和人脸识别的区别：\n- 人脸验证(face verification)：\n - 输入：一张人脸图片以及姓名/ID\n - 输出：图片中是否为声称的那个人\n- 人脸识别(face recognition)：\n - 有$K$个人的数据集\n - 输入：人脸图片\n - 输出：如果输入图片中是$K$个人中的一个，则输出姓名/ID\n- 人脸验证是一对一问题，人脸识别是1对多问题，人脸识别比人脸验证更难。假设人脸验证系统的错误率是1%，那么在人脸识别中，则相应的错误率就会增加，约$K$%。因此要构建人脸识别，需要使得人脸验证模块达到很高的准确率如(99%)，才能将人脸验证模块用于人脸识别系统中，使得人脸识别系统有高准确率。\n\n### One-shot learning\n对于人类识别任务，挑战之一是要解决One-shot learning问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning1.JPG\" width=\"80%\" height=\"80%\"> \n- One-shot learning：仅从一个样本中学习，然后再次识别出这个人。\n- 如图，左侧为拥有的数据库，有四个员工的各一个样本。\n- 对于该人脸识别任务，不好的解决方法：将四个样本，通过CNN进行训练，输出层为softmax层。\n - 缺点一：如此小的训练集，不足以训练一个鲁棒的CNN。\n - 缺点二：若有新员工加入，需要修改CNN的softmax层，且需要重新训练。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning2.JPG\" width=\"80%\" height=\"80%\"> 对于该人脸识别任务，正确的解决方法：\n- 首先， 通过训练神经网络，去学习一个相似度函数(similarity function)：\n - $d(img1,img2)=degree\\ of\\ difference\\ between\\ images$\n - $d(img1,img2)≤\\tau$: 则判断为同一个人\n - $d(img1,img2)>\\tau$: 则判断为不是同一个人\n - 这样，通过相似度函数，解决了**人脸验证(face verification)**问题。\n- 然后用于人脸识别任务中，将测试图像与数据库中的每一图像进行相似度计算，找出匹配的那个人。\n- 若有新员工加入，只需将他的人脸图像加入数据库，系统依然能照常工作。\n\n### Siamese network\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C1.JPG\" width=\"80%\" height=\"80%\"> 通过Siamese network来学习相似度函数$d(img1,img2)$：\n- 如图，输入为图像$x^{(1)}$。\n- 通过典型的CNN结构(卷积层->池化层->全连接层)，最终得到全连接层输出的特征向量，其维度为$(128,1)$。\n- 该全连接层输出的特征向量可以看成是对图片$x^{(1)}$的编码(encoding)，记为$f(x^{(1)})$。\n- 要比较两张图片$x^{(1)}$和$x^{(2)}$的相似度：\n - 将$x^{(2)}$喂给上述网络，得到图片$x^{(2)}$的编码(encoding)，即$f(x^{(2)})$\n - 计算相似度函数$d(x^{(1)},x^{(2)})$，$d(x^{(1)},x^{(2)})$的定义为$f(x^{(1)})$与$f(x^{(2)})$之差的L2范数，即$d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||_2^2$\n- 该网络源自论文DeepFace。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C2.JPG\" width=\"80%\" height=\"80%\"> Siamese network学习的目标：\n- Siamese network的参数决定了$f(x^{(i)})$\n- 因此相通过学习Siamese network的参数，达到如下目的：\n - 若$x^{(i)}$，$x^{(j)}$是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较小\n - 若$x^{(i)}$，$x^{(j)}$不是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较大\n- 对于如何定义代价函数，下节介绍triplet损失函数。\n\n### Triplet loss function\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss1.JPG\" width=\"80%\" height=\"80%\"> \n- Triplet Loss需要每个样本包含三张图片：Anchor、Positive、Negative，这就是triplet名称的由来。\n- 将三张图片(Anchor,Positive,Negative)的编码简写为$f(A),f(P),f(N)$，由上一节内容可知，我们希望$f(A)$和$f(P)$的距离较小，即$||f(A)-f(P)||^2$较小，而$f(A)$和$f(N)$的距离较大，即$||f(A)-f(N)||^2$较大：\n - $||f(A)-f(P)||^2\\leq ||f(A)-F(N)||^2$\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq 0$\n- 对于上面的不等式，若$f(x^{(i)})$恒为0，会使得$f(A)=0$,$f(P)=0$,$f(N)=0$，那么上述不等式也满足。因此，对上述不等式做出如下修改，通过添加一个超参数 $\\alpha(\\alpha>0)$，以避免$f(x^{(i)})$恒为0的情况：\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq -\\alpha$\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha \\leq 0$\n - 其中，$\\alpha$也被称为间隔(margin)，类似支持向量机中的间隔(margin)。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss2.JPG\" width=\"80%\" height=\"80%\"> \n- 定义triplet loss function：给定3张图片(Anchor、Positive、Negative)，$L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha,\\ 0)$\n - 解释：若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha\\leq 0$，则$L(A,P,N)=0$，没有惩罚。\n - 若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha >  0$，则$L(A,P,N)=||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha$，较大惩罚。\n- cost function：$J=\\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})$\n- 假如训练集为1k个人的10k张图片，组成不同的三元组(Anchor、Positive、Negative)，然后进行训练网络，使用梯度下降法，最小化代价函数$J$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss3.JPG\" width=\"80%\" height=\"80%\"> 训练样本中三元组(Anchor、Positive、Negative)选择：\n- 若三元组(Anchor、Positive、Negative)是随意选择的，意为只要求Anchor和Positive是一个人，Negative是另一个人。那么，$d(A,P)+\\alpha\\leq d(A,N)$这个条件很容易满足。在训练网络的过程中，学习不到有用的东西。\n- 应该选择较难的三元组(Anchor、Positive、Negative)，来用于网络的训练。\n - 想要满足$d(A,P)+\\alpha\\leq d(A,N)$，则较难的三元组(Anchor、Positive、Negative)，意味着$d(A,P)\\approx d(A,N)$。这样算法会尽力使得$d(A,N)$变大，使得$d(A,P)$变小。在训练网络的过程中，才能学习到有用的东西。\n- 更多细节在论文FaceNet中。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss4.JPG\" width=\"80%\" height=\"80%\"> \n- 一些(Anchor、Positive、Negative)的例子。\n\n最后，现在许多商业公司构建的大型人脸识别模型都需要百万级别甚至上亿的训练样本。如此之大的训练样本我们一般很难获取。但是一些公司将他们训练的人脸识别模型发布在了网上，我们可以下载这些预训练的模型进行使用，而不是一切从头开始。\n\n### 人脸验证和二元分类\nTriplet loss 是学习人脸识别CNN的参数的好方法，还有其他的参数学习方法，即将人脸识别问题看成二元分类问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB1.JPG\" width=\"80%\" height=\"80%\">  \n- 如图，选取Siamese network，将两个全连接层的输出给一个逻辑回归单元，然后进行预测。\n- 若是同一个人，则输出1；若是不同的人，则输出0。这样就将人脸识别问题看成二元分类问题。\n- 对于最后的逻辑单元，输出$\\hat y$表达式为：\n - $\\hat y=\\sigma(\\sum_{k=1}^Kw_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)$\n - $\\hat y=\\sigma(\\sum_{k=1}^Kw_k\\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)$，上式被称为$\\chi$ 方公式，也叫$\\chi$方相似度。\n - 具体见DeepFace论文。\n- 该节可再回顾下视频。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB2.JPG\" width=\"80%\" height=\"80%\"> \n- 如图，对于此方法，$x$为一对人脸图片，输出标签为1或0。然后去训练Siamese network。\n\n## 4.2 风格迁移\n### 什么是风格迁移\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB.JPG\" width=\"80%\" height=\"80%\"> \n- 如图，列出几个神经风格迁移的例子。神经风格迁移是CNN模型一个非常有趣的应用，它可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片。\n- 一般用C表示内容(Content)图片，S表示风格(Style)图片，G表示生成的(Generated)图片。\n\n### 深度卷积神经网络学习到的是什么？\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%881.JPG\" width=\"80%\" height=\"80%\"> 可视化深度卷积神经网络的每一层学习到了什么：\n- 可视化方法：选择第一个隐藏层的一个神经元，找出使得该神经元激活值最大化的9个图像块。\n- 如图右侧，每一个$3\\times 3$的小区域，即为使得一个神经元激活值最大的9个图像块。\n- 源自论文Visualizing and understand convolutional networks。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%882.JPG\" width=\"80%\" height=\"80%\">\n可视化的结果可以理解为：\n- 第一层的隐藏神经元通常会寻找相对简单的特征，比如边缘(edge)、颜色阴影(shade of color)。\n- 第二层的隐藏神经元检测到的是纹理(texture)。越深层的神经元检测到越复杂的物体。\n- 浅层网络的感受野(receptive field)较小，深层网络的感受野较大（网络越深，感受野越大）。\n\n### 代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\">\n- 对于内容图片C，风格图片S，生成图片G：为了实现风格迁移，定义一个关于$G$的代价函数$J(G)$，用来评价生成图像的好坏。\n- 用梯度下降法最小化$J(G)$，可以生成想要的任何图片。\n- 定义生成图片G的代价函数：$$J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)$$\n - 其中，$J_{content}(C,G)$为内容代价函数，它用来衡量C的内容与G的内容有多相似。\n - $J_{style}(S,G)$是风格代价函数，它用来衡量S的内容与G的内容有多相似。\n - $$\\alpha$$,$$\\beta$$是超参数，用来调整$$J_{content}(C,G)$$与$$J_{style}(S,G)$$的权重。\n - 用$$\\alpha$$,$$\\beta$$这两个超参数来控制权重，似乎有些冗余。但原论文中就是这样，故保持一致。\n- 源自论文A neual algorithm of artistic style。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"> 在定义了$J(G)$后，为了生成新的图像：\n- 随机初始化生成图像$G$，比如G的尺寸为$100\\times 10 \\times 3$\n- 用梯度下降法去最小化$J(G)$\n - $G=G-\\frac{\\partial}{\\partial G}J(G)$\n - 不断更新G的像素值，使得$J(G)$不断减小，从而使G逐渐有C的内容和G的风格。\n- 如图右侧从随机初始化生成图像$G$，到不断更新G后G的结果。\n\n### 内容代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%86%85%E5%AE%B9%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.JPG\" width=\"80%\" height=\"80%\">\n对于$J(G)$的第一部分$J_{content}(C,G)$，它表示内容图片C与生成图片G之间的相似度。\n- 使用一个预训练好的CNN模型，例如VGG网络。C，S，G共用相同模型和参数。\n- 首先，需要选择合适的层数$l$来计算$J_{content}(C,G)$。根据上一小节的内容，CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果$l$太小，则G与C在像素上会非常接近，没有迁移效果；如果$l$太深，则G上某个区域将直接会出现C中的物体。因此，$l$既不能太浅也不能太深，一般选择网络中间层。\n- 然后计算C和G在$l$层的激活函数输出`$a^{[l](C)}$`与`$a^{[l](G)}$`。\n- $J_{content}(C,G)$的定义为：\n - $$J_{content}(C,G)=\\frac12||a^{[l](C)}-a^{[l](G)}||^2$$\n- 使用梯度下降算法，使$J_{content}(C,G)$不断减小。即可使得$$a^{[l](C)}$$与$$a^{[l](G)}$$越相似，即C和G越相似。\n\n### 风格代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\">\n- 什么是图片的风格？利用CNN网络模型，图片的风格可以定义成第$l$层隐藏层不同通道间激活函数的乘积（相关性）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\">\n- 例如我们选取第$l$层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如1通道（红色）提取的是图片的垂直纹理特征，2通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B03.JPG\" width=\"80%\" height=\"80%\">\n- 接下来我们就可以定义图片的风格矩阵（style matrix）为：\n - $$G_{kk'}^{[l]}=\\sum_{i=1}^{n_H^{[l]}}\\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}$$\n - 其中，$[l]$表示第$l$层隐藏层，$k$，$k’$分别表示不同通道，总共通道数为`$n_C^{[l]}$`。$i$，$j$分别表示该隐藏层的高度和宽度。风格矩阵`$G_{kk'}^{[l]}$`计算第$l$层隐藏层不同通道对应的所有激活函数输出和。`$G_{kk'}^{[l]}$`的维度为 `$n_c^{[l]}\\times n_c^{[l]}$`。若两个通道之间相似性高，则对应的`$G_{kk'}^{[l]}$`较大；若两个通道之间相似性低，则对应的`$G_{kk'}^{[l]}$`较小。\n- 风格矩阵`$G_{kk'}^{[l](S)}$`表征了风格图片S第$l$层隐藏层的“风格”。相应地，生成图片G也有`$G_{kk'}^{[l](G)}$`。那么，`$G_{kk'}^{[l][S]}$`与`$G_{kk'}^{[l][G]}$`越相近，则表示G的风格越接近S。\n- 这样，我们就可以定义出`$J^{[l]}_{style}(S,G)$`的表达式：\n - $$J^{[l]}_{style}(S,G)=\\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}\\sum_{k=1}^{n_H^{[l]}}\\sum_{k'=1}^{n_W^{[l]}}||G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}||^2$$\n- 定义完`$J^{[l]}_{style}(S,G)$`之后，我们的目标就是使用梯度下降算法，不断迭代修正G的像素值，使`$J^{[l]}_{style}(S,G)$`不断减小。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B04.JPG\" width=\"80%\" height=\"80%\">\n- 以上我们只比较计算了一层隐藏层$l$。为了提取的“风格”更多，也可以使用多层隐藏层，然后相加，表达式为：\n - $$J_{style}(S,G)=\\sum_l\\lambda^{[l]}\\cdot J^{[l]}_{style}(S,G)$$\n - 其中，`$\\lambda^{[l]}$`表示累加过程中各层`$J^{[l]}_{style}(S,G)$`的权重系数，为超参数。\n- 根据以上两小节的推导，最终的代价函数为：\n - $$J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)$$\n - 使用梯度下降算法进行迭代优化即可。\n\n### 从1维卷积到3维卷积\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF1.JPG\" width=\"80%\" height=\"80%\">\n- 之前介绍的CNN网络处理的都是2D图片，2D卷积的规则：\n - 输入图片维度：14 x 14 x 3\n - 滤波器尺寸：5 x 5 x 3，滤波器个数：16\n - 输出图片维度：10 x 10 x 16\n- 将2D卷积推广到1D卷积，1D卷积的规则：\n - 输入时间序列维度：14 x 1\n - 滤波器尺寸：5 x 1，滤波器个数：16\n - 输出时间序列维度：10 x 16\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF2.JPG\" width=\"80%\" height=\"80%\">\n- 对于3D卷积，其规则：\n - 输入3D图片维度：14 x 14 x 14 x 1\n - 滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16\n - 输出3D图片维度：10 x 10 x 10 x 16\n","source":"_posts/深度学习课程(四)卷积神经网络.md","raw":"---\ntitle: 深度学习课程(四)卷积神经网络\nmathjax: true\ndate: 2018-1-11 17:21:50\ncategories: \n- 深度学习\ntags:\n---\n# 1.卷积神经网络基础\n## 1.1 卷积神经网络\n### 计算机视觉\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%891.JPG\" width=\"50%\" height=\"50%\"> 举了计算机视觉中的几个典型应用：\n- 图像分类\n- 目标检测\n- 风格迁移\n\n<!-- more --> \n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%892.JPG\" width=\"80%\" height=\"80%\"> 在应用计算机视觉时，所面临的一个挑战是数据的输入可能会非常大：\n- 对$64 \\times 64$的小图片，输入特征的维度是$12288(64\\times 64\\times 3)$。\n- 对稍大的$1000\\times 1000$的图片，输入特征的维度是$3million(1000\\times 1000\\times 3)$：\n - 神经网络的输入$x\\in R^{3m}$，假设第一个隐藏层有1000个神经元，则第一层的参数$W^{[1]}$的维度为$(1000,3m)$，即包含30亿个参数。\n - 对于如此大量的参数，难以获取足够多的数据来防止过拟合。\n - 内存需要处理30个参数的神经网络，所需内存太大。\n - 要解决这个问题，需进行卷积操作。\n\n### 边缘检测示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B1.JPG\" width=\"90%\" height=\"90%\"> 以边缘检测为例，说明卷积操作是如何进行的。如图：\n- 卷积神经网络的浅层检测到的是边缘，然后是物体的部件，深层检测到整体。\n- 想要检测图像中的垂直边缘，下图继续。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 介绍卷积操作：\n- $6\\times 6$的图像(灰度图，单通道)与可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器，以步长为1，进行卷积操作，结果如图。\n - $*$ 表示卷积操作。Python中，卷积用函数conv_forward()；tensorflow中，卷积用函数tf.nn.conv2d()；keras中，卷积用函数Conv2D()。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B3.JPG\" width=\"90%\" height=\"90%\"> \n- $6\\times 6$的图像(灰度图，单通道)的左半部分像素强度较大，即较白，右半部分像素强度较小，故较暗（其实灰度图中白为255，黑为0）。\n- 仍是上图中可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器。左侧较白，中间较暗，右侧最暗。\n- 卷积结果如图所示。输出图像像中中间有一条较白的宽带，即垂直边缘。\n - 输出图像中边缘太粗，是因为图像过小，若对$1000\\times 1000$的图像进行卷积，输出图像中的边缘将不会显得这么粗。\n\n### 更多边缘检测内容\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B1.JPG\" width=\"90%\" height=\"90%\"> \n- 图片边缘有两种边缘过渡方式，一种是由明变暗，另一种是由暗变明。从输出图像可看出，该垂直边缘滤波器，可以区别出这两种明暗变化的区别。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B2.JPG\" width=\"90%\" height=\"90%\">\n- 如图，垂直边缘检测和水平边缘检测的滤波器如图所示。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B3.JPG\" width=\"90%\" height=\"90%\">\n- 更经典的Sobel滤波器和Scharr滤波器。\n - Sobel滤波器的优点是增加了中间一行的权重，也就是处在中央的像素点，使得结果更鲁棒一些。\n - 图中为进行垂直边缘检测的形式，翻转90度后即得进行水平边缘检测的形式。\n- 随着深度学习的兴起，我们学习到的事情是：当你想检测出某些复杂图像的边缘，你不一定要去使用那些研究者们手工设计的滤波器。而将滤波器中的数字当作参数，通过神经网络学习这些参数。学习到的滤波器对于数据的统计特性的捕捉能力甚至比任何一个手工设计的滤波器要好。\n\n### 填充\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%851.JPG\" width=\"90%\" height=\"90%\">\n不进行填充(padding)：\n- $n\\times n$的图像与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n-f+1)\\times (n-f+1)$。\n - 理解公式：$1$为卷积核位于图像最后一个位置，即进行一次卷积操作，$(n-f)$表示图像空出最后一个卷积核位置后的尺寸，也即可进行卷积的次数。故总的输出尺寸为$(n-f+1)$。\n - 如$6\\times 6$的图像与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸尺寸为$4\\times 4$。\n- 缺点：每次做卷积操作后：\n - 图像会缩小(图像的高度和宽度都会缩小)。\n - 丢失边缘信息(原图像中处于边缘的像素进行较少次的卷积运算，而处于中间的像素进行较多次的卷积运算)。\n- 解决方法：对图像进行填充后，进行卷积。\n\n进行填充：\n- $n\\times n$的图像,进行$p=padding=p$的填充后，与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n+2p-f+1)\\times (n+2p-f+1)$。\n - 如$6\\times 6$的图像,进行$p=1$的填充后，尺寸为$8\\times 8$。与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸为$6\\times 6$。\n - 通常采用零填充(zero-padding)，即在图像边缘填充的值为0。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%852.JPG\" width=\"90%\" height=\"90%\">\n- \"Valid\" convolution：不进行填充。即$p=0$。 \n- \"Same\" convolution：进行填充，使得输出尺寸和输入尺寸相同(保留图像的高度和宽度。但输入和输出的通道数可以不同)。\n - 进行填充的输出尺寸为：$(n+2p-f+1)\\times (n+2p-f+1)$，原始输入尺寸为：$n\\times n$。令$(n+2p-f+1)=n$，则$p=\\frac{f-1}{2}$。\n- 另外，按照惯例，在计算机视觉中，对于卷积核/滤波器的尺寸$f \\times f$，$f$通常是奇数。\n - 如果$f$是偶数，则只能使用一些不对称的填充。$f$是奇数，才能有自然的填充。\n - 奇数的卷积核/滤波器，会有一个中心位置。在计算机视觉中，有一个中间像素，便于指出卷积核的位置。\n - 大小为$3\\times 3$、$5\\times 5$和$7\\times 7$的卷积核很常见，$1\\times 1$也有意义。稍后讲解。\n \n### 步长\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF1.JPG\" width=\"90%\" height=\"90%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF2.JPG\" width=\"90%\" height=\"90%\">\n- 输入图片尺寸为$n \\times n$，卷积核尺寸为$f \\times f$，填充(padding)为$p$，步长(stride)为$s$。\n - 则输出尺寸为：$$\\lfloor\\frac{n+2p-f}{s}+1\\rfloor\\ \\times \\ \\lfloor\\frac{n+2p-f}{s}+1\\rfloor$$\n - 其中，$\\lfloor z \\rfloor=floor(z)$，为向下取整，地板除法。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF3.JPG\" width=\"90%\" height=\"90%\">\n- 在机器学习或深度学习领域，我们所使用的卷积操作，严格意义上应叫做互相关(cross-correlation)。\n- 在数学或信号处理的教科书中，卷积操作需先对卷积核进行翻转(双重镜像)后，再进行卷积操作。包含对卷积核的反转，可使得卷积运算拥有$(A\\*B)\\*C=A\\*(B\\*C)$的结合律性质。\n- 本课程按照机器学习或深度学习中的惯例，将不包含翻转操作的互相关，称为卷积操作。\n\n### 对体进行卷积操作\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF2.JPG\" width=\"90%\" height=\"90%\">\n- 彩色图像的尺寸为$6 \\times 6 \\times 3$，分别表示图片的高度(height)、宽度(weight)和通道数(#channels)。\n- 卷积核的尺寸为$3 \\times 3 \\times 3$，分别表示卷积核的高度(height)、宽度(weight)和通道数(#channels)。\n- 输出尺寸为$4 \\times 4$。\n - 解释：卷积核置于起始卷积位置(输入图像的左上)，卷积核的各通道与输入图像的各通道做卷积操作，然后3个通道的各个输出(各一个数)相加，得到最终输出(一个数)。卷积核移动，进行下一次卷积。\n- 其中，输入图像的通道数(#channels)与卷积核的通道数必须相等。\n- 其中，通道数(#channels)也称为深度(depth)，但容易与神经网络的深度混淆，本课程只称其为通道数(#channels)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF3.JPG\" width=\"90%\" height=\"90%\">\n- 输入图像的尺寸为$6 \\times 6 \\times 3$\n- 两个卷积核，第一个卷积核用来检测垂直边缘，其尺寸为$3 \\times 3 \\times 3$。第二个卷积核用来检测水平边缘，其尺寸为$3 \\times 3 \\times 3$。\n- 输出尺寸为$4 \\times 4 \\times 2$。\n\n总结，假设$p=0$，$s=1$：\n- 输入尺寸：$n \\times n \\times n_c$\n- 卷积核尺寸：$f \\times f \\times n_c$ \n- 输出尺寸为：$(n-f+1) \\times (n-f+1) \\times n_c^{\\prime}$。\n - 其中$n_c^{\\prime}$为输出尺寸的通道数，等于卷积核个数(#filters)。\n\n### 单层卷积网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1.JPG\" width=\"90%\" height=\"90%\"> \n- 单层卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C4.jpg\" width=\"90%\" height=\"90%\">\n - 相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏置$b$(每个卷积核有一个偏置，例如图中两个卷积核各有一个偏置)。\n - 整个过程与标准的神经网络单层结构非常类似：\n $$Z^{[l]}=W^{[l]}A^{[l-1]}+b$$\n $$A^{[l]}=g^{[l]}(Z^{[l]})$$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2.JPG\" width=\"90%\" height=\"90%\"> 单卷积层中的参数：\n- 若一个卷积层有，卷积核个数为10，每个卷积核尺寸为$3 \\times 3 \\times 3$，每个卷积核有1个偏置参数(一个实数)。\n- 则，单卷积层中的参数个数为：$(3\\*3\\*3+1)\\*10=280$个参数。\n- **注意到，无论输入图像的尺寸多大，该卷积层的参数个数始终为280个。即使图片很大，参数依然很少，因此卷积神经网络不容易过拟合(less prone to overfitting)**。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3.JPG\" width=\"90%\" height=\"90%\"> **总结CNN中的符号表示**，若第$l$层是卷积层：\n- 符号表示：\n - $f^{[l]} = $卷积核尺寸(filter size)\n - $p^{[l]} = $填充(padding)\n - $s^{[l]} = $步长(stride)\n - $n_c^{[l]} = $卷积核个数(number of filters)\n- 输入尺寸：$n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_c^{[l-1]}$\n- 每个卷积核的尺寸：$f^{[l]} \\times f^{[l]} \\times  n_c^{[l-1]}$\n- 权重尺寸为： $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times  n_c^{[l]}$\n- 偏置尺寸为：$n_c^{[l]}$ 或$(1,1,1,n_c^{[l]})$\n- 输出$a^{[l]}$的尺寸为： $n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$\n- 输出$A^{[l]}$的尺寸为： $m \\times n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$\n - 其中，$$n_H^{[l]}=\\lfloor \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor$$，$$n_W^{[l]}=\\lfloor \\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor$$\n\n### 简单的卷积网络示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\">\n- 该CNN模型各层结构如上图所示。\n- 需要注意的是，$a^{[3]}$的维度是$7 \\times 7 \\times 40$，将$a^{[3]}$排列成1列，维度为$1960 \\times 1$，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 $\\hat y$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> CNN有三种类型的层：\n- 卷积层(Convolution, CONV）\n- 池化层(Pooling, POOL）\n- 全连接层(Fully connected, FC）\n\n### 池化层\n除了卷积层(convolutional layers)，CNN中也经常使用池化层(pooling layers)来减小模型来加速计算，同时让检测到的特征更鲁棒。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%821.JPG\" width=\"100%\" height=\"100%\"> 最大池化(max pooling)，即取滤波器区域内的最大值。对二维矩阵做最大池化：\n- 输入尺寸为$4 \\times 4$\n- 超参数：$f=2$，$s=2$\n- 没有参数。 \n- 输出尺寸为$2 \\times 2$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> 对三维矩阵做最大池化：\n- 输入尺寸为$5 \\times 5 \\times n_c$\n- 超参数：$f=3$，$s=1$\n- 没有参数。 \n- 输出尺寸为$3 \\times 3 \\times n_c$\n - 注意，对每一通道，分别做最大池化，故输出尺寸的通道数等于输入尺寸的通道数。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 平均池化(average pooling)，即计算滤波器区域内的平均值。其它同上。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%824.JPG\" width=\"90%\" height=\"90%\"> 总结：\n- 池化层的超参数：\n - 滤波器尺寸(filter size)：$f$\n - 步长(stride)：$s$\n - 极少使用填充(padding)\n - 最大池化(max pooling)或平均池化(average pooling)。最大池化层更常用。\n- 常用的池化层超参数有$f=2$，$s=2$，相当于将输入尺寸(高度和宽度)缩小一半。也有$f=3$，$s=2$用法。\n- 没有参数！\n - 池化过程中没有参数需要学习。只有需要设置的上述超参数，可能是手工设置，也可能是通过交叉验证设置。\n- 输入尺寸为：$n_H \\times n_W \\times n_c$\n- 输出尺寸为： $\\lfloor \\frac{n_H-f}{s}+1 \\rfloor \\times \\lfloor \\frac{n_W-f}{s}+1 \\rfloor \\times n_c$\n - 注意到，输出尺寸的通道数与输入尺寸的通道数相同。\n\n### 卷积神经网络示例\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"> 该CNN为了识别0~9的数字。该CNN类似Yann LeCun提出的LeNet-5:\n- 卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B3.jpg\" width=\"100%\" height=\"100%\"> \n- 输入为0~9的数字的图像。\n- 将CONV1和POOL1称为网络的第一层(Layer 1)。\n  - 在CNN相关文献中，一种惯例是将一个卷积层和一个池化层合称为一层；一种惯例是将一个卷积层称为一层，一个池化层称为一层。\n  - 本课程在统计网络层数时，只统计有权重的层，即将CONV1和POOL1作为网络第一层。 \n- 将CONV2和POOL2称为网络的第二层(Layer 2)。然后，将POOL2的输出平整化为维度为$400\\times 1$的向量。\n- 全连接层FC3为网络第三层(Layer 3)。全连接层即为标准神经网络结构。输入的400个单元和该层的120个单元每个都相连接，故称为全连接层。权重$W^{[3]}$的维度为$(120,400)$。偏置$b^{[3]}$的维度为$(120,1)$\n- 全连接层FC4为网络第四层(Layer 4)。\n- 最后的输出层为softmax层，由10个神经元构成(识别0~9的数字)。\n- 注意到，随着网络深度的加深，高度$n_H$和宽度$n_W$会减小，而通道数$n_c$会增加。\n- CNN的另一种常见模式是一个或多个卷积层后面跟一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 展示上图中CNN的各层的激活值维度和参数数量：\n- 池化层没有参数。\n- 卷积层的参数相对较少，许多参数都存在于全连接层。\n- 随着网络的加深，激活函数的尺寸逐渐变小。减小的太快会影响网络性能，故是逐渐减小。\n\n### 为什么使用卷积层？\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%821.JPG\" width=\"90%\" height=\"90%\"> 相比标准神经网络，CNN的优势之一就是参数数目要少得多：\n- 对于一张$32 \\times 32 \\times 3$的图片。卷积层的超参数为$f=5$，卷积核的个数为$n_c=6$。则输出维度为$28 \\times 28 \\times 6$。\n- 输入尺寸为$32 \\times 32 \\times 3=3072$，输出尺寸为$28 \\times 28 \\times 6=4704$。\n- 若采用标准神经网络，则参数$W$的维度为$(4704,3072)$，共$4704 \\times 3072+4704 \\approx 14m$个参数。仅对于$32 \\times 32 \\times 3$的小图片，就有如此多的参数。\n- 而采用卷积层，每个卷积核的参数为$5\\times 5 +1=26$，有6个卷积核，则共有$6 \\times 26= 156$个参数。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> CNN的参数数目少的原因有两个：\n- 参数共享：一个特征检测器（例如垂直边缘检测器）如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。\n- 稀疏连接：每一层的每个输出只与一小部分输入有关。\n - 如图，输出矩阵的左上角的0，只与输入矩阵的左上角的$3\\times 3$的矩阵有关。其他像素值都不会对该输出产生影响。\n- 通过以上两种机制，CNN有较少的参数，允许我们以较小的训练集训练它，从而不易过拟合。\n- 此外，CNN善于捕捉平移不变性(translation invariance)。即CNN进行分类时，不易受物体所处图片位置发生平移的影响，更鲁棒。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 如何训练一个CNN：\n- 为了构建一个猫的检测器。\n- 训练集为$(x^{(1)},y^{(1)})...(x^{(m)},y^{(m)})$，$x^{(i)}$为输入图像，$y^{(i)}$为标签。\n- 如图，若选定了CNN结构：包含输入层，卷积层，池化层，全连接层和softmax输出层。\n- 依然同之前课程一样，定义代价函数$J=\\frac{1}{m}\\sum_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})$。\n- 采用优化算法(如梯度下降/Momentum/RMSprop/Adam)，来优化网络中的所有参数，去减小代价函数$J$。\n\n# 2.深度卷积模型：案例学习\n## 2.1 案例学习\n### 为什么进行案例学习\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0.JPG\" width=\"90%\" height=\"90%\">  \n- 这一周会讲解的经典CNN模型：\n - LeNet-5\n - AlexNet\n - VGG\n- 另外，还会讲解：\n - ResNet\n - Inception \n\n### 经典卷积网络\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C1.JPG\" width=\"100%\" height=\"100%\"> LeNet-5由Yann LeCun于1998年提出，用于识别0~9的手写数字：\n- 针对灰度图像，故输入图片维度为$32\\times 32\\times 1$\n- 对于卷积层，那时人们不使用填充(padding)，即通常采取\"valid\" convolution。\n- 对于池化层，那时人们更多使用平均池化(现在通常使用最大池化)。\n- 该模型约有6万个参数。\n- 后来沿用的模式一：**随着网络的加深，图像的高度$n_H$和宽度$n_W$在减小，而通道数$n_c$在增加**。\n- 后来沿用的模式二：一个或多个卷积层接一个池化层，一个或多个卷积层接一个池化层，然后是几个全连接层，然后是输出层。\n- 对于激活函数，那时人们使用的是sigmoid/tanh(如今通常使用ReLU，AlexNet提出)。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C2.JPG\" width=\"100%\" height=\"100%\"> AlexNet是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton于2012年共同提出，用于识别ImageNet中的1000类图像：\n- AlexNet模型与LeNet-5模型类似，但更大，约有6千万个参数。\n- 对于激活函数，AlexNet使用了ReLU激活函数。\n- 当时，GPU还较慢，AlexNet采用了在两个GPU上并行计算。\n- AlexNet中含有一种特殊的层，叫做局部相应归一化层(Local Response Normalization, LRN)。但后来研究者发现效果有限，故如今并不使用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C3.JPG\" width=\"100%\" height=\"100%\">\n- VGG-16中一个精彩的地方在于，没有那么多的超参数，专注于构建简单的网络结构：\n - 对于卷积层，只使用$f=3$，$s=1$，\"same\"填充。\n - 对于池化层，只使用$f=2$，$s=2$的最大池化层。\n- 每次池化后，图像的高度$n_H$和宽度$n_W$缩小一半。每一组卷积层之后，通道数$n_c$增加一倍，直到512。\n- 缺点：包含1亿三千万个参数，以现在的标准来看，都是非常大的网络，有太多参数需要训练。\n- 优点：VGG-16的结构并不复杂，**结构很规整**，这一点非常吸引研究者。\n- VGG-16中的16指的是包含权重的卷积层、全连接层和输出层(未计没有参数的池化层)。\n- VGG-19的表现与VGG-16差不多，更多的人使用VGG-16。\n\n### ResNets\n由于梯度消失(vanishing gradients)和梯度爆炸(exploding gradients)的原因，非常非常深的网络是难以训练的。这一节学习跳跃连接(skip connection)，它可从某一层网络获取激活值，然后喂给更深的一层网络。通过跳跃连接，即可构建出ResNets(Residual Networks)，让我们可以训练非常非常深的网络。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets1.JPG\" width=\"100%\" height=\"100%\"> ResNet是由残差模块(residual block)构建的，上图介绍残差模块：\n- 残差模块的主路径(main path)为：$a^{[l]}$ -> 线性操作 -> ReLU(得$a^{[l+1]}$) -> 线性操作 -> ReLU(得$a^{[l+2]}$)。\n- 残差模块的捷径(short cut)/跳跃连接为：$a^{[l]}$ 直接隔层与$l+2$层的线性输出相连，与$z^{[l+2]}$共同通过激活函数（ReLU）输出 $a^{[l+2]}$。\n- 具体公式如下：\n - $z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}$\n - $a^{[l+1]}=g(z^{[l+1]})$\n - $z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}$\n - $a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets2.JPG\" width=\"100%\" height=\"100%\"> 通过堆叠许多残差模块在一起，即构建成ResNet：\n- 在ResNet论文中，将非Residual Network称为Plain Network。\n- 在一个Plain Network中，加上捷径/跳跃连接，如图中每两层构成一个残差模块，共5个残差模块。整体即构成一个残差网络(residual network)。\n- 若用优化算法优化一个朴素的网络(plain network)，其效果如图：\n - 理论上：随着网络深度的加深，训练误差应越来越小。\n - 实际上：起初，训练误差会降低。但随着层数的增多，训练误差上升。\n- 若用优化算法优化一个ResNet，其效果如图：\n - 随着网络深度的加深，训练误差越来越小。\n- 跳跃连接确实有助于解决梯度消失和梯度爆炸的问题，让我们在训练十分深层的网络时得到好的性能。\n\n### RestNets为何有效\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%881.JPG\" width=\"100%\" height=\"100%\"> 给一个深度网络，增加了一个残差模块后，网络的深度得到了增加：\n- $a^{[l+2]}$的表达式为：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})$。\n- 注意到，如果使用L2正则化或权重衰减，将会使得$W^{[l+2]}$不断减小。假设$W^{[l+2]}=0$，$b^{[l+2]}=0$（发生梯度消失）。\n- 那么，$$a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}$$（$a^{[l]}$本就大于等于0，再经过ReLU激活函数，还是$a^{[l]}$本身）。\n- 以上结果表明：恒等函数(identity function)对于残差模块来说，非常容易学习。因此，尽管增加了残差模块，一方面没有伤害网络的效率，另一方面还提升了网络的性能。\n- 残差网络有效的原因：\n - 残差模块学习恒等函数非常容易(没有伤害网络的学习效率)。\n - 残差模块的添加起码不会降低网络的表现，很多时候可以提升网络的表现。\n- 另外，残差网络的另一个细节是：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中$z^{[l+2]}$与$a^{[l]}$拥有相同的维度：\n - 故ResNets中使用了许多\"same\"卷积。\n - 若$a^{[l+2]}$与$a^{[l]}$维度不一样，可以引入矩阵$W_s$，使得$W_s \\cdot a^{[l]}$的维度与$a^{[l+2]}$一致，即$$a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})$$。矩阵$W_s$可以设置为通过网络学习的参数矩阵，也可以设置为固定矩阵(如只是给$a^{[l]}$进行零填充)。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%882.JPG\" width=\"100%\" height=\"100%\"> 简单分析ResNets结构特点：\n- ResNets中采用了很多$3\\times 3$的same卷积。\n - same卷积是为了进行$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中的$z^{[l+2]}+a^{[l]}$。\n- 池化层后需调整$W_s$的维度，即进行$$a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})$$。\n- ResNets的网络结构是几个卷积层接一个池化层，然后重复，然后是一个全连接层，然后是softmax输出层。\n\n### Network in NetWork以及1x1卷积\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/netwrok%20in%20network1.JPG\" width=\"100%\" height=\"100%\">\n- 如图上半部分，对于单通道的二维矩阵，进行$1\\times 1$卷积的效果就是乘以一个数字。\n- 如图下半部分，对$6 \\times 6 \\times 32$的体，卷积核为$1 \\times 1 \\times 32$，进行卷积的效果是：\n - 对于输入体的36个切片，每个切片的维度都为(1,1,32)。每一个切片都与卷积核逐元素相乘，然后求和，得到一个实数，即输出矩阵中的一个绿点。\n - 若应用在CNN中，则相当于：输入体中的每一切片逐元素乘以卷积核中的权重，然后求和，加上偏置，然后进行ReLU激活，如输出矩阵中的一个黄点。\n - 若有多个卷积核，则输出结果为多通道。\n- 因此，$1\\times 1$卷积应用在CNN中，则可以理解为：36个切片中的32个单元，与#filters中的每个卷积核进行了全连接，输出维度为$6 \\times 6 \\times n_c^{[l+1]}$，其中$$n_c^{[l+1]}= \\# filters$$。\n- 此方法称为$1\\times 1$卷积或Network in NetWork。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/network%20in%20network2.JPG\" width=\"90%\" height=\"90%\"> $1\\times 1$卷积可以用来缩小通道数量：\n- 输入维度是$28 \\times 28 \\times 192$，通过32个$1\\times 1$卷积核(准确地说，维度为$1\\times 1\\times 192$)，输出为$28 \\times 28 \\times 32$，缩小了通道数。\n\n总结：\n- $1\\times 1$卷积**给网络增加了非线性，可以让网络学习更复杂的函数**。\n- 通过$1\\times 1$卷积，**可减少或保持或增加通道数**。\n\n### Inception Network动机\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA1.JPG\" width=\"90%\" height=\"90%\"> Inception网络的基本思想是：代替人为选择卷积核尺寸以及是否使用池化层，而是将它们都添加进网络，然后将输出串联起来，然后让网络去学习参数，去决定采用哪些组合：\n- 输入维度为$29\\times 28 \\times 192$\n- 通过$1\\times 1$的same卷积，使得输出为$28 \\times 28 \\times 64$\n- 通过$3\\times 3$的same卷积，使得输出为$28 \\times 28 \\times 128$\n- 通过$5\\times 5$的same卷积，使得输出为$28 \\times 28 \\times 32$\n- 通过最大池化层，$s=1$，使用填充，使成为same-pool，使得输出为$28 \\times 28 \\times 32$\n- 将所有输出串联起来，维度为$28 \\times 28 \\times 256$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA2.JPG\" width=\"90%\" height=\"90%\"> 上图中描述的Inception模块中有一个问题，就是计算成本的问题：\n- 集中讨论上图中的$5 \\times 5$的卷积核\n- 进行该卷积计算，需要进行的乘法次数为：\n - 输出个数为：$28\\times 28\\times 32$\n - 每个输出需进行的乘法次数为：$5\\times 5\\times 192$\n - 故需进行的乘法次数为：$(28\\times 28\\times 32)\\times (5\\times 5\\times 192)\\approx 120m$\n- 即使用现代计算机，计算1.2亿次计算，也是相当昂贵的操作。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA3.JPG\" width=\"90%\" height=\"90%\"> 通过$1\\times 1$卷积层，降低计算成本：\n- 结构如图，先通过$1\\times 1$卷积，再进行$5\\times 5$卷积，最终输出和上图相同。\n- 加入$1\\times 1$卷积后，进行两次卷积计算，需要进行的乘法次数为：\n - $1\\times 1$卷积需要的乘法次数：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)$\n - $5\\times 5$卷积需要的乘法次数：$(28\\times 28\\times 32)\\times (5\\times 5\\times 16)$\n - 进行两次卷积计算，需要进行的乘法次数为：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)+(28\\times 28\\times 32)\\times (5\\times 5\\times 16)\\approx 12.4m$\n- 通常我们把该$1\\times 1$卷积层称为“瓶颈层”(bottleneck layer)，因为它是网络中最小的那个部分。**先通过“瓶颈层”缩小网络，然后再扩大网络，显著降低了计算成本**，乘法计算次数从120m减少为12.4m。\n\n### Inception Network\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork1.JPG\" width=\"90%\" height=\"90%\"> 正式介绍Inception模块：\n- 输入为前一层的激活函数。\n- 单独的$1\\times 1$卷积层，输出维度为$28 \\times 28 \\times 64$。\n- 先是$1\\times 1$卷积层，再接$3\\times 3$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 128$。\n- 先是$1\\times 1$卷积层，再接$5\\times 5$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 32$。\n- 先是$f=3$，$s=1$的same最大池化层，再接$1\\times 1$卷积层(为了降低通道数)，输出维度为$28 \\times 28 \\times 32$。\n- 串联(concatenate)所有输出，输出维度为$28 \\times 28 \\times 256$。(Caffe中的concat层，实现此串联操作。)\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetworkk2.JPG\" width=\"100%\" height=\"100%\"> 正式介绍Inception Network，如图：\n- Inception Network由很多Inception模块构成。\n- Inception Network中的另一个细节是：在中间层设置了两个辅助softmax分类器，它们保证了即便是中间层的隐藏神经元计算的特征，在预测图像类别时，表现也不太差。它们在Inception Network起着正则化的效果，帮助防止过拟合。\n- Inception Network也称为GoogleNet。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork3.JPG\" width=\"90%\" height=\"90%\"> \n- Inception Network中“Inception”取自莱昂纳多的电影《Inception》。\n\n## 2.2 使用卷积网络的实用建议\n### 使用开源实现\n- 对于许多经典的神经网络，因为许多细节问题（如超参数的调节，学习率衰减或其它）而很难实现复现。因此，仅靠论文去从零实现，是很困难的。\n- 建议从其他研究者贡献出的开源代码开始研究或使用，如在Github中搜索并获取开源代码。\n\n### 迁移学习\n你如果要做一个计算机视觉应用，相比于从头(随机初始化权重)开始训练权重，如果你下载别人已经训练好的权重，然后把它当做预训练，然后迁移到你感兴趣的任务中，通常能够取得更快的进展。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.JPG\" width=\"100%\" height=\"100%\"> 假设你训练猫分类器，能够分类Tigger，Misty和Neither。\n- 如图第一行，若你没有关于Tigger，Misty大量图片，即训练集很小：\n - 下载经典网络的代码以及权重，删去最后的Softmax层，创建你自己的Softmax层(Tigger/Misty/Neither)。\n - 将你下载的网络，看作是冻结的，冻结该网络的所有参数。将别人训练好的权重，作为初始权重，只训练和你自己的Softmax层有关的参数。\n - 这样，即使你只有一个小的训练集，也能取得好的性能。\n - 加速训练的技巧：由于前面的层都冻结了，即相当于一个不需要改变的固定函数(相当于取输入$X$，然后映射到选用的最后一层的激活函数)。预先计算这个固定函数的得到的特征或是说激活值，然后将它们存到硬盘中（对于每一周期(epoch)，不用重复遍历数据集计算激活值）。然后将它们作为输入，相当于训练一个浅层的softmax模型。\n- 如图第二行，若有一个更大的训练集：\n - 可以冻结更少的层，如图。然后训练后面的所有层（构建自己的Softmax层后）。\n - 也可将未冻结的后面几层全部删去，构建自己的几个隐藏层和Softmax层，然后只训练后面几层。\n - 模式就是：如果有更多的数据，那么你需要冻结的层数就更少，你需要训练的末端的层数就更多。\n- 如图第三行，如果你有足够多的大量的训练集：\n - 将下载的权重作为初始权重(代替随机初始化)，重新训练网络的所有层。\n- 在所有深度学习的应用中，计算机视觉领域是一个经常用到迁移学习的领域。除非你有极其大的数据集和非常大的计算预算，能让你能够自己从头训练所有东西，那么迁移学习总是值得你考虑的方案。\n\n### 数据增强\n数据增强是经常用来提升计算机视觉系统性能的技巧。计算机视觉任务是一项相当复杂的工作，你需要输入图像中的像素值，然后弄清楚图片中有什么，似乎你需要学习一个相当复杂的函数。对于几乎所有的计算机视觉任务，通常的问题是数据远远不够。因此，对于计算机视觉任务，数据增强通常都会有帮助。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA1.JPG\" width=\"100%\" height=\"100%\"> 介绍了常用的数据增强方法：\n- 镜像(mirroring)：以垂直轴为基准，进行镜像。\n- 随机裁剪(random cropping)：裁剪出原图像中的一部分。\n- 理论上，还有一些方法，如旋转(rotation)，剪切(shearing)，local warping(局部弯曲)等。但因为过于复杂，实践中很少使用。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA2.JPG\" width=\"50%\" height=\"50%\"> 第二种经常使用的数据增强方法：\n- 色彩转换(color shifting)/色彩失真(color distortion)：分别对图片的RGB通道中的像素值进行增加或者减少，改变图片色彩。\n - 解释：进行色彩转换，希望能让算法对图片的色彩的改变更具鲁棒性。\n - AlexNet论文中采用了“PCA color augmentation”：减少主要色调成分(如R和B通道)的像素值多一点，减少G通道的像素值少点，使得整体的色调保持一致。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA3.JPG\" width=\"90%\" height=\"90%\">\n- 可通过CPU/GPU的不同进程，并行地进行数据增强和训练。\n\n### 计算机视觉的现状\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B61.JPG\" width=\"90%\" height=\"90%\"> \n- 对于图像识别(image recognition)任务，尽管今天我们有很大的数据集，但仍想要更多的数据。\n- 对于目标检测(object detection)任务，我们有着更少的数据，因为标注边框这一步的成本太高。\n\n**学习算法有两个主要的知识来源：一是带标签的数据；二是手工设计的特征或网络结构或其他组件**：\n- 当有大量数据时，人们倾向于使用更简单的算法和更少的手工工程。\n- 而当有较少量的数据时，人们倾向于使用更多的手工工程\n - 解释：但当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的好的途径。\n - 举例：计算机视觉是在试图学习一个非常复杂的函数，因此我们总感觉没有足够的数据来满足我们的需求。在计算机视觉的初期，拥有的数据量很小，所以依赖手工设计的特征。近几年，数据量剧增，但对于计算机视觉还是不够，因此人们设计复杂的网络结构(包含很多超参数)。对于目标检测任务，拥有的数据量比图像识别任务更少，因此人们手工设计了许多组件。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B62.JPG\" width=\"100%\" height=\"100%\"> 在基准数据集或竞赛中取得好成绩的技巧：\n- 集成(ensembling):\n - 独立训练多个(3~15)网络，然后平均它们的输出。\n- 在测试阶段进行多裁剪(multi-crop)：\n - 在测试阶段，对于一张测试图片，通过镜像(mirroring)以及随机裁剪(random cropping)的方式，获得该图像的多个版本。然后平均它们的测试结果。\n- 集成(ensembling)方式占用过多内存且运行速度慢；在测试阶段进行多裁剪(multi-crop)，运行速度慢。因此它们在实际应用中没有意义。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B63.JPG\" width=\"90%\" height=\"90%\"> 若你要建立一个实际系统，采用以下步骤，能让你的应用进行的更快：\n- 从使用文献中的网络结构开始。\n- 使用开源的代码实现。\n - 因为开源代码已经解决了所有的繁琐细节，如学习率衰减或其他超参数。\n- 使用预训练的模型然后用你的数据集微调。\n - 因为其他人可能已经在多个GPU上花了几个星期对超过一百万张图片进行训练后，得到这个模型。\n\n# 3.目标检测\n## 3.1 检测算法\n### 目标定位\n目标定位(object localization)\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D1.JPG\" width=\"90%\" height=\"90%\"> 图像分类任务与目标检测任务的区别：\n- 图像分类(Image classification)：对于给定图像，预测出类别（通常只有一个较大物体在图片中央）。\n- 分类且定位(Classification with Localization)：对于给定图像，预测类别，且给出物体在图片中的位置，即标出包围框(bounding box)（通常只有一个较大物体在图片中央）。\n- 检测(Detection)问题：图片中可存在多个属于不同类别的物体，对每个物体分类且定位。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D2.JPG\" width=\"100%\" height=\"100%\"> 分类且定位的实现方法：\n- 图像分类的方式就是构建CNN，然后通过softmax分类层进行分类。\n - softmax层有四个神经元，分别对应行人(pedestrain)，车辆(car)，摩托车(motorcycle)和背景(background)四类。\n- 要实现定位，修改输出层，通过增加神经元，来输出表示包围框的四个数字：`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`。\n - `$b_x$`，`$b_y$`对应包围框的中点，`$b_h$`，`$b_w$`分别对应包围框的高和宽。\n - 本课程约定，以图像的左上角为$(0,0)$点，右下角为$(1,1)$点，横向为$x$方向，纵向为$y$方向。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D3.JPG\" width=\"90%\" height=\"90%\"> 为了用监督学习算法解决分类且定位任务，需要定义训练集$(x,y)$，其中标签$y$该这样定义：\n- $$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ] $$。其中，$$Pc$$表示是否检测到目标，$$Pc=1$$代表图片中检测到目标。$$Pc=0$$代表图片中未检测到目标。\n- 如上图中的左图，检测到目标，$Pc=1$。训练集中应标注标签：$$ \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 如上图中的右图，未检测到目标，$Pc=0$，则$Pc$后面参数都没有意义，都可以忽略。训练集中应标注标签：$$\\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]$$\n\n最后，对于神经网络的损失函数，若全部使用平方误差形式，有两种情况：\n- 若$y_1=1$,即$Pc=1$，那么：$$L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2$$\n- 若$y_1=0$,即$Pc=0$，那么：$$L(\\hat y,y)=(\\hat y_1-y_1)^2$$\n- 这里用平方误差简化了描述过程，在实际应用中，可以对$Pc$使用逻辑回归损失，对`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`使用平方误差损失，对于$c_1$，$c_2$，$c_3$使用softmax损失。\n\n### 特征点检测\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.JPG\" width=\"100%\" height=\"100%\"> \n- 上节中，通过让网络输出四个实数(`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`)的方式，指定了想要定位的物体的包围边框。\n- 在更一般的情况下，可以通过神经网络输出图像中关键特征点的$(x,y)$坐标（这些点称作landmarks），来实现对这些关键特征点的检测。\n\n上图中举了两例：\n- 例1：人脸关键特征点检测。\n - 在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人脸特征点的坐标。\n - 如图，在输出层中，第一个神经元代表是否属于人脸，第二个神经原代表特征点1的$x$坐标，第三个神经元代表特征点1的$y$坐标，等等。\n- 例2：人体姿态检测。\n - 在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人体关键特征点的坐标。\n- 想要训练这样的网络，需要一个带标签的训练集$(X,Y)$。\n - 其中在人工标注关键特征点时，对于每一个样本，每一特征点代表的含义顺序，必须一致。如对于人脸特征点检测，特征点1代表左眼角，特征点2代表右眼角等等。对于人体姿态检测，特征点1代表左肩，特征点2代表胸部中点，特征点3代表右肩等等。\n \n### 目标检测\n本节以车辆检测为例，介绍基于滑动窗口的目标检测算法。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B1.JPG\" width=\"100%\" height=\"100%\"> 第一步，构建CNN以进行车辆分类：\n- 对于训练集$(x,y)$，$x$是适当剪切的图片。如上图，$x$为剪切后的汽车图片样本，即剪去其他部分，只有车辆在图片中央并占据了整个图片。\n- 然后即可训练CNN。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 第二步，滑动窗口检测(sliding window detection)：\n- 选择固定大小的矩形窗口，按某个步长，滑动遍历整个图片。滑动窗口每到达一个位置，就将该窗口内的图片送入CNN进行分类。CNN输出1(是汽车)或者0(背景，不是汽车)。\n- 然后选择一个更大的窗口，继续滑动窗口检测操作。\n- 然后再选择一个更大的窗口，继续滑动窗口检测操作。\n\n基于滑动窗口检测目标检测算法的缺点：\n- 计算成本高。滑动窗口到达的每一个位置的图片，都需要用CNN进行处理。\n- 如果选用大步长，窗口数会减少，但会影响性能。\n- 如果选用小步长，窗口数会剧增，计算成本过高。\n\n### 滑动窗口的卷积实现\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B01.JPG\" width=\"100%\" height=\"100%\"> **用卷积层替换全连接层**：\n- 上图中第一行是用来进行分类的CNN结构：输入为尺寸为$14\\times 14 \\times 3$的图片，卷积层，池化层，全连接层，全连接层，然后是softmax分类层（含四个结点，每个结点对应一个类别的概率）。\n- 上图中的第二行是将全连接层转换为卷积层后的CNN结构：\n - 首先通过400个$5\\times 5$的卷积核(每个卷积核的尺寸为$5\\times 5\\times 16$)，将输出尺寸变为$1\\times 1\\times 400$。(将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)\n - 然后通过400个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，将输出尺寸变为$1\\times 1\\times 400$。(**将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)\n - 然后通过4个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，输出层的输出尺寸为$1\\times 1\\times 4$，然后进行softmax激活函数，作为最终的输出结果。(将此处输出的$1\\times 1\\times 4$的体，视为原softmax输出层的4个结点。)\n- 用卷积层替换全连接层的目的是为了使得能够输入任意尺寸的图片，而如果存在全连接层，则输入和输出的维度必须是固定的。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B02.JPG\" width=\"100%\" height=\"100%\"> 基于滑动窗口的目标检测算法的卷积实现：\n- 上图中第一行的输入为一个滑动窗口内的图像，即尺寸为$14\\times 14 \\times 3$的体，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$1\\times 1\\times 4$的体，相当于softmax输出层的4个输出结点。\n- 上图中第二行的输入为一张$16\\times 16 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$2\\times 2\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。4个$1\\times 1\\times 4$的体即对应4个滑动窗口的输出结果。\n- 上图中第三行的输入为一张$28\\times 28 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$8\\times 8\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。64个$1\\times 1\\times 4$的体即对应64个滑动窗口的输出结果。\n- 该模型源于OverFeat。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B03.JPG\" width=\"100%\" height=\"100%\"> 总结：\n- 原始的基于滑动窗口的目标检测算法，会分别将每一个滑动窗口内的图像，单独给CNN处理。并且这样会使得很多CNN的处理过程是重复的。\n- 而基于滑动窗口的目标检测算法的卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的窗口图像共享了许多计算。\n- 基于滑动窗口的目标检测算法的卷积实现，极大地提高了效率。但存在一个缺点：不能输出最准确的包围边框。下节解决这个问题。\n\n### 包围边框预测\n上节中基于滑动窗口的目标检测算法的卷积实现，其计算效率很高，但存在不能输出非常准确的包围边框的问题。本节介绍YOLO(You Only Look Once)算法，它可以得到准确的包围边框。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B1JPG.JPG\" width=\"80%\" height=\"80%\"> \n- 基于滑动窗口的目标检测算法，很有可能没有一个合适的滑动窗口，能够完美匹配图中的汽车的位置，即红色包围边框。最接近的，可能只是图中的蓝色窗口。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 介绍YOLO算法：\n- YOLO算法首先将原始图片分割成$n\\times n$网格，每个网格代表一块区域。为简化说明，将图片分成$3 \\times 3$网格。\n - 实际应用中采用更精细的网格，如$19\\times 19$。更精细的网格也可以使得多个物体分配到同一格子的概率减小。\n- 然后，采用本周第一个视频讲述过的图像分类且定位算法(image classification and localization algorithm)，应用在9个格子的每一个格子上。\n- 训练集$(x,y)$的构建：\n - $x$即为输入图像矩阵，例如尺寸为$100 \\times 100 \\times 3$\n - 标签$y$的维度为$3 \\times 3 \\times 8$，即共9个$1 \\times 1 \\times 8$，其中每一个$1 \\times 1 \\times 8$代表着一个格子的标签。\n - 每个格子对应的$1 \\times 1 \\times 8$的标签，同本周第一个视频讲述过的一样。$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$\n - 需强调：将物体分配给哪个格子是由物体的中点$(b_x,b_y)$属于哪个格子决定的。\n - 对于一个格子可能存在多个物体的情况，稍后讨论。\n- 构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 8$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的进行训练。\n\n总结：\n- 该算法和图像分类且定位算法很相似，它显示的输出包围边框的坐标，它能让神经网络输出任意长宽比的坐标，而不收到滑动窗口的步长的限制。因此，该算法能够输出精确的包围边框。\n- 此外，该算法也是卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的网格共享了许多计算。正因为它是卷积实现，因此该算法的效率非常高，运行得非常快，能达到实时目标检测。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B3.JPG\" width=\"100%\" height=\"100%\"> 如何定义包围边框，即如何编码(encode)`$b_x$`，`$b_y$`，`$b_h$`，`$b_w$`：\n- 如图，以每个网格的左上角为$(0,0)$点，以右下角为$(1,1)$点。\n- 中心点`$b_x$`，`$b_y$`为距离$(0,0)$点的水平距离和垂直距离相对网格边长的比值。因此，`$b_x$`和`$b_y$`在0~1之间。\n- 高度`$b_h$`和宽度`$b_w$`，为包围边框的高和宽与网格边长的比值。因此，`$b_h$`和`$b_w$`可能大于1。\n- 如图，图中样本$x$对应的标签应该为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ 0.4 \\\\ 0.3 \\\\ 0.9 \\\\ 0.5 \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 当然编码包围框的方式很多，YOLO论文中也交待了其他更复杂的参数化方式。但本课程给出了此种方法是合理且可使用的一种方式。\n\n### 交并比\n交并比(Intersection over Union, IoU)是评价目标定位算法准确性的指标。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%A4%E5%B9%B6%E6%AF%94.JPG\" width=\"100%\" height=\"100%\"> 交并比讲解：\n- 如图，紫色边框为预测边框，红色边框为真实边框。\n- 黄色阴影部分为两边框区域的交集(Intersection)，绿色阴影部分为两边框区域的并集(Union)。\n- 交并比(Intersection over Union, IoU)即为：$$IoU=\\frac{Intersection}{Union}$$\n - 一般人为规定当$IoU \\geq 0.5$时，预测的包围边框是正确的。\n- 更一般的说，IoU衡量了两个包围边框的重叠程度。\n\n### 非极大值抑制\n目标检测算法可能会检测同一个目标多次。非极大值抑制(Non-max Suppression, NMS)可以确保对每个对象只检测一次。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B61.JPG\" width=\"80%\" height=\"80%\"> 如图，以YOLO算法检测汽车为例，对于该图片，会有多个网格对同一汽车做出检测。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B62.JPG\" width=\"100%\" height=\"100%\"> 极大值抑制的效果：\n- 如图，当运行目标检测算法时，最终出现了对同一个对象进行多次检测的情况。\n- 通过非极大值抑制，清理了这些检测结果。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B63.JPG\" width=\"100%\" height=\"100%\"> 非极大值抑制的实现细节：\n- 假设只检测车辆，用YOLO算法检测这张图片后的输出的维度为$19\\times 19 \\times 5$。共$19\\times 19 = 361$个格子，每一个格子的输出为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw  \\end{matrix} \\right ]$$。其中，$p_c$为存在对象的概率，在此处即是车辆的概率。\n- 第一步，丢弃所有$p_c \\leq 0.6$的包围框。\n - 在编程作业中，这一步作为单独的步骤，不在NMS之内。先算得分($p_c$与$c_1$或$c_2$或$c_3$相乘)再取阈值。\n- 第二步，只要有剩余包围框，则一直循环：\n - 选择$p_c$最大的包围框为一个预测包围框。\n - 舍弃所有与上一步中的预测包围框的$IoU\\geq 0.5$的剩余的包围框。\n- 另外，该节只是介绍了只检测车辆这一类目标的情况，如果想要检测三类目标(如行人，车辆，摩托车)，那么每个格子的输出向量就会有额外三个分量($c_1$，$c_2$，$c_3$)。正确的做法是，对每个类别都独立进行一次非极大值抑制，即进行三次非极大值抑制。\n \n### Anchor Boxes\n到目前位置，我们介绍的是每个网格只能包含一个物体，若一个网格包含两个或以上物体，则无法处理。使用anchor boxes可以解决这个问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes1.JPG\" width=\"100%\" height=\"100%\">\n- 如图，对图片采用$3\\times 3$的网格划分。汽车和行人的中点，几乎重叠，都落在一个格子中。\n - 此前每个格子的输出定义为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$，无法描述该情况，只能舍去一个物体，只描述一个物体。\n- 预先定义两个不同形状的anchor box：Anchor box1和Anchor box2。\n - 通常使用更多的anchor box，如5个或更多。这里为了方便讲解，只定义两个。\n- 则上图对应的输出标签应为$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]$$。其中，前8个分量为与Anchor box1相关的输出，后8个分量为与Anchor box2相关的输出。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes2.JPG\" width=\"80%\" height=\"80%\"> Anchor box算法：\n- 在之前(不采用Anchor box时)：我们将每个训练图像中的物体分配给其中点所处的那个网格。输出$y$的维度为$3\\times 3\\times 8$。\n- 采用两个Anchor box后：我们将将每个训练图像中的物体分配给其中点所处的那个网格，以及分配给与该物体包围框的IoU最大的那个Anchor box。输出$y$的维度为$3\\times 3\\times 16$，即$3\\times 3\\times (8\\times 2)$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes3.JPG\" width=\"90%\" height=\"90%\"> 示例：\n- 图中一个格子中包含两个物体，其中行人的包围框应该分配给Anchor box1，车辆包围框应该分配给Anchor box2，因此，该图像的输出应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\n- 若某格子，只含一个车辆物体，则其输出应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\n- 当遇到一个格子包含三个或更多物体时，该算法无法处理。当遇到两个物体被分配给同一Anchor box时，该算法也无法处理。\n- 另外，人们通常人工指定Anchor box的形状，可以选择5~10个形状，覆盖你想要检测的对象的各种形状。后期的YOLO论文中介绍了通过$k$均值来自动选择Anchor box的高级方法。\n\n### YOLO算法\n将所有学过的组件组合在一起，构成YOLO目标检测算法。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%951.JPG\" width=\"100%\" height=\"100%\"> 训练阶段：\n- 假设检测三类物体：行人，车辆和摩托车。采用的是$3 \\times 3$的网格划分。采用两个anchor box。\n- 对于训练集$(x,y)$：\n - $x$为输入图像，维度为$100 \\times 100 \\times 3$\n - 标签$y$的维度为$3 \\times 3 \\times 16$，即$3 \\times 3 \\times (2\\times 8)$。每个$1 \\times 1 \\times 16$对应一个网格的目标标签，共9个网格。\n - 例如对于不含物体的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]$$。对于含有车辆（分配给Anchor box2）的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$\n- 构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 16$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的对网络进行训练。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%952.JPG\" width=\"100%\" height=\"100%\"> 预测阶段：\n- 将图片$x$输入网络，输出维度为$3 \\times 3 \\times 16$。其中，对于不包含物体的网格，其输出向量应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\end{matrix} \\right ]$$。对于包含车辆的网格，其输出向量应为：$$y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]$$。\"..\"代表网络输出的一些无意义的数字（网络不会输出问号）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%95%E6%B3%953.JPG\" width=\"100%\" height=\"100%\"> 进行极大值抑制：\n- 对每一类，分别独立的进行一次非极大值抑制。即分别对行人，车辆及摩托车分别进行一次极大值抑制。\n- 最后的结果，作为算法的输出结果。\n\n### 区域建议\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE1.JPG\" width=\"100%\" height=\"100%\"> R-CNN：\n- 基于滑动窗口的目标检测算法(无论是原始的，还是卷积实现)，对于整张图片中的每一个滑动窗口，都会通过CNN去检测。对于其中很多的明显没有任务物体的窗口，通过CNN去处理它们是浪费时间的。\n- R-CNN(基于区域的CNN)的做法是尝试选出一些区域，然后通过CNN进行检测。\n - R-CNN给出区域建议(region proposals)的做法是运行图像分割算法(结果如图)，其中一些色块(如2000个)的矩形包围边框，即是给出的区域建议。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE2.JPG\" width=\"80%\" height=\"80%\">\n- R-CNN：给出建议区域(通过图像分割算法)；每次对一个区域进行分类；输出类别标签+包围边框。\n - R-CNN并不是以色块的包围边框为最后的预测包围边框，而是会输出包围边框($b_x,b_y,b_h,b_w$)，因此可以得到精确的包围边框。\n - 缺点：太慢。\n- Fast R-CNN：给出建议区域；通过滑动窗口的卷积实现去分类所有的建议区域（R-CNN一次只对一个建议区域做分类）。\n - 缺点：给出建议区域的步骤仍然过慢。\n- Faster R-CNN：用CNN进行区域建议(RPN网络)。\n - 缺点：比Fast R-CNN快，但仍比YOLO慢很多，达不到实时。\n\n吴恩达的观点：\n- 区域建议(region proposals)的思想，在计算机视觉领域有着相当大的影响，值得去了解这些算法。\n- 但这类方法需要分成两个步骤：先是得到建议区域，然后再进行分类。相比较之下，从长远的角度看，一步到位的YOLO这类算法，才是有发展前景的方向。\n\n# 4.特殊应用：人脸识别和风格迁移\n## 4.1 人脸识别\n### 什么是人脸识别\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.JPG\" width=\"80%\" height=\"80%\"> 人脸验证和人脸识别的区别：\n- 人脸验证(face verification)：\n - 输入：一张人脸图片以及姓名/ID\n - 输出：图片中是否为声称的那个人\n- 人脸识别(face recognition)：\n - 有$K$个人的数据集\n - 输入：人脸图片\n - 输出：如果输入图片中是$K$个人中的一个，则输出姓名/ID\n- 人脸验证是一对一问题，人脸识别是1对多问题，人脸识别比人脸验证更难。假设人脸验证系统的错误率是1%，那么在人脸识别中，则相应的错误率就会增加，约$K$%。因此要构建人脸识别，需要使得人脸验证模块达到很高的准确率如(99%)，才能将人脸验证模块用于人脸识别系统中，使得人脸识别系统有高准确率。\n\n### One-shot learning\n对于人类识别任务，挑战之一是要解决One-shot learning问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning1.JPG\" width=\"80%\" height=\"80%\"> \n- One-shot learning：仅从一个样本中学习，然后再次识别出这个人。\n- 如图，左侧为拥有的数据库，有四个员工的各一个样本。\n- 对于该人脸识别任务，不好的解决方法：将四个样本，通过CNN进行训练，输出层为softmax层。\n - 缺点一：如此小的训练集，不足以训练一个鲁棒的CNN。\n - 缺点二：若有新员工加入，需要修改CNN的softmax层，且需要重新训练。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning2.JPG\" width=\"80%\" height=\"80%\"> 对于该人脸识别任务，正确的解决方法：\n- 首先， 通过训练神经网络，去学习一个相似度函数(similarity function)：\n - $d(img1,img2)=degree\\ of\\ difference\\ between\\ images$\n - $d(img1,img2)≤\\tau$: 则判断为同一个人\n - $d(img1,img2)>\\tau$: 则判断为不是同一个人\n - 这样，通过相似度函数，解决了**人脸验证(face verification)**问题。\n- 然后用于人脸识别任务中，将测试图像与数据库中的每一图像进行相似度计算，找出匹配的那个人。\n- 若有新员工加入，只需将他的人脸图像加入数据库，系统依然能照常工作。\n\n### Siamese network\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C1.JPG\" width=\"80%\" height=\"80%\"> 通过Siamese network来学习相似度函数$d(img1,img2)$：\n- 如图，输入为图像$x^{(1)}$。\n- 通过典型的CNN结构(卷积层->池化层->全连接层)，最终得到全连接层输出的特征向量，其维度为$(128,1)$。\n- 该全连接层输出的特征向量可以看成是对图片$x^{(1)}$的编码(encoding)，记为$f(x^{(1)})$。\n- 要比较两张图片$x^{(1)}$和$x^{(2)}$的相似度：\n - 将$x^{(2)}$喂给上述网络，得到图片$x^{(2)}$的编码(encoding)，即$f(x^{(2)})$\n - 计算相似度函数$d(x^{(1)},x^{(2)})$，$d(x^{(1)},x^{(2)})$的定义为$f(x^{(1)})$与$f(x^{(2)})$之差的L2范数，即$d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||_2^2$\n- 该网络源自论文DeepFace。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C2.JPG\" width=\"80%\" height=\"80%\"> Siamese network学习的目标：\n- Siamese network的参数决定了$f(x^{(i)})$\n- 因此相通过学习Siamese network的参数，达到如下目的：\n - 若$x^{(i)}$，$x^{(j)}$是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较小\n - 若$x^{(i)}$，$x^{(j)}$不是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较大\n- 对于如何定义代价函数，下节介绍triplet损失函数。\n\n### Triplet loss function\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss1.JPG\" width=\"80%\" height=\"80%\"> \n- Triplet Loss需要每个样本包含三张图片：Anchor、Positive、Negative，这就是triplet名称的由来。\n- 将三张图片(Anchor,Positive,Negative)的编码简写为$f(A),f(P),f(N)$，由上一节内容可知，我们希望$f(A)$和$f(P)$的距离较小，即$||f(A)-f(P)||^2$较小，而$f(A)$和$f(N)$的距离较大，即$||f(A)-f(N)||^2$较大：\n - $||f(A)-f(P)||^2\\leq ||f(A)-F(N)||^2$\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq 0$\n- 对于上面的不等式，若$f(x^{(i)})$恒为0，会使得$f(A)=0$,$f(P)=0$,$f(N)=0$，那么上述不等式也满足。因此，对上述不等式做出如下修改，通过添加一个超参数 $\\alpha(\\alpha>0)$，以避免$f(x^{(i)})$恒为0的情况：\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq -\\alpha$\n - $||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha \\leq 0$\n - 其中，$\\alpha$也被称为间隔(margin)，类似支持向量机中的间隔(margin)。\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss2.JPG\" width=\"80%\" height=\"80%\"> \n- 定义triplet loss function：给定3张图片(Anchor、Positive、Negative)，$L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha,\\ 0)$\n - 解释：若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha\\leq 0$，则$L(A,P,N)=0$，没有惩罚。\n - 若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha >  0$，则$L(A,P,N)=||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha$，较大惩罚。\n- cost function：$J=\\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})$\n- 假如训练集为1k个人的10k张图片，组成不同的三元组(Anchor、Positive、Negative)，然后进行训练网络，使用梯度下降法，最小化代价函数$J$。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss3.JPG\" width=\"80%\" height=\"80%\"> 训练样本中三元组(Anchor、Positive、Negative)选择：\n- 若三元组(Anchor、Positive、Negative)是随意选择的，意为只要求Anchor和Positive是一个人，Negative是另一个人。那么，$d(A,P)+\\alpha\\leq d(A,N)$这个条件很容易满足。在训练网络的过程中，学习不到有用的东西。\n- 应该选择较难的三元组(Anchor、Positive、Negative)，来用于网络的训练。\n - 想要满足$d(A,P)+\\alpha\\leq d(A,N)$，则较难的三元组(Anchor、Positive、Negative)，意味着$d(A,P)\\approx d(A,N)$。这样算法会尽力使得$d(A,N)$变大，使得$d(A,P)$变小。在训练网络的过程中，才能学习到有用的东西。\n- 更多细节在论文FaceNet中。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss4.JPG\" width=\"80%\" height=\"80%\"> \n- 一些(Anchor、Positive、Negative)的例子。\n\n最后，现在许多商业公司构建的大型人脸识别模型都需要百万级别甚至上亿的训练样本。如此之大的训练样本我们一般很难获取。但是一些公司将他们训练的人脸识别模型发布在了网上，我们可以下载这些预训练的模型进行使用，而不是一切从头开始。\n\n### 人脸验证和二元分类\nTriplet loss 是学习人脸识别CNN的参数的好方法，还有其他的参数学习方法，即将人脸识别问题看成二元分类问题。\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB1.JPG\" width=\"80%\" height=\"80%\">  \n- 如图，选取Siamese network，将两个全连接层的输出给一个逻辑回归单元，然后进行预测。\n- 若是同一个人，则输出1；若是不同的人，则输出0。这样就将人脸识别问题看成二元分类问题。\n- 对于最后的逻辑单元，输出$\\hat y$表达式为：\n - $\\hat y=\\sigma(\\sum_{k=1}^Kw_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)$\n - $\\hat y=\\sigma(\\sum_{k=1}^Kw_k\\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)$，上式被称为$\\chi$ 方公式，也叫$\\chi$方相似度。\n - 具体见DeepFace论文。\n- 该节可再回顾下视频。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB2.JPG\" width=\"80%\" height=\"80%\"> \n- 如图，对于此方法，$x$为一对人脸图片，输出标签为1或0。然后去训练Siamese network。\n\n## 4.2 风格迁移\n### 什么是风格迁移\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB.JPG\" width=\"80%\" height=\"80%\"> \n- 如图，列出几个神经风格迁移的例子。神经风格迁移是CNN模型一个非常有趣的应用，它可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片。\n- 一般用C表示内容(Content)图片，S表示风格(Style)图片，G表示生成的(Generated)图片。\n\n### 深度卷积神经网络学习到的是什么？\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%881.JPG\" width=\"80%\" height=\"80%\"> 可视化深度卷积神经网络的每一层学习到了什么：\n- 可视化方法：选择第一个隐藏层的一个神经元，找出使得该神经元激活值最大化的9个图像块。\n- 如图右侧，每一个$3\\times 3$的小区域，即为使得一个神经元激活值最大的9个图像块。\n- 源自论文Visualizing and understand convolutional networks。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%882.JPG\" width=\"80%\" height=\"80%\">\n可视化的结果可以理解为：\n- 第一层的隐藏神经元通常会寻找相对简单的特征，比如边缘(edge)、颜色阴影(shade of color)。\n- 第二层的隐藏神经元检测到的是纹理(texture)。越深层的神经元检测到越复杂的物体。\n- 浅层网络的感受野(receptive field)较小，深层网络的感受野较大（网络越深，感受野越大）。\n\n### 代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\">\n- 对于内容图片C，风格图片S，生成图片G：为了实现风格迁移，定义一个关于$G$的代价函数$J(G)$，用来评价生成图像的好坏。\n- 用梯度下降法最小化$J(G)$，可以生成想要的任何图片。\n- 定义生成图片G的代价函数：$$J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)$$\n - 其中，$J_{content}(C,G)$为内容代价函数，它用来衡量C的内容与G的内容有多相似。\n - $J_{style}(S,G)$是风格代价函数，它用来衡量S的内容与G的内容有多相似。\n - $$\\alpha$$,$$\\beta$$是超参数，用来调整$$J_{content}(C,G)$$与$$J_{style}(S,G)$$的权重。\n - 用$$\\alpha$$,$$\\beta$$这两个超参数来控制权重，似乎有些冗余。但原论文中就是这样，故保持一致。\n- 源自论文A neual algorithm of artistic style。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"> 在定义了$J(G)$后，为了生成新的图像：\n- 随机初始化生成图像$G$，比如G的尺寸为$100\\times 10 \\times 3$\n- 用梯度下降法去最小化$J(G)$\n - $G=G-\\frac{\\partial}{\\partial G}J(G)$\n - 不断更新G的像素值，使得$J(G)$不断减小，从而使G逐渐有C的内容和G的风格。\n- 如图右侧从随机初始化生成图像$G$，到不断更新G后G的结果。\n\n### 内容代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%86%85%E5%AE%B9%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.JPG\" width=\"80%\" height=\"80%\">\n对于$J(G)$的第一部分$J_{content}(C,G)$，它表示内容图片C与生成图片G之间的相似度。\n- 使用一个预训练好的CNN模型，例如VGG网络。C，S，G共用相同模型和参数。\n- 首先，需要选择合适的层数$l$来计算$J_{content}(C,G)$。根据上一小节的内容，CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果$l$太小，则G与C在像素上会非常接近，没有迁移效果；如果$l$太深，则G上某个区域将直接会出现C中的物体。因此，$l$既不能太浅也不能太深，一般选择网络中间层。\n- 然后计算C和G在$l$层的激活函数输出`$a^{[l](C)}$`与`$a^{[l](G)}$`。\n- $J_{content}(C,G)$的定义为：\n - $$J_{content}(C,G)=\\frac12||a^{[l](C)}-a^{[l](G)}||^2$$\n- 使用梯度下降算法，使$J_{content}(C,G)$不断减小。即可使得$$a^{[l](C)}$$与$$a^{[l](G)}$$越相似，即C和G越相似。\n\n### 风格代价函数\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\">\n- 什么是图片的风格？利用CNN网络模型，图片的风格可以定义成第$l$层隐藏层不同通道间激活函数的乘积（相关性）。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\">\n- 例如我们选取第$l$层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如1通道（红色）提取的是图片的垂直纹理特征，2通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B03.JPG\" width=\"80%\" height=\"80%\">\n- 接下来我们就可以定义图片的风格矩阵（style matrix）为：\n - $$G_{kk'}^{[l]}=\\sum_{i=1}^{n_H^{[l]}}\\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}$$\n - 其中，$[l]$表示第$l$层隐藏层，$k$，$k’$分别表示不同通道，总共通道数为`$n_C^{[l]}$`。$i$，$j$分别表示该隐藏层的高度和宽度。风格矩阵`$G_{kk'}^{[l]}$`计算第$l$层隐藏层不同通道对应的所有激活函数输出和。`$G_{kk'}^{[l]}$`的维度为 `$n_c^{[l]}\\times n_c^{[l]}$`。若两个通道之间相似性高，则对应的`$G_{kk'}^{[l]}$`较大；若两个通道之间相似性低，则对应的`$G_{kk'}^{[l]}$`较小。\n- 风格矩阵`$G_{kk'}^{[l](S)}$`表征了风格图片S第$l$层隐藏层的“风格”。相应地，生成图片G也有`$G_{kk'}^{[l](G)}$`。那么，`$G_{kk'}^{[l][S]}$`与`$G_{kk'}^{[l][G]}$`越相近，则表示G的风格越接近S。\n- 这样，我们就可以定义出`$J^{[l]}_{style}(S,G)$`的表达式：\n - $$J^{[l]}_{style}(S,G)=\\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}\\sum_{k=1}^{n_H^{[l]}}\\sum_{k'=1}^{n_W^{[l]}}||G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}||^2$$\n- 定义完`$J^{[l]}_{style}(S,G)$`之后，我们的目标就是使用梯度下降算法，不断迭代修正G的像素值，使`$J^{[l]}_{style}(S,G)$`不断减小。\n\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B04.JPG\" width=\"80%\" height=\"80%\">\n- 以上我们只比较计算了一层隐藏层$l$。为了提取的“风格”更多，也可以使用多层隐藏层，然后相加，表达式为：\n - $$J_{style}(S,G)=\\sum_l\\lambda^{[l]}\\cdot J^{[l]}_{style}(S,G)$$\n - 其中，`$\\lambda^{[l]}$`表示累加过程中各层`$J^{[l]}_{style}(S,G)$`的权重系数，为超参数。\n- 根据以上两小节的推导，最终的代价函数为：\n - $$J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)$$\n - 使用梯度下降算法进行迭代优化即可。\n\n### 从1维卷积到3维卷积\n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF1.JPG\" width=\"80%\" height=\"80%\">\n- 之前介绍的CNN网络处理的都是2D图片，2D卷积的规则：\n - 输入图片维度：14 x 14 x 3\n - 滤波器尺寸：5 x 5 x 3，滤波器个数：16\n - 输出图片维度：10 x 10 x 16\n- 将2D卷积推广到1D卷积，1D卷积的规则：\n - 输入时间序列维度：14 x 1\n - 滤波器尺寸：5 x 1，滤波器个数：16\n - 输出时间序列维度：10 x 16\n \n<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF2.JPG\" width=\"80%\" height=\"80%\">\n- 对于3D卷积，其规则：\n - 输入3D图片维度：14 x 14 x 14 x 1\n - 滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16\n - 输出3D图片维度：10 x 10 x 10 x 16\n","slug":"深度学习课程(四)卷积神经网络","published":1,"updated":"2018-01-31T13:41:31.271Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w4e006fqslpmt8nb8pr","content":"<h1 id=\"1-卷积神经网络基础\"><a href=\"#1-卷积神经网络基础\" class=\"headerlink\" title=\"1.卷积神经网络基础\"></a>1.卷积神经网络基础</h1><h2 id=\"1-1-卷积神经网络\"><a href=\"#1-1-卷积神经网络\" class=\"headerlink\" title=\"1.1 卷积神经网络\"></a>1.1 卷积神经网络</h2><h3 id=\"计算机视觉\"><a href=\"#计算机视觉\" class=\"headerlink\" title=\"计算机视觉\"></a>计算机视觉</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%891.JPG\" width=\"50%\" height=\"50%\"> 举了计算机视觉中的几个典型应用：</p>\n<ul>\n<li>图像分类</li>\n<li>目标检测</li>\n<li>风格迁移</li>\n</ul>\n<a id=\"more\"></a> \n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%892.JPG\" width=\"80%\" height=\"80%\"> 在应用计算机视觉时，所面临的一个挑战是数据的输入可能会非常大：</p>\n<ul>\n<li>对$64 \\times 64$的小图片，输入特征的维度是$12288(64\\times 64\\times 3)$。</li>\n<li>对稍大的$1000\\times 1000$的图片，输入特征的维度是$3million(1000\\times 1000\\times 3)$：<ul>\n<li>神经网络的输入$x\\in R^{3m}$，假设第一个隐藏层有1000个神经元，则第一层的参数$W^{[1]}$的维度为$(1000,3m)$，即包含30亿个参数。</li>\n<li>对于如此大量的参数，难以获取足够多的数据来防止过拟合。</li>\n<li>内存需要处理30个参数的神经网络，所需内存太大。</li>\n<li>要解决这个问题，需进行卷积操作。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"边缘检测示例\"><a href=\"#边缘检测示例\" class=\"headerlink\" title=\"边缘检测示例\"></a>边缘检测示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B1.JPG\" width=\"90%\" height=\"90%\"> 以边缘检测为例，说明卷积操作是如何进行的。如图：</p>\n<ul>\n<li>卷积神经网络的浅层检测到的是边缘，然后是物体的部件，深层检测到整体。</li>\n<li>想要检测图像中的垂直边缘，下图继续。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 介绍卷积操作：</p>\n<ul>\n<li>$6\\times 6$的图像(灰度图，单通道)与可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器，以步长为1，进行卷积操作，结果如图。<ul>\n<li>$*$ 表示卷积操作。Python中，卷积用函数conv_forward()；tensorflow中，卷积用函数tf.nn.conv2d()；keras中，卷积用函数Conv2D()。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B3.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>$6\\times 6$的图像(灰度图，单通道)的左半部分像素强度较大，即较白，右半部分像素强度较小，故较暗（其实灰度图中白为255，黑为0）。</li>\n<li>仍是上图中可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器。左侧较白，中间较暗，右侧最暗。</li>\n<li>卷积结果如图所示。输出图像像中中间有一条较白的宽带，即垂直边缘。<ul>\n<li>输出图像中边缘太粗，是因为图像过小，若对$1000\\times 1000$的图像进行卷积，输出图像中的边缘将不会显得这么粗。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"更多边缘检测内容\"><a href=\"#更多边缘检测内容\" class=\"headerlink\" title=\"更多边缘检测内容\"></a>更多边缘检测内容</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B1.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>图片边缘有两种边缘过渡方式，一种是由明变暗，另一种是由暗变明。从输出图像可看出，该垂直边缘滤波器，可以区别出这两种明暗变化的区别。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>如图，垂直边缘检测和水平边缘检测的滤波器如图所示。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>更经典的Sobel滤波器和Scharr滤波器。<ul>\n<li>Sobel滤波器的优点是增加了中间一行的权重，也就是处在中央的像素点，使得结果更鲁棒一些。</li>\n<li>图中为进行垂直边缘检测的形式，翻转90度后即得进行水平边缘检测的形式。</li>\n</ul>\n</li>\n<li>随着深度学习的兴起，我们学习到的事情是：当你想检测出某些复杂图像的边缘，你不一定要去使用那些研究者们手工设计的滤波器。而将滤波器中的数字当作参数，通过神经网络学习这些参数。学习到的滤波器对于数据的统计特性的捕捉能力甚至比任何一个手工设计的滤波器要好。</li>\n</ul>\n<h3 id=\"填充\"><a href=\"#填充\" class=\"headerlink\" title=\"填充\"></a>填充</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%851.JPG\" width=\"90%\" height=\"90%\"><br>不进行填充(padding)：</p>\n<ul>\n<li>$n\\times n$的图像与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n-f+1)\\times (n-f+1)$。<ul>\n<li>理解公式：$1$为卷积核位于图像最后一个位置，即进行一次卷积操作，$(n-f)$表示图像空出最后一个卷积核位置后的尺寸，也即可进行卷积的次数。故总的输出尺寸为$(n-f+1)$。</li>\n<li>如$6\\times 6$的图像与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸尺寸为$4\\times 4$。</li>\n</ul>\n</li>\n<li>缺点：每次做卷积操作后：<ul>\n<li>图像会缩小(图像的高度和宽度都会缩小)。</li>\n<li>丢失边缘信息(原图像中处于边缘的像素进行较少次的卷积运算，而处于中间的像素进行较多次的卷积运算)。</li>\n</ul>\n</li>\n<li>解决方法：对图像进行填充后，进行卷积。</li>\n</ul>\n<p>进行填充：</p>\n<ul>\n<li>$n\\times n$的图像,进行$p=padding=p$的填充后，与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n+2p-f+1)\\times (n+2p-f+1)$。<ul>\n<li>如$6\\times 6$的图像,进行$p=1$的填充后，尺寸为$8\\times 8$。与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸为$6\\times 6$。</li>\n<li>通常采用零填充(zero-padding)，即在图像边缘填充的值为0。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%852.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>“Valid” convolution：不进行填充。即$p=0$。 </li>\n<li>“Same” convolution：进行填充，使得输出尺寸和输入尺寸相同(保留图像的高度和宽度。但输入和输出的通道数可以不同)。<ul>\n<li>进行填充的输出尺寸为：$(n+2p-f+1)\\times (n+2p-f+1)$，原始输入尺寸为：$n\\times n$。令$(n+2p-f+1)=n$，则$p=\\frac{f-1}{2}$。</li>\n</ul>\n</li>\n<li>另外，按照惯例，在计算机视觉中，对于卷积核/滤波器的尺寸$f \\times f$，$f$通常是奇数。<ul>\n<li>如果$f$是偶数，则只能使用一些不对称的填充。$f$是奇数，才能有自然的填充。</li>\n<li>奇数的卷积核/滤波器，会有一个中心位置。在计算机视觉中，有一个中间像素，便于指出卷积核的位置。</li>\n<li>大小为$3\\times 3$、$5\\times 5$和$7\\times 7$的卷积核很常见，$1\\times 1$也有意义。稍后讲解。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"步长\"><a href=\"#步长\" class=\"headerlink\" title=\"步长\"></a>步长</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF1.JPG\" width=\"90%\" height=\"90%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>输入图片尺寸为$n \\times n$，卷积核尺寸为$f \\times f$，填充(padding)为$p$，步长(stride)为$s$。<ul>\n<li>则输出尺寸为：<script type=\"math/tex\">\\lfloor\\frac{n+2p-f}{s}+1\\rfloor\\ \\times \\ \\lfloor\\frac{n+2p-f}{s}+1\\rfloor</script></li>\n<li>其中，$\\lfloor z \\rfloor=floor(z)$，为向下取整，地板除法。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>在机器学习或深度学习领域，我们所使用的卷积操作，严格意义上应叫做互相关(cross-correlation)。</li>\n<li>在数学或信号处理的教科书中，卷积操作需先对卷积核进行翻转(双重镜像)后，再进行卷积操作。包含对卷积核的反转，可使得卷积运算拥有$(A*B)*C=A*(B*C)$的结合律性质。</li>\n<li>本课程按照机器学习或深度学习中的惯例，将不包含翻转操作的互相关，称为卷积操作。</li>\n</ul>\n<h3 id=\"对体进行卷积操作\"><a href=\"#对体进行卷积操作\" class=\"headerlink\" title=\"对体进行卷积操作\"></a>对体进行卷积操作</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>彩色图像的尺寸为$6 \\times 6 \\times 3$，分别表示图片的高度(height)、宽度(weight)和通道数(#channels)。</li>\n<li>卷积核的尺寸为$3 \\times 3 \\times 3$，分别表示卷积核的高度(height)、宽度(weight)和通道数(#channels)。</li>\n<li>输出尺寸为$4 \\times 4$。<ul>\n<li>解释：卷积核置于起始卷积位置(输入图像的左上)，卷积核的各通道与输入图像的各通道做卷积操作，然后3个通道的各个输出(各一个数)相加，得到最终输出(一个数)。卷积核移动，进行下一次卷积。</li>\n</ul>\n</li>\n<li>其中，输入图像的通道数(#channels)与卷积核的通道数必须相等。</li>\n<li>其中，通道数(#channels)也称为深度(depth)，但容易与神经网络的深度混淆，本课程只称其为通道数(#channels)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>输入图像的尺寸为$6 \\times 6 \\times 3$</li>\n<li>两个卷积核，第一个卷积核用来检测垂直边缘，其尺寸为$3 \\times 3 \\times 3$。第二个卷积核用来检测水平边缘，其尺寸为$3 \\times 3 \\times 3$。</li>\n<li>输出尺寸为$4 \\times 4 \\times 2$。</li>\n</ul>\n<p>总结，假设$p=0$，$s=1$：</p>\n<ul>\n<li>输入尺寸：$n \\times n \\times n_c$</li>\n<li>卷积核尺寸：$f \\times f \\times n_c$ </li>\n<li>输出尺寸为：$(n-f+1) \\times (n-f+1) \\times n_c^{\\prime}$。<ul>\n<li>其中$n_c^{\\prime}$为输出尺寸的通道数，等于卷积核个数(#filters)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"单层卷积网络\"><a href=\"#单层卷积网络\" class=\"headerlink\" title=\"单层卷积网络\"></a>单层卷积网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>单层卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C4.jpg\" width=\"90%\" height=\"90%\"><ul>\n<li>相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏置$b$(每个卷积核有一个偏置，例如图中两个卷积核各有一个偏置)。</li>\n<li>整个过程与标准的神经网络单层结构非常类似：<script type=\"math/tex; mode=display\">Z^{[l]}=W^{[l]}A^{[l-1]}+b</script><script type=\"math/tex; mode=display\">A^{[l]}=g^{[l]}(Z^{[l]})</script></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2.JPG\" width=\"90%\" height=\"90%\"> 单卷积层中的参数：</p>\n<ul>\n<li>若一个卷积层有，卷积核个数为10，每个卷积核尺寸为$3 \\times 3 \\times 3$，每个卷积核有1个偏置参数(一个实数)。</li>\n<li>则，单卷积层中的参数个数为：$(3*3*3+1)*10=280$个参数。</li>\n<li><strong>注意到，无论输入图像的尺寸多大，该卷积层的参数个数始终为280个。即使图片很大，参数依然很少，因此卷积神经网络不容易过拟合(less prone to overfitting)</strong>。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3.JPG\" width=\"90%\" height=\"90%\"> <strong>总结CNN中的符号表示</strong>，若第$l$层是卷积层：</p>\n<ul>\n<li>符号表示：<ul>\n<li>$f^{[l]} = $卷积核尺寸(filter size)</li>\n<li>$p^{[l]} = $填充(padding)</li>\n<li>$s^{[l]} = $步长(stride)</li>\n<li>$n_c^{[l]} = $卷积核个数(number of filters)</li>\n</ul>\n</li>\n<li>输入尺寸：$n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_c^{[l-1]}$</li>\n<li>每个卷积核的尺寸：$f^{[l]} \\times f^{[l]} \\times  n_c^{[l-1]}$</li>\n<li>权重尺寸为： $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times  n_c^{[l]}$</li>\n<li>偏置尺寸为：$n_c^{[l]}$ 或$(1,1,1,n_c^{[l]})$</li>\n<li>输出$a^{[l]}$的尺寸为： $n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$</li>\n<li>输出$A^{[l]}$的尺寸为： $m \\times n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$<ul>\n<li>其中，<script type=\"math/tex\">n_H^{[l]}=\\lfloor \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor</script>，<script type=\"math/tex\">n_W^{[l]}=\\lfloor \\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor</script></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"简单的卷积网络示例\"><a href=\"#简单的卷积网络示例\" class=\"headerlink\" title=\"简单的卷积网络示例\"></a>简单的卷积网络示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>该CNN模型各层结构如上图所示。</li>\n<li>需要注意的是，$a^{[3]}$的维度是$7 \\times 7 \\times 40$，将$a^{[3]}$排列成1列，维度为$1960 \\times 1$，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 $\\hat y$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> CNN有三种类型的层：</p>\n<ul>\n<li>卷积层(Convolution, CONV）</li>\n<li>池化层(Pooling, POOL）</li>\n<li>全连接层(Fully connected, FC）</li>\n</ul>\n<h3 id=\"池化层\"><a href=\"#池化层\" class=\"headerlink\" title=\"池化层\"></a>池化层</h3><p>除了卷积层(convolutional layers)，CNN中也经常使用池化层(pooling layers)来减小模型来加速计算，同时让检测到的特征更鲁棒。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%821.JPG\" width=\"100%\" height=\"100%\"> 最大池化(max pooling)，即取滤波器区域内的最大值。对二维矩阵做最大池化：</p>\n<ul>\n<li>输入尺寸为$4 \\times 4$</li>\n<li>超参数：$f=2$，$s=2$</li>\n<li>没有参数。 </li>\n<li>输出尺寸为$2 \\times 2$</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> 对三维矩阵做最大池化：</p>\n<ul>\n<li>输入尺寸为$5 \\times 5 \\times n_c$</li>\n<li>超参数：$f=3$，$s=1$</li>\n<li>没有参数。 </li>\n<li>输出尺寸为$3 \\times 3 \\times n_c$<ul>\n<li>注意，对每一通道，分别做最大池化，故输出尺寸的通道数等于输入尺寸的通道数。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 平均池化(average pooling)，即计算滤波器区域内的平均值。其它同上。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%824.JPG\" width=\"90%\" height=\"90%\"> 总结：</p>\n<ul>\n<li>池化层的超参数：<ul>\n<li>滤波器尺寸(filter size)：$f$</li>\n<li>步长(stride)：$s$</li>\n<li>极少使用填充(padding)</li>\n<li>最大池化(max pooling)或平均池化(average pooling)。最大池化层更常用。</li>\n</ul>\n</li>\n<li>常用的池化层超参数有$f=2$，$s=2$，相当于将输入尺寸(高度和宽度)缩小一半。也有$f=3$，$s=2$用法。</li>\n<li>没有参数！<ul>\n<li>池化过程中没有参数需要学习。只有需要设置的上述超参数，可能是手工设置，也可能是通过交叉验证设置。</li>\n</ul>\n</li>\n<li>输入尺寸为：$n_H \\times n_W \\times n_c$</li>\n<li>输出尺寸为： $\\lfloor \\frac{n_H-f}{s}+1 \\rfloor \\times \\lfloor \\frac{n_W-f}{s}+1 \\rfloor \\times n_c$<ul>\n<li>注意到，输出尺寸的通道数与输入尺寸的通道数相同。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"卷积神经网络示例\"><a href=\"#卷积神经网络示例\" class=\"headerlink\" title=\"卷积神经网络示例\"></a>卷积神经网络示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"> 该CNN为了识别0~9的数字。该CNN类似Yann LeCun提出的LeNet-5:</p>\n<ul>\n<li>卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B3.jpg\" width=\"100%\" height=\"100%\"> </li>\n<li>输入为0~9的数字的图像。</li>\n<li>将CONV1和POOL1称为网络的第一层(Layer 1)。<ul>\n<li>在CNN相关文献中，一种惯例是将一个卷积层和一个池化层合称为一层；一种惯例是将一个卷积层称为一层，一个池化层称为一层。</li>\n<li>本课程在统计网络层数时，只统计有权重的层，即将CONV1和POOL1作为网络第一层。 </li>\n</ul>\n</li>\n<li>将CONV2和POOL2称为网络的第二层(Layer 2)。然后，将POOL2的输出平整化为维度为$400\\times 1$的向量。</li>\n<li>全连接层FC3为网络第三层(Layer 3)。全连接层即为标准神经网络结构。输入的400个单元和该层的120个单元每个都相连接，故称为全连接层。权重$W^{[3]}$的维度为$(120,400)$。偏置$b^{[3]}$的维度为$(120,1)$</li>\n<li>全连接层FC4为网络第四层(Layer 4)。</li>\n<li>最后的输出层为softmax层，由10个神经元构成(识别0~9的数字)。</li>\n<li>注意到，随着网络深度的加深，高度$n_H$和宽度$n_W$会减小，而通道数$n_c$会增加。</li>\n<li>CNN的另一种常见模式是一个或多个卷积层后面跟一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 展示上图中CNN的各层的激活值维度和参数数量：</p>\n<ul>\n<li>池化层没有参数。</li>\n<li>卷积层的参数相对较少，许多参数都存在于全连接层。</li>\n<li>随着网络的加深，激活函数的尺寸逐渐变小。减小的太快会影响网络性能，故是逐渐减小。</li>\n</ul>\n<h3 id=\"为什么使用卷积层？\"><a href=\"#为什么使用卷积层？\" class=\"headerlink\" title=\"为什么使用卷积层？\"></a>为什么使用卷积层？</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%821.JPG\" width=\"90%\" height=\"90%\"> 相比标准神经网络，CNN的优势之一就是参数数目要少得多：</p>\n<ul>\n<li>对于一张$32 \\times 32 \\times 3$的图片。卷积层的超参数为$f=5$，卷积核的个数为$n_c=6$。则输出维度为$28 \\times 28 \\times 6$。</li>\n<li>输入尺寸为$32 \\times 32 \\times 3=3072$，输出尺寸为$28 \\times 28 \\times 6=4704$。</li>\n<li>若采用标准神经网络，则参数$W$的维度为$(4704,3072)$，共$4704 \\times 3072+4704 \\approx 14m$个参数。仅对于$32 \\times 32 \\times 3$的小图片，就有如此多的参数。</li>\n<li>而采用卷积层，每个卷积核的参数为$5\\times 5 +1=26$，有6个卷积核，则共有$6 \\times 26= 156$个参数。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> CNN的参数数目少的原因有两个：</p>\n<ul>\n<li>参数共享：一个特征检测器（例如垂直边缘检测器）如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。</li>\n<li>稀疏连接：每一层的每个输出只与一小部分输入有关。<ul>\n<li>如图，输出矩阵的左上角的0，只与输入矩阵的左上角的$3\\times 3$的矩阵有关。其他像素值都不会对该输出产生影响。</li>\n</ul>\n</li>\n<li>通过以上两种机制，CNN有较少的参数，允许我们以较小的训练集训练它，从而不易过拟合。</li>\n<li>此外，CNN善于捕捉平移不变性(translation invariance)。即CNN进行分类时，不易受物体所处图片位置发生平移的影响，更鲁棒。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 如何训练一个CNN：</p>\n<ul>\n<li>为了构建一个猫的检测器。</li>\n<li>训练集为$(x^{(1)},y^{(1)})…(x^{(m)},y^{(m)})$，$x^{(i)}$为输入图像，$y^{(i)}$为标签。</li>\n<li>如图，若选定了CNN结构：包含输入层，卷积层，池化层，全连接层和softmax输出层。</li>\n<li>依然同之前课程一样，定义代价函数$J=\\frac{1}{m}\\sum_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})$。</li>\n<li>采用优化算法(如梯度下降/Momentum/RMSprop/Adam)，来优化网络中的所有参数，去减小代价函数$J$。</li>\n</ul>\n<h1 id=\"2-深度卷积模型：案例学习\"><a href=\"#2-深度卷积模型：案例学习\" class=\"headerlink\" title=\"2.深度卷积模型：案例学习\"></a>2.深度卷积模型：案例学习</h1><h2 id=\"2-1-案例学习\"><a href=\"#2-1-案例学习\" class=\"headerlink\" title=\"2.1 案例学习\"></a>2.1 案例学习</h2><h3 id=\"为什么进行案例学习\"><a href=\"#为什么进行案例学习\" class=\"headerlink\" title=\"为什么进行案例学习\"></a>为什么进行案例学习</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0.JPG\" width=\"90%\" height=\"90%\">  </p>\n<ul>\n<li>这一周会讲解的经典CNN模型：<ul>\n<li>LeNet-5</li>\n<li>AlexNet</li>\n<li>VGG</li>\n</ul>\n</li>\n<li>另外，还会讲解：<ul>\n<li>ResNet</li>\n<li>Inception </li>\n</ul>\n</li>\n</ul>\n<h3 id=\"经典卷积网络\"><a href=\"#经典卷积网络\" class=\"headerlink\" title=\"经典卷积网络\"></a>经典卷积网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C1.JPG\" width=\"100%\" height=\"100%\"> LeNet-5由Yann LeCun于1998年提出，用于识别0~9的手写数字：</p>\n<ul>\n<li>针对灰度图像，故输入图片维度为$32\\times 32\\times 1$</li>\n<li>对于卷积层，那时人们不使用填充(padding)，即通常采取”valid” convolution。</li>\n<li>对于池化层，那时人们更多使用平均池化(现在通常使用最大池化)。</li>\n<li>该模型约有6万个参数。</li>\n<li>后来沿用的模式一：<strong>随着网络的加深，图像的高度$n_H$和宽度$n_W$在减小，而通道数$n_c$在增加</strong>。</li>\n<li>后来沿用的模式二：一个或多个卷积层接一个池化层，一个或多个卷积层接一个池化层，然后是几个全连接层，然后是输出层。</li>\n<li>对于激活函数，那时人们使用的是sigmoid/tanh(如今通常使用ReLU，AlexNet提出)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C2.JPG\" width=\"100%\" height=\"100%\"> AlexNet是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton于2012年共同提出，用于识别ImageNet中的1000类图像：</p>\n<ul>\n<li>AlexNet模型与LeNet-5模型类似，但更大，约有6千万个参数。</li>\n<li>对于激活函数，AlexNet使用了ReLU激活函数。</li>\n<li>当时，GPU还较慢，AlexNet采用了在两个GPU上并行计算。</li>\n<li>AlexNet中含有一种特殊的层，叫做局部相应归一化层(Local Response Normalization, LRN)。但后来研究者发现效果有限，故如今并不使用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C3.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>VGG-16中一个精彩的地方在于，没有那么多的超参数，专注于构建简单的网络结构：<ul>\n<li>对于卷积层，只使用$f=3$，$s=1$，”same”填充。</li>\n<li>对于池化层，只使用$f=2$，$s=2$的最大池化层。</li>\n</ul>\n</li>\n<li>每次池化后，图像的高度$n_H$和宽度$n_W$缩小一半。每一组卷积层之后，通道数$n_c$增加一倍，直到512。</li>\n<li>缺点：包含1亿三千万个参数，以现在的标准来看，都是非常大的网络，有太多参数需要训练。</li>\n<li>优点：VGG-16的结构并不复杂，<strong>结构很规整</strong>，这一点非常吸引研究者。</li>\n<li>VGG-16中的16指的是包含权重的卷积层、全连接层和输出层(未计没有参数的池化层)。</li>\n<li>VGG-19的表现与VGG-16差不多，更多的人使用VGG-16。</li>\n</ul>\n<h3 id=\"ResNets\"><a href=\"#ResNets\" class=\"headerlink\" title=\"ResNets\"></a>ResNets</h3><p>由于梯度消失(vanishing gradients)和梯度爆炸(exploding gradients)的原因，非常非常深的网络是难以训练的。这一节学习跳跃连接(skip connection)，它可从某一层网络获取激活值，然后喂给更深的一层网络。通过跳跃连接，即可构建出ResNets(Residual Networks)，让我们可以训练非常非常深的网络。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets1.JPG\" width=\"100%\" height=\"100%\"> ResNet是由残差模块(residual block)构建的，上图介绍残差模块：</p>\n<ul>\n<li>残差模块的主路径(main path)为：$a^{[l]}$ -&gt; 线性操作 -&gt; ReLU(得$a^{[l+1]}$) -&gt; 线性操作 -&gt; ReLU(得$a^{[l+2]}$)。</li>\n<li>残差模块的捷径(short cut)/跳跃连接为：$a^{[l]}$ 直接隔层与$l+2$层的线性输出相连，与$z^{[l+2]}$共同通过激活函数（ReLU）输出 $a^{[l+2]}$。</li>\n<li>具体公式如下：<ul>\n<li>$z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}$</li>\n<li>$a^{[l+1]}=g(z^{[l+1]})$</li>\n<li>$z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}$</li>\n<li>$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets2.JPG\" width=\"100%\" height=\"100%\"> 通过堆叠许多残差模块在一起，即构建成ResNet：</p>\n<ul>\n<li>在ResNet论文中，将非Residual Network称为Plain Network。</li>\n<li>在一个Plain Network中，加上捷径/跳跃连接，如图中每两层构成一个残差模块，共5个残差模块。整体即构成一个残差网络(residual network)。</li>\n<li>若用优化算法优化一个朴素的网络(plain network)，其效果如图：<ul>\n<li>理论上：随着网络深度的加深，训练误差应越来越小。</li>\n<li>实际上：起初，训练误差会降低。但随着层数的增多，训练误差上升。</li>\n</ul>\n</li>\n<li>若用优化算法优化一个ResNet，其效果如图：<ul>\n<li>随着网络深度的加深，训练误差越来越小。</li>\n</ul>\n</li>\n<li>跳跃连接确实有助于解决梯度消失和梯度爆炸的问题，让我们在训练十分深层的网络时得到好的性能。</li>\n</ul>\n<h3 id=\"RestNets为何有效\"><a href=\"#RestNets为何有效\" class=\"headerlink\" title=\"RestNets为何有效\"></a>RestNets为何有效</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%881.JPG\" width=\"100%\" height=\"100%\"> 给一个深度网络，增加了一个残差模块后，网络的深度得到了增加：</p>\n<ul>\n<li>$a^{[l+2]}$的表达式为：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})$。</li>\n<li>注意到，如果使用L2正则化或权重衰减，将会使得$W^{[l+2]}$不断减小。假设$W^{[l+2]}=0$，$b^{[l+2]}=0$（发生梯度消失）。</li>\n<li>那么，<script type=\"math/tex\">a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}</script>（$a^{[l]}$本就大于等于0，再经过ReLU激活函数，还是$a^{[l]}$本身）。</li>\n<li>以上结果表明：恒等函数(identity function)对于残差模块来说，非常容易学习。因此，尽管增加了残差模块，一方面没有伤害网络的效率，另一方面还提升了网络的性能。</li>\n<li>残差网络有效的原因：<ul>\n<li>残差模块学习恒等函数非常容易(没有伤害网络的学习效率)。</li>\n<li>残差模块的添加起码不会降低网络的表现，很多时候可以提升网络的表现。</li>\n</ul>\n</li>\n<li>另外，残差网络的另一个细节是：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中$z^{[l+2]}$与$a^{[l]}$拥有相同的维度：<ul>\n<li>故ResNets中使用了许多”same”卷积。</li>\n<li>若$a^{[l+2]}$与$a^{[l]}$维度不一样，可以引入矩阵$W_s$，使得$W_s \\cdot a^{[l]}$的维度与$a^{[l+2]}$一致，即<script type=\"math/tex\">a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})</script>。矩阵$W_s$可以设置为通过网络学习的参数矩阵，也可以设置为固定矩阵(如只是给$a^{[l]}$进行零填充)。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%882.JPG\" width=\"100%\" height=\"100%\"> 简单分析ResNets结构特点：</p>\n<ul>\n<li>ResNets中采用了很多$3\\times 3$的same卷积。<ul>\n<li>same卷积是为了进行$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中的$z^{[l+2]}+a^{[l]}$。</li>\n</ul>\n</li>\n<li>池化层后需调整$W_s$的维度，即进行<script type=\"math/tex\">a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})</script>。</li>\n<li>ResNets的网络结构是几个卷积层接一个池化层，然后重复，然后是一个全连接层，然后是softmax输出层。</li>\n</ul>\n<h3 id=\"Network-in-NetWork以及1x1卷积\"><a href=\"#Network-in-NetWork以及1x1卷积\" class=\"headerlink\" title=\"Network in NetWork以及1x1卷积\"></a>Network in NetWork以及1x1卷积</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/netwrok%20in%20network1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>如图上半部分，对于单通道的二维矩阵，进行$1\\times 1$卷积的效果就是乘以一个数字。</li>\n<li>如图下半部分，对$6 \\times 6 \\times 32$的体，卷积核为$1 \\times 1 \\times 32$，进行卷积的效果是：<ul>\n<li>对于输入体的36个切片，每个切片的维度都为(1,1,32)。每一个切片都与卷积核逐元素相乘，然后求和，得到一个实数，即输出矩阵中的一个绿点。</li>\n<li>若应用在CNN中，则相当于：输入体中的每一切片逐元素乘以卷积核中的权重，然后求和，加上偏置，然后进行ReLU激活，如输出矩阵中的一个黄点。</li>\n<li>若有多个卷积核，则输出结果为多通道。</li>\n</ul>\n</li>\n<li>因此，$1\\times 1$卷积应用在CNN中，则可以理解为：36个切片中的32个单元，与#filters中的每个卷积核进行了全连接，输出维度为$6 \\times 6 \\times n_c^{[l+1]}$，其中<script type=\"math/tex\">n_c^{[l+1]}= \\# filters</script>。</li>\n<li>此方法称为$1\\times 1$卷积或Network in NetWork。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/network%20in%20network2.JPG\" width=\"90%\" height=\"90%\"> $1\\times 1$卷积可以用来缩小通道数量：</p>\n<ul>\n<li>输入维度是$28 \\times 28 \\times 192$，通过32个$1\\times 1$卷积核(准确地说，维度为$1\\times 1\\times 192$)，输出为$28 \\times 28 \\times 32$，缩小了通道数。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>$1\\times 1$卷积<strong>给网络增加了非线性，可以让网络学习更复杂的函数</strong>。</li>\n<li>通过$1\\times 1$卷积，<strong>可减少或保持或增加通道数</strong>。</li>\n</ul>\n<h3 id=\"Inception-Network动机\"><a href=\"#Inception-Network动机\" class=\"headerlink\" title=\"Inception Network动机\"></a>Inception Network动机</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA1.JPG\" width=\"90%\" height=\"90%\"> Inception网络的基本思想是：代替人为选择卷积核尺寸以及是否使用池化层，而是将它们都添加进网络，然后将输出串联起来，然后让网络去学习参数，去决定采用哪些组合：</p>\n<ul>\n<li>输入维度为$29\\times 28 \\times 192$</li>\n<li>通过$1\\times 1$的same卷积，使得输出为$28 \\times 28 \\times 64$</li>\n<li>通过$3\\times 3$的same卷积，使得输出为$28 \\times 28 \\times 128$</li>\n<li>通过$5\\times 5$的same卷积，使得输出为$28 \\times 28 \\times 32$</li>\n<li>通过最大池化层，$s=1$，使用填充，使成为same-pool，使得输出为$28 \\times 28 \\times 32$</li>\n<li>将所有输出串联起来，维度为$28 \\times 28 \\times 256$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA2.JPG\" width=\"90%\" height=\"90%\"> 上图中描述的Inception模块中有一个问题，就是计算成本的问题：</p>\n<ul>\n<li>集中讨论上图中的$5 \\times 5$的卷积核</li>\n<li>进行该卷积计算，需要进行的乘法次数为：<ul>\n<li>输出个数为：$28\\times 28\\times 32$</li>\n<li>每个输出需进行的乘法次数为：$5\\times 5\\times 192$</li>\n<li>故需进行的乘法次数为：$(28\\times 28\\times 32)\\times (5\\times 5\\times 192)\\approx 120m$</li>\n</ul>\n</li>\n<li>即使用现代计算机，计算1.2亿次计算，也是相当昂贵的操作。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA3.JPG\" width=\"90%\" height=\"90%\"> 通过$1\\times 1$卷积层，降低计算成本：</p>\n<ul>\n<li>结构如图，先通过$1\\times 1$卷积，再进行$5\\times 5$卷积，最终输出和上图相同。</li>\n<li>加入$1\\times 1$卷积后，进行两次卷积计算，需要进行的乘法次数为：<ul>\n<li>$1\\times 1$卷积需要的乘法次数：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)$</li>\n<li>$5\\times 5$卷积需要的乘法次数：$(28\\times 28\\times 32)\\times (5\\times 5\\times 16)$</li>\n<li>进行两次卷积计算，需要进行的乘法次数为：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)+(28\\times 28\\times 32)\\times (5\\times 5\\times 16)\\approx 12.4m$</li>\n</ul>\n</li>\n<li>通常我们把该$1\\times 1$卷积层称为“瓶颈层”(bottleneck layer)，因为它是网络中最小的那个部分。<strong>先通过“瓶颈层”缩小网络，然后再扩大网络，显著降低了计算成本</strong>，乘法计算次数从120m减少为12.4m。</li>\n</ul>\n<h3 id=\"Inception-Network\"><a href=\"#Inception-Network\" class=\"headerlink\" title=\"Inception Network\"></a>Inception Network</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork1.JPG\" width=\"90%\" height=\"90%\"> 正式介绍Inception模块：</p>\n<ul>\n<li>输入为前一层的激活函数。</li>\n<li>单独的$1\\times 1$卷积层，输出维度为$28 \\times 28 \\times 64$。</li>\n<li>先是$1\\times 1$卷积层，再接$3\\times 3$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 128$。</li>\n<li>先是$1\\times 1$卷积层，再接$5\\times 5$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 32$。</li>\n<li>先是$f=3$，$s=1$的same最大池化层，再接$1\\times 1$卷积层(为了降低通道数)，输出维度为$28 \\times 28 \\times 32$。</li>\n<li>串联(concatenate)所有输出，输出维度为$28 \\times 28 \\times 256$。(Caffe中的concat层，实现此串联操作。)</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetworkk2.JPG\" width=\"100%\" height=\"100%\"> 正式介绍Inception Network，如图：</p>\n<ul>\n<li>Inception Network由很多Inception模块构成。</li>\n<li>Inception Network中的另一个细节是：在中间层设置了两个辅助softmax分类器，它们保证了即便是中间层的隐藏神经元计算的特征，在预测图像类别时，表现也不太差。它们在Inception Network起着正则化的效果，帮助防止过拟合。</li>\n<li>Inception Network也称为GoogleNet。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork3.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>Inception Network中“Inception”取自莱昂纳多的电影《Inception》。</li>\n</ul>\n<h2 id=\"2-2-使用卷积网络的实用建议\"><a href=\"#2-2-使用卷积网络的实用建议\" class=\"headerlink\" title=\"2.2 使用卷积网络的实用建议\"></a>2.2 使用卷积网络的实用建议</h2><h3 id=\"使用开源实现\"><a href=\"#使用开源实现\" class=\"headerlink\" title=\"使用开源实现\"></a>使用开源实现</h3><ul>\n<li>对于许多经典的神经网络，因为许多细节问题（如超参数的调节，学习率衰减或其它）而很难实现复现。因此，仅靠论文去从零实现，是很困难的。</li>\n<li>建议从其他研究者贡献出的开源代码开始研究或使用，如在Github中搜索并获取开源代码。</li>\n</ul>\n<h3 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h3><p>你如果要做一个计算机视觉应用，相比于从头(随机初始化权重)开始训练权重，如果你下载别人已经训练好的权重，然后把它当做预训练，然后迁移到你感兴趣的任务中，通常能够取得更快的进展。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.JPG\" width=\"100%\" height=\"100%\"> 假设你训练猫分类器，能够分类Tigger，Misty和Neither。</p>\n<ul>\n<li>如图第一行，若你没有关于Tigger，Misty大量图片，即训练集很小：<ul>\n<li>下载经典网络的代码以及权重，删去最后的Softmax层，创建你自己的Softmax层(Tigger/Misty/Neither)。</li>\n<li>将你下载的网络，看作是冻结的，冻结该网络的所有参数。将别人训练好的权重，作为初始权重，只训练和你自己的Softmax层有关的参数。</li>\n<li>这样，即使你只有一个小的训练集，也能取得好的性能。</li>\n<li>加速训练的技巧：由于前面的层都冻结了，即相当于一个不需要改变的固定函数(相当于取输入$X$，然后映射到选用的最后一层的激活函数)。预先计算这个固定函数的得到的特征或是说激活值，然后将它们存到硬盘中（对于每一周期(epoch)，不用重复遍历数据集计算激活值）。然后将它们作为输入，相当于训练一个浅层的softmax模型。</li>\n</ul>\n</li>\n<li>如图第二行，若有一个更大的训练集：<ul>\n<li>可以冻结更少的层，如图。然后训练后面的所有层（构建自己的Softmax层后）。</li>\n<li>也可将未冻结的后面几层全部删去，构建自己的几个隐藏层和Softmax层，然后只训练后面几层。</li>\n<li>模式就是：如果有更多的数据，那么你需要冻结的层数就更少，你需要训练的末端的层数就更多。</li>\n</ul>\n</li>\n<li>如图第三行，如果你有足够多的大量的训练集：<ul>\n<li>将下载的权重作为初始权重(代替随机初始化)，重新训练网络的所有层。</li>\n</ul>\n</li>\n<li>在所有深度学习的应用中，计算机视觉领域是一个经常用到迁移学习的领域。除非你有极其大的数据集和非常大的计算预算，能让你能够自己从头训练所有东西，那么迁移学习总是值得你考虑的方案。</li>\n</ul>\n<h3 id=\"数据增强\"><a href=\"#数据增强\" class=\"headerlink\" title=\"数据增强\"></a>数据增强</h3><p>数据增强是经常用来提升计算机视觉系统性能的技巧。计算机视觉任务是一项相当复杂的工作，你需要输入图像中的像素值，然后弄清楚图片中有什么，似乎你需要学习一个相当复杂的函数。对于几乎所有的计算机视觉任务，通常的问题是数据远远不够。因此，对于计算机视觉任务，数据增强通常都会有帮助。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA1.JPG\" width=\"100%\" height=\"100%\"> 介绍了常用的数据增强方法：</p>\n<ul>\n<li>镜像(mirroring)：以垂直轴为基准，进行镜像。</li>\n<li>随机裁剪(random cropping)：裁剪出原图像中的一部分。</li>\n<li>理论上，还有一些方法，如旋转(rotation)，剪切(shearing)，local warping(局部弯曲)等。但因为过于复杂，实践中很少使用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA2.JPG\" width=\"50%\" height=\"50%\"> 第二种经常使用的数据增强方法：</p>\n<ul>\n<li>色彩转换(color shifting)/色彩失真(color distortion)：分别对图片的RGB通道中的像素值进行增加或者减少，改变图片色彩。<ul>\n<li>解释：进行色彩转换，希望能让算法对图片的色彩的改变更具鲁棒性。</li>\n<li>AlexNet论文中采用了“PCA color augmentation”：减少主要色调成分(如R和B通道)的像素值多一点，减少G通道的像素值少点，使得整体的色调保持一致。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>可通过CPU/GPU的不同进程，并行地进行数据增强和训练。</li>\n</ul>\n<h3 id=\"计算机视觉的现状\"><a href=\"#计算机视觉的现状\" class=\"headerlink\" title=\"计算机视觉的现状\"></a>计算机视觉的现状</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B61.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>对于图像识别(image recognition)任务，尽管今天我们有很大的数据集，但仍想要更多的数据。</li>\n<li>对于目标检测(object detection)任务，我们有着更少的数据，因为标注边框这一步的成本太高。</li>\n</ul>\n<p><strong>学习算法有两个主要的知识来源：一是带标签的数据；二是手工设计的特征或网络结构或其他组件</strong>：</p>\n<ul>\n<li>当有大量数据时，人们倾向于使用更简单的算法和更少的手工工程。</li>\n<li>而当有较少量的数据时，人们倾向于使用更多的手工工程<ul>\n<li>解释：但当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的好的途径。</li>\n<li>举例：计算机视觉是在试图学习一个非常复杂的函数，因此我们总感觉没有足够的数据来满足我们的需求。在计算机视觉的初期，拥有的数据量很小，所以依赖手工设计的特征。近几年，数据量剧增，但对于计算机视觉还是不够，因此人们设计复杂的网络结构(包含很多超参数)。对于目标检测任务，拥有的数据量比图像识别任务更少，因此人们手工设计了许多组件。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B62.JPG\" width=\"100%\" height=\"100%\"> 在基准数据集或竞赛中取得好成绩的技巧：</p>\n<ul>\n<li>集成(ensembling):<ul>\n<li>独立训练多个(3~15)网络，然后平均它们的输出。</li>\n</ul>\n</li>\n<li>在测试阶段进行多裁剪(multi-crop)：<ul>\n<li>在测试阶段，对于一张测试图片，通过镜像(mirroring)以及随机裁剪(random cropping)的方式，获得该图像的多个版本。然后平均它们的测试结果。</li>\n</ul>\n</li>\n<li>集成(ensembling)方式占用过多内存且运行速度慢；在测试阶段进行多裁剪(multi-crop)，运行速度慢。因此它们在实际应用中没有意义。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B63.JPG\" width=\"90%\" height=\"90%\"> 若你要建立一个实际系统，采用以下步骤，能让你的应用进行的更快：</p>\n<ul>\n<li>从使用文献中的网络结构开始。</li>\n<li>使用开源的代码实现。<ul>\n<li>因为开源代码已经解决了所有的繁琐细节，如学习率衰减或其他超参数。</li>\n</ul>\n</li>\n<li>使用预训练的模型然后用你的数据集微调。<ul>\n<li>因为其他人可能已经在多个GPU上花了几个星期对超过一百万张图片进行训练后，得到这个模型。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"3-目标检测\"><a href=\"#3-目标检测\" class=\"headerlink\" title=\"3.目标检测\"></a>3.目标检测</h1><h2 id=\"3-1-检测算法\"><a href=\"#3-1-检测算法\" class=\"headerlink\" title=\"3.1 检测算法\"></a>3.1 检测算法</h2><h3 id=\"目标定位\"><a href=\"#目标定位\" class=\"headerlink\" title=\"目标定位\"></a>目标定位</h3><p>目标定位(object localization)<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D1.JPG\" width=\"90%\" height=\"90%\"> 图像分类任务与目标检测任务的区别：</p>\n<ul>\n<li>图像分类(Image classification)：对于给定图像，预测出类别（通常只有一个较大物体在图片中央）。</li>\n<li>分类且定位(Classification with Localization)：对于给定图像，预测类别，且给出物体在图片中的位置，即标出包围框(bounding box)（通常只有一个较大物体在图片中央）。</li>\n<li>检测(Detection)问题：图片中可存在多个属于不同类别的物体，对每个物体分类且定位。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D2.JPG\" width=\"100%\" height=\"100%\"> 分类且定位的实现方法：</p>\n<ul>\n<li>图像分类的方式就是构建CNN，然后通过softmax分类层进行分类。<ul>\n<li>softmax层有四个神经元，分别对应行人(pedestrain)，车辆(car)，摩托车(motorcycle)和背景(background)四类。</li>\n</ul>\n</li>\n<li>要实现定位，修改输出层，通过增加神经元，来输出表示包围框的四个数字：<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>。<ul>\n<li><script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>对应包围框的中点，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>分别对应包围框的高和宽。</li>\n<li>本课程约定，以图像的左上角为$(0,0)$点，右下角为$(1,1)$点，横向为$x$方向，纵向为$y$方向。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D3.JPG\" width=\"90%\" height=\"90%\"> 为了用监督学习算法解决分类且定位任务，需要定义训练集$(x,y)$，其中标签$y$该这样定义：</p>\n<ul>\n<li><script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>。其中，<script type=\"math/tex\">Pc</script>表示是否检测到目标，<script type=\"math/tex\">Pc=1</script>代表图片中检测到目标。<script type=\"math/tex\">Pc=0</script>代表图片中未检测到目标。</li>\n<li>如上图中的左图，检测到目标，$Pc=1$。训练集中应标注标签：<script type=\"math/tex\">\\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n<li>如上图中的右图，未检测到目标，$Pc=0$，则$Pc$后面参数都没有意义，都可以忽略。训练集中应标注标签：<script type=\"math/tex\">\\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]</script></li>\n</ul>\n<p>最后，对于神经网络的损失函数，若全部使用平方误差形式，有两种情况：</p>\n<ul>\n<li>若$y_1=1$,即$Pc=1$，那么：<script type=\"math/tex\">L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2</script></li>\n<li>若$y_1=0$,即$Pc=0$，那么：<script type=\"math/tex\">L(\\hat y,y)=(\\hat y_1-y_1)^2</script></li>\n<li>这里用平方误差简化了描述过程，在实际应用中，可以对$Pc$使用逻辑回归损失，对<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>使用平方误差损失，对于$c_1$，$c_2$，$c_3$使用softmax损失。</li>\n</ul>\n<h3 id=\"特征点检测\"><a href=\"#特征点检测\" class=\"headerlink\" title=\"特征点检测\"></a>特征点检测</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.JPG\" width=\"100%\" height=\"100%\"> </p>\n<ul>\n<li>上节中，通过让网络输出四个实数(<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>)的方式，指定了想要定位的物体的包围边框。</li>\n<li>在更一般的情况下，可以通过神经网络输出图像中关键特征点的$(x,y)$坐标（这些点称作landmarks），来实现对这些关键特征点的检测。</li>\n</ul>\n<p>上图中举了两例：</p>\n<ul>\n<li>例1：人脸关键特征点检测。<ul>\n<li>在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人脸特征点的坐标。</li>\n<li>如图，在输出层中，第一个神经元代表是否属于人脸，第二个神经原代表特征点1的$x$坐标，第三个神经元代表特征点1的$y$坐标，等等。</li>\n</ul>\n</li>\n<li>例2：人体姿态检测。<ul>\n<li>在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人体关键特征点的坐标。</li>\n</ul>\n</li>\n<li>想要训练这样的网络，需要一个带标签的训练集$(X,Y)$。<ul>\n<li>其中在人工标注关键特征点时，对于每一个样本，每一特征点代表的含义顺序，必须一致。如对于人脸特征点检测，特征点1代表左眼角，特征点2代表右眼角等等。对于人体姿态检测，特征点1代表左肩，特征点2代表胸部中点，特征点3代表右肩等等。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h3><p>本节以车辆检测为例，介绍基于滑动窗口的目标检测算法。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B1.JPG\" width=\"100%\" height=\"100%\"> 第一步，构建CNN以进行车辆分类：</p>\n<ul>\n<li>对于训练集$(x,y)$，$x$是适当剪切的图片。如上图，$x$为剪切后的汽车图片样本，即剪去其他部分，只有车辆在图片中央并占据了整个图片。</li>\n<li>然后即可训练CNN。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 第二步，滑动窗口检测(sliding window detection)：</p>\n<ul>\n<li>选择固定大小的矩形窗口，按某个步长，滑动遍历整个图片。滑动窗口每到达一个位置，就将该窗口内的图片送入CNN进行分类。CNN输出1(是汽车)或者0(背景，不是汽车)。</li>\n<li>然后选择一个更大的窗口，继续滑动窗口检测操作。</li>\n<li>然后再选择一个更大的窗口，继续滑动窗口检测操作。</li>\n</ul>\n<p>基于滑动窗口检测目标检测算法的缺点：</p>\n<ul>\n<li>计算成本高。滑动窗口到达的每一个位置的图片，都需要用CNN进行处理。</li>\n<li>如果选用大步长，窗口数会减少，但会影响性能。</li>\n<li>如果选用小步长，窗口数会剧增，计算成本过高。</li>\n</ul>\n<h3 id=\"滑动窗口的卷积实现\"><a href=\"#滑动窗口的卷积实现\" class=\"headerlink\" title=\"滑动窗口的卷积实现\"></a>滑动窗口的卷积实现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B01.JPG\" width=\"100%\" height=\"100%\"> <strong>用卷积层替换全连接层</strong>：</p>\n<ul>\n<li>上图中第一行是用来进行分类的CNN结构：输入为尺寸为$14\\times 14 \\times 3$的图片，卷积层，池化层，全连接层，全连接层，然后是softmax分类层（含四个结点，每个结点对应一个类别的概率）。</li>\n<li>上图中的第二行是将全连接层转换为卷积层后的CNN结构：<ul>\n<li>首先通过400个$5\\times 5$的卷积核(每个卷积核的尺寸为$5\\times 5\\times 16$)，将输出尺寸变为$1\\times 1\\times 400$。(将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)</li>\n<li>然后通过400个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，将输出尺寸变为$1\\times 1\\times 400$。(**将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)</li>\n<li>然后通过4个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，输出层的输出尺寸为$1\\times 1\\times 4$，然后进行softmax激活函数，作为最终的输出结果。(将此处输出的$1\\times 1\\times 4$的体，视为原softmax输出层的4个结点。)</li>\n</ul>\n</li>\n<li>用卷积层替换全连接层的目的是为了使得能够输入任意尺寸的图片，而如果存在全连接层，则输入和输出的维度必须是固定的。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B02.JPG\" width=\"100%\" height=\"100%\"> 基于滑动窗口的目标检测算法的卷积实现：</p>\n<ul>\n<li>上图中第一行的输入为一个滑动窗口内的图像，即尺寸为$14\\times 14 \\times 3$的体，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$1\\times 1\\times 4$的体，相当于softmax输出层的4个输出结点。</li>\n<li>上图中第二行的输入为一张$16\\times 16 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$2\\times 2\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。4个$1\\times 1\\times 4$的体即对应4个滑动窗口的输出结果。</li>\n<li>上图中第三行的输入为一张$28\\times 28 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$8\\times 8\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。64个$1\\times 1\\times 4$的体即对应64个滑动窗口的输出结果。</li>\n<li>该模型源于OverFeat。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B03.JPG\" width=\"100%\" height=\"100%\"> 总结：</p>\n<ul>\n<li>原始的基于滑动窗口的目标检测算法，会分别将每一个滑动窗口内的图像，单独给CNN处理。并且这样会使得很多CNN的处理过程是重复的。</li>\n<li>而基于滑动窗口的目标检测算法的卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的窗口图像共享了许多计算。</li>\n<li>基于滑动窗口的目标检测算法的卷积实现，极大地提高了效率。但存在一个缺点：不能输出最准确的包围边框。下节解决这个问题。</li>\n</ul>\n<h3 id=\"包围边框预测\"><a href=\"#包围边框预测\" class=\"headerlink\" title=\"包围边框预测\"></a>包围边框预测</h3><p>上节中基于滑动窗口的目标检测算法的卷积实现，其计算效率很高，但存在不能输出非常准确的包围边框的问题。本节介绍YOLO(You Only Look Once)算法，它可以得到准确的包围边框。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B1JPG.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>基于滑动窗口的目标检测算法，很有可能没有一个合适的滑动窗口，能够完美匹配图中的汽车的位置，即红色包围边框。最接近的，可能只是图中的蓝色窗口。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 介绍YOLO算法：</p>\n<ul>\n<li>YOLO算法首先将原始图片分割成$n\\times n$网格，每个网格代表一块区域。为简化说明，将图片分成$3 \\times 3$网格。<ul>\n<li>实际应用中采用更精细的网格，如$19\\times 19$。更精细的网格也可以使得多个物体分配到同一格子的概率减小。</li>\n</ul>\n</li>\n<li>然后，采用本周第一个视频讲述过的图像分类且定位算法(image classification and localization algorithm)，应用在9个格子的每一个格子上。</li>\n<li>训练集$(x,y)$的构建：<ul>\n<li>$x$即为输入图像矩阵，例如尺寸为$100 \\times 100 \\times 3$</li>\n<li>标签$y$的维度为$3 \\times 3 \\times 8$，即共9个$1 \\times 1 \\times 8$，其中每一个$1 \\times 1 \\times 8$代表着一个格子的标签。</li>\n<li>每个格子对应的$1 \\times 1 \\times 8$的标签，同本周第一个视频讲述过的一样。<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script></li>\n<li>需强调：将物体分配给哪个格子是由物体的中点$(b_x,b_y)$属于哪个格子决定的。</li>\n<li>对于一个格子可能存在多个物体的情况，稍后讨论。</li>\n</ul>\n</li>\n<li>构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 8$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的进行训练。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>该算法和图像分类且定位算法很相似，它显示的输出包围边框的坐标，它能让神经网络输出任意长宽比的坐标，而不收到滑动窗口的步长的限制。因此，该算法能够输出精确的包围边框。</li>\n<li>此外，该算法也是卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的网格共享了许多计算。正因为它是卷积实现，因此该算法的效率非常高，运行得非常快，能达到实时目标检测。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B3.JPG\" width=\"100%\" height=\"100%\"> 如何定义包围边框，即如何编码(encode)<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>：</p>\n<ul>\n<li>如图，以每个网格的左上角为$(0,0)$点，以右下角为$(1,1)$点。</li>\n<li>中心点<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>为距离$(0,0)$点的水平距离和垂直距离相对网格边长的比值。因此，<script type=\"math/tex\">b_x</script>和<script type=\"math/tex\">b_y</script>在0~1之间。</li>\n<li>高度<script type=\"math/tex\">b_h</script>和宽度<script type=\"math/tex\">b_w</script>，为包围边框的高和宽与网格边长的比值。因此，<script type=\"math/tex\">b_h</script>和<script type=\"math/tex\">b_w</script>可能大于1。</li>\n<li>如图，图中样本$x$对应的标签应该为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ 0.4 \\\\ 0.3 \\\\ 0.9 \\\\ 0.5 \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n<li>当然编码包围框的方式很多，YOLO论文中也交待了其他更复杂的参数化方式。但本课程给出了此种方法是合理且可使用的一种方式。</li>\n</ul>\n<h3 id=\"交并比\"><a href=\"#交并比\" class=\"headerlink\" title=\"交并比\"></a>交并比</h3><p>交并比(Intersection over Union, IoU)是评价目标定位算法准确性的指标。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%A4%E5%B9%B6%E6%AF%94.JPG\" width=\"100%\" height=\"100%\"> 交并比讲解：</p>\n<ul>\n<li>如图，紫色边框为预测边框，红色边框为真实边框。</li>\n<li>黄色阴影部分为两边框区域的交集(Intersection)，绿色阴影部分为两边框区域的并集(Union)。</li>\n<li>交并比(Intersection over Union, IoU)即为：<script type=\"math/tex\">IoU=\\frac{Intersection}{Union}</script><ul>\n<li>一般人为规定当$IoU \\geq 0.5$时，预测的包围边框是正确的。</li>\n</ul>\n</li>\n<li>更一般的说，IoU衡量了两个包围边框的重叠程度。</li>\n</ul>\n<h3 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h3><p>目标检测算法可能会检测同一个目标多次。非极大值抑制(Non-max Suppression, NMS)可以确保对每个对象只检测一次。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B61.JPG\" width=\"80%\" height=\"80%\"> 如图，以YOLO算法检测汽车为例，对于该图片，会有多个网格对同一汽车做出检测。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B62.JPG\" width=\"100%\" height=\"100%\"> 极大值抑制的效果：</p>\n<ul>\n<li>如图，当运行目标检测算法时，最终出现了对同一个对象进行多次检测的情况。</li>\n<li>通过非极大值抑制，清理了这些检测结果。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B63.JPG\" width=\"100%\" height=\"100%\"> 非极大值抑制的实现细节：</p>\n<ul>\n<li>假设只检测车辆，用YOLO算法检测这张图片后的输出的维度为$19\\times 19 \\times 5$。共$19\\times 19 = 361$个格子，每一个格子的输出为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw  \\end{matrix} \\right ]</script>。其中，$p_c$为存在对象的概率，在此处即是车辆的概率。</li>\n<li>第一步，丢弃所有$p_c \\leq 0.6$的包围框。<ul>\n<li>在编程作业中，这一步作为单独的步骤，不在NMS之内。先算得分($p_c$与$c_1$或$c_2$或$c_3$相乘)再取阈值。</li>\n</ul>\n</li>\n<li>第二步，只要有剩余包围框，则一直循环：<ul>\n<li>选择$p_c$最大的包围框为一个预测包围框。</li>\n<li>舍弃所有与上一步中的预测包围框的$IoU\\geq 0.5$的剩余的包围框。</li>\n</ul>\n</li>\n<li>另外，该节只是介绍了只检测车辆这一类目标的情况，如果想要检测三类目标(如行人，车辆，摩托车)，那么每个格子的输出向量就会有额外三个分量($c_1$，$c_2$，$c_3$)。正确的做法是，对每个类别都独立进行一次非极大值抑制，即进行三次非极大值抑制。</li>\n</ul>\n<h3 id=\"Anchor-Boxes\"><a href=\"#Anchor-Boxes\" class=\"headerlink\" title=\"Anchor Boxes\"></a>Anchor Boxes</h3><p>到目前位置，我们介绍的是每个网格只能包含一个物体，若一个网格包含两个或以上物体，则无法处理。使用anchor boxes可以解决这个问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>如图，对图片采用$3\\times 3$的网格划分。汽车和行人的中点，几乎重叠，都落在一个格子中。<ul>\n<li>此前每个格子的输出定义为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>，无法描述该情况，只能舍去一个物体，只描述一个物体。</li>\n</ul>\n</li>\n<li>预先定义两个不同形状的anchor box：Anchor box1和Anchor box2。<ul>\n<li>通常使用更多的anchor box，如5个或更多。这里为了方便讲解，只定义两个。</li>\n</ul>\n</li>\n<li>则上图对应的输出标签应为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>。其中，前8个分量为与Anchor box1相关的输出，后8个分量为与Anchor box2相关的输出。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes2.JPG\" width=\"80%\" height=\"80%\"> Anchor box算法：</p>\n<ul>\n<li>在之前(不采用Anchor box时)：我们将每个训练图像中的物体分配给其中点所处的那个网格。输出$y$的维度为$3\\times 3\\times 8$。</li>\n<li>采用两个Anchor box后：我们将将每个训练图像中的物体分配给其中点所处的那个网格，以及分配给与该物体包围框的IoU最大的那个Anchor box。输出$y$的维度为$3\\times 3\\times 16$，即$3\\times 3\\times (8\\times 2)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes3.JPG\" width=\"90%\" height=\"90%\"> 示例：</p>\n<ul>\n<li>图中一个格子中包含两个物体，其中行人的包围框应该分配给Anchor box1，车辆包围框应该分配给Anchor box2，因此，该图像的输出应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。</li>\n<li>若某格子，只含一个车辆物体，则其输出应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。</li>\n<li>当遇到一个格子包含三个或更多物体时，该算法无法处理。当遇到两个物体被分配给同一Anchor box时，该算法也无法处理。</li>\n<li>另外，人们通常人工指定Anchor box的形状，可以选择5~10个形状，覆盖你想要检测的对象的各种形状。后期的YOLO论文中介绍了通过$k$均值来自动选择Anchor box的高级方法。</li>\n</ul>\n<h3 id=\"YOLO算法\"><a href=\"#YOLO算法\" class=\"headerlink\" title=\"YOLO算法\"></a>YOLO算法</h3><p>将所有学过的组件组合在一起，构成YOLO目标检测算法。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%951.JPG\" width=\"100%\" height=\"100%\"> 训练阶段：</p>\n<ul>\n<li>假设检测三类物体：行人，车辆和摩托车。采用的是$3 \\times 3$的网格划分。采用两个anchor box。</li>\n<li>对于训练集$(x,y)$：<ul>\n<li>$x$为输入图像，维度为$100 \\times 100 \\times 3$</li>\n<li>标签$y$的维度为$3 \\times 3 \\times 16$，即$3 \\times 3 \\times (2\\times 8)$。每个$1 \\times 1 \\times 16$对应一个网格的目标标签，共9个网格。</li>\n<li>例如对于不含物体的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]</script>。对于含有车辆（分配给Anchor box2）的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n</ul>\n</li>\n<li>构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 16$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的对网络进行训练。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%952.JPG\" width=\"100%\" height=\"100%\"> 预测阶段：</p>\n<ul>\n<li>将图片$x$输入网络，输出维度为$3 \\times 3 \\times 16$。其中，对于不包含物体的网格，其输出向量应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\end{matrix} \\right ]</script>。对于包含车辆的网格，其输出向量应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。”..”代表网络输出的一些无意义的数字（网络不会输出问号）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%95%E6%B3%953.JPG\" width=\"100%\" height=\"100%\"> 进行极大值抑制：</p>\n<ul>\n<li>对每一类，分别独立的进行一次非极大值抑制。即分别对行人，车辆及摩托车分别进行一次极大值抑制。</li>\n<li>最后的结果，作为算法的输出结果。</li>\n</ul>\n<h3 id=\"区域建议\"><a href=\"#区域建议\" class=\"headerlink\" title=\"区域建议\"></a>区域建议</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE1.JPG\" width=\"100%\" height=\"100%\"> R-CNN：</p>\n<ul>\n<li>基于滑动窗口的目标检测算法(无论是原始的，还是卷积实现)，对于整张图片中的每一个滑动窗口，都会通过CNN去检测。对于其中很多的明显没有任务物体的窗口，通过CNN去处理它们是浪费时间的。</li>\n<li>R-CNN(基于区域的CNN)的做法是尝试选出一些区域，然后通过CNN进行检测。<ul>\n<li>R-CNN给出区域建议(region proposals)的做法是运行图像分割算法(结果如图)，其中一些色块(如2000个)的矩形包围边框，即是给出的区域建议。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>R-CNN：给出建议区域(通过图像分割算法)；每次对一个区域进行分类；输出类别标签+包围边框。<ul>\n<li>R-CNN并不是以色块的包围边框为最后的预测包围边框，而是会输出包围边框($b_x,b_y,b_h,b_w$)，因此可以得到精确的包围边框。</li>\n<li>缺点：太慢。</li>\n</ul>\n</li>\n<li>Fast R-CNN：给出建议区域；通过滑动窗口的卷积实现去分类所有的建议区域（R-CNN一次只对一个建议区域做分类）。<ul>\n<li>缺点：给出建议区域的步骤仍然过慢。</li>\n</ul>\n</li>\n<li>Faster R-CNN：用CNN进行区域建议(RPN网络)。<ul>\n<li>缺点：比Fast R-CNN快，但仍比YOLO慢很多，达不到实时。</li>\n</ul>\n</li>\n</ul>\n<p>吴恩达的观点：</p>\n<ul>\n<li>区域建议(region proposals)的思想，在计算机视觉领域有着相当大的影响，值得去了解这些算法。</li>\n<li>但这类方法需要分成两个步骤：先是得到建议区域，然后再进行分类。相比较之下，从长远的角度看，一步到位的YOLO这类算法，才是有发展前景的方向。</li>\n</ul>\n<h1 id=\"4-特殊应用：人脸识别和风格迁移\"><a href=\"#4-特殊应用：人脸识别和风格迁移\" class=\"headerlink\" title=\"4.特殊应用：人脸识别和风格迁移\"></a>4.特殊应用：人脸识别和风格迁移</h1><h2 id=\"4-1-人脸识别\"><a href=\"#4-1-人脸识别\" class=\"headerlink\" title=\"4.1 人脸识别\"></a>4.1 人脸识别</h2><h3 id=\"什么是人脸识别\"><a href=\"#什么是人脸识别\" class=\"headerlink\" title=\"什么是人脸识别\"></a>什么是人脸识别</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.JPG\" width=\"80%\" height=\"80%\"> 人脸验证和人脸识别的区别：</p>\n<ul>\n<li>人脸验证(face verification)：<ul>\n<li>输入：一张人脸图片以及姓名/ID</li>\n<li>输出：图片中是否为声称的那个人</li>\n</ul>\n</li>\n<li>人脸识别(face recognition)：<ul>\n<li>有$K$个人的数据集</li>\n<li>输入：人脸图片</li>\n<li>输出：如果输入图片中是$K$个人中的一个，则输出姓名/ID</li>\n</ul>\n</li>\n<li>人脸验证是一对一问题，人脸识别是1对多问题，人脸识别比人脸验证更难。假设人脸验证系统的错误率是1%，那么在人脸识别中，则相应的错误率就会增加，约$K$%。因此要构建人脸识别，需要使得人脸验证模块达到很高的准确率如(99%)，才能将人脸验证模块用于人脸识别系统中，使得人脸识别系统有高准确率。</li>\n</ul>\n<h3 id=\"One-shot-learning\"><a href=\"#One-shot-learning\" class=\"headerlink\" title=\"One-shot learning\"></a>One-shot learning</h3><p>对于人类识别任务，挑战之一是要解决One-shot learning问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>One-shot learning：仅从一个样本中学习，然后再次识别出这个人。</li>\n<li>如图，左侧为拥有的数据库，有四个员工的各一个样本。</li>\n<li>对于该人脸识别任务，不好的解决方法：将四个样本，通过CNN进行训练，输出层为softmax层。<ul>\n<li>缺点一：如此小的训练集，不足以训练一个鲁棒的CNN。</li>\n<li>缺点二：若有新员工加入，需要修改CNN的softmax层，且需要重新训练。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning2.JPG\" width=\"80%\" height=\"80%\"> 对于该人脸识别任务，正确的解决方法：</p>\n<ul>\n<li>首先， 通过训练神经网络，去学习一个相似度函数(similarity function)：<ul>\n<li>$d(img1,img2)=degree\\ of\\ difference\\ between\\ images$</li>\n<li>$d(img1,img2)≤\\tau$: 则判断为同一个人</li>\n<li>$d(img1,img2)&gt;\\tau$: 则判断为不是同一个人</li>\n<li>这样，通过相似度函数，解决了<strong>人脸验证(face verification)</strong>问题。</li>\n</ul>\n</li>\n<li>然后用于人脸识别任务中，将测试图像与数据库中的每一图像进行相似度计算，找出匹配的那个人。</li>\n<li>若有新员工加入，只需将他的人脸图像加入数据库，系统依然能照常工作。</li>\n</ul>\n<h3 id=\"Siamese-network\"><a href=\"#Siamese-network\" class=\"headerlink\" title=\"Siamese network\"></a>Siamese network</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C1.JPG\" width=\"80%\" height=\"80%\"> 通过Siamese network来学习相似度函数$d(img1,img2)$：</p>\n<ul>\n<li>如图，输入为图像$x^{(1)}$。</li>\n<li>通过典型的CNN结构(卷积层-&gt;池化层-&gt;全连接层)，最终得到全连接层输出的特征向量，其维度为$(128,1)$。</li>\n<li>该全连接层输出的特征向量可以看成是对图片$x^{(1)}$的编码(encoding)，记为$f(x^{(1)})$。</li>\n<li>要比较两张图片$x^{(1)}$和$x^{(2)}$的相似度：<ul>\n<li>将$x^{(2)}$喂给上述网络，得到图片$x^{(2)}$的编码(encoding)，即$f(x^{(2)})$</li>\n<li>计算相似度函数$d(x^{(1)},x^{(2)})$，$d(x^{(1)},x^{(2)})$的定义为$f(x^{(1)})$与$f(x^{(2)})$之差的L2范数，即$d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||_2^2$</li>\n</ul>\n</li>\n<li>该网络源自论文DeepFace。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C2.JPG\" width=\"80%\" height=\"80%\"> Siamese network学习的目标：</p>\n<ul>\n<li>Siamese network的参数决定了$f(x^{(i)})$</li>\n<li>因此相通过学习Siamese network的参数，达到如下目的：<ul>\n<li>若$x^{(i)}$，$x^{(j)}$是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较小</li>\n<li>若$x^{(i)}$，$x^{(j)}$不是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较大</li>\n</ul>\n</li>\n<li>对于如何定义代价函数，下节介绍triplet损失函数。</li>\n</ul>\n<h3 id=\"Triplet-loss-function\"><a href=\"#Triplet-loss-function\" class=\"headerlink\" title=\"Triplet loss function\"></a>Triplet loss function</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>Triplet Loss需要每个样本包含三张图片：Anchor、Positive、Negative，这就是triplet名称的由来。</li>\n<li>将三张图片(Anchor,Positive,Negative)的编码简写为$f(A),f(P),f(N)$，由上一节内容可知，我们希望$f(A)$和$f(P)$的距离较小，即$||f(A)-f(P)||^2$较小，而$f(A)$和$f(N)$的距离较大，即$||f(A)-f(N)||^2$较大：<ul>\n<li>$||f(A)-f(P)||^2\\leq ||f(A)-F(N)||^2$</li>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq 0$</li>\n</ul>\n</li>\n<li>对于上面的不等式，若$f(x^{(i)})$恒为0，会使得$f(A)=0$,$f(P)=0$,$f(N)=0$，那么上述不等式也满足。因此，对上述不等式做出如下修改，通过添加一个超参数 $\\alpha(\\alpha&gt;0)$，以避免$f(x^{(i)})$恒为0的情况：<ul>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq -\\alpha$</li>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha \\leq 0$</li>\n<li>其中，$\\alpha$也被称为间隔(margin)，类似支持向量机中的间隔(margin)。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss2.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>定义triplet loss function：给定3张图片(Anchor、Positive、Negative)，$L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha,\\ 0)$<ul>\n<li>解释：若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha\\leq 0$，则$L(A,P,N)=0$，没有惩罚。</li>\n<li>若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha &gt;  0$，则$L(A,P,N)=||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha$，较大惩罚。</li>\n</ul>\n</li>\n<li>cost function：$J=\\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})$</li>\n<li>假如训练集为1k个人的10k张图片，组成不同的三元组(Anchor、Positive、Negative)，然后进行训练网络，使用梯度下降法，最小化代价函数$J$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss3.JPG\" width=\"80%\" height=\"80%\"> 训练样本中三元组(Anchor、Positive、Negative)选择：</p>\n<ul>\n<li>若三元组(Anchor、Positive、Negative)是随意选择的，意为只要求Anchor和Positive是一个人，Negative是另一个人。那么，$d(A,P)+\\alpha\\leq d(A,N)$这个条件很容易满足。在训练网络的过程中，学习不到有用的东西。</li>\n<li>应该选择较难的三元组(Anchor、Positive、Negative)，来用于网络的训练。<ul>\n<li>想要满足$d(A,P)+\\alpha\\leq d(A,N)$，则较难的三元组(Anchor、Positive、Negative)，意味着$d(A,P)\\approx d(A,N)$。这样算法会尽力使得$d(A,N)$变大，使得$d(A,P)$变小。在训练网络的过程中，才能学习到有用的东西。</li>\n</ul>\n</li>\n<li>更多细节在论文FaceNet中。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss4.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>一些(Anchor、Positive、Negative)的例子。</li>\n</ul>\n<p>最后，现在许多商业公司构建的大型人脸识别模型都需要百万级别甚至上亿的训练样本。如此之大的训练样本我们一般很难获取。但是一些公司将他们训练的人脸识别模型发布在了网上，我们可以下载这些预训练的模型进行使用，而不是一切从头开始。</p>\n<h3 id=\"人脸验证和二元分类\"><a href=\"#人脸验证和二元分类\" class=\"headerlink\" title=\"人脸验证和二元分类\"></a>人脸验证和二元分类</h3><p>Triplet loss 是学习人脸识别CNN的参数的好方法，还有其他的参数学习方法，即将人脸识别问题看成二元分类问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB1.JPG\" width=\"80%\" height=\"80%\">  </p>\n<ul>\n<li>如图，选取Siamese network，将两个全连接层的输出给一个逻辑回归单元，然后进行预测。</li>\n<li>若是同一个人，则输出1；若是不同的人，则输出0。这样就将人脸识别问题看成二元分类问题。</li>\n<li>对于最后的逻辑单元，输出$\\hat y$表达式为：<ul>\n<li>$\\hat y=\\sigma(\\sum_{k=1}^Kw_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)$</li>\n<li>$\\hat y=\\sigma(\\sum_{k=1}^Kw_k\\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)$，上式被称为$\\chi$ 方公式，也叫$\\chi$方相似度。</li>\n<li>具体见DeepFace论文。</li>\n</ul>\n</li>\n<li>该节可再回顾下视频。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB2.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>如图，对于此方法，$x$为一对人脸图片，输出标签为1或0。然后去训练Siamese network。</li>\n</ul>\n<h2 id=\"4-2-风格迁移\"><a href=\"#4-2-风格迁移\" class=\"headerlink\" title=\"4.2 风格迁移\"></a>4.2 风格迁移</h2><h3 id=\"什么是风格迁移\"><a href=\"#什么是风格迁移\" class=\"headerlink\" title=\"什么是风格迁移\"></a>什么是风格迁移</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>如图，列出几个神经风格迁移的例子。神经风格迁移是CNN模型一个非常有趣的应用，它可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片。</li>\n<li>一般用C表示内容(Content)图片，S表示风格(Style)图片，G表示生成的(Generated)图片。</li>\n</ul>\n<h3 id=\"深度卷积神经网络学习到的是什么？\"><a href=\"#深度卷积神经网络学习到的是什么？\" class=\"headerlink\" title=\"深度卷积神经网络学习到的是什么？\"></a>深度卷积神经网络学习到的是什么？</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%881.JPG\" width=\"80%\" height=\"80%\"> 可视化深度卷积神经网络的每一层学习到了什么：</p>\n<ul>\n<li>可视化方法：选择第一个隐藏层的一个神经元，找出使得该神经元激活值最大化的9个图像块。</li>\n<li>如图右侧，每一个$3\\times 3$的小区域，即为使得一个神经元激活值最大的9个图像块。</li>\n<li>源自论文Visualizing and understand convolutional networks。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%882.JPG\" width=\"80%\" height=\"80%\"><br>可视化的结果可以理解为：</p>\n<ul>\n<li>第一层的隐藏神经元通常会寻找相对简单的特征，比如边缘(edge)、颜色阴影(shade of color)。</li>\n<li>第二层的隐藏神经元检测到的是纹理(texture)。越深层的神经元检测到越复杂的物体。</li>\n<li>浅层网络的感受野(receptive field)较小，深层网络的感受野较大（网络越深，感受野越大）。</li>\n</ul>\n<h3 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于内容图片C，风格图片S，生成图片G：为了实现风格迁移，定义一个关于$G$的代价函数$J(G)$，用来评价生成图像的好坏。</li>\n<li>用梯度下降法最小化$J(G)$，可以生成想要的任何图片。</li>\n<li>定义生成图片G的代价函数：<script type=\"math/tex\">J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)</script><ul>\n<li>其中，$J_{content}(C,G)$为内容代价函数，它用来衡量C的内容与G的内容有多相似。</li>\n<li>$J_{style}(S,G)$是风格代价函数，它用来衡量S的内容与G的内容有多相似。</li>\n<li><script type=\"math/tex\">\\alpha</script>,<script type=\"math/tex\">\\beta</script>是超参数，用来调整<script type=\"math/tex\">J_{content}(C,G)</script>与<script type=\"math/tex\">J_{style}(S,G)</script>的权重。</li>\n<li>用<script type=\"math/tex\">\\alpha</script>,<script type=\"math/tex\">\\beta</script>这两个超参数来控制权重，似乎有些冗余。但原论文中就是这样，故保持一致。</li>\n</ul>\n</li>\n<li>源自论文A neual algorithm of artistic style。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"> 在定义了$J(G)$后，为了生成新的图像：</p>\n<ul>\n<li>随机初始化生成图像$G$，比如G的尺寸为$100\\times 10 \\times 3$</li>\n<li>用梯度下降法去最小化$J(G)$<ul>\n<li>$G=G-\\frac{\\partial}{\\partial G}J(G)$</li>\n<li>不断更新G的像素值，使得$J(G)$不断减小，从而使G逐渐有C的内容和G的风格。</li>\n</ul>\n</li>\n<li>如图右侧从随机初始化生成图像$G$，到不断更新G后G的结果。</li>\n</ul>\n<h3 id=\"内容代价函数\"><a href=\"#内容代价函数\" class=\"headerlink\" title=\"内容代价函数\"></a>内容代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%86%85%E5%AE%B9%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.JPG\" width=\"80%\" height=\"80%\"><br>对于$J(G)$的第一部分$J_{content}(C,G)$，它表示内容图片C与生成图片G之间的相似度。</p>\n<ul>\n<li>使用一个预训练好的CNN模型，例如VGG网络。C，S，G共用相同模型和参数。</li>\n<li>首先，需要选择合适的层数$l$来计算$J_{content}(C,G)$。根据上一小节的内容，CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果$l$太小，则G与C在像素上会非常接近，没有迁移效果；如果$l$太深，则G上某个区域将直接会出现C中的物体。因此，$l$既不能太浅也不能太深，一般选择网络中间层。</li>\n<li>然后计算C和G在$l$层的激活函数输出<script type=\"math/tex\">a^{[l](C)}</script>与<script type=\"math/tex\">a^{[l](G)}</script>。</li>\n<li>$J_{content}(C,G)$的定义为：<ul>\n<li><script type=\"math/tex; mode=display\">J_{content}(C,G)=\\frac12||a^{[l](C)}-a^{[l](G)}||^2</script></li>\n</ul>\n</li>\n<li>使用梯度下降算法，使$J_{content}(C,G)$不断减小。即可使得<script type=\"math/tex\">a^{[l](C)}</script>与<script type=\"math/tex\">a^{[l](G)}</script>越相似，即C和G越相似。</li>\n</ul>\n<h3 id=\"风格代价函数\"><a href=\"#风格代价函数\" class=\"headerlink\" title=\"风格代价函数\"></a>风格代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>什么是图片的风格？利用CNN网络模型，图片的风格可以定义成第$l$层隐藏层不同通道间激活函数的乘积（相关性）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>例如我们选取第$l$层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如1通道（红色）提取的是图片的垂直纹理特征，2通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B03.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>接下来我们就可以定义图片的风格矩阵（style matrix）为：<ul>\n<li><script type=\"math/tex; mode=display\">G_{kk'}^{[l]}=\\sum_{i=1}^{n_H^{[l]}}\\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}</script></li>\n<li>其中，$[l]$表示第$l$层隐藏层，$k$，$k’$分别表示不同通道，总共通道数为<script type=\"math/tex\">n_C^{[l]}</script>。$i$，$j$分别表示该隐藏层的高度和宽度。风格矩阵<script type=\"math/tex\">G_{kk'}^{[l]}</script>计算第$l$层隐藏层不同通道对应的所有激活函数输出和。<script type=\"math/tex\">G_{kk'}^{[l]}</script>的维度为 <script type=\"math/tex\">n_c^{[l]}\\times n_c^{[l]}</script>。若两个通道之间相似性高，则对应的<script type=\"math/tex\">G_{kk'}^{[l]}</script>较大；若两个通道之间相似性低，则对应的<script type=\"math/tex\">G_{kk'}^{[l]}</script>较小。</li>\n</ul>\n</li>\n<li>风格矩阵<script type=\"math/tex\">G_{kk'}^{[l](S)}</script>表征了风格图片S第$l$层隐藏层的“风格”。相应地，生成图片G也有<script type=\"math/tex\">G_{kk'}^{[l](G)}</script>。那么，<script type=\"math/tex\">G_{kk'}^{[l][S]}</script>与<script type=\"math/tex\">G_{kk'}^{[l][G]}</script>越相近，则表示G的风格越接近S。</li>\n<li>这样，我们就可以定义出<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>的表达式：<ul>\n<li><script type=\"math/tex; mode=display\">J^{[l]}_{style}(S,G)=\\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}\\sum_{k=1}^{n_H^{[l]}}\\sum_{k'=1}^{n_W^{[l]}}||G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}||^2</script></li>\n</ul>\n</li>\n<li>定义完<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>之后，我们的目标就是使用梯度下降算法，不断迭代修正G的像素值，使<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>不断减小。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B04.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>以上我们只比较计算了一层隐藏层$l$。为了提取的“风格”更多，也可以使用多层隐藏层，然后相加，表达式为：<ul>\n<li><script type=\"math/tex; mode=display\">J_{style}(S,G)=\\sum_l\\lambda^{[l]}\\cdot J^{[l]}_{style}(S,G)</script></li>\n<li>其中，<script type=\"math/tex\">\\lambda^{[l]}</script>表示累加过程中各层<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>的权重系数，为超参数。</li>\n</ul>\n</li>\n<li>根据以上两小节的推导，最终的代价函数为：<ul>\n<li><script type=\"math/tex; mode=display\">J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)</script></li>\n<li>使用梯度下降算法进行迭代优化即可。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"从1维卷积到3维卷积\"><a href=\"#从1维卷积到3维卷积\" class=\"headerlink\" title=\"从1维卷积到3维卷积\"></a>从1维卷积到3维卷积</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF1.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>之前介绍的CNN网络处理的都是2D图片，2D卷积的规则：<ul>\n<li>输入图片维度：14 x 14 x 3</li>\n<li>滤波器尺寸：5 x 5 x 3，滤波器个数：16</li>\n<li>输出图片维度：10 x 10 x 16</li>\n</ul>\n</li>\n<li>将2D卷积推广到1D卷积，1D卷积的规则：<ul>\n<li>输入时间序列维度：14 x 1</li>\n<li>滤波器尺寸：5 x 1，滤波器个数：16</li>\n<li>输出时间序列维度：10 x 16</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于3D卷积，其规则：<ul>\n<li>输入3D图片维度：14 x 14 x 14 x 1</li>\n<li>滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16</li>\n<li>输出3D图片维度：10 x 10 x 10 x 16</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"1-卷积神经网络基础\"><a href=\"#1-卷积神经网络基础\" class=\"headerlink\" title=\"1.卷积神经网络基础\"></a>1.卷积神经网络基础</h1><h2 id=\"1-1-卷积神经网络\"><a href=\"#1-1-卷积神经网络\" class=\"headerlink\" title=\"1.1 卷积神经网络\"></a>1.1 卷积神经网络</h2><h3 id=\"计算机视觉\"><a href=\"#计算机视觉\" class=\"headerlink\" title=\"计算机视觉\"></a>计算机视觉</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%891.JPG\" width=\"50%\" height=\"50%\"> 举了计算机视觉中的几个典型应用：</p>\n<ul>\n<li>图像分类</li>\n<li>目标检测</li>\n<li>风格迁移</li>\n</ul>","more":"<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%892.JPG\" width=\"80%\" height=\"80%\"> 在应用计算机视觉时，所面临的一个挑战是数据的输入可能会非常大：</p>\n<ul>\n<li>对$64 \\times 64$的小图片，输入特征的维度是$12288(64\\times 64\\times 3)$。</li>\n<li>对稍大的$1000\\times 1000$的图片，输入特征的维度是$3million(1000\\times 1000\\times 3)$：<ul>\n<li>神经网络的输入$x\\in R^{3m}$，假设第一个隐藏层有1000个神经元，则第一层的参数$W^{[1]}$的维度为$(1000,3m)$，即包含30亿个参数。</li>\n<li>对于如此大量的参数，难以获取足够多的数据来防止过拟合。</li>\n<li>内存需要处理30个参数的神经网络，所需内存太大。</li>\n<li>要解决这个问题，需进行卷积操作。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"边缘检测示例\"><a href=\"#边缘检测示例\" class=\"headerlink\" title=\"边缘检测示例\"></a>边缘检测示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B1.JPG\" width=\"90%\" height=\"90%\"> 以边缘检测为例，说明卷积操作是如何进行的。如图：</p>\n<ul>\n<li>卷积神经网络的浅层检测到的是边缘，然后是物体的部件，深层检测到整体。</li>\n<li>想要检测图像中的垂直边缘，下图继续。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 介绍卷积操作：</p>\n<ul>\n<li>$6\\times 6$的图像(灰度图，单通道)与可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器，以步长为1，进行卷积操作，结果如图。<ul>\n<li>$*$ 表示卷积操作。Python中，卷积用函数conv_forward()；tensorflow中，卷积用函数tf.nn.conv2d()；keras中，卷积用函数Conv2D()。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%A4%BA%E4%BE%8B3.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>$6\\times 6$的图像(灰度图，单通道)的左半部分像素强度较大，即较白，右半部分像素强度较小，故较暗（其实灰度图中白为255，黑为0）。</li>\n<li>仍是上图中可检测垂直边缘的$3\\times 3$大小的卷积核/滤波器。左侧较白，中间较暗，右侧最暗。</li>\n<li>卷积结果如图所示。输出图像像中中间有一条较白的宽带，即垂直边缘。<ul>\n<li>输出图像中边缘太粗，是因为图像过小，若对$1000\\times 1000$的图像进行卷积，输出图像中的边缘将不会显得这么粗。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"更多边缘检测内容\"><a href=\"#更多边缘检测内容\" class=\"headerlink\" title=\"更多边缘检测内容\"></a>更多边缘检测内容</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B1.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>图片边缘有两种边缘过渡方式，一种是由明变暗，另一种是由暗变明。从输出图像可看出，该垂直边缘滤波器，可以区别出这两种明暗变化的区别。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>如图，垂直边缘检测和水平边缘检测的滤波器如图所示。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%9B%B4%E5%A4%9A%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>更经典的Sobel滤波器和Scharr滤波器。<ul>\n<li>Sobel滤波器的优点是增加了中间一行的权重，也就是处在中央的像素点，使得结果更鲁棒一些。</li>\n<li>图中为进行垂直边缘检测的形式，翻转90度后即得进行水平边缘检测的形式。</li>\n</ul>\n</li>\n<li>随着深度学习的兴起，我们学习到的事情是：当你想检测出某些复杂图像的边缘，你不一定要去使用那些研究者们手工设计的滤波器。而将滤波器中的数字当作参数，通过神经网络学习这些参数。学习到的滤波器对于数据的统计特性的捕捉能力甚至比任何一个手工设计的滤波器要好。</li>\n</ul>\n<h3 id=\"填充\"><a href=\"#填充\" class=\"headerlink\" title=\"填充\"></a>填充</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%851.JPG\" width=\"90%\" height=\"90%\"><br>不进行填充(padding)：</p>\n<ul>\n<li>$n\\times n$的图像与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n-f+1)\\times (n-f+1)$。<ul>\n<li>理解公式：$1$为卷积核位于图像最后一个位置，即进行一次卷积操作，$(n-f)$表示图像空出最后一个卷积核位置后的尺寸，也即可进行卷积的次数。故总的输出尺寸为$(n-f+1)$。</li>\n<li>如$6\\times 6$的图像与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸尺寸为$4\\times 4$。</li>\n</ul>\n</li>\n<li>缺点：每次做卷积操作后：<ul>\n<li>图像会缩小(图像的高度和宽度都会缩小)。</li>\n<li>丢失边缘信息(原图像中处于边缘的像素进行较少次的卷积运算，而处于中间的像素进行较多次的卷积运算)。</li>\n</ul>\n</li>\n<li>解决方法：对图像进行填充后，进行卷积。</li>\n</ul>\n<p>进行填充：</p>\n<ul>\n<li>$n\\times n$的图像,进行$p=padding=p$的填充后，与$f \\times f$的卷积核/滤波器进行卷积运算，输出尺寸为$(n+2p-f+1)\\times (n+2p-f+1)$。<ul>\n<li>如$6\\times 6$的图像,进行$p=1$的填充后，尺寸为$8\\times 8$。与$3 \\times 3$的卷积核/滤波器进行卷积运算，输出尺寸为$6\\times 6$。</li>\n<li>通常采用零填充(zero-padding)，即在图像边缘填充的值为0。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%A1%AB%E5%85%852.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>“Valid” convolution：不进行填充。即$p=0$。 </li>\n<li>“Same” convolution：进行填充，使得输出尺寸和输入尺寸相同(保留图像的高度和宽度。但输入和输出的通道数可以不同)。<ul>\n<li>进行填充的输出尺寸为：$(n+2p-f+1)\\times (n+2p-f+1)$，原始输入尺寸为：$n\\times n$。令$(n+2p-f+1)=n$，则$p=\\frac{f-1}{2}$。</li>\n</ul>\n</li>\n<li>另外，按照惯例，在计算机视觉中，对于卷积核/滤波器的尺寸$f \\times f$，$f$通常是奇数。<ul>\n<li>如果$f$是偶数，则只能使用一些不对称的填充。$f$是奇数，才能有自然的填充。</li>\n<li>奇数的卷积核/滤波器，会有一个中心位置。在计算机视觉中，有一个中间像素，便于指出卷积核的位置。</li>\n<li>大小为$3\\times 3$、$5\\times 5$和$7\\times 7$的卷积核很常见，$1\\times 1$也有意义。稍后讲解。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"步长\"><a href=\"#步长\" class=\"headerlink\" title=\"步长\"></a>步长</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF1.JPG\" width=\"90%\" height=\"90%\"> <img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>输入图片尺寸为$n \\times n$，卷积核尺寸为$f \\times f$，填充(padding)为$p$，步长(stride)为$s$。<ul>\n<li>则输出尺寸为：<script type=\"math/tex\">\\lfloor\\frac{n+2p-f}{s}+1\\rfloor\\ \\times \\ \\lfloor\\frac{n+2p-f}{s}+1\\rfloor</script></li>\n<li>其中，$\\lfloor z \\rfloor=floor(z)$，为向下取整，地板除法。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%AD%A5%E9%95%BF3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>在机器学习或深度学习领域，我们所使用的卷积操作，严格意义上应叫做互相关(cross-correlation)。</li>\n<li>在数学或信号处理的教科书中，卷积操作需先对卷积核进行翻转(双重镜像)后，再进行卷积操作。包含对卷积核的反转，可使得卷积运算拥有$(A*B)*C=A*(B*C)$的结合律性质。</li>\n<li>本课程按照机器学习或深度学习中的惯例，将不包含翻转操作的互相关，称为卷积操作。</li>\n</ul>\n<h3 id=\"对体进行卷积操作\"><a href=\"#对体进行卷积操作\" class=\"headerlink\" title=\"对体进行卷积操作\"></a>对体进行卷积操作</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF2.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>彩色图像的尺寸为$6 \\times 6 \\times 3$，分别表示图片的高度(height)、宽度(weight)和通道数(#channels)。</li>\n<li>卷积核的尺寸为$3 \\times 3 \\times 3$，分别表示卷积核的高度(height)、宽度(weight)和通道数(#channels)。</li>\n<li>输出尺寸为$4 \\times 4$。<ul>\n<li>解释：卷积核置于起始卷积位置(输入图像的左上)，卷积核的各通道与输入图像的各通道做卷积操作，然后3个通道的各个输出(各一个数)相加，得到最终输出(一个数)。卷积核移动，进行下一次卷积。</li>\n</ul>\n</li>\n<li>其中，输入图像的通道数(#channels)与卷积核的通道数必须相等。</li>\n<li>其中，通道数(#channels)也称为深度(depth)，但容易与神经网络的深度混淆，本课程只称其为通道数(#channels)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%AF%B9%E4%BD%93%E8%BF%9B%E8%A1%8C%E5%8D%B7%E7%A7%AF3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>输入图像的尺寸为$6 \\times 6 \\times 3$</li>\n<li>两个卷积核，第一个卷积核用来检测垂直边缘，其尺寸为$3 \\times 3 \\times 3$。第二个卷积核用来检测水平边缘，其尺寸为$3 \\times 3 \\times 3$。</li>\n<li>输出尺寸为$4 \\times 4 \\times 2$。</li>\n</ul>\n<p>总结，假设$p=0$，$s=1$：</p>\n<ul>\n<li>输入尺寸：$n \\times n \\times n_c$</li>\n<li>卷积核尺寸：$f \\times f \\times n_c$ </li>\n<li>输出尺寸为：$(n-f+1) \\times (n-f+1) \\times n_c^{\\prime}$。<ul>\n<li>其中$n_c^{\\prime}$为输出尺寸的通道数，等于卷积核个数(#filters)。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"单层卷积网络\"><a href=\"#单层卷积网络\" class=\"headerlink\" title=\"单层卷积网络\"></a>单层卷积网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>单层卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C4.jpg\" width=\"90%\" height=\"90%\"><ul>\n<li>相比之前的卷积过程，CNN的单层结构多了激活函数ReLU和偏置$b$(每个卷积核有一个偏置，例如图中两个卷积核各有一个偏置)。</li>\n<li>整个过程与标准的神经网络单层结构非常类似：<script type=\"math/tex; mode=display\">Z^{[l]}=W^{[l]}A^{[l-1]}+b</script><script type=\"math/tex; mode=display\">A^{[l]}=g^{[l]}(Z^{[l]})</script></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2.JPG\" width=\"90%\" height=\"90%\"> 单卷积层中的参数：</p>\n<ul>\n<li>若一个卷积层有，卷积核个数为10，每个卷积核尺寸为$3 \\times 3 \\times 3$，每个卷积核有1个偏置参数(一个实数)。</li>\n<li>则，单卷积层中的参数个数为：$(3*3*3+1)*10=280$个参数。</li>\n<li><strong>注意到，无论输入图像的尺寸多大，该卷积层的参数个数始终为280个。即使图片很大，参数依然很少，因此卷积神经网络不容易过拟合(less prone to overfitting)</strong>。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%95%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3.JPG\" width=\"90%\" height=\"90%\"> <strong>总结CNN中的符号表示</strong>，若第$l$层是卷积层：</p>\n<ul>\n<li>符号表示：<ul>\n<li>$f^{[l]} = $卷积核尺寸(filter size)</li>\n<li>$p^{[l]} = $填充(padding)</li>\n<li>$s^{[l]} = $步长(stride)</li>\n<li>$n_c^{[l]} = $卷积核个数(number of filters)</li>\n</ul>\n</li>\n<li>输入尺寸：$n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_c^{[l-1]}$</li>\n<li>每个卷积核的尺寸：$f^{[l]} \\times f^{[l]} \\times  n_c^{[l-1]}$</li>\n<li>权重尺寸为： $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times  n_c^{[l]}$</li>\n<li>偏置尺寸为：$n_c^{[l]}$ 或$(1,1,1,n_c^{[l]})$</li>\n<li>输出$a^{[l]}$的尺寸为： $n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$</li>\n<li>输出$A^{[l]}$的尺寸为： $m \\times n_H^{[l]} \\times n_W^{[l]} \\times  n_c^{[l]}$<ul>\n<li>其中，<script type=\"math/tex\">n_H^{[l]}=\\lfloor \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor</script>，<script type=\"math/tex\">n_W^{[l]}=\\lfloor \\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \\rfloor</script></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"简单的卷积网络示例\"><a href=\"#简单的卷积网络示例\" class=\"headerlink\" title=\"简单的卷积网络示例\"></a>简单的卷积网络示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>该CNN模型各层结构如上图所示。</li>\n<li>需要注意的是，$a^{[3]}$的维度是$7 \\times 7 \\times 40$，将$a^{[3]}$排列成1列，维度为$1960 \\times 1$，然后连接最后一级输出层。输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出 $\\hat y$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%AE%80%E5%8D%95%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> CNN有三种类型的层：</p>\n<ul>\n<li>卷积层(Convolution, CONV）</li>\n<li>池化层(Pooling, POOL）</li>\n<li>全连接层(Fully connected, FC）</li>\n</ul>\n<h3 id=\"池化层\"><a href=\"#池化层\" class=\"headerlink\" title=\"池化层\"></a>池化层</h3><p>除了卷积层(convolutional layers)，CNN中也经常使用池化层(pooling layers)来减小模型来加速计算，同时让检测到的特征更鲁棒。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%821.JPG\" width=\"100%\" height=\"100%\"> 最大池化(max pooling)，即取滤波器区域内的最大值。对二维矩阵做最大池化：</p>\n<ul>\n<li>输入尺寸为$4 \\times 4$</li>\n<li>超参数：$f=2$，$s=2$</li>\n<li>没有参数。 </li>\n<li>输出尺寸为$2 \\times 2$</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> 对三维矩阵做最大池化：</p>\n<ul>\n<li>输入尺寸为$5 \\times 5 \\times n_c$</li>\n<li>超参数：$f=3$，$s=1$</li>\n<li>没有参数。 </li>\n<li>输出尺寸为$3 \\times 3 \\times n_c$<ul>\n<li>注意，对每一通道，分别做最大池化，故输出尺寸的通道数等于输入尺寸的通道数。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 平均池化(average pooling)，即计算滤波器区域内的平均值。其它同上。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B1%A0%E5%8C%96%E5%B1%824.JPG\" width=\"90%\" height=\"90%\"> 总结：</p>\n<ul>\n<li>池化层的超参数：<ul>\n<li>滤波器尺寸(filter size)：$f$</li>\n<li>步长(stride)：$s$</li>\n<li>极少使用填充(padding)</li>\n<li>最大池化(max pooling)或平均池化(average pooling)。最大池化层更常用。</li>\n</ul>\n</li>\n<li>常用的池化层超参数有$f=2$，$s=2$，相当于将输入尺寸(高度和宽度)缩小一半。也有$f=3$，$s=2$用法。</li>\n<li>没有参数！<ul>\n<li>池化过程中没有参数需要学习。只有需要设置的上述超参数，可能是手工设置，也可能是通过交叉验证设置。</li>\n</ul>\n</li>\n<li>输入尺寸为：$n_H \\times n_W \\times n_c$</li>\n<li>输出尺寸为： $\\lfloor \\frac{n_H-f}{s}+1 \\rfloor \\times \\lfloor \\frac{n_W-f}{s}+1 \\rfloor \\times n_c$<ul>\n<li>注意到，输出尺寸的通道数与输入尺寸的通道数相同。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"卷积神经网络示例\"><a href=\"#卷积神经网络示例\" class=\"headerlink\" title=\"卷积神经网络示例\"></a>卷积神经网络示例</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B1.JPG\" width=\"100%\" height=\"100%\"> 该CNN为了识别0~9的数字。该CNN类似Yann LeCun提出的LeNet-5:</p>\n<ul>\n<li>卷积神经网络结构如图所示，重绘如下：<img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B3.jpg\" width=\"100%\" height=\"100%\"> </li>\n<li>输入为0~9的数字的图像。</li>\n<li>将CONV1和POOL1称为网络的第一层(Layer 1)。<ul>\n<li>在CNN相关文献中，一种惯例是将一个卷积层和一个池化层合称为一层；一种惯例是将一个卷积层称为一层，一个池化层称为一层。</li>\n<li>本课程在统计网络层数时，只统计有权重的层，即将CONV1和POOL1作为网络第一层。 </li>\n</ul>\n</li>\n<li>将CONV2和POOL2称为网络的第二层(Layer 2)。然后，将POOL2的输出平整化为维度为$400\\times 1$的向量。</li>\n<li>全连接层FC3为网络第三层(Layer 3)。全连接层即为标准神经网络结构。输入的400个单元和该层的120个单元每个都相连接，故称为全连接层。权重$W^{[3]}$的维度为$(120,400)$。偏置$b^{[3]}$的维度为$(120,1)$</li>\n<li>全连接层FC4为网络第四层(Layer 4)。</li>\n<li>最后的输出层为softmax层，由10个神经元构成(识别0~9的数字)。</li>\n<li>注意到，随着网络深度的加深，高度$n_H$和宽度$n_W$会减小，而通道数$n_c$会增加。</li>\n<li>CNN的另一种常见模式是一个或多个卷积层后面跟一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%A4%BA%E4%BE%8B2.JPG\" width=\"90%\" height=\"90%\"> 展示上图中CNN的各层的激活值维度和参数数量：</p>\n<ul>\n<li>池化层没有参数。</li>\n<li>卷积层的参数相对较少，许多参数都存在于全连接层。</li>\n<li>随着网络的加深，激活函数的尺寸逐渐变小。减小的太快会影响网络性能，故是逐渐减小。</li>\n</ul>\n<h3 id=\"为什么使用卷积层？\"><a href=\"#为什么使用卷积层？\" class=\"headerlink\" title=\"为什么使用卷积层？\"></a>为什么使用卷积层？</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%821.JPG\" width=\"90%\" height=\"90%\"> 相比标准神经网络，CNN的优势之一就是参数数目要少得多：</p>\n<ul>\n<li>对于一张$32 \\times 32 \\times 3$的图片。卷积层的超参数为$f=5$，卷积核的个数为$n_c=6$。则输出维度为$28 \\times 28 \\times 6$。</li>\n<li>输入尺寸为$32 \\times 32 \\times 3=3072$，输出尺寸为$28 \\times 28 \\times 6=4704$。</li>\n<li>若采用标准神经网络，则参数$W$的维度为$(4704,3072)$，共$4704 \\times 3072+4704 \\approx 14m$个参数。仅对于$32 \\times 32 \\times 3$的小图片，就有如此多的参数。</li>\n<li>而采用卷积层，每个卷积核的参数为$5\\times 5 +1=26$，有6个卷积核，则共有$6 \\times 26= 156$个参数。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%822.JPG\" width=\"90%\" height=\"90%\"> CNN的参数数目少的原因有两个：</p>\n<ul>\n<li>参数共享：一个特征检测器（例如垂直边缘检测器）如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。</li>\n<li>稀疏连接：每一层的每个输出只与一小部分输入有关。<ul>\n<li>如图，输出矩阵的左上角的0，只与输入矩阵的左上角的$3\\times 3$的矩阵有关。其他像素值都不会对该输出产生影响。</li>\n</ul>\n</li>\n<li>通过以上两种机制，CNN有较少的参数，允许我们以较小的训练集训练它，从而不易过拟合。</li>\n<li>此外，CNN善于捕捉平移不变性(translation invariance)。即CNN进行分类时，不易受物体所处图片位置发生平移的影响，更鲁棒。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E5%B1%823.JPG\" width=\"90%\" height=\"90%\"> 如何训练一个CNN：</p>\n<ul>\n<li>为了构建一个猫的检测器。</li>\n<li>训练集为$(x^{(1)},y^{(1)})…(x^{(m)},y^{(m)})$，$x^{(i)}$为输入图像，$y^{(i)}$为标签。</li>\n<li>如图，若选定了CNN结构：包含输入层，卷积层，池化层，全连接层和softmax输出层。</li>\n<li>依然同之前课程一样，定义代价函数$J=\\frac{1}{m}\\sum_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})$。</li>\n<li>采用优化算法(如梯度下降/Momentum/RMSprop/Adam)，来优化网络中的所有参数，去减小代价函数$J$。</li>\n</ul>\n<h1 id=\"2-深度卷积模型：案例学习\"><a href=\"#2-深度卷积模型：案例学习\" class=\"headerlink\" title=\"2.深度卷积模型：案例学习\"></a>2.深度卷积模型：案例学习</h1><h2 id=\"2-1-案例学习\"><a href=\"#2-1-案例学习\" class=\"headerlink\" title=\"2.1 案例学习\"></a>2.1 案例学习</h2><h3 id=\"为什么进行案例学习\"><a href=\"#为什么进行案例学习\" class=\"headerlink\" title=\"为什么进行案例学习\"></a>为什么进行案例学习</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%9B%E8%A1%8C%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0.JPG\" width=\"90%\" height=\"90%\">  </p>\n<ul>\n<li>这一周会讲解的经典CNN模型：<ul>\n<li>LeNet-5</li>\n<li>AlexNet</li>\n<li>VGG</li>\n</ul>\n</li>\n<li>另外，还会讲解：<ul>\n<li>ResNet</li>\n<li>Inception </li>\n</ul>\n</li>\n</ul>\n<h3 id=\"经典卷积网络\"><a href=\"#经典卷积网络\" class=\"headerlink\" title=\"经典卷积网络\"></a>经典卷积网络</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C1.JPG\" width=\"100%\" height=\"100%\"> LeNet-5由Yann LeCun于1998年提出，用于识别0~9的手写数字：</p>\n<ul>\n<li>针对灰度图像，故输入图片维度为$32\\times 32\\times 1$</li>\n<li>对于卷积层，那时人们不使用填充(padding)，即通常采取”valid” convolution。</li>\n<li>对于池化层，那时人们更多使用平均池化(现在通常使用最大池化)。</li>\n<li>该模型约有6万个参数。</li>\n<li>后来沿用的模式一：<strong>随着网络的加深，图像的高度$n_H$和宽度$n_W$在减小，而通道数$n_c$在增加</strong>。</li>\n<li>后来沿用的模式二：一个或多个卷积层接一个池化层，一个或多个卷积层接一个池化层，然后是几个全连接层，然后是输出层。</li>\n<li>对于激活函数，那时人们使用的是sigmoid/tanh(如今通常使用ReLU，AlexNet提出)。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C2.JPG\" width=\"100%\" height=\"100%\"> AlexNet是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton于2012年共同提出，用于识别ImageNet中的1000类图像：</p>\n<ul>\n<li>AlexNet模型与LeNet-5模型类似，但更大，约有6千万个参数。</li>\n<li>对于激活函数，AlexNet使用了ReLU激活函数。</li>\n<li>当时，GPU还较慢，AlexNet采用了在两个GPU上并行计算。</li>\n<li>AlexNet中含有一种特殊的层，叫做局部相应归一化层(Local Response Normalization, LRN)。但后来研究者发现效果有限，故如今并不使用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C3.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>VGG-16中一个精彩的地方在于，没有那么多的超参数，专注于构建简单的网络结构：<ul>\n<li>对于卷积层，只使用$f=3$，$s=1$，”same”填充。</li>\n<li>对于池化层，只使用$f=2$，$s=2$的最大池化层。</li>\n</ul>\n</li>\n<li>每次池化后，图像的高度$n_H$和宽度$n_W$缩小一半。每一组卷积层之后，通道数$n_c$增加一倍，直到512。</li>\n<li>缺点：包含1亿三千万个参数，以现在的标准来看，都是非常大的网络，有太多参数需要训练。</li>\n<li>优点：VGG-16的结构并不复杂，<strong>结构很规整</strong>，这一点非常吸引研究者。</li>\n<li>VGG-16中的16指的是包含权重的卷积层、全连接层和输出层(未计没有参数的池化层)。</li>\n<li>VGG-19的表现与VGG-16差不多，更多的人使用VGG-16。</li>\n</ul>\n<h3 id=\"ResNets\"><a href=\"#ResNets\" class=\"headerlink\" title=\"ResNets\"></a>ResNets</h3><p>由于梯度消失(vanishing gradients)和梯度爆炸(exploding gradients)的原因，非常非常深的网络是难以训练的。这一节学习跳跃连接(skip connection)，它可从某一层网络获取激活值，然后喂给更深的一层网络。通过跳跃连接，即可构建出ResNets(Residual Networks)，让我们可以训练非常非常深的网络。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets1.JPG\" width=\"100%\" height=\"100%\"> ResNet是由残差模块(residual block)构建的，上图介绍残差模块：</p>\n<ul>\n<li>残差模块的主路径(main path)为：$a^{[l]}$ -&gt; 线性操作 -&gt; ReLU(得$a^{[l+1]}$) -&gt; 线性操作 -&gt; ReLU(得$a^{[l+2]}$)。</li>\n<li>残差模块的捷径(short cut)/跳跃连接为：$a^{[l]}$ 直接隔层与$l+2$层的线性输出相连，与$z^{[l+2]}$共同通过激活函数（ReLU）输出 $a^{[l+2]}$。</li>\n<li>具体公式如下：<ul>\n<li>$z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]}$</li>\n<li>$a^{[l+1]}=g(z^{[l+1]})$</li>\n<li>$z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]}$</li>\n<li>$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/ResNets2.JPG\" width=\"100%\" height=\"100%\"> 通过堆叠许多残差模块在一起，即构建成ResNet：</p>\n<ul>\n<li>在ResNet论文中，将非Residual Network称为Plain Network。</li>\n<li>在一个Plain Network中，加上捷径/跳跃连接，如图中每两层构成一个残差模块，共5个残差模块。整体即构成一个残差网络(residual network)。</li>\n<li>若用优化算法优化一个朴素的网络(plain network)，其效果如图：<ul>\n<li>理论上：随着网络深度的加深，训练误差应越来越小。</li>\n<li>实际上：起初，训练误差会降低。但随着层数的增多，训练误差上升。</li>\n</ul>\n</li>\n<li>若用优化算法优化一个ResNet，其效果如图：<ul>\n<li>随着网络深度的加深，训练误差越来越小。</li>\n</ul>\n</li>\n<li>跳跃连接确实有助于解决梯度消失和梯度爆炸的问题，让我们在训练十分深层的网络时得到好的性能。</li>\n</ul>\n<h3 id=\"RestNets为何有效\"><a href=\"#RestNets为何有效\" class=\"headerlink\" title=\"RestNets为何有效\"></a>RestNets为何有效</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%881.JPG\" width=\"100%\" height=\"100%\"> 给一个深度网络，增加了一个残差模块后，网络的深度得到了增加：</p>\n<ul>\n<li>$a^{[l+2]}$的表达式为：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})$。</li>\n<li>注意到，如果使用L2正则化或权重衰减，将会使得$W^{[l+2]}$不断减小。假设$W^{[l+2]}=0$，$b^{[l+2]}=0$（发生梯度消失）。</li>\n<li>那么，<script type=\"math/tex\">a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}</script>（$a^{[l]}$本就大于等于0，再经过ReLU激活函数，还是$a^{[l]}$本身）。</li>\n<li>以上结果表明：恒等函数(identity function)对于残差模块来说，非常容易学习。因此，尽管增加了残差模块，一方面没有伤害网络的效率，另一方面还提升了网络的性能。</li>\n<li>残差网络有效的原因：<ul>\n<li>残差模块学习恒等函数非常容易(没有伤害网络的学习效率)。</li>\n<li>残差模块的添加起码不会降低网络的表现，很多时候可以提升网络的表现。</li>\n</ul>\n</li>\n<li>另外，残差网络的另一个细节是：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中$z^{[l+2]}$与$a^{[l]}$拥有相同的维度：<ul>\n<li>故ResNets中使用了许多”same”卷积。</li>\n<li>若$a^{[l+2]}$与$a^{[l]}$维度不一样，可以引入矩阵$W_s$，使得$W_s \\cdot a^{[l]}$的维度与$a^{[l+2]}$一致，即<script type=\"math/tex\">a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})</script>。矩阵$W_s$可以设置为通过网络学习的参数矩阵，也可以设置为固定矩阵(如只是给$a^{[l]}$进行零填充)。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%B8%BA%E4%BB%80%E4%B9%88ResNet%E6%9C%89%E6%95%882.JPG\" width=\"100%\" height=\"100%\"> 简单分析ResNets结构特点：</p>\n<ul>\n<li>ResNets中采用了很多$3\\times 3$的same卷积。<ul>\n<li>same卷积是为了进行$a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$中的$z^{[l+2]}+a^{[l]}$。</li>\n</ul>\n</li>\n<li>池化层后需调整$W_s$的维度，即进行<script type=\"math/tex\">a^{[l+2]}=g(z^{[l+2]}+W_s \\cdot a^{[l]})</script>。</li>\n<li>ResNets的网络结构是几个卷积层接一个池化层，然后重复，然后是一个全连接层，然后是softmax输出层。</li>\n</ul>\n<h3 id=\"Network-in-NetWork以及1x1卷积\"><a href=\"#Network-in-NetWork以及1x1卷积\" class=\"headerlink\" title=\"Network in NetWork以及1x1卷积\"></a>Network in NetWork以及1x1卷积</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/netwrok%20in%20network1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>如图上半部分，对于单通道的二维矩阵，进行$1\\times 1$卷积的效果就是乘以一个数字。</li>\n<li>如图下半部分，对$6 \\times 6 \\times 32$的体，卷积核为$1 \\times 1 \\times 32$，进行卷积的效果是：<ul>\n<li>对于输入体的36个切片，每个切片的维度都为(1,1,32)。每一个切片都与卷积核逐元素相乘，然后求和，得到一个实数，即输出矩阵中的一个绿点。</li>\n<li>若应用在CNN中，则相当于：输入体中的每一切片逐元素乘以卷积核中的权重，然后求和，加上偏置，然后进行ReLU激活，如输出矩阵中的一个黄点。</li>\n<li>若有多个卷积核，则输出结果为多通道。</li>\n</ul>\n</li>\n<li>因此，$1\\times 1$卷积应用在CNN中，则可以理解为：36个切片中的32个单元，与#filters中的每个卷积核进行了全连接，输出维度为$6 \\times 6 \\times n_c^{[l+1]}$，其中<script type=\"math/tex\">n_c^{[l+1]}= \\# filters</script>。</li>\n<li>此方法称为$1\\times 1$卷积或Network in NetWork。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/network%20in%20network2.JPG\" width=\"90%\" height=\"90%\"> $1\\times 1$卷积可以用来缩小通道数量：</p>\n<ul>\n<li>输入维度是$28 \\times 28 \\times 192$，通过32个$1\\times 1$卷积核(准确地说，维度为$1\\times 1\\times 192$)，输出为$28 \\times 28 \\times 32$，缩小了通道数。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>$1\\times 1$卷积<strong>给网络增加了非线性，可以让网络学习更复杂的函数</strong>。</li>\n<li>通过$1\\times 1$卷积，<strong>可减少或保持或增加通道数</strong>。</li>\n</ul>\n<h3 id=\"Inception-Network动机\"><a href=\"#Inception-Network动机\" class=\"headerlink\" title=\"Inception Network动机\"></a>Inception Network动机</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA1.JPG\" width=\"90%\" height=\"90%\"> Inception网络的基本思想是：代替人为选择卷积核尺寸以及是否使用池化层，而是将它们都添加进网络，然后将输出串联起来，然后让网络去学习参数，去决定采用哪些组合：</p>\n<ul>\n<li>输入维度为$29\\times 28 \\times 192$</li>\n<li>通过$1\\times 1$的same卷积，使得输出为$28 \\times 28 \\times 64$</li>\n<li>通过$3\\times 3$的same卷积，使得输出为$28 \\times 28 \\times 128$</li>\n<li>通过$5\\times 5$的same卷积，使得输出为$28 \\times 28 \\times 32$</li>\n<li>通过最大池化层，$s=1$，使用填充，使成为same-pool，使得输出为$28 \\times 28 \\times 32$</li>\n<li>将所有输出串联起来，维度为$28 \\times 28 \\times 256$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA2.JPG\" width=\"90%\" height=\"90%\"> 上图中描述的Inception模块中有一个问题，就是计算成本的问题：</p>\n<ul>\n<li>集中讨论上图中的$5 \\times 5$的卷积核</li>\n<li>进行该卷积计算，需要进行的乘法次数为：<ul>\n<li>输出个数为：$28\\times 28\\times 32$</li>\n<li>每个输出需进行的乘法次数为：$5\\times 5\\times 192$</li>\n<li>故需进行的乘法次数为：$(28\\times 28\\times 32)\\times (5\\times 5\\times 192)\\approx 120m$</li>\n</ul>\n</li>\n<li>即使用现代计算机，计算1.2亿次计算，也是相当昂贵的操作。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Inception%E5%8A%A8%E6%9C%BA3.JPG\" width=\"90%\" height=\"90%\"> 通过$1\\times 1$卷积层，降低计算成本：</p>\n<ul>\n<li>结构如图，先通过$1\\times 1$卷积，再进行$5\\times 5$卷积，最终输出和上图相同。</li>\n<li>加入$1\\times 1$卷积后，进行两次卷积计算，需要进行的乘法次数为：<ul>\n<li>$1\\times 1$卷积需要的乘法次数：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)$</li>\n<li>$5\\times 5$卷积需要的乘法次数：$(28\\times 28\\times 32)\\times (5\\times 5\\times 16)$</li>\n<li>进行两次卷积计算，需要进行的乘法次数为：$(28\\times 28\\times 16)\\times (1\\times 1\\times 192)+(28\\times 28\\times 32)\\times (5\\times 5\\times 16)\\approx 12.4m$</li>\n</ul>\n</li>\n<li>通常我们把该$1\\times 1$卷积层称为“瓶颈层”(bottleneck layer)，因为它是网络中最小的那个部分。<strong>先通过“瓶颈层”缩小网络，然后再扩大网络，显著降低了计算成本</strong>，乘法计算次数从120m减少为12.4m。</li>\n</ul>\n<h3 id=\"Inception-Network\"><a href=\"#Inception-Network\" class=\"headerlink\" title=\"Inception Network\"></a>Inception Network</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork1.JPG\" width=\"90%\" height=\"90%\"> 正式介绍Inception模块：</p>\n<ul>\n<li>输入为前一层的激活函数。</li>\n<li>单独的$1\\times 1$卷积层，输出维度为$28 \\times 28 \\times 64$。</li>\n<li>先是$1\\times 1$卷积层，再接$3\\times 3$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 128$。</li>\n<li>先是$1\\times 1$卷积层，再接$5\\times 5$卷积层(降低计算成本)，输出维度为$28 \\times 28 \\times 32$。</li>\n<li>先是$f=3$，$s=1$的same最大池化层，再接$1\\times 1$卷积层(为了降低通道数)，输出维度为$28 \\times 28 \\times 32$。</li>\n<li>串联(concatenate)所有输出，输出维度为$28 \\times 28 \\times 256$。(Caffe中的concat层，实现此串联操作。)</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetworkk2.JPG\" width=\"100%\" height=\"100%\"> 正式介绍Inception Network，如图：</p>\n<ul>\n<li>Inception Network由很多Inception模块构成。</li>\n<li>Inception Network中的另一个细节是：在中间层设置了两个辅助softmax分类器，它们保证了即便是中间层的隐藏神经元计算的特征，在预测图像类别时，表现也不太差。它们在Inception Network起着正则化的效果，帮助防止过拟合。</li>\n<li>Inception Network也称为GoogleNet。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/InceptionNetwork3.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>Inception Network中“Inception”取自莱昂纳多的电影《Inception》。</li>\n</ul>\n<h2 id=\"2-2-使用卷积网络的实用建议\"><a href=\"#2-2-使用卷积网络的实用建议\" class=\"headerlink\" title=\"2.2 使用卷积网络的实用建议\"></a>2.2 使用卷积网络的实用建议</h2><h3 id=\"使用开源实现\"><a href=\"#使用开源实现\" class=\"headerlink\" title=\"使用开源实现\"></a>使用开源实现</h3><ul>\n<li>对于许多经典的神经网络，因为许多细节问题（如超参数的调节，学习率衰减或其它）而很难实现复现。因此，仅靠论文去从零实现，是很困难的。</li>\n<li>建议从其他研究者贡献出的开源代码开始研究或使用，如在Github中搜索并获取开源代码。</li>\n</ul>\n<h3 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h3><p>你如果要做一个计算机视觉应用，相比于从头(随机初始化权重)开始训练权重，如果你下载别人已经训练好的权重，然后把它当做预训练，然后迁移到你感兴趣的任务中，通常能够取得更快的进展。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.JPG\" width=\"100%\" height=\"100%\"> 假设你训练猫分类器，能够分类Tigger，Misty和Neither。</p>\n<ul>\n<li>如图第一行，若你没有关于Tigger，Misty大量图片，即训练集很小：<ul>\n<li>下载经典网络的代码以及权重，删去最后的Softmax层，创建你自己的Softmax层(Tigger/Misty/Neither)。</li>\n<li>将你下载的网络，看作是冻结的，冻结该网络的所有参数。将别人训练好的权重，作为初始权重，只训练和你自己的Softmax层有关的参数。</li>\n<li>这样，即使你只有一个小的训练集，也能取得好的性能。</li>\n<li>加速训练的技巧：由于前面的层都冻结了，即相当于一个不需要改变的固定函数(相当于取输入$X$，然后映射到选用的最后一层的激活函数)。预先计算这个固定函数的得到的特征或是说激活值，然后将它们存到硬盘中（对于每一周期(epoch)，不用重复遍历数据集计算激活值）。然后将它们作为输入，相当于训练一个浅层的softmax模型。</li>\n</ul>\n</li>\n<li>如图第二行，若有一个更大的训练集：<ul>\n<li>可以冻结更少的层，如图。然后训练后面的所有层（构建自己的Softmax层后）。</li>\n<li>也可将未冻结的后面几层全部删去，构建自己的几个隐藏层和Softmax层，然后只训练后面几层。</li>\n<li>模式就是：如果有更多的数据，那么你需要冻结的层数就更少，你需要训练的末端的层数就更多。</li>\n</ul>\n</li>\n<li>如图第三行，如果你有足够多的大量的训练集：<ul>\n<li>将下载的权重作为初始权重(代替随机初始化)，重新训练网络的所有层。</li>\n</ul>\n</li>\n<li>在所有深度学习的应用中，计算机视觉领域是一个经常用到迁移学习的领域。除非你有极其大的数据集和非常大的计算预算，能让你能够自己从头训练所有东西，那么迁移学习总是值得你考虑的方案。</li>\n</ul>\n<h3 id=\"数据增强\"><a href=\"#数据增强\" class=\"headerlink\" title=\"数据增强\"></a>数据增强</h3><p>数据增强是经常用来提升计算机视觉系统性能的技巧。计算机视觉任务是一项相当复杂的工作，你需要输入图像中的像素值，然后弄清楚图片中有什么，似乎你需要学习一个相当复杂的函数。对于几乎所有的计算机视觉任务，通常的问题是数据远远不够。因此，对于计算机视觉任务，数据增强通常都会有帮助。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA1.JPG\" width=\"100%\" height=\"100%\"> 介绍了常用的数据增强方法：</p>\n<ul>\n<li>镜像(mirroring)：以垂直轴为基准，进行镜像。</li>\n<li>随机裁剪(random cropping)：裁剪出原图像中的一部分。</li>\n<li>理论上，还有一些方法，如旋转(rotation)，剪切(shearing)，local warping(局部弯曲)等。但因为过于复杂，实践中很少使用。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA2.JPG\" width=\"50%\" height=\"50%\"> 第二种经常使用的数据增强方法：</p>\n<ul>\n<li>色彩转换(color shifting)/色彩失真(color distortion)：分别对图片的RGB通道中的像素值进行增加或者减少，改变图片色彩。<ul>\n<li>解释：进行色彩转换，希望能让算法对图片的色彩的改变更具鲁棒性。</li>\n<li>AlexNet论文中采用了“PCA color augmentation”：减少主要色调成分(如R和B通道)的像素值多一点，减少G通道的像素值少点，使得整体的色调保持一致。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA3.JPG\" width=\"90%\" height=\"90%\"></p>\n<ul>\n<li>可通过CPU/GPU的不同进程，并行地进行数据增强和训练。</li>\n</ul>\n<h3 id=\"计算机视觉的现状\"><a href=\"#计算机视觉的现状\" class=\"headerlink\" title=\"计算机视觉的现状\"></a>计算机视觉的现状</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B61.JPG\" width=\"90%\" height=\"90%\"> </p>\n<ul>\n<li>对于图像识别(image recognition)任务，尽管今天我们有很大的数据集，但仍想要更多的数据。</li>\n<li>对于目标检测(object detection)任务，我们有着更少的数据，因为标注边框这一步的成本太高。</li>\n</ul>\n<p><strong>学习算法有两个主要的知识来源：一是带标签的数据；二是手工设计的特征或网络结构或其他组件</strong>：</p>\n<ul>\n<li>当有大量数据时，人们倾向于使用更简单的算法和更少的手工工程。</li>\n<li>而当有较少量的数据时，人们倾向于使用更多的手工工程<ul>\n<li>解释：但当没有大量数据时，手工设计的组件或特征，是把人类知识直接注入算法的好的途径。</li>\n<li>举例：计算机视觉是在试图学习一个非常复杂的函数，因此我们总感觉没有足够的数据来满足我们的需求。在计算机视觉的初期，拥有的数据量很小，所以依赖手工设计的特征。近几年，数据量剧增，但对于计算机视觉还是不够，因此人们设计复杂的网络结构(包含很多超参数)。对于目标检测任务，拥有的数据量比图像识别任务更少，因此人们手工设计了许多组件。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B62.JPG\" width=\"100%\" height=\"100%\"> 在基准数据集或竞赛中取得好成绩的技巧：</p>\n<ul>\n<li>集成(ensembling):<ul>\n<li>独立训练多个(3~15)网络，然后平均它们的输出。</li>\n</ul>\n</li>\n<li>在测试阶段进行多裁剪(multi-crop)：<ul>\n<li>在测试阶段，对于一张测试图片，通过镜像(mirroring)以及随机裁剪(random cropping)的方式，获得该图像的多个版本。然后平均它们的测试结果。</li>\n</ul>\n</li>\n<li>集成(ensembling)方式占用过多内存且运行速度慢；在测试阶段进行多裁剪(multi-crop)，运行速度慢。因此它们在实际应用中没有意义。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%8E%B0%E7%8A%B63.JPG\" width=\"90%\" height=\"90%\"> 若你要建立一个实际系统，采用以下步骤，能让你的应用进行的更快：</p>\n<ul>\n<li>从使用文献中的网络结构开始。</li>\n<li>使用开源的代码实现。<ul>\n<li>因为开源代码已经解决了所有的繁琐细节，如学习率衰减或其他超参数。</li>\n</ul>\n</li>\n<li>使用预训练的模型然后用你的数据集微调。<ul>\n<li>因为其他人可能已经在多个GPU上花了几个星期对超过一百万张图片进行训练后，得到这个模型。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"3-目标检测\"><a href=\"#3-目标检测\" class=\"headerlink\" title=\"3.目标检测\"></a>3.目标检测</h1><h2 id=\"3-1-检测算法\"><a href=\"#3-1-检测算法\" class=\"headerlink\" title=\"3.1 检测算法\"></a>3.1 检测算法</h2><h3 id=\"目标定位\"><a href=\"#目标定位\" class=\"headerlink\" title=\"目标定位\"></a>目标定位</h3><p>目标定位(object localization)<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D1.JPG\" width=\"90%\" height=\"90%\"> 图像分类任务与目标检测任务的区别：</p>\n<ul>\n<li>图像分类(Image classification)：对于给定图像，预测出类别（通常只有一个较大物体在图片中央）。</li>\n<li>分类且定位(Classification with Localization)：对于给定图像，预测类别，且给出物体在图片中的位置，即标出包围框(bounding box)（通常只有一个较大物体在图片中央）。</li>\n<li>检测(Detection)问题：图片中可存在多个属于不同类别的物体，对每个物体分类且定位。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D2.JPG\" width=\"100%\" height=\"100%\"> 分类且定位的实现方法：</p>\n<ul>\n<li>图像分类的方式就是构建CNN，然后通过softmax分类层进行分类。<ul>\n<li>softmax层有四个神经元，分别对应行人(pedestrain)，车辆(car)，摩托车(motorcycle)和背景(background)四类。</li>\n</ul>\n</li>\n<li>要实现定位，修改输出层，通过增加神经元，来输出表示包围框的四个数字：<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>。<ul>\n<li><script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>对应包围框的中点，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>分别对应包围框的高和宽。</li>\n<li>本课程约定，以图像的左上角为$(0,0)$点，右下角为$(1,1)$点，横向为$x$方向，纵向为$y$方向。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%BD%8D3.JPG\" width=\"90%\" height=\"90%\"> 为了用监督学习算法解决分类且定位任务，需要定义训练集$(x,y)$，其中标签$y$该这样定义：</p>\n<ul>\n<li><script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>。其中，<script type=\"math/tex\">Pc</script>表示是否检测到目标，<script type=\"math/tex\">Pc=1</script>代表图片中检测到目标。<script type=\"math/tex\">Pc=0</script>代表图片中未检测到目标。</li>\n<li>如上图中的左图，检测到目标，$Pc=1$。训练集中应标注标签：<script type=\"math/tex\">\\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n<li>如上图中的右图，未检测到目标，$Pc=0$，则$Pc$后面参数都没有意义，都可以忽略。训练集中应标注标签：<script type=\"math/tex\">\\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]</script></li>\n</ul>\n<p>最后，对于神经网络的损失函数，若全部使用平方误差形式，有两种情况：</p>\n<ul>\n<li>若$y_1=1$,即$Pc=1$，那么：<script type=\"math/tex\">L(\\hat y,y)=(\\hat y_1-y_1)^2+(\\hat y_2-y_2)^2+\\cdots+(\\hat y_8-y_8)^2</script></li>\n<li>若$y_1=0$,即$Pc=0$，那么：<script type=\"math/tex\">L(\\hat y,y)=(\\hat y_1-y_1)^2</script></li>\n<li>这里用平方误差简化了描述过程，在实际应用中，可以对$Pc$使用逻辑回归损失，对<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>使用平方误差损失，对于$c_1$，$c_2$，$c_3$使用softmax损失。</li>\n</ul>\n<h3 id=\"特征点检测\"><a href=\"#特征点检测\" class=\"headerlink\" title=\"特征点检测\"></a>特征点检测</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%89%B9%E5%BE%81%E7%82%B9%E6%A3%80%E6%B5%8B.JPG\" width=\"100%\" height=\"100%\"> </p>\n<ul>\n<li>上节中，通过让网络输出四个实数(<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>)的方式，指定了想要定位的物体的包围边框。</li>\n<li>在更一般的情况下，可以通过神经网络输出图像中关键特征点的$(x,y)$坐标（这些点称作landmarks），来实现对这些关键特征点的检测。</li>\n</ul>\n<p>上图中举了两例：</p>\n<ul>\n<li>例1：人脸关键特征点检测。<ul>\n<li>在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人脸特征点的坐标。</li>\n<li>如图，在输出层中，第一个神经元代表是否属于人脸，第二个神经原代表特征点1的$x$坐标，第三个神经元代表特征点1的$y$坐标，等等。</li>\n</ul>\n</li>\n<li>例2：人体姿态检测。<ul>\n<li>在进行分类的CNN的输出层中添加一些神经元，每个神经元对应于一个你想要检测的人体关键特征点的坐标。</li>\n</ul>\n</li>\n<li>想要训练这样的网络，需要一个带标签的训练集$(X,Y)$。<ul>\n<li>其中在人工标注关键特征点时，对于每一个样本，每一特征点代表的含义顺序，必须一致。如对于人脸特征点检测，特征点1代表左眼角，特征点2代表右眼角等等。对于人体姿态检测，特征点1代表左肩，特征点2代表胸部中点，特征点3代表右肩等等。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"目标检测\"><a href=\"#目标检测\" class=\"headerlink\" title=\"目标检测\"></a>目标检测</h3><p>本节以车辆检测为例，介绍基于滑动窗口的目标检测算法。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B1.JPG\" width=\"100%\" height=\"100%\"> 第一步，构建CNN以进行车辆分类：</p>\n<ul>\n<li>对于训练集$(x,y)$，$x$是适当剪切的图片。如上图，$x$为剪切后的汽车图片样本，即剪去其他部分，只有车辆在图片中央并占据了整个图片。</li>\n<li>然后即可训练CNN。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 第二步，滑动窗口检测(sliding window detection)：</p>\n<ul>\n<li>选择固定大小的矩形窗口，按某个步长，滑动遍历整个图片。滑动窗口每到达一个位置，就将该窗口内的图片送入CNN进行分类。CNN输出1(是汽车)或者0(背景，不是汽车)。</li>\n<li>然后选择一个更大的窗口，继续滑动窗口检测操作。</li>\n<li>然后再选择一个更大的窗口，继续滑动窗口检测操作。</li>\n</ul>\n<p>基于滑动窗口检测目标检测算法的缺点：</p>\n<ul>\n<li>计算成本高。滑动窗口到达的每一个位置的图片，都需要用CNN进行处理。</li>\n<li>如果选用大步长，窗口数会减少，但会影响性能。</li>\n<li>如果选用小步长，窗口数会剧增，计算成本过高。</li>\n</ul>\n<h3 id=\"滑动窗口的卷积实现\"><a href=\"#滑动窗口的卷积实现\" class=\"headerlink\" title=\"滑动窗口的卷积实现\"></a>滑动窗口的卷积实现</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B01.JPG\" width=\"100%\" height=\"100%\"> <strong>用卷积层替换全连接层</strong>：</p>\n<ul>\n<li>上图中第一行是用来进行分类的CNN结构：输入为尺寸为$14\\times 14 \\times 3$的图片，卷积层，池化层，全连接层，全连接层，然后是softmax分类层（含四个结点，每个结点对应一个类别的概率）。</li>\n<li>上图中的第二行是将全连接层转换为卷积层后的CNN结构：<ul>\n<li>首先通过400个$5\\times 5$的卷积核(每个卷积核的尺寸为$5\\times 5\\times 16$)，将输出尺寸变为$1\\times 1\\times 400$。(将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)</li>\n<li>然后通过400个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，将输出尺寸变为$1\\times 1\\times 400$。(**将此处输出的$1\\times 1\\times 400$的体，视为原本全连接层的400个结点。)</li>\n<li>然后通过4个$1\\times 1$的卷积核(每个卷积核的尺寸为$1\\times 1\\times 400$)，输出层的输出尺寸为$1\\times 1\\times 4$，然后进行softmax激活函数，作为最终的输出结果。(将此处输出的$1\\times 1\\times 4$的体，视为原softmax输出层的4个结点。)</li>\n</ul>\n</li>\n<li>用卷积层替换全连接层的目的是为了使得能够输入任意尺寸的图片，而如果存在全连接层，则输入和输出的维度必须是固定的。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B02.JPG\" width=\"100%\" height=\"100%\"> 基于滑动窗口的目标检测算法的卷积实现：</p>\n<ul>\n<li>上图中第一行的输入为一个滑动窗口内的图像，即尺寸为$14\\times 14 \\times 3$的体，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$1\\times 1\\times 4$的体，相当于softmax输出层的4个输出结点。</li>\n<li>上图中第二行的输入为一张$16\\times 16 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$2\\times 2\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。4个$1\\times 1\\times 4$的体即对应4个滑动窗口的输出结果。</li>\n<li>上图中第三行的输入为一张$28\\times 28 \\times 3$的图像，输入上节中CNN(用卷积层替换了全连接层)的效果，输出为$8\\times 8\\times 4$的体，其中每一个$1\\times 1\\times 4$的体都相当于一个滑动窗口内的图像的输出结果。64个$1\\times 1\\times 4$的体即对应64个滑动窗口的输出结果。</li>\n<li>该模型源于OverFeat。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E5%AE%9E%E7%8E%B03.JPG\" width=\"100%\" height=\"100%\"> 总结：</p>\n<ul>\n<li>原始的基于滑动窗口的目标检测算法，会分别将每一个滑动窗口内的图像，单独给CNN处理。并且这样会使得很多CNN的处理过程是重复的。</li>\n<li>而基于滑动窗口的目标检测算法的卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的窗口图像共享了许多计算。</li>\n<li>基于滑动窗口的目标检测算法的卷积实现，极大地提高了效率。但存在一个缺点：不能输出最准确的包围边框。下节解决这个问题。</li>\n</ul>\n<h3 id=\"包围边框预测\"><a href=\"#包围边框预测\" class=\"headerlink\" title=\"包围边框预测\"></a>包围边框预测</h3><p>上节中基于滑动窗口的目标检测算法的卷积实现，其计算效率很高，但存在不能输出非常准确的包围边框的问题。本节介绍YOLO(You Only Look Once)算法，它可以得到准确的包围边框。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B1JPG.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>基于滑动窗口的目标检测算法，很有可能没有一个合适的滑动窗口，能够完美匹配图中的汽车的位置，即红色包围边框。最接近的，可能只是图中的蓝色窗口。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B2.JPG\" width=\"100%\" height=\"100%\"> 介绍YOLO算法：</p>\n<ul>\n<li>YOLO算法首先将原始图片分割成$n\\times n$网格，每个网格代表一块区域。为简化说明，将图片分成$3 \\times 3$网格。<ul>\n<li>实际应用中采用更精细的网格，如$19\\times 19$。更精细的网格也可以使得多个物体分配到同一格子的概率减小。</li>\n</ul>\n</li>\n<li>然后，采用本周第一个视频讲述过的图像分类且定位算法(image classification and localization algorithm)，应用在9个格子的每一个格子上。</li>\n<li>训练集$(x,y)$的构建：<ul>\n<li>$x$即为输入图像矩阵，例如尺寸为$100 \\times 100 \\times 3$</li>\n<li>标签$y$的维度为$3 \\times 3 \\times 8$，即共9个$1 \\times 1 \\times 8$，其中每一个$1 \\times 1 \\times 8$代表着一个格子的标签。</li>\n<li>每个格子对应的$1 \\times 1 \\times 8$的标签，同本周第一个视频讲述过的一样。<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script></li>\n<li>需强调：将物体分配给哪个格子是由物体的中点$(b_x,b_y)$属于哪个格子决定的。</li>\n<li>对于一个格子可能存在多个物体的情况，稍后讨论。</li>\n</ul>\n</li>\n<li>构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 8$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的进行训练。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>该算法和图像分类且定位算法很相似，它显示的输出包围边框的坐标，它能让神经网络输出任意长宽比的坐标，而不收到滑动窗口的步长的限制。因此，该算法能够输出精确的包围边框。</li>\n<li>此外，该算法也是卷积实现，直接对整张图片进行卷积，一次性地同时得到所有预测值。并且使得所有的网格共享了许多计算。正因为它是卷积实现，因此该算法的效率非常高，运行得非常快，能达到实时目标检测。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%85%E5%9B%B4%E8%BE%B9%E6%A1%86%E9%A2%84%E6%B5%8B3.JPG\" width=\"100%\" height=\"100%\"> 如何定义包围边框，即如何编码(encode)<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>，<script type=\"math/tex\">b_h</script>，<script type=\"math/tex\">b_w</script>：</p>\n<ul>\n<li>如图，以每个网格的左上角为$(0,0)$点，以右下角为$(1,1)$点。</li>\n<li>中心点<script type=\"math/tex\">b_x</script>，<script type=\"math/tex\">b_y</script>为距离$(0,0)$点的水平距离和垂直距离相对网格边长的比值。因此，<script type=\"math/tex\">b_x</script>和<script type=\"math/tex\">b_y</script>在0~1之间。</li>\n<li>高度<script type=\"math/tex\">b_h</script>和宽度<script type=\"math/tex\">b_w</script>，为包围边框的高和宽与网格边长的比值。因此，<script type=\"math/tex\">b_h</script>和<script type=\"math/tex\">b_w</script>可能大于1。</li>\n<li>如图，图中样本$x$对应的标签应该为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ 0.4 \\\\ 0.3 \\\\ 0.9 \\\\ 0.5 \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n<li>当然编码包围框的方式很多，YOLO论文中也交待了其他更复杂的参数化方式。但本课程给出了此种方法是合理且可使用的一种方式。</li>\n</ul>\n<h3 id=\"交并比\"><a href=\"#交并比\" class=\"headerlink\" title=\"交并比\"></a>交并比</h3><p>交并比(Intersection over Union, IoU)是评价目标定位算法准确性的指标。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%A4%E5%B9%B6%E6%AF%94.JPG\" width=\"100%\" height=\"100%\"> 交并比讲解：</p>\n<ul>\n<li>如图，紫色边框为预测边框，红色边框为真实边框。</li>\n<li>黄色阴影部分为两边框区域的交集(Intersection)，绿色阴影部分为两边框区域的并集(Union)。</li>\n<li>交并比(Intersection over Union, IoU)即为：<script type=\"math/tex\">IoU=\\frac{Intersection}{Union}</script><ul>\n<li>一般人为规定当$IoU \\geq 0.5$时，预测的包围边框是正确的。</li>\n</ul>\n</li>\n<li>更一般的说，IoU衡量了两个包围边框的重叠程度。</li>\n</ul>\n<h3 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h3><p>目标检测算法可能会检测同一个目标多次。非极大值抑制(Non-max Suppression, NMS)可以确保对每个对象只检测一次。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B61.JPG\" width=\"80%\" height=\"80%\"> 如图，以YOLO算法检测汽车为例，对于该图片，会有多个网格对同一汽车做出检测。</p>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B62.JPG\" width=\"100%\" height=\"100%\"> 极大值抑制的效果：</p>\n<ul>\n<li>如图，当运行目标检测算法时，最终出现了对同一个对象进行多次检测的情况。</li>\n<li>通过非极大值抑制，清理了这些检测结果。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B63.JPG\" width=\"100%\" height=\"100%\"> 非极大值抑制的实现细节：</p>\n<ul>\n<li>假设只检测车辆，用YOLO算法检测这张图片后的输出的维度为$19\\times 19 \\times 5$。共$19\\times 19 = 361$个格子，每一个格子的输出为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw  \\end{matrix} \\right ]</script>。其中，$p_c$为存在对象的概率，在此处即是车辆的概率。</li>\n<li>第一步，丢弃所有$p_c \\leq 0.6$的包围框。<ul>\n<li>在编程作业中，这一步作为单独的步骤，不在NMS之内。先算得分($p_c$与$c_1$或$c_2$或$c_3$相乘)再取阈值。</li>\n</ul>\n</li>\n<li>第二步，只要有剩余包围框，则一直循环：<ul>\n<li>选择$p_c$最大的包围框为一个预测包围框。</li>\n<li>舍弃所有与上一步中的预测包围框的$IoU\\geq 0.5$的剩余的包围框。</li>\n</ul>\n</li>\n<li>另外，该节只是介绍了只检测车辆这一类目标的情况，如果想要检测三类目标(如行人，车辆，摩托车)，那么每个格子的输出向量就会有额外三个分量($c_1$，$c_2$，$c_3$)。正确的做法是，对每个类别都独立进行一次非极大值抑制，即进行三次非极大值抑制。</li>\n</ul>\n<h3 id=\"Anchor-Boxes\"><a href=\"#Anchor-Boxes\" class=\"headerlink\" title=\"Anchor Boxes\"></a>Anchor Boxes</h3><p>到目前位置，我们介绍的是每个网格只能包含一个物体，若一个网格包含两个或以上物体，则无法处理。使用anchor boxes可以解决这个问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes1.JPG\" width=\"100%\" height=\"100%\"></p>\n<ul>\n<li>如图，对图片采用$3\\times 3$的网格划分。汽车和行人的中点，几乎重叠，都落在一个格子中。<ul>\n<li>此前每个格子的输出定义为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>，无法描述该情况，只能舍去一个物体，只描述一个物体。</li>\n</ul>\n</li>\n<li>预先定义两个不同形状的anchor box：Anchor box1和Anchor box2。<ul>\n<li>通常使用更多的anchor box，如5个或更多。这里为了方便讲解，只定义两个。</li>\n</ul>\n</li>\n<li>则上图对应的输出标签应为<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]</script>。其中，前8个分量为与Anchor box1相关的输出，后8个分量为与Anchor box2相关的输出。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes2.JPG\" width=\"80%\" height=\"80%\"> Anchor box算法：</p>\n<ul>\n<li>在之前(不采用Anchor box时)：我们将每个训练图像中的物体分配给其中点所处的那个网格。输出$y$的维度为$3\\times 3\\times 8$。</li>\n<li>采用两个Anchor box后：我们将将每个训练图像中的物体分配给其中点所处的那个网格，以及分配给与该物体包围框的IoU最大的那个Anchor box。输出$y$的维度为$3\\times 3\\times 16$，即$3\\times 3\\times (8\\times 2)$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/anchorboxes3.JPG\" width=\"90%\" height=\"90%\"> 示例：</p>\n<ul>\n<li>图中一个格子中包含两个物体，其中行人的包围框应该分配给Anchor box1，车辆包围框应该分配给Anchor box2，因此，该图像的输出应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。</li>\n<li>若某格子，只含一个车辆物体，则其输出应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。</li>\n<li>当遇到一个格子包含三个或更多物体时，该算法无法处理。当遇到两个物体被分配给同一Anchor box时，该算法也无法处理。</li>\n<li>另外，人们通常人工指定Anchor box的形状，可以选择5~10个形状，覆盖你想要检测的对象的各种形状。后期的YOLO论文中介绍了通过$k$均值来自动选择Anchor box的高级方法。</li>\n</ul>\n<h3 id=\"YOLO算法\"><a href=\"#YOLO算法\" class=\"headerlink\" title=\"YOLO算法\"></a>YOLO算法</h3><p>将所有学过的组件组合在一起，构成YOLO目标检测算法。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%951.JPG\" width=\"100%\" height=\"100%\"> 训练阶段：</p>\n<ul>\n<li>假设检测三类物体：行人，车辆和摩托车。采用的是$3 \\times 3$的网格划分。采用两个anchor box。</li>\n<li>对于训练集$(x,y)$：<ul>\n<li>$x$为输入图像，维度为$100 \\times 100 \\times 3$</li>\n<li>标签$y$的维度为$3 \\times 3 \\times 16$，即$3 \\times 3 \\times (2\\times 8)$。每个$1 \\times 1 \\times 16$对应一个网格的目标标签，共9个网格。</li>\n<li>例如对于不含物体的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\end{matrix} \\right ]</script>。对于含有车辆（分配给Anchor box2）的网格，其标签$y$（$1 \\times 1 \\times 16$）应该为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ ? \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script></li>\n</ul>\n</li>\n<li>构建CNN，通过选择卷积层及池化层的参数，使得输入$x$后，输出的尺寸为$3 \\times 3 \\times 16$。同样本标签$y$的维度相等，因此可以用反向传播算法有监督的对网络进行训练。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%952.JPG\" width=\"100%\" height=\"100%\"> 预测阶段：</p>\n<ul>\n<li>将图片$x$输入网络，输出维度为$3 \\times 3 \\times 16$。其中，对于不包含物体的网格，其输出向量应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\end{matrix} \\right ]</script>。对于包含车辆的网格，其输出向量应为：<script type=\"math/tex\">y=\\left [ \\begin{matrix} Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\\\ Pc \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ c1 \\\\ c2 \\\\ c3 \\end{matrix} \\right ]= \\left [ \\begin{matrix} 0 \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ .. \\\\ 1 \\\\ bx \\\\ by \\\\ bh \\\\ bw \\\\ 0 \\\\ 1 \\\\ 0 \\end{matrix} \\right ]</script>。”..”代表网络输出的一些无意义的数字（网络不会输出问号）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/yolo%E7%AE%97%E6%B3%95%E6%B3%953.JPG\" width=\"100%\" height=\"100%\"> 进行极大值抑制：</p>\n<ul>\n<li>对每一类，分别独立的进行一次非极大值抑制。即分别对行人，车辆及摩托车分别进行一次极大值抑制。</li>\n<li>最后的结果，作为算法的输出结果。</li>\n</ul>\n<h3 id=\"区域建议\"><a href=\"#区域建议\" class=\"headerlink\" title=\"区域建议\"></a>区域建议</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE1.JPG\" width=\"100%\" height=\"100%\"> R-CNN：</p>\n<ul>\n<li>基于滑动窗口的目标检测算法(无论是原始的，还是卷积实现)，对于整张图片中的每一个滑动窗口，都会通过CNN去检测。对于其中很多的明显没有任务物体的窗口，通过CNN去处理它们是浪费时间的。</li>\n<li>R-CNN(基于区域的CNN)的做法是尝试选出一些区域，然后通过CNN进行检测。<ul>\n<li>R-CNN给出区域建议(region proposals)的做法是运行图像分割算法(结果如图)，其中一些色块(如2000个)的矩形包围边框，即是给出的区域建议。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%8C%BA%E5%9F%9F%E5%BB%BA%E8%AE%AE2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>R-CNN：给出建议区域(通过图像分割算法)；每次对一个区域进行分类；输出类别标签+包围边框。<ul>\n<li>R-CNN并不是以色块的包围边框为最后的预测包围边框，而是会输出包围边框($b_x,b_y,b_h,b_w$)，因此可以得到精确的包围边框。</li>\n<li>缺点：太慢。</li>\n</ul>\n</li>\n<li>Fast R-CNN：给出建议区域；通过滑动窗口的卷积实现去分类所有的建议区域（R-CNN一次只对一个建议区域做分类）。<ul>\n<li>缺点：给出建议区域的步骤仍然过慢。</li>\n</ul>\n</li>\n<li>Faster R-CNN：用CNN进行区域建议(RPN网络)。<ul>\n<li>缺点：比Fast R-CNN快，但仍比YOLO慢很多，达不到实时。</li>\n</ul>\n</li>\n</ul>\n<p>吴恩达的观点：</p>\n<ul>\n<li>区域建议(region proposals)的思想，在计算机视觉领域有着相当大的影响，值得去了解这些算法。</li>\n<li>但这类方法需要分成两个步骤：先是得到建议区域，然后再进行分类。相比较之下，从长远的角度看，一步到位的YOLO这类算法，才是有发展前景的方向。</li>\n</ul>\n<h1 id=\"4-特殊应用：人脸识别和风格迁移\"><a href=\"#4-特殊应用：人脸识别和风格迁移\" class=\"headerlink\" title=\"4.特殊应用：人脸识别和风格迁移\"></a>4.特殊应用：人脸识别和风格迁移</h1><h2 id=\"4-1-人脸识别\"><a href=\"#4-1-人脸识别\" class=\"headerlink\" title=\"4.1 人脸识别\"></a>4.1 人脸识别</h2><h3 id=\"什么是人脸识别\"><a href=\"#什么是人脸识别\" class=\"headerlink\" title=\"什么是人脸识别\"></a>什么是人脸识别</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB.JPG\" width=\"80%\" height=\"80%\"> 人脸验证和人脸识别的区别：</p>\n<ul>\n<li>人脸验证(face verification)：<ul>\n<li>输入：一张人脸图片以及姓名/ID</li>\n<li>输出：图片中是否为声称的那个人</li>\n</ul>\n</li>\n<li>人脸识别(face recognition)：<ul>\n<li>有$K$个人的数据集</li>\n<li>输入：人脸图片</li>\n<li>输出：如果输入图片中是$K$个人中的一个，则输出姓名/ID</li>\n</ul>\n</li>\n<li>人脸验证是一对一问题，人脸识别是1对多问题，人脸识别比人脸验证更难。假设人脸验证系统的错误率是1%，那么在人脸识别中，则相应的错误率就会增加，约$K$%。因此要构建人脸识别，需要使得人脸验证模块达到很高的准确率如(99%)，才能将人脸验证模块用于人脸识别系统中，使得人脸识别系统有高准确率。</li>\n</ul>\n<h3 id=\"One-shot-learning\"><a href=\"#One-shot-learning\" class=\"headerlink\" title=\"One-shot learning\"></a>One-shot learning</h3><p>对于人类识别任务，挑战之一是要解决One-shot learning问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>One-shot learning：仅从一个样本中学习，然后再次识别出这个人。</li>\n<li>如图，左侧为拥有的数据库，有四个员工的各一个样本。</li>\n<li>对于该人脸识别任务，不好的解决方法：将四个样本，通过CNN进行训练，输出层为softmax层。<ul>\n<li>缺点一：如此小的训练集，不足以训练一个鲁棒的CNN。</li>\n<li>缺点二：若有新员工加入，需要修改CNN的softmax层，且需要重新训练。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/one-shot%20learning2.JPG\" width=\"80%\" height=\"80%\"> 对于该人脸识别任务，正确的解决方法：</p>\n<ul>\n<li>首先， 通过训练神经网络，去学习一个相似度函数(similarity function)：<ul>\n<li>$d(img1,img2)=degree\\ of\\ difference\\ between\\ images$</li>\n<li>$d(img1,img2)≤\\tau$: 则判断为同一个人</li>\n<li>$d(img1,img2)&gt;\\tau$: 则判断为不是同一个人</li>\n<li>这样，通过相似度函数，解决了<strong>人脸验证(face verification)</strong>问题。</li>\n</ul>\n</li>\n<li>然后用于人脸识别任务中，将测试图像与数据库中的每一图像进行相似度计算，找出匹配的那个人。</li>\n<li>若有新员工加入，只需将他的人脸图像加入数据库，系统依然能照常工作。</li>\n</ul>\n<h3 id=\"Siamese-network\"><a href=\"#Siamese-network\" class=\"headerlink\" title=\"Siamese network\"></a>Siamese network</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C1.JPG\" width=\"80%\" height=\"80%\"> 通过Siamese network来学习相似度函数$d(img1,img2)$：</p>\n<ul>\n<li>如图，输入为图像$x^{(1)}$。</li>\n<li>通过典型的CNN结构(卷积层-&gt;池化层-&gt;全连接层)，最终得到全连接层输出的特征向量，其维度为$(128,1)$。</li>\n<li>该全连接层输出的特征向量可以看成是对图片$x^{(1)}$的编码(encoding)，记为$f(x^{(1)})$。</li>\n<li>要比较两张图片$x^{(1)}$和$x^{(2)}$的相似度：<ul>\n<li>将$x^{(2)}$喂给上述网络，得到图片$x^{(2)}$的编码(encoding)，即$f(x^{(2)})$</li>\n<li>计算相似度函数$d(x^{(1)},x^{(2)})$，$d(x^{(1)},x^{(2)})$的定义为$f(x^{(1)})$与$f(x^{(2)})$之差的L2范数，即$d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||_2^2$</li>\n</ul>\n</li>\n<li>该网络源自论文DeepFace。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/Siamese%E7%BD%91%E7%BB%9C2.JPG\" width=\"80%\" height=\"80%\"> Siamese network学习的目标：</p>\n<ul>\n<li>Siamese network的参数决定了$f(x^{(i)})$</li>\n<li>因此相通过学习Siamese network的参数，达到如下目的：<ul>\n<li>若$x^{(i)}$，$x^{(j)}$是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较小</li>\n<li>若$x^{(i)}$，$x^{(j)}$不是同一个人，则$||f(x^{(1)})-f(x^{(2)})||^2$较大</li>\n</ul>\n</li>\n<li>对于如何定义代价函数，下节介绍triplet损失函数。</li>\n</ul>\n<h3 id=\"Triplet-loss-function\"><a href=\"#Triplet-loss-function\" class=\"headerlink\" title=\"Triplet loss function\"></a>Triplet loss function</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss1.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>Triplet Loss需要每个样本包含三张图片：Anchor、Positive、Negative，这就是triplet名称的由来。</li>\n<li>将三张图片(Anchor,Positive,Negative)的编码简写为$f(A),f(P),f(N)$，由上一节内容可知，我们希望$f(A)$和$f(P)$的距离较小，即$||f(A)-f(P)||^2$较小，而$f(A)$和$f(N)$的距离较大，即$||f(A)-f(N)||^2$较大：<ul>\n<li>$||f(A)-f(P)||^2\\leq ||f(A)-F(N)||^2$</li>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq 0$</li>\n</ul>\n</li>\n<li>对于上面的不等式，若$f(x^{(i)})$恒为0，会使得$f(A)=0$,$f(P)=0$,$f(N)=0$，那么上述不等式也满足。因此，对上述不等式做出如下修改，通过添加一个超参数 $\\alpha(\\alpha&gt;0)$，以避免$f(x^{(i)})$恒为0的情况：<ul>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2\\leq -\\alpha$</li>\n<li>$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha \\leq 0$</li>\n<li>其中，$\\alpha$也被称为间隔(margin)，类似支持向量机中的间隔(margin)。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss2.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>定义triplet loss function：给定3张图片(Anchor、Positive、Negative)，$L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha,\\ 0)$<ul>\n<li>解释：若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha\\leq 0$，则$L(A,P,N)=0$，没有惩罚。</li>\n<li>若$||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha &gt;  0$，则$L(A,P,N)=||f(A)-f(P)||^2-||f(A)-F(N)||^2+\\alpha$，较大惩罚。</li>\n</ul>\n</li>\n<li>cost function：$J=\\sum_{i=1}^mL(A^{(i)},P^{(i)},N^{(i)})$</li>\n<li>假如训练集为1k个人的10k张图片，组成不同的三元组(Anchor、Positive、Negative)，然后进行训练网络，使用梯度下降法，最小化代价函数$J$。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss3.JPG\" width=\"80%\" height=\"80%\"> 训练样本中三元组(Anchor、Positive、Negative)选择：</p>\n<ul>\n<li>若三元组(Anchor、Positive、Negative)是随意选择的，意为只要求Anchor和Positive是一个人，Negative是另一个人。那么，$d(A,P)+\\alpha\\leq d(A,N)$这个条件很容易满足。在训练网络的过程中，学习不到有用的东西。</li>\n<li>应该选择较难的三元组(Anchor、Positive、Negative)，来用于网络的训练。<ul>\n<li>想要满足$d(A,P)+\\alpha\\leq d(A,N)$，则较难的三元组(Anchor、Positive、Negative)，意味着$d(A,P)\\approx d(A,N)$。这样算法会尽力使得$d(A,N)$变大，使得$d(A,P)$变小。在训练网络的过程中，才能学习到有用的东西。</li>\n</ul>\n</li>\n<li>更多细节在论文FaceNet中。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/tripletloss4.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>一些(Anchor、Positive、Negative)的例子。</li>\n</ul>\n<p>最后，现在许多商业公司构建的大型人脸识别模型都需要百万级别甚至上亿的训练样本。如此之大的训练样本我们一般很难获取。但是一些公司将他们训练的人脸识别模型发布在了网上，我们可以下载这些预训练的模型进行使用，而不是一切从头开始。</p>\n<h3 id=\"人脸验证和二元分类\"><a href=\"#人脸验证和二元分类\" class=\"headerlink\" title=\"人脸验证和二元分类\"></a>人脸验证和二元分类</h3><p>Triplet loss 是学习人脸识别CNN的参数的好方法，还有其他的参数学习方法，即将人脸识别问题看成二元分类问题。<br><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB1.JPG\" width=\"80%\" height=\"80%\">  </p>\n<ul>\n<li>如图，选取Siamese network，将两个全连接层的输出给一个逻辑回归单元，然后进行预测。</li>\n<li>若是同一个人，则输出1；若是不同的人，则输出0。这样就将人脸识别问题看成二元分类问题。</li>\n<li>对于最后的逻辑单元，输出$\\hat y$表达式为：<ul>\n<li>$\\hat y=\\sigma(\\sum_{k=1}^Kw_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)$</li>\n<li>$\\hat y=\\sigma(\\sum_{k=1}^Kw_k\\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)$，上式被称为$\\chi$ 方公式，也叫$\\chi$方相似度。</li>\n<li>具体见DeepFace论文。</li>\n</ul>\n</li>\n<li>该节可再回顾下视频。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BA%BA%E8%84%B8%E9%AA%8C%E8%AF%81%E5%92%8C%E4%BA%8C%E5%85%83%E5%88%86%E7%B1%BB2.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>如图，对于此方法，$x$为一对人脸图片，输出标签为1或0。然后去训练Siamese network。</li>\n</ul>\n<h2 id=\"4-2-风格迁移\"><a href=\"#4-2-风格迁移\" class=\"headerlink\" title=\"4.2 风格迁移\"></a>4.2 风格迁移</h2><h3 id=\"什么是风格迁移\"><a href=\"#什么是风格迁移\" class=\"headerlink\" title=\"什么是风格迁移\"></a>什么是风格迁移</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%80%E4%B9%88%E6%98%AF%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB.JPG\" width=\"80%\" height=\"80%\"> </p>\n<ul>\n<li>如图，列出几个神经风格迁移的例子。神经风格迁移是CNN模型一个非常有趣的应用，它可以实现将一张图片的风格“迁移”到另外一张图片中，生成具有其特色的图片。</li>\n<li>一般用C表示内容(Content)图片，S表示风格(Style)图片，G表示生成的(Generated)图片。</li>\n</ul>\n<h3 id=\"深度卷积神经网络学习到的是什么？\"><a href=\"#深度卷积神经网络学习到的是什么？\" class=\"headerlink\" title=\"深度卷积神经网络学习到的是什么？\"></a>深度卷积神经网络学习到的是什么？</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%881.JPG\" width=\"80%\" height=\"80%\"> 可视化深度卷积神经网络的每一层学习到了什么：</p>\n<ul>\n<li>可视化方法：选择第一个隐藏层的一个神经元，找出使得该神经元激活值最大化的9个图像块。</li>\n<li>如图右侧，每一个$3\\times 3$的小区域，即为使得一个神经元激活值最大的9个图像块。</li>\n<li>源自论文Visualizing and understand convolutional networks。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%882.JPG\" width=\"80%\" height=\"80%\"><br>可视化的结果可以理解为：</p>\n<ul>\n<li>第一层的隐藏神经元通常会寻找相对简单的特征，比如边缘(edge)、颜色阴影(shade of color)。</li>\n<li>第二层的隐藏神经元检测到的是纹理(texture)。越深层的神经元检测到越复杂的物体。</li>\n<li>浅层网络的感受野(receptive field)较小，深层网络的感受野较大（网络越深，感受野越大）。</li>\n</ul>\n<h3 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于内容图片C，风格图片S，生成图片G：为了实现风格迁移，定义一个关于$G$的代价函数$J(G)$，用来评价生成图像的好坏。</li>\n<li>用梯度下降法最小化$J(G)$，可以生成想要的任何图片。</li>\n<li>定义生成图片G的代价函数：<script type=\"math/tex\">J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)</script><ul>\n<li>其中，$J_{content}(C,G)$为内容代价函数，它用来衡量C的内容与G的内容有多相似。</li>\n<li>$J_{style}(S,G)$是风格代价函数，它用来衡量S的内容与G的内容有多相似。</li>\n<li><script type=\"math/tex\">\\alpha</script>,<script type=\"math/tex\">\\beta</script>是超参数，用来调整<script type=\"math/tex\">J_{content}(C,G)</script>与<script type=\"math/tex\">J_{style}(S,G)</script>的权重。</li>\n<li>用<script type=\"math/tex\">\\alpha</script>,<script type=\"math/tex\">\\beta</script>这两个超参数来控制权重，似乎有些冗余。但原论文中就是这样，故保持一致。</li>\n</ul>\n</li>\n<li>源自论文A neual algorithm of artistic style。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"> 在定义了$J(G)$后，为了生成新的图像：</p>\n<ul>\n<li>随机初始化生成图像$G$，比如G的尺寸为$100\\times 10 \\times 3$</li>\n<li>用梯度下降法去最小化$J(G)$<ul>\n<li>$G=G-\\frac{\\partial}{\\partial G}J(G)$</li>\n<li>不断更新G的像素值，使得$J(G)$不断减小，从而使G逐渐有C的内容和G的风格。</li>\n</ul>\n</li>\n<li>如图右侧从随机初始化生成图像$G$，到不断更新G后G的结果。</li>\n</ul>\n<h3 id=\"内容代价函数\"><a href=\"#内容代价函数\" class=\"headerlink\" title=\"内容代价函数\"></a>内容代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E5%86%85%E5%AE%B9%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.JPG\" width=\"80%\" height=\"80%\"><br>对于$J(G)$的第一部分$J_{content}(C,G)$，它表示内容图片C与生成图片G之间的相似度。</p>\n<ul>\n<li>使用一个预训练好的CNN模型，例如VGG网络。C，S，G共用相同模型和参数。</li>\n<li>首先，需要选择合适的层数$l$来计算$J_{content}(C,G)$。根据上一小节的内容，CNN的每个隐藏层分别提取原始图片的不同深度特征，由简单到复杂。如果$l$太小，则G与C在像素上会非常接近，没有迁移效果；如果$l$太深，则G上某个区域将直接会出现C中的物体。因此，$l$既不能太浅也不能太深，一般选择网络中间层。</li>\n<li>然后计算C和G在$l$层的激活函数输出<script type=\"math/tex\">a^{[l](C)}</script>与<script type=\"math/tex\">a^{[l](G)}</script>。</li>\n<li>$J_{content}(C,G)$的定义为：<ul>\n<li><script type=\"math/tex; mode=display\">J_{content}(C,G)=\\frac12||a^{[l](C)}-a^{[l](G)}||^2</script></li>\n</ul>\n</li>\n<li>使用梯度下降算法，使$J_{content}(C,G)$不断减小。即可使得<script type=\"math/tex\">a^{[l](C)}</script>与<script type=\"math/tex\">a^{[l](G)}</script>越相似，即C和G越相似。</li>\n</ul>\n<h3 id=\"风格代价函数\"><a href=\"#风格代价函数\" class=\"headerlink\" title=\"风格代价函数\"></a>风格代价函数</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B01.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>什么是图片的风格？利用CNN网络模型，图片的风格可以定义成第$l$层隐藏层不同通道间激活函数的乘积（相关性）。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B02.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>例如我们选取第$l$层隐藏层，其各通道使用不同颜色标注，如下图所示。因为每个通道提取图片的特征不同，比如1通道（红色）提取的是图片的垂直纹理特征，2通道（黄色）提取的是图片的橙色背景特征。那么计算这两个通道的相关性大小，相关性越大，表示原始图片及既包含了垂直纹理也包含了该橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。也就是说，计算不同通道的相关性，反映了原始图片特征间的相互关系，从某种程度上刻画了图片的“风格”。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B03.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>接下来我们就可以定义图片的风格矩阵（style matrix）为：<ul>\n<li><script type=\"math/tex; mode=display\">G_{kk'}^{[l]}=\\sum_{i=1}^{n_H^{[l]}}\\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}</script></li>\n<li>其中，$[l]$表示第$l$层隐藏层，$k$，$k’$分别表示不同通道，总共通道数为<script type=\"math/tex\">n_C^{[l]}</script>。$i$，$j$分别表示该隐藏层的高度和宽度。风格矩阵<script type=\"math/tex\">G_{kk'}^{[l]}</script>计算第$l$层隐藏层不同通道对应的所有激活函数输出和。<script type=\"math/tex\">G_{kk'}^{[l]}</script>的维度为 <script type=\"math/tex\">n_c^{[l]}\\times n_c^{[l]}</script>。若两个通道之间相似性高，则对应的<script type=\"math/tex\">G_{kk'}^{[l]}</script>较大；若两个通道之间相似性低，则对应的<script type=\"math/tex\">G_{kk'}^{[l]}</script>较小。</li>\n</ul>\n</li>\n<li>风格矩阵<script type=\"math/tex\">G_{kk'}^{[l](S)}</script>表征了风格图片S第$l$层隐藏层的“风格”。相应地，生成图片G也有<script type=\"math/tex\">G_{kk'}^{[l](G)}</script>。那么，<script type=\"math/tex\">G_{kk'}^{[l][S]}</script>与<script type=\"math/tex\">G_{kk'}^{[l][G]}</script>越相近，则表示G的风格越接近S。</li>\n<li>这样，我们就可以定义出<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>的表达式：<ul>\n<li><script type=\"math/tex; mode=display\">J^{[l]}_{style}(S,G)=\\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})}\\sum_{k=1}^{n_H^{[l]}}\\sum_{k'=1}^{n_W^{[l]}}||G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]}||^2</script></li>\n</ul>\n</li>\n<li>定义完<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>之后，我们的目标就是使用梯度下降算法，不断迭代修正G的像素值，使<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>不断减小。</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E9%A3%8E%E6%A0%BC%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B04.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>以上我们只比较计算了一层隐藏层$l$。为了提取的“风格”更多，也可以使用多层隐藏层，然后相加，表达式为：<ul>\n<li><script type=\"math/tex; mode=display\">J_{style}(S,G)=\\sum_l\\lambda^{[l]}\\cdot J^{[l]}_{style}(S,G)</script></li>\n<li>其中，<script type=\"math/tex\">\\lambda^{[l]}</script>表示累加过程中各层<script type=\"math/tex\">J^{[l]}_{style}(S,G)</script>的权重系数，为超参数。</li>\n</ul>\n</li>\n<li>根据以上两小节的推导，最终的代价函数为：<ul>\n<li><script type=\"math/tex; mode=display\">J(G)=\\alpha \\cdot J_{content}(C,G)+\\beta \\cdot J_{style}(S,G)</script></li>\n<li>使用梯度下降算法进行迭代优化即可。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"从1维卷积到3维卷积\"><a href=\"#从1维卷积到3维卷积\" class=\"headerlink\" title=\"从1维卷积到3维卷积\"></a>从1维卷积到3维卷积</h3><p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF1.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>之前介绍的CNN网络处理的都是2D图片，2D卷积的规则：<ul>\n<li>输入图片维度：14 x 14 x 3</li>\n<li>滤波器尺寸：5 x 5 x 3，滤波器个数：16</li>\n<li>输出图片维度：10 x 10 x 16</li>\n</ul>\n</li>\n<li>将2D卷积推广到1D卷积，1D卷积的规则：<ul>\n<li>输入时间序列维度：14 x 1</li>\n<li>滤波器尺寸：5 x 1，滤波器个数：16</li>\n<li>输出时间序列维度：10 x 16</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"http://ozruihqgo.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%BE%E7%A8%8B4/%E4%BB%8E1%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%88%B03%E7%BB%B4%E5%8D%B7%E7%A7%AF2.JPG\" width=\"80%\" height=\"80%\"></p>\n<ul>\n<li>对于3D卷积，其规则：<ul>\n<li>输入3D图片维度：14 x 14 x 14 x 1</li>\n<li>滤波器尺寸：5 x 5 x 5 x 1，滤波器个数：16</li>\n<li>输出3D图片维度：10 x 10 x 10 x 16</li>\n</ul>\n</li>\n</ul>"},{"title":"剑指Offer解题记录","date":"2017-12-01T01:19:49.000Z","mathjax":true,"top":true,"_content":"注：该记录中解题答案均为在牛客网进行[在线编程测试](https://www.nowcoder.net/ta/coding-interviews)时的答案记录，故未自己写测试代码。\n\n# 一、链表\n## 1. 两个链表的第一个公共结点\n**题目描述**：\n输入两个链表，找出它们的第一个公共结点。\n**思路**：\n- **关键点**：如果两个单链表有公共的结点，那么这两个链表从某一结点开始，它们的`next`指针都指向同一个结点，又由于是单向链表的结点，每个结点只有一个`next`指针，因此**从第一个公共结点开始，之后它们所有的结点都是重合的，不再出现分叉**。\n- **思路1**：\n - 对于对于链表一上的每一个结点，顺序遍历链表二上的每一个结点。\n - 若第一个链表的长度为$m$，第二个链表的长度为$n$，那么时间复杂度为$O(mn)$。\n- **思路2**：\n - 分别把两个链表的结点放入栈里，这样两个链表的尾结点就位于两个栈的栈顶，接下来比较两个栈顶的结点是否相同。如果相同，则把栈顶弹出接着比较下一个栈顶，直到找到最后一个相同的结点。\n - 该思路需要用到两个辅助栈，如果链表的长度分别为$m$和$n$，那么空间复杂度是$O(m+n)$，时间复杂度是$O(m+n)$。和思路1相比，时间效率得到了提高，相当于用空间消耗换取了时间效率。\n- **思路3**：\n - 首先遍历两个链表得到它们的长度。在第二次遍历时，在较长的链表上先走若干步，接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点。\n - 与思路2相比，该思路的时间复杂度为$O(m+n)$，但不需辅助栈，因此提高了空间效率。\n\n <!-- more --> \n\n**代码**：\n```C++\n//思路3\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x):val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) \n    {\n    \tif(pHead1==nullptr || pHead2==nullptr)\n            return nullptr;\n        //首先遍历两个链表得到它们的长度\n        int length1,length2;\n        length1=length2= 0;\n        ListNode* pTemp1 = pHead1;\n        ListNode* pTemp2 = pHead2;\n        while(pTemp1!=nullptr)\n        {\n            length1++;\n            pTemp1 = pTemp1->next;\n        }\n        while(pTemp2!=nullptr)\n        {\n            length2++;\n            pTemp2 = pTemp2->next;\n        }\n        //在第二次遍历时，在较长的链表上先走若干步\n        pTemp1 = pHead1;\n        pTemp2 = pHead2;\n        if(length1>length2)\n        {\n            int dif = length1-length2;\n            for(int i = 0;i<dif;i++)\n            {\n                pTemp1 = pTemp1->next;\n            }\n        }\n        else\n        {\n            int dif = length2-length1;\n            for(int i = 0;i<dif;i++)\n            {\n                pTemp2 = pTemp2->next;\n            }\n        }\n        //接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点\n        ListNode* pResult = nullptr;\n        while(pTemp1!=nullptr && pTemp2!=nullptr)\n        {\n        \tif(pTemp1 == pTemp2)\n            {\n            \tpResult = pTemp1;\n                break;\n            }\n            else\n            {\n                pTemp1 = pTemp1->next;\n                pTemp2 = pTemp2->next;\n            }\n        }\n        return pResult;\n    }\n};\n```\n## 2. 链表中环的入口结点\n**题目描述**：\n一个链表中包含环，请找出该链表的环的入口结点。\n**思路**：\n- **核心思想**：假定有环且已知环的结点个数为$y$，令指针`pTemp1`从首结点开始先走$y$步，再令`pTemp2`从首结点开始同`pTemp1`一起向前走，相遇处，即为环的入口结点。\n- **证明**：假定环的结点个数为$y$，环之前的结点个数为$x$。`pTemp1`先走$y$步，然后`pTemp2`从首结点开始同`pTemp1`一起再走$x$步，则`pTemp2`在第$(x+1)$个结点处，`pTemp1`在第$(x+y+1)$个结点处。$(x+1)$结点位置和$(x+y+1)$结点位置都是环的入口结点位置。因此，依上述核心思想的步骤，`pTemp1`与`pTemp2`定会相遇，相遇处恰好为环的入口结点。\n- **环的结点个数求法**：首先，令一指针`pFast`一次走两步，一指针`pSlow`一次走一步，若相遇，则有环，且相遇处定在环内。然后，`pFast`不动，令一指针`pSlow`继续走且计数，当`pSlow`与`pFast`再次相遇，即得出环的结点个数。\n- 注意，代码中充斥着防止指针为空的情况，繁琐但必不可少。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* EntryNodeOfLoop(ListNode* pHead)\n    {\n        if(pHead==nullptr)\n            return nullptr;\n        //通过getNumberOfLoop()获取环的结点个数，0则无环；大于0则有环\n        ListNode* pTemp1, *pTemp2;\n        pTemp1 = pTemp2 = pHead;\n        int num = getNumberOfLoop(pHead);\n        //若环结点数等于0，直接返回nullptr\n        if(num==0) \n            return nullptr;\n        //依照核心思想执行，获取pTemp1与pTemp2相遇处指针\n        for(int i = 0;i<num;i++)\n        {\n            pTemp1 = pTemp1->next;\n        }\n        while(pTemp1!=pTemp2)\n        {\n            pTemp1 = pTemp1->next;\n            pTemp2 = pTemp2->next;\n        }\n        return pTemp1;\n    }\n    int getNumberOfLoop(ListNode* pHead)\n    {\n        //1.令pFast一次走两步，pSlow一次走一步，若相遇，则有环，且相遇处定在环内\n        int num = 0;\n        ListNode* pFast, *pSlow;\n        pFast = pSlow = pHead;\n        pFast=pFast->next;    //为了下个while循环的判断条件，pFast先走一步\n        while(pFast!=pSlow)\n        {\n            if(pFast==nullptr)\n                break;\n            pFast = pFast->next;\n            if(pFast==nullptr)\n                break;\n            pFast = pFast->next;\n            if(pSlow==nullptr)\n                break;\n            pSlow=pSlow->next;\n        }\n        if(pFast==nullptr || pSlow==nullptr)\n            num=0;\n        //2.pFast不动，令pSlow继续走且计数，当pSlow与pFast再次相遇，即得出环的结点个数\n        else\n        {\n            pSlow=pSlow->next; //为了下个while循环的判断条件，pSlow先走一步\n            num++;\n            while(pSlow!=pFast)\n            {\n                pSlow=pSlow->next;\n                num++;\n            }\n        }\n        return num;\n    }\n};\n```\n\n## 3. 反转链表\n**题目描述**：\n给出一个链表`1->2->3->nullptr`，这个翻转后的链表为`3->2->1->nullptr`\n**思路**：\n- **方法1**：迭代实现。维护三个指针`pPrev`,`pCurrent`,`pNext`，通过迭代完成链表的反转（画图使思路清晰）：\n - 起始情况：`pPrev`为`nullptr`，`pCurrent`指向`pHead`\n - 终止情况：`pPrev`指向链表尾元素，`pCurrent`为`nullptr`\n- **方法2**：递归实现。利用递归走到链表的末端，然后再更新每一个结点的`next`指针 ，实现链表的反转。\n- **方法3**：用栈实现。将链表结点指针全部压入栈中。头指针指向链表末尾结点。将栈中结点指针反串起来，栈中最后结点指针指向`nullptr`。\n\n**代码**：\n```C++\n//方法1：迭代实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* ReverseList(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return nullptr;\n        ListNode* pPre, *pCurrent, *pNext;\n        pPre=nullptr;\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        {\n            pNext = pCurrent->next;\n            pCurrent->next = pPre;\n            pPre = pCurrent;\n            pCurrent = pNext;\n        }\n        pHead=pPre;\n        return pHead;\n    }\n};\n```\n```C++\n//方法2：递归实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* ReverseList(ListNode* pHead) \n    {\n        //如果链表为空或者链表中只有一个元素\n        if(pHead==NULL || pHead->next==NULL) \n            return pHead;\n        //先反转后面的链表，走到链表的末端结点，返回末端结点，作为新的头结点，保存起来\n        ListNode* pHeadReverse=ReverseList(pHead->next);\n        //再将当前节点设置为后面节点的后续节点\n        pHead->next->next = pHead;\n        //当前节点指向NULL\n        pHead->next=NULL;\n        //返回新的头结点\n        return pHeadReverse;\n    }\n};\n```\n```C++\n//方法3：用栈实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode * reverse(ListNode * head) \n    {\n        // write your code here\n        //防御性编程\n        if(head==NULL) return NULL;\n        //1.将链表结点指针全部压入栈中\n        stack<ListNode*> stack1;\n        ListNode* temp = head;\n        while(temp!=NULL) \n        {\n            stack1.push(temp);\n            temp=temp->next;\n        }\n        //2.头指针指向链表末尾结点\n        temp = stack1.top();\n        head=temp;\n        //3.将栈中结点指针反串起来，栈中最后结点指针指向NULL\n        while(!stack1.empty())\n        {\n            ListNode* pNode1 = stack1.top();\n            stack1.pop();\n            if(stack1.empty())\n            {\n                pNode1->next=NULL;\n                break;\n            }\n            ListNode* pNode2 = stack1.top();\n            pNode1->next = pNode2;\n        }\n        return head;\n    }\n};\n\n```\n## 4. 合并两个排序的链表\n**题目**：输入两个递增排序的链表，合并这两个链表并使新链表中的结点仍然是按照递增排序的。\n**思路**：\n- 依照归并排序中的`merge`函数的思想，`merge`两个链表：\n - 1.比较两个链表的头结点，较小的作为新链表的头结点`pHeadNew`；\n - 2.归并两个链表，迭代比较，较小者作为新的尾结点`pTailNew`。\n - 注意，直接改动每一结点的`next`指针，故不需另外的辅助空间。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* Merge(ListNode* pHead1, ListNode* pHead2)\n    {\n        //防御性编程：若输入链表有任一为空，返回另一个\n        if(pHead1==nullptr)\n            return pHead2;\n        if(pHead2==nullptr)\n            return pHead1;\n        //1.找出新链表的头结点pHeadNew\n        ListNode* pHeadNew = nullptr;\n        ListNode* pTemp1 = pHead1;\n        ListNode* pTemp2 = pHead2;\n        if(pTemp1->val < pTemp2->val)\n        {\n            pHeadNew = pTemp1;\n            pTemp1 = pTemp1->next;\n        }\n        else\n        {\n            pHeadNew = pTemp2;\n            pTemp2 = pTemp2->next;\n        }\n        //2.归并两个链表，迭代比较，较小者作为新的尾结点pTailNew\n        //直接改动每一结点的next指针，故不需另外的辅助空间\n        ListNode* pTailNew = pHeadNew; \n        while(pTemp1!=nullptr && pTemp2!=nullptr)\n        {\n            if(pTemp1->val < pTemp2->val)\n            {\n                pTailNew->next = pTemp1;\n                pTailNew = pTemp1;\n                pTemp1 = pTemp1->next;\n            }\n            else\n            {\n                pTailNew->next = pTemp2;\n                pTailNew = pTemp2;\n                pTemp2 = pTemp2->next;\n            }    \n        }\n        if(pTemp1!=nullptr) pTailNew->next = pTemp1;\n        if(pTemp2!=nullptr) pTailNew->next = pTemp2;\n        return pHeadNew;\n    }\n};\n```\n\n## 5. 从尾到头打印链表\n**题目描述**：\n输入一个链表的头结点，从尾到头反过来打印出每个结点的值。\n**思路**：\n- 首先，假定不能改变链表结构，故不采用迭代反转链表，然后后再打印链表的方法。\n- **方法1**：遍历的顺序是从头到尾，输出的顺序是从尾到头，是典型的“后进先出”，用栈实现这种顺序：\n - 遍历链表，每经过一个结点的时候，把该结点压入辅助栈中。\n - 当遍历完整个链表后，再从栈顶开始逐个输出结点的值。\n- **方法2**：用递归方法反向打印链表。既然可以用栈实现，而递归本质上就是一个栈结构，故可用递归来实现：\n - 每访问到一个结点，先递归输出它后面的结点，再输出该结点自身，这样链表的输出结果就反过来了。\n- 注意，虽然基于递归的代码看起来很简洁，但有一个问题：当链表非常长的时候，就会导致函数调用的层级很深，从而有可能导致函数调用栈溢出。显然用栈基于循环实现的代码的鲁棒性要好一些（存放于自由存储的堆区）。\n \n**代码**：\n```C++\n//方法1\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    vector<int> result;    \n    stack<ListNode*> s;\npublic:\n    vector<int> printListFromTailToHead(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return result;\n        //遍历链表，每经过一个结点的时候，把该结点压入辅助栈中\n        ListNode* pTemp = pHead;\n        while(pTemp!=nullptr)\n        {\n            s.push(pTemp);\n            pTemp = pTemp->next;\n        }\n        //当遍历完整个链表后，再从栈顶开始逐个输出结点的值\n        while(!s.empty())\n        {\n            pTemp = s.top();\n            result.push_back(pTemp->val);\n            s.pop();\n        }\n        return result;\n    }\n};\n```\n```C++\n//方法2\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    vector<int> result;    \npublic:\n    vector<int> printListFromTailToHead(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return result;\n        printListFromTailToHead(pHead->next);\n        result.push_back(pHead->val);\n        return result;\n    }\n};\n```\n## 6. 复杂链表的复制\n**题目描述**\n输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）\n**思路**：\n- **步骤1**：复制原始链表的任意结点$N$并创建新结点$N'$，再把$N'$链接到$N$的后面。如原来是`A->B->C`，则变成`A->A'->B->B'->C->C'`。\n- **步骤2**：设置复制出来的结点的`random`指针。如果原始链表上的结点$N$的`random`指针指向$S$，则它对应的复制结点$N'$的`ramdon`指针指向$S$的复制结点$S'$。如`A1->random = A->random->next;`\n- **步骤3**：把长链表拆分成两个链表：把奇数位置的结点用`next`指针链接起来就是原始链表，把偶数位置的结点用`next`指针链接起来就是复制出来的链表。\n\n**代码**：\n```C++\n/*\nstruct RandomListNode \n{\n    int label;\n    struct RandomListNode *next, *random;\n    RandomListNode(int x) :label(x), next(NULL), random(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    RandomListNode* Clone(RandomListNode* pHead)\n    {\n        if(pHead==nullptr)\n            return nullptr;\n        RandomListNode* pCurrent = pHead;\n        //1.复制原始链表的任一节点N并创建新节点N'，再把N'链接到N的后边\n        while(pCurrent!=nullptr)\n        {\n            RandomListNode* pClone = new RandomListNode(pCurrent->label);\n            pClone->next = pCurrent->next;\n            pCurrent->next = pClone;\n            pCurrent = pClone->next;\n        }\n        //2.如果原始链表上的节点N的random指向S，则对应的复制节点N'的random指向S的下一个节点S'\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        {\n            RandomListNode* pClone = pCurrent->next;\n            if(pCurrent->random!=nullptr)\n                pClone->random = pCurrent->random->next;\n            pCurrent = pClone->next;\n        }\n        //3.把得到的链表拆成两个链表，奇数位置上的结点组成原始链表，偶数位置上的结点组成复制出来的链表\n        RandomListNode* pCloneHead=pHead->next;\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        { \n            RandomListNode* pClone = pCurrent->next;\n            pCurrent->next = pClone->next;\n            pCurrent = pCurrent->next;\n            //pCurrent为nullptr，即pClone->next为nullptr，不用再继续，拆分结束。\n            if(pCurrent==nullptr)\n                break;\n            pClone->next = pCurrent->next;\n        }\n        return pCloneHead;\n    }\n};\n```\n\n## 7. 链表中倒数第k个结点\n**题目**：\n输入一个链表，输出该链表中倒数第$k$个结点。本题从1开始计数，即链表的尾结点是倒数第1个结点。例如一个链表有6个结点，从头结点开始它们的值依次是1、2、3、4、5、6。这个链表的倒数第3个结点是值为4的结点。\n**思路**：\n- 递归遍历链表，返回时通过`count`计数，当`count==k`时，当前`pHead`即为倒数第$K$个结点。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x):val(x), next(NULL) {}\n};*/\nclass Solution \n{\n    int count = 0;\n    ListNode* pTarget=nullptr;\npublic:\n    ListNode* FindKthToTail(ListNode* pHead, unsigned int k) \n    {\n        if(pHead==nullptr)\n            return nullptr;\n        Find(pHead,k);\n        return pTarget;\n    }\n    void Find(ListNode* pHead, unsigned int k)\n    {\n        if(pHead==nullptr)\n            return;\n        Find(pHead->next,k);\n        count++;\n        if(count==k)\n            pTarget = pHead;\n    }\n};\n```\n## 8. 删除链表中的重复结点\n**题目**：\n在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表`1->2->3->3->4->4->5`，处理后为`1->2->5`\n**思路**：\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution\n {\npublic:\n    ListNode* deleteDuplication(ListNode* pHead)\n    {\n        // 只有0个或1个结点，则返回\n        if(pHead==nullptr || pHead->next==nullptr) \n            return pHead;\n        ListNode* pNext = pHead->next;\n        // 当前结点是重复结点\n        if(pHead->val == pNext->val)\n        {\n            // 跳过值与当前结点相同的全部结点,找到第一个与当前结点不同的结点\n            while(pNext!=nullptr && pNext->val==pHead->val)\n            {\n                pNext = pNext->next;\n            }\n            // 从第一个与当前结点不同的结点开始递归\n            return deleteDuplication(pNext);\n        }\n         // 当前结点不是重复结点\n        else\n        {\n            // 保留当前结点，从下一个结点开始递归\n            pHead->next = deleteDuplication(pHead->next);\n            return pHead;\n        }\n    }\n};\n```\n-----------\n# 二、栈和队列\n## 1. 用两个栈实现队列\n**题目**：用两个栈来实现一个队列，完成队列的`push`和`pop`操作。队列中的元素为`int`类型。\n**思路**：\n- 栈是后进先出，队列是先进先出。\n- 利用栈`stack1`负责`push`操作。\n- 利用栈`stack2`负责`pop`操作：先将`stack1`中所有元素弹出到`stack2`中，然后`stack2`出栈一个元素，最后`stack2`中所有元素弹出到`stack1`。\n\n**代码**：\n```C++\nclass Solution\n{\nprivate:\n    stack<int> stack1;\n    stack<int> stack2;\npublic:\n    //利用栈stack1负责入栈操作\n    void push(int node) \n    {\n        stack1.push(node);\n    }\n    //利用栈stack2负责出栈操作\n    int pop() \n    {\n        //先将stack1中所有元素弹出到stack2中\n        while(!stack1.empty())\n        {\n            int temp = stack1.top();\n            stack2.push(temp);\n            stack1.pop();\n        }\n        //然后stack2出栈一个元素\n        int result = stack2.top();\n        stack2.pop();\n        //最后stack2中所有元素弹出到stack1\n        while(!stack2.empty())\n        {\n            int temp = stack2.top();\n            stack1.push(temp);\n            stack2.pop();\n        }\n        return result;\n    }\n};\n```\n\n## 2. 包含min函数的栈\n**题目**：定义栈的数据结构，请在该类型中实现一个能够得到栈的最小元素的`min`函数。在该栈中，调用`min`、`push`及`pop`的时间复杂度都是$O(1)$。\n**思路**：\n- 题目要求的是栈在进行任何的入栈和出栈操作后，都能调用`min`函数返回最小值。两种思路不可行：\n - 定义一个变量`value`存储最小值。因为栈一旦`pop`后，不知道最小值是什么。\n - 每次进栈出栈都重新对栈内元素进行排序。因为复杂度太高。\n- 正确解法：采用一个辅助栈，其栈顶保存主栈当前的最小值。主栈每一次`push`，辅助栈都将主栈当前的最小值压入栈顶。主栈每一次`pop`，辅助栈都`pop`。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    stack<int> s1; //主栈\n    stack<int> s2; //辅助栈\npublic:\n    //主栈stack1每一次push，辅助栈stack2都将主栈当前的最小值压入栈顶\n    void push(int value) \n    {\n        if(s1.empty())\n        {\n            s1.push(value);\n            s2.push(value);\n        }\n        else if(value<s2.top())\n        {\n            s1.push(value);\n            s2.push(value);\n        }\n        else\n        {\n            s1.push(value);\n            s2.push(s2.top());\n        }\n    }\n    //主栈stack1每一次pop，辅助栈stack2都pop\n    void pop() \n    {\n        s1.pop();\n        s2.pop();\n    }\n    int top() \n    {\n        return s1.top();\n    }\n    int min() \n    {\n        return s2.top();\n    }\n};\n```\n## 3. 栈的压入、弹出序列\n**题目描述**\n输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列$1,2,3,4,5$是某栈的压入顺序，序列$4,5,3,2,1$是该压栈序列对应的一个弹出序列，但$4,3,5,1,2$就不可能是该压栈序列的弹出序列。\n**思路**：\n- 判断一个序列是不是栈的弹出序列的规律：\n - 如果下一个弹出的数字刚好是栈顶数字，那么直接弹出；\n - 如果下一个弹出的数字不在栈顶，则把压栈序列中还没有入栈的数字压入辅助栈，直到把下一个需要弹出的数字压入栈为止；\n - 如果所有数字都压入栈后仍然没有找到下一个弹出的数字，那么该序列不可能是一个弹出序列。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    stack<int> s;\npublic:\n    bool IsPopOrder(vector<int> pushV,vector<int> popV) \n    {\n        if(pushV.size()==0 || popV.size()==0)\n            return false;\n        int i=0; //标记pushV\n        int j=0; //标记popV\n        while(i<pushV.size())\n        {\n            s.push(pushV[i++]);\n            while(!s.empty() && s.top()==popV[j])\n            {\n                s.pop();\n                j++;\n            }\n        }\n        return s.empty();\n    }\n};\n```\n--------\n# 三、树\n## 1. 二叉树的深度\n**题目描述**:\n输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。\n**思路**：\n**解法1**：\n- 前序遍历二叉树，计算每一叶结点的深度，找出最大的叶结点的深度，即树的高度。\n- 在两种情况下，当前深度变量`currentDepth`进行减一操作：\n - 当前结点是叶结点，则将`currentDepth`与最大的叶结点深度`maxDepth`比较，更新`maxDepth`。之后，`currentDepth`进行减一操作；\n - 任一结点的左右子树遍历完成，`currentDepth`进行减一操作。\n- 注：该题规定空树深度为0，根结点深度为1。\n\n**解法2**：\n- 将结点的深度从该角度计算：后序遍历时，结点的左右子树的深度较大值加一。\n- 因此，树的深度可以这样计算：后序遍历二叉树，较大子树的深度值加一。\n\n**代码**：\n```C++\n//解法1\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    int maxDepth=0;\n    int currentDepth=0;\npublic:\n    int TreeDepth(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return maxDepth;\n        currentDepth++;\n        //当前结点是叶结点\n        if(pRoot->left==nullptr && pRoot->right==nullptr)\n        {\n            //更新maxDepth\n            if(currentDepth>maxDepth)\n            {\n                maxDepth = currentDepth;\n            }\n            //currentDepth进行减一操作\n            currentDepth--;\n            return maxDepth;\n        }\n        TreeDepth(pRoot->left);\n        TreeDepth(pRoot->right);\n        //任一结点的左右子树遍历完成，currentDepth进行减一操作\n        currentDepth--;\n        return maxDepth;\n    }\n};\n```\n```C++\n//解法2\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    //递归后序遍历二叉树\n    int TreeDepth(TreeNode* pRoot)\n    {\n        //递归出口条件：若pRoot为nullptr，则返回0\n        if(pRoot==nullptr)\n            return 0;\n    \tint left=TreeDepth(pRoot->left);\n        int right=TreeDepth(pRoot->right);\n        //较大子树的深度值加一\n        if(left>right)\n            return left+1;\n        else\n            return right+1;\n    }\n};\n```\n## 2. 二叉树的镜像\n**题目描述**:\n操作给定的二叉树，将其变换为源二叉树的镜像。\n**输入描述**:\n二叉树的镜像定义：\n```\n源二叉树 \n    \t    8\n    \t   /  \\\n    \t  6   10\n    \t / \\  / \\\n    \t5  7 9  11\n镜像二叉树\n    \t    8\n    \t   /  \\\n    \t  10   6\n    \t / \\  / \\\n    \t11 9 7   5\n```\n**思路**：\n- 前序遍历二叉树，“访问”操作为：交换每一结点的左右子树（左右子树是`nullptr`也没关系，照样交换）。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    void Mirror(TreeNode *pRoot) \n    {\n        if(pRoot==nullptr)\n            return;\n        //交换左右子树\n        TreeNode* temp = pRoot->left;\n        pRoot->left = pRoot->right;\n        pRoot->right = temp;\n        Mirror(pRoot->left);\n        Mirror(pRoot->right);\n    }\n};\n```\n\n## 3. 平衡二叉树\n**题目描述**\n输入一棵二叉树，判断该二叉树是否是平衡二叉树。注意，空树默认为平衡二叉树。\n**思路**：\n- 依据#1题<二叉树的深度>中解法2的思想，将平衡二叉树的判断准则定为：每一结点的左右子树的深度值相差不超过1。\n- 后序遍历二叉树，计算每一结点的左右子树的深度，比较差值。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    bool result=true;\npublic:\n    bool IsBalanced_Solution(TreeNode* pRoot) \n    {\n        if(pRoot==nullptr)\n            return true;\n        TreeDepth(pRoot);\n        return result;\n    }\n    //后序遍历二叉树，计算树的深度\n    int TreeDepth(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return 0;\n        int left = TreeDepth(pRoot->left);\n        int right = TreeDepth(pRoot->right);\n        //比较左右子树深度的差值\n        if(abs(left-right)>1)\n            result = false;\n        //计算每一结点的左右子树的深度\n        if(left>right)\n            return left+1;\n        else\n            return right+1;\n    }\n};\n```\n\n## 4. 把二叉树打印成多行\n**题目描述**：\n从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。\n**思路**：\n- 层序遍历二叉树，在每一层末尾加入一个换行符。\n- 通过变量`toBePrinted`记录当前层要打印结点个数,`nextLevel`记录下一层要打印结点个数。\n- 对于根结点，`toBePrinted`为1，在将根结点的左右子结点入队时记录`nextLevel`。\n- 当`toBePrinted`为0，则打印一个换行，`toBePrinted`置为`nextLevel`，`nextLevel`清零。接着，开始处理下一层。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    int toBePrinted=1;\n    int nextLevel = 0;\n    queue<TreeNode*> q; \n    vector<int> level;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> Print(TreeNode* pRoot) \n    {\n        if(pRoot==nullptr)\n            return result;\n        q.push(pRoot);\n        while(!q.empty())\n        {\n            TreeNode* pCurrent = q.front();\n            q.pop();\n            toBePrinted--;\n            level.push_back(pCurrent->val);\n            if(pCurrent->left!=nullptr)\n            {\n                q.push(pCurrent->left);\n                nextLevel++;\n            }\n            if(pCurrent->right != nullptr)\n            {\n                q.push(pCurrent->right);\n                nextLevel++;\n            }\n            if(toBePrinted==0)\n            {\n                toBePrinted=nextLevel;\n                nextLevel=0;\n                result.push_back(level);\n                level.clear();\n            }\n        }\n        return result; //注意，最后要return\n    }\n};\n```\n\n## 5. 对称的二叉树\n**题目描述**:\n请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。\n**思路**：\n- 一开始的想法：构建该二叉树的镜像二叉树，然后同时遍历两个树，逐一进行比较。但空间复杂度为$O(n)$，不可行。\n- 正确解法：前序遍历是`<root><left><right>`。定义一种新的和前序遍历对称的遍历方式`<root><right><left>`。对于对称的二叉树，前序遍历的结果，和新定义的遍历方式的结果应该是一样的。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    bool isSymmetrical(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return true;\n        return treversal(pRoot, pRoot);\n    }\n    bool treversal(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr && pRoot2==nullptr)\n            return true;\n        if(pRoot1==nullptr || pRoot2==nullptr)\n            return false;\n        if(pRoot1->val!=pRoot2->val)\n            return false;\n        bool result1=treversal(pRoot1->left, pRoot2->right);\n        bool result2=treversal(pRoot1->right, pRoot2->left);\n        return result1 && result2;\n    }\n};\n```\n\n## 6. 二叉树的下一个结点\n**题目描述**:\n给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，**同时包含指向父结点的指针**。\n**思路**：\n- 在中序遍历顺序`<left，root，right>`下，二叉树某一结点`pNode`的下一个结点规律如下：\n - 如果`pNode`含有右子树，则下一结点为`pNode`的**右子树中最深最左的那个结点**。\n - 如果`pNode`不含右子树，则下一结点为**使得`pNode`在其左子树中的最近的祖先结点**。\n 注：最极端情况是`pNode`是二叉树中序遍历的最后一个结点，即在二叉树的最右末端，直到回溯到根结点，`pNode`还是在右子树中，即没有满足题意的下一结点。根结点的父节点为`nullptr`，祖先结点为`nullptr`也是终止循环条件之一。\n \n**代码**：\n```C++\n/*\nstruct TreeLinkNode \n{\n    int val;\n    struct TreeLinkNode *left;\n    struct TreeLinkNode *right;\n    struct TreeLinkNode *next;\n    TreeLinkNode(int x) :val(x), left(NULL), right(NULL), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    TreeLinkNode* pNext=nullptr; //记录目标结点\npublic:\n    TreeLinkNode* GetNext(TreeLinkNode* pNode)\n    {\n        if(pNode==nullptr)\n            return nullptr;\n        //如果pNode含有右子树，则下一结点为pNode的右子树中最深最左的那个结点\n        if(pNode->right!=nullptr)\n        {\n            pNext=pNode->right;\n            while(pNext->left!=nullptr)\n            {\n                pNext=pNext->left;\n            }\n        }\n        //如果pNode不含右子树，则下一结点为使得pNode在其左子树中的最近的祖先结点\n        else if(pNode->right==nullptr)\n        {\n            TreeLinkNode* pParent = pNode->next;\n            //最极端情况：若到根节点还没找到\n            while(pParent!=nullptr)\n            {\n                if(pParent->left==pNode)\n                {\n                    pNext=pParent;\n                    break;\n                }\n                else\n                {\n                    pNode = pParent;\n                    pParent=pParent->next;\n                }\n            }\n        }\n        return pNext;\n    }\n};\n```\n\n## 7. 二叉搜索树与双向链表\n**题目描述**：\n输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。\n**思路**：\n- 首先，二叉搜索树的中序遍历结果即为有序序列。\n- 然后，在中序遍历的“访问”操作中进行如下操作完成双向链表的转换：\n - 维护双向链表的尾结点`pLastNode`，初始化为`nullptr`。 \n - 当前结点的`left`指针指向`pLastNode`，`pLastNode`的`right`指针指向当前结点，更新`pLastNode`。\n - 最终结果： `nullptr<-1<=>2<=>3<=>4<=>5->nullptr`（自己画图即可知）。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    TreeNode* Convert(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return nullptr;\n        //pLastNode表示双向链表中的最后一个结点\n        TreeNode* pLastNode=nullptr;\n        InorderTraversal(pRoot,&pLastNode);\n        TreeNode* pHead=pLastNode;\n        //找出双向链表中的头结点，并返回\n        while(pHead->left!=nullptr)\n        {\n            pHead=pHead->left;    \n        }\n        return pHead;\n    }\n    //中序遍历二叉搜索树\n    void InorderTraversal(TreeNode* pRoot,TreeNode** pLastNode)\n    {\n        if(pRoot==nullptr)\n            return;\n        InorderTraversal(pRoot->left,pLastNode);\n        //如果pLastNode为nullptr\n        if(*pLastNode==nullptr)\n        {\n            pRoot->left=*pLastNode;     //当前结点的left指针指向链表中最后一个结点\n            *pLastNode=pRoot;           //更新链表中最后一个结点\n        }\n        else\n        {\n            pRoot->left=*pLastNode;     //当前结点的left指针指向链表中最后一个结点\n            (*pLastNode)->right=pRoot;  //链表中最后一个结点的right指针指向当前结点\n            *pLastNode=pRoot;           //更新链表中最后一个结点\n        }\n        InorderTraversal(pRoot->right,pLastNode);\n    }\n};\n```\n\n## 8. 从上往下打印二叉树\n**题目描述**:\n从上往下打印出二叉树的每个节点，同层节点从左至右打印。\n**思路**：\n- 层序遍历二叉树。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    queue<TreeNode*> q;\n    vector<int> v;\npublic:\n    vector<int> PrintFromTopToBottom(TreeNode* root) \n    {\n        if(root == nullptr) \n            return v;\n        q.push(root);\n        while(!q.empty())\n        {\n            TreeNode* pCurrent = q.front();\n            q.pop();\n            v.push_back(pCurrent->val);\n            if(pCurrent->left!=nullptr)\n                q.push(pCurrent->left);\n            if(pCurrent->right!=nullptr)\n                q.push(pCurrent->right);\n        }\n        return v;\n    }\n};\n```\n## 9. 二叉树中和为某一值的路径\n**题目描述**:\n输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。\n**思路**：\n- 前序遍历二叉树，计算每一路径和，与期望值进行比较。\n- 在两种情况下，从当前状态存储变量（`currentSum`及 `path`）中移去当前结点：\n - 当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点(`path.pop_back()`,`currentSum-=root->val`)；\n - 任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点(`path.pop_back()`,`currentSum-=root->val`)。\n \n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    int currentSum=0;\n    vector<int> path;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> FindPath(TreeNode* root,int expectNumber) \n    {\n        if(root==nullptr)\n            return result;\n        preOrder(root,expectNumber);\n        return result;\n    }\n    //前序遍历二叉树，计算每一路径和。\n    void preOrder(TreeNode* root, int expectNumber)\n    {\n        if(root==nullptr)\n            return;\n        path.push_back(root->val);\n        currentSum+=root->val;\n        //1.当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点；\n        if(root->left==nullptr && root->right==nullptr)\n        {\n            if(currentSum==expectNumber)\n            {\n                result.push_back(path);\n            }\n            //下面该段可都不写，都留给情况2去处理，但若写，就需要return，否则会处理两次。\n            if(path.size()>0)\n                path.pop_back();\n            currentSum-=root->val;\n            return; //注意，需要return\n        }\n        preOrder(root->left,expectNumber);\n        preOrder(root->right,expectNumber);\n        //2.任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点。\n        currentSum-=root->val;\n        if(path.size()>0)\n            path.pop_back();\n    } \n};\n```\n\n## 10. 按之字形顺序打印二叉树\n**题目描述**：\n请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。\n**思路**：\n- 按之字形顺序打印二叉树需要两个栈。\n- 若当前打印的是奇数层（如第1层、第3层），则先保存左子节点再保存右子节点到第一个栈。\n- 若当前打印的是偶数层（如第2层、第4层），则先保存右子节点再保存左子节点到第二个栈。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    stack<TreeNode*> s1;\n    stack<TreeNode*> s2;\n    vector<int> level;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> Print(TreeNode* pRoot) \n    {\n        if(pRoot==NULL) \n            return result;\n        s1.push(pRoot);\n        while(!s1.empty()||!s2.empty())\n        {\n            if(!s1.empty())\n            {\n                while(!s1.empty())\n                {\n                    TreeNode* pTemp = s1.top();\n                    s1.pop();\n                    level.push_back(pTemp->val);\n                    if(pTemp->left!=nullptr)\n                        s2.push(pTemp->left);\n                    if(pTemp->right!=nullptr)\n                        s2.push(pTemp->right);\n                }\n                result.push_back(level);\n                level.clear();\n            }\n            if(!s2.empty())\n            {\n                while(!s2.empty())\n                {\n                    TreeNode* pTemp = s2.top();\n                    s2.pop();\n                    level.push_back(pTemp->val);\n                    if(pTemp->right!=nullptr)\n                        s1.push(pTemp->right);\n                    if(pTemp->left!=nullptr)\n                        s1.push(pTemp->left);                 \n                }\n                result.push_back(level);\n                level.clear();\n            }\n        }\n        return result;\n    }\n};\n```\n\n## 11. 二叉搜索树的第k个结点\n**题目描述**:\n给定一颗二叉搜索树，请找出其中的第$k$大的结点。例如， 5 / \\ 3 7 / \\ / \\ 2 4 6 8 中，按结点数值大小顺序第三个结点的值为4。\n**思路**：\n- 中序遍历BST可得有序序列。\n- 在中序遍历的“访问”操作中计数。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    int num=0;\n    TreeNode* pNode=nullptr;\npublic:\n    TreeNode* KthNode(TreeNode* pRoot, int k)\n    {\n        if(pRoot==nullptr)\n            return pNode;\n        KthNode(pRoot->left,k);\n        //在“访问”操作中计数\n        num++;\n        if(num==k)\n        {\n            pNode=pRoot; \n            return pNode;\n        }\n        KthNode(pRoot->right,k);\n        return pNode;\n    }\n};\n```\n\n## 12. 二叉搜索树的后序遍历序列\n**题目描述**：\n输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。\n**思路**：\n- 后序遍历顺序：`<left，right，root>`。\n- 对于二叉搜索树的后续遍历序列，如果去掉最后一个元素x（也就是根）的序列为T，那么T满足：T可以分成两段，前一段（左子树）小于x，后一段（右子树）大于x，且这两段（子树）都是合法的后序序列。\n- 故以该规律，递归验证每一左右子树。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    bool VerifySquenceOfBST(vector<int> sequence) \n    {\n        if(sequence.empty())\n            return false;\n        return Check(sequence,0,sequence.size()-1);\n    }\n    bool Check(vector<int> sequence, int start, int end)\n    {\n        //递归出口条件1：一个或零个元素，返回true\n        if(start>=end)\n            return true;\n        int rootVal = sequence[end];\n        //分出左子树\n        int i = start;\n        for(;i<end;i++)\n        {\n            if(sequence[i]>rootVal)\n                break;\n        }\n        //验证右子树中所有元素都大于root值\n        for(int j = i;j<end;j++)\n        {\n            //递归出口条件2：右子树中存在小于root值的元素\n            if(sequence[j]<rootVal)\n            {\n                return false;\n            }\n        }\n        //递归验证左右子树，需都返回true\n        bool result1 = Check(sequence,start,i-1);\n        bool result2 = Check(sequence,i,end-1);\n        return result1 && result2;\n    }\n};\n```\n\n## 13. 树的子结构\n**题目描述**:\n输入两棵二叉树A，B，判断B是不是A的子结构。此外，约定空树不是任意一个树的子结构。\n**思路**：\n- 遍历树A，在树A中找出所有与树B的根节点值相等的结点，保存至vector容器`v`中。\n- 函数`bool Check(TreeNode* pTest, TreeNode* pRoot2)`：检验以`pTest`为根结点的树是否包含树B。**注意，左右子树都需返回`true`**。\n- 对于容器`v`中所有的`pTest`结点，逐一进行检验，**只要有一个成立即可**，即包含。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    vector<TreeNode*> v;\npublic:\n    bool HasSubtree(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr || pRoot2==nullptr)\n            return false;\n        //在树A中找出所有与树B的根节点值相等的结点，保存至容器v中\n        Find(pRoot1,pRoot2);\n        bool result = false;\n        //对于容器v中所有的pTest结点，逐一进行检验\n        for(int i = 0;i<v.size();i++)\n        {\n            result = Check(v[i],pRoot2);\n            //只要有一个成立即可，即包含\n            if(result==true) \n                break;\n        }\n        return result;\n    }\n    void Find(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr)\n            return;\n        if(pRoot1->val==pRoot2->val)\n            v.push_back(pRoot1);\n        Find(pRoot1->left,pRoot2);\n        Find(pRoot1->right,pRoot2);\n    }\n    bool Check(TreeNode* pTest, TreeNode* pRoot2)\n    {\n        if(pTest==nullptr && pRoot2==nullptr)\n            return true;\n        if(pTest==nullptr)\n            return false;\n        if(pRoot2==nullptr)\n            return true;\n        if(pTest->val!=pRoot2->val)\n            return false;\n        bool result1 = Check(pTest->left,pRoot2->left);\n        bool result2 = Check(pTest->right,pRoot2->right);\n        return result1 && result2;\n    }\n};\n```\n\n## 14. 重建二叉树\n**题目描述**:\n输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列$$\\{1,2,4,7,3,5,6,8\\}$$和中序遍历序列$$\\{4,7,2,1,5,3,8,6\\}$$，则重建二叉树并返回。\n**思路**：\n- 首先，前序遍历序列的首元素给出根结点；然后，通过中序遍历序列得出左右子树长度；最后，可分割出左右子树各自的前序序列和中序序列。\n- 分别递归重建左子树和右子树，递归终止条件：\n - 当序列中只剩一元素(`start==end`)时，返回该根结点指针；\n - 当序列中无元素(`start>end`)时，返回`nullptr`。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    TreeNode* reConstructBinaryTree(vector<int> pre,vector<int> vin) \n    {\n        if(pre.empty() || vin.empty() || pre.size()!=vin.size())\n            return nullptr;\n        return reConstruct(pre, 0, pre.size()-1,vin,0, vin.size()-1);\n    }\n    TreeNode* reConstruct(vector<int> pre, int preStart, int preEnd,vector<int> vin,int vinStart, int vinEnd)\n    {\n        //递归出口条件1：当序列中只剩一结点，返回该结点指针\n        if(preStart==preEnd)\n        {\n            TreeNode* pNode = new TreeNode(pre[preStart]);\n            return pNode;\n        }\n        //递归出口条件2：当序列无结点时，返回nullptr\n        if(preStart>preEnd)\n            return nullptr;\n        //前序遍历序列的首元素给出根结点\n        int rootVal = pre[preStart];\n        TreeNode* pRoot = new TreeNode(rootVal);\n        //通过中序遍历序列得出左右子树长度\n        int i = vinStart;\n        for(;i<vinEnd;i++)\n        {\n            if(vin[i]==rootVal)\n                break;\n        }\n        int leftLength = i-vinStart; int rightLength = vinEnd-i;\n        //分割出左右子树各自的前序序列和中序序列\n        int preStartLeft = preStart+1;int preEndLeft=preStartLeft+leftLength-1;\n        int vinStartLeft=vinStart;int vinEndLeft=i-1;\n        int preStartRight = preEndLeft+1;int preEndRight=preEnd;\n        int vinStartRight = i+1;int vinEndRight=vinEnd;\n        //分别递归重建左子树和右子树\n        pRoot->left = reConstruct(pre,preStartLeft,preEndLeft,vin,vinStartLeft,vinEndLeft);\n        pRoot->right =reConstruct(pre,preStartRight,preEndRight,vin,vinStartRight,vinEndRight);\n        return pRoot;\n    }\n};\n```\n\n## 15. 序列化二叉树\n**题目描述**：\n请实现两个函数，分别用来序列化和反序列化二叉树\n**思路**：\n- 对于序列化：\n - 使用前序遍历，递归的将二叉树的值转化为字符，并且在每次二叉树的结点不为空时，在转化val所得的字符之后添加一个`'，'`作为分割。对于空节点则以 `'#'` 代替。\n- 对于反序列化：\n - 按照前序顺序，递归的使用字符串中的字符创建左右子树。注意：在递归时，递归函数的参数一定要是`char **`，这样才能保证每次递归后指向字符串的指针会随着递归的进行而移动。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    char* Serialize(TreeNode *root) \n    {    \n        if(root==nullptr)\n            return nullptr;\n        string str;\n        Serialize2(root,str);\n        char* result = new char[str.size()+1];\n        for(int i = 0;i<str.size();i++)\n            result[i] = str[i];\n        result[str.size()] = '\\0';\n        return result;\n    }\n    void Serialize2(TreeNode* root, string& str)\n    {\n        if(root==nullptr)\n        {\n            str+='#';\n            return;\n        }\n        string r = to_string(root->val);\n        str+=r;\n        str+=',';\n        Serialize2(root->left, str);\n        Serialize2(root->right, str);\n    }\n    TreeNode* Deserialize(char *str) \n    {\n        if(str==nullptr)\n            return nullptr;\n        TreeNode* result = Deserialize2(&str);\n        return result;\n    }\n    TreeNode* Deserialize2(char** str) \n    {\n        if(**str=='#')\n        {\n            (*str)++;\n            return nullptr;\n        }\n        int num=0;\n        while(**str!= '\\0' && **str!=',')\n        {\n            num=num*10+((**str)-'0');\n            (*str)++;\n        }\n        TreeNode* pRoot = new TreeNode(num);\n        if(**str =='\\0')\n            return pRoot;\n        else\n            (*str)++;\n        pRoot->left = Deserialize2(str);\n        pRoot->right= Deserialize2(str);\n        return pRoot;\n    }\n};\n```\n---------\n# 四、字符串\n## 1. 替换空格\n**题目描述**：\n请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为\"We Are Happy.\"则经过替换之后的字符串为\"We%20Are%20Happy.\"\n**思路**：\n- **注意**：假设在原来的字符串上进行替换，并保证输入的字符串后面有足够多的空余内存。\n- **步骤**：从后向前替换：\n - 1.遍历字符串，得到原字符串的长度和空格的个数;\n - 2.计算新字符串的长度，新串长度为原串长度加上两倍的空格个数；\n - 3.从后向前替换：设置两个指针，p1指向原字符串末尾，p2指向新字符串末尾。前移指针p1，逐个把它指向的内容复制到p2指向的位置；\n- 所有字符串都只复制一次，时间复杂度：O(n)。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    void replaceSpace(char *str,int length) \n    {\n        if(str==nullptr || length<1)\n            return;\n        //1.遍历字符串，得到空格的个数\n        int numSpace = 0;\n        for(int i = 0;i<length;i++)\n        {\n            if(str[i]==' ')\n                numSpace++;\n        }\n        //2.计算新字符串的长度\n        int lengthNew = length+2*numSpace;\n        //3.从后向前替换：设置两个指针，i指向原字符串末尾，j指向新字符串末尾\n        int i = length-1;\n        int j = lengthNew-1;\n        //终止条件，i<0\n        while(i>=0)\n        {\n            if(str[i]==' ')\n            {\n                str[j--] = '0';\n                str[j--] = '2';\n                str[j--] = '%';\n                i--;\n            }\n            else\n            {\n                str[j--] = str[i--];\n            }\n        }\n    }\n};\n```\n## 2. 整数中1出现的次数（从1到n整数中1出现的次数）\n**题目描述**\n求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。\n**思路**：\n- 对1~n的每一个数：通过对10求余数判断整数的个位数字是不是1，如果这个数字大于10，则除以10之后再判断个位数字是不是1。\n- 对每个数字都要做除法和求余运算，以求出该数字中1出现的次数。如果输入数字为$n$，$n$有$O(logn)$位，我们需要判断每一位是不是1，那么它的时间复杂度是$O(nlogn)$。\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    int NumberOf1Between1AndN_Solution(int n)\n    {\n    \tint number=0;\n        for(unsigned int i = 1;i<=n;i++)\n            number+=NumberOf1(i);\n        return number;\n    }\n    int NumberOf1(unsigned int n)\n    {\n        int number=0;\n        while(n)\n        {\n            if(n%10 ==1)\n                number++;\n            n=n/10;\n        }\n        return number;\n    }\n};\n```\n## 3. 翻转单词顺序列\n**题目描述**:输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串\"I am a student.\"，则输出\"student. a am I\"。 \n**思路**：\n- 第一步翻转句子中所有的字符。比如翻转\"I am a student.\"中所有的字符得到\".tenduts a ma I\"，此时不但翻转了句子中单词的顺序，连单词内的字符顺序也被翻转了。\n- 第二步再翻转每个单词中字符的顺序，就得到了“studnet. a am I”。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    string ReverseSentence(string str) \n    {\n        //1.先整体翻转\n        ReverseWord(str,0,str.size()-1);\n        int i,start,end;\n        i=start=end=0;\n        while(i<str.size())\n        {\n            //空格跳过\n            while(i<str.size() && str[i]==' ')\n            {\n                i++;\n            }\n            //不是空格，找单词最后一个字符的位置\n            start = end = i;\n            while(i<str.size() && str[i]!=' ')\n            {\n                i++;\n                end++;\n            }\n            //2.局部翻转\n            ReverseWord(str,start,end-1);\n        }\n        return str;\n    }\n    void ReverseWord(string& str, int start, int end)\n    {\n        while(start<end)\n        {\n            swap(str[start++],str[end--]);\n        }\n    }\n};\n```\n## 4. 左旋转字符串\n**题目描述**\n汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！\n**思路**：\n-  以\"abcdefg\"为例，想把它的前两个字符移到后面，得到\"cdefgab\"。\n- 将前两个字符分到第一部分，将后面的所有字符分到第二部分。\n- 先分别翻转这两部分，于是得到“bagfedc”。\n- 接下来翻转整个字符串，得到“cdefgab”，刚好就是把原始字符串左旋转两位的结果。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    string LeftRotateString(string str, int n) \n    {\n        if(str.size()<1 || n>str.size() || n<0)\n            return str;\n        int startFirst = 0;\n        int endFirst = n-1;\n        int startSecond = n;\n        int endSecond = str.size()-1;\n        // 翻转字符串的前面n个字符\n        ReverseWord(str,startFirst,endFirst);\n        // 翻转字符串的后面部分\n        ReverseWord(str,startSecond,endSecond);\n        // 翻转整个字符串\n        ReverseWord(str,0,str.size()-1);\n        return str;\n    }\n    void ReverseWord(string& str, int start, int end)\n    {\n        while(start<end)\n        {\n            char temp = str[start];\n            str[start] = str[end];\n            str[end] = temp;\n            start++;\n            end--;\n        }\n    }\n};\n```\n## 5. 把字符串转换成整数\n**题目描述**\n将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0\n**输入描述**:\n输入一个字符串,包括数字字母符号,可以为空\n**输出描述**:\n如果是合法的数值表达则返回该数字，否则返回0\n**示例**:\n输入:\n+2147483647\n    1a33\n输出:\n2147483647\n    0\n**思路**：\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    \n    int StrToInt(string str) {\n        const char* cstr = str.c_str();\n        long long num = 0;\n        if((cstr != NULL) && (*cstr!= '\\0')) //字符串不为空\n        {\n            bool minus = false; //检查第一位是否为正负号\n            if(*cstr=='+')\n                cstr++;\n            else if(*cstr=='-')\n            {\n                cstr++;\n                minus = true;\n            }\n            if(*cstr!='\\0')\n                num = StrToIntCore(cstr,minus);\n        }\n        return num;\n    }\n    long long StrToIntCore(const char* digit, bool minus)\n    {\n        long long num = 0;\n        while(*digit!='\\0')\n        {   \n            //计算数字大小\n            if(*digit>='\\0' && *digit<='9')\n            {\n                int flag = minus? -1:1;\n                num = num*10+flag*(*digit-'0');\n                //溢出判断\n                if((!minus && num>0x7FFFFFFF) || (minus && num<(signed int)0x80000000))\n                {\n                    num=0;\n                    break;\n                }\n         \t\tdigit++;\n            }\n            //非法输入\n            else\n            {\n                num=0;\n                break;\n            }\n        }\n\t\treturn num;        \n    }\n};\n```\n\n\n## 6. 正则表达式匹配\n**题目描述**:\n请实现一个函数用来匹配包括'.'和'\\*'的正则表达式。模式中的字符'.'表示任意一个字符，而'\\*'表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串\"aaa\"与模式\"a.a\"和\"ab\\*ac\\*a\"匹配，但是与\"aa.a\"和\"ab\\*a\"均不匹配\n**思路**：\nA：下一个字符是`*`\n　　1.若当前字符匹配\n　　　　选择1：匹配了，但我当作0匹配(匹配0次)。`s不动，p加2`\n　　　　选择2：匹配了，匹配结束(匹配1次)。`s+1,p+2`\n　　　　选择3：匹配了，我继续匹配下一个(匹配多次)。`s+1，p不动`\n　　2.当前字符不匹配。`s不动，p加2`\nB:下一个字符不是`*`，当前字符匹配。`s+1,p+1`\nC:下一个字符不是`*`，当前字符不匹配。`返回false`\n递归出口条件：\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool match(char* str, char* pattern)\n    {\n    \tif(str==NULL || pattern==NULL)\n        \treturn false;\n        return matchCore(str,pattern);\n    }\n    bool matchCore(char* str, char* pattern)\n    {\n        //递归出口条件:字符串和模式串同时走完\n        if(*str=='\\0' && *pattern=='\\0')\n            return true;\n        //递归出口条件：字符串没走完，模式串走完，返回false\n        if(*str!='\\0' && *pattern=='\\0')\n            return false;\n        //A：下一个字符是*\n        if(*(pattern+1)=='*') \n        {\n            //1.若当前字符匹配\n            if(*pattern==*str || (*pattern=='.' && *str!='\\0'))\n            \treturn matchCore(str,pattern+2)    //选择1：匹配了，但我当作0匹配(匹配0次)\n            \t\t|| matchCore(str+1,pattern+2)  //选择2：匹配了，匹配结束(匹配1次)    \t\n            \t\t|| matchCore(str+1,pattern);    //选择3：匹配了，我继续匹配下一个(匹配多次)\n            //2.当前字符不匹配\n            else \n            \treturn matchCore(str,pattern+2); //匹配结束\n        }\n        //B:下一个字符不是*，当前字符匹配\n        if(*pattern==*str || (*pattern=='.' && *str!='\\0'))\n             \treturn matchCore(str+1,pattern+1);\n        //C:下一个字符不是*，当前字符不匹配\n\t\treturn false;           \n    }\n};\n```\n## 7. 表示数值的字符串\n**题目描述**\n请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串\"+100\",\"5e2\",\"-123\",\"3.1416\"和\"-1E-16\"都表示数值。 但是\"12e\",\"1a3.14\",\"1.2.3\",\"+-5\"和\"12e+4.3\"都不是。\n**思路**：\n- 表示数值的字符串: A`.`B`e/E`C 例如：“+123.45e+6”\n - 其中，A、C可能是以+/-开头的0~9的数位串，即整型；B也是0~9的数位串，但前面不能有正负号，即无符号整型。\n- 故步骤为：扫描A部分；遇到小数点`.`，扫描B部分；遇到`e/E`，扫描C部分。\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool isNumeric(char* str)\n    {\n        if(str==NULL)\n            return false;\n        bool numeric = scanInteger(&str);\n        if(*str=='.')\n        {\n            ++str;\n            numeric = scanUnsignedInteger(&str) || numeric;\n        }\n        if(*str=='e' || *str=='E')\n        {\n            ++str;\n            numeric = numeric && scanInteger(&str);\n        }\n        return numeric && *str=='\\0';\n    }\n\tbool scanInteger(char** str)\n    {\n        if(**str=='+' || **str=='-')\n            ++(*str);\n        return scanUnsignedInteger(str);\n    }\n    bool scanUnsignedInteger(char** str)\n    {\n        const char* before = *str;\n        while(**str!='\\0' && **str>='0' && **str<='9')\n            ++(*str);\n        return *str>before;\n    }\n};\n```\n## 8. 字符串的排列\n**题目描述**\n输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。\n**输入描述**:\n输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。\n**思路**：\n\n**代码**：\n```C++\n待\n```\n-----------\n# 五、数组\n## 1. 构建乘积数组\n**题目描述**\n给定一个数组A[0,1,...,n-1],请构建一个数组B[0,1,...,n-1],其中B中的元素`B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]`。不能使用除法。\n**思路**：\n- 把数组B看成一个矩阵来创建（见书中）。B[i]的值可以看作图中的矩阵中每行的乘积。\n- 下三角用自上而下的顺序计算，`C[i] =C[i-1]*A[i-1]`。\n- 上三角用自下而上的顺序计算，`D[i]= D[i+1]*A[i+1]`。\n- 因此，先算下三角中的连乘，即先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    vector<int> multiply(const vector<int>& A) \n    {\n    \tint length = A.size();\n        vector<int> B(length); //vector容器的构造函数\n        if(length<=0) return B;\n        //计算下三角连乘\n        B[0]=1;\n        for(int i = 1;i<length;i++)\n        {\n            B[i]=B[i-1]*A[i-1];\n        }\n        //计算上三角\n        int temp = 1;\n        for(int j=length-2;j>=0;j--)\n        {\n            temp *= A[j+1];\n            B[j] *= temp;\n        }\n        return B;\n    }\n};\n```\n## 2. 连续子数组的最大和\n**题目**：输入一个整型数组，数组里有正数也有负数。数组中一个或连续的多个整数组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为 O(n)。\n**说明**：例如输入的数组为{1, -2, 3, 10, -4, 7, 2, -5}，和最大的子数组为｛3, 10, -4, 7, 2}。因此输出为该子数组的和18。\n**思路**：\n- 从头到尾逐个累加数组中的每个数字。若加上`arr[i]`后的当前和`sumCurrent`小于`arr[i]`，则抛弃当前和`sumCurrent`及之前的所有数字，置当前和`sumCurrent`为`arr[i]`。同时每一步累加都记录下最大和`sumMax`。\n\n**代码**： \n```C++\nclass Solution \n{\npublic:\n    int FindGreatestSumOfSubArray(vector<int> array)\n    {\n    \tif(array.empty()) return 0;\n        int size = array.size();\n        int sumCurrent=0;\n        int sumMax = 0x80000000;//int的最小值\n        //从头到尾逐个累加数组中的每个数字\n        for(int i = 0; i<size;i++)\n        {\n            sumCurrent += array[i];\n            //若当前和sumCurrent小于arr[i]\n            if(array[i]>sumCurrent)\n                sumCurrent=array[i];\n            //记录下最大和sumMax\n            if(sumCurrent>sumMax) \n                sumMax = sumCurrent;\n        }\n        return sumMax;\n    }\n};\n```\n## 3. 旋转数组的最小数字\n**题目描述**\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序（递增，可能相等）的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。\n**思路**：\n**思路1**：顺序查找，遍历数组，找到`arr[i]>arr[i+1]`（稍微优化），时间复杂度$O(n)$，需改进。\n**思路2**：旋转数组是两个排序的子数组，采用二分查找。时间复杂度$O(logn)$：\n- **情况1**：\n - 用指针`p1`指向第一个数组的第一个元素，用指针`p2`指向第二个数组的第2个元素。对于旋转数组，有特性：`arr[p1]>arr[p2]`（`第一个数组>=第二个数组`）；\n - 计算中间元素为指针`p`，如果`arr[p]>=arr[p1]`，则指针`p`在第一个数组中，此时最小元素应该位于中间元素的后面，令`p1=p;`如果`arr[p]<=arr[p1]`，则指针`p`在第二个数组中，此时最小元素应该位于中间元素的前面，令`p2 = p;`；\n - `p1`始终在第一个数组，`p2`始终在第二个数组，故循环终止条件为：`(p1+1)=p2`，`arr[p2]`即为最小元素。\n- **情况2**：若旋转数组是将原来的0个元素搬到最后面，即数组有序，即`arr[p1]<arr[p2]`，该情况是情况1中的特例，情况1中的做法是不适用的，直接返回最小元素`arr[0]`。\n- **情况3**：当指针`p`，`p1`，`p2`指向的元素相同时，即`arr[p]==arr[p1] && arr[p]==arr[p2]`时，无法判断该将中间的数字是位于第一个数组还是第二个数组，无法继续用二分法，转而对`[p1，p2]`采用顺序查找法。\n\n**代码**：\n```C++\n//思路1：顺序查找，时间复杂度O(n)\nclass Solution \n{\npublic:\n    int minNumberInRotateArray(vector<int> rotateArray) \n    {\n        int min = 0;\n        if(!rotateArray.empty())\n        {\n            int size = rotateArray.size();\n            //顺序查找，遍历数组，找到arr[i+1]<arr[i]\n            for(int i = 0;i<size-1;i++)\n            {\n                if(rotateArray[i+1]<rotateArray[i])\n                {\n                    min = rotateArray[i+1];\n                    break;\n                }\n            }\n        }\n        return min;\n    }\n};\n```\n```C++\n//思路2：二分查找，时间复杂度O(logn)\nclass Solution {\npublic:\n    int minNumberInRotateArray(vector<int> rotateArray) {\n        if(rotateArray.empty())  return 0;\n        int size = rotateArray.size();\n        int p1 = 0;\n        int p2 = size-1;\n        int minIndex=0;\n        //情况2，数组有序，直接返回arr[0]\n        if(rotateArray[p1]<rotateArray[p2]) return rotateArray[0];\n        //情况1，二分查找\n        while((p1+1)!=p2)\n        {\n            int p = (p1+p2)/2;\n            //情况3，转为对[p1,p2]采用顺序查找\n            if(rotateArray[p1]==rotateArray[p] && rotateArray[p]==rotateArray[p2])\n                return MinInOrder(rotateArray,p1,p2);\n            if(rotateArray[p]>=rotateArray[p1]) p1 = p;\n            else if(rotateArray[p]<=rotateArray[p2]) p2 = p;\n        }\n        return rotateArray[p2];\n    }\n    int MinInOrder(vector<int>& rotateArray,int p1, int p2)\n    {\n        int min = 0;\n    \tfor(int i = p1;i<p2;i++)\n        {\n            \tif(rotateArray[i+1]<rotateArray[i])\n            \t{\n                \tmin = rotateArray[i+1];\n                \tbreak;\n            \t}\n        }\n        return min;\n    }\n    \n};\n```\n## 4. 数字在排序数组中出现的次数\n**题目描述**\n统计一个数字在排序数组中出现的次数。\n**思路**：\n- **思路1**：顺序遍历数组，时间复杂度$O(n)$，需改进。\n- **思路2**：有序数组，使用二分查找。分两次二分查找：\n - **第一次**找出该数字第一次出现的位置:`(mid==start) || (data[mid-1]!=target))`即已经是最左边的位置或其左边的一个数不等于该数；\n - **第二次**找出该数字最后一次出现的位置：`(mid==end) || (data[mid+1]!=target)`即已经是最右边的位置或其右边的一个数不等于该数。\n- 可用递归实现，也可以用循环实现。\n\n**代码**：\n```C++\n//思路2，递归实现\nclass Solution \n{\npublic:\n    int GetNumberOfK(vector<int> data ,int k) \n    {\n        int number = 0;\n        if(data.empty()) return number;\n        int size = data.size();\n        int firstIndex = getFirst(data,0,size-1,k);\n        int lastIndex = getLast(data,0,size-1,k);\n        if (firstIndex > -1 && lastIndex > -1)\n        {\n        \tnumber = lastIndex - firstIndex + 1;\n        }\n        return number;\n    }\n    int getFirst(vector<int>& data, int start, int end, int target)\n    {\n        if(start>end) return -1;\n        int mid = (start+end)/2;\n        if(data[mid]==target)\n        {\n            if((mid==start) || (data[mid-1]!=target))//让它是第一个出现的位置\n            //if((mid==start) || (mid-1>start&&data[mid-1]!=target))//等价\n                return mid;\n            else end = mid-1;\n        }\n        else if(data[mid]>target) end = mid-1;\n        else start = mid+1;\n        return getFirst(data,start,end,target);\n    }\n    int getLast(vector<int>& data, int start, int end, int target)\n    {\n        if(start>end) return -1;\n        int mid = (start+end)/2;\n        if(data[mid]==target)\n        {\n           if((mid==end) || (data[mid+1]!=target))//让它是最后一个出现的位置\n           //if((mid==end) || (mid+1<end&&data[mid+1]!=target))//等价\n                return mid;\n            else\n                start = mid+1;\n        }\n        else if(data[mid]>target) end = mid-1;\n        else start = mid+1;\n        return getLast(data,start,end,target);\n    }\n};\n```\n## 5. 数组中重复的数字\n题目描述\n在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。\n\n\n## 6. 数组中只出现一次的数字\n题目描述\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n\n## 7. 数组中出现次数超过一半的数字\n题目描述\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。\n\n## 8. 把数组排成最小的数\n**题目描述**\n输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。\n**思路**：\n**代码**：\n```C++\nclass Solution {\npublic:\n    string PrintMinNumber(vector<int> numbers) {\n        int length = numbers.size();\n        if(length==0) return \"\";\n        sort(numbers.begin(),numbers.end(),compare);\n        string result;\n        for(int i = 0; i<length;i++)\n            result += to_string(numbers[i]);\n        return result;\n    }\n    static bool compare(int a, int b)\n    {\n        string A = to_string(a)+to_string(b);\n        string B = to_string(b)+to_string(a);\n        return A<B;\n    }\n};\n```\n## 9. 调整数组顺序使奇数位于偶数前面\n**题目描述**\n输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。\n**思路**：\n1.剑指offer书中，是要求调整数组顺序，使得奇数位于偶数前面，没有要求奇数和奇数，偶数和偶数的相对位置不变。\n解法是：指针`p1`指向数组头部，`p1`只后移。指针`p2`指向数组尾部，`p2`只前移。当`arr[p1]`为偶数，`arr[p2]`为奇数，则交换。`p1`继续后移，`p2`继续前移，一直循环。终止条件是：`p1`与`p2`交叉。\n2.本题目中，要求奇数在前，偶数在后，且奇数相对于奇数，偶数相对于偶数的相对位置不变。则解法是：新建一个数组，先把原数组中的奇数push进去，再把偶数push进去，然后用新数组数据覆盖原数组即可。复杂度O(n)。\n**代码**：\n```C++\nclass Solution {\npublic:\n    void reOrderArray(vector<int> &array) {\n        if(array.empty()) return;\n        int size = array.size();\n        //新建一个数组\n        vector<int> result;\n        //先把原数组中的奇数push进去\n        for(int i = 0; i<size;i++)\n        {\n        \tif(array[i]%2==1)\n                result.push_back(array[i]);\n        }\n        //再把原数组中的偶数push进去\n        for(int i = 0; i<size;i++)\n        {\n        \tif(array[i]%2==0)\n                result.push_back(array[i]);\n        }\n        //用新数组覆盖原数组\n        array=result;\n    }\n};\n```\n## 10. 二维数组中的查找\n**题目描述**\n在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n**思路**：首先选取数组中右上角的数字。如果该数字等于要查找的数字，则查找过程结束；如果该数字大于要查找的数字，则去除该数字所在列；如果该数字小于要查找的数字，则去除该数字所在行。\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool Find(int target, vector<vector<int>> array) {\n\t\t//防御型编程\n        if(array.empty()) return false;\n        //计算二维数组的行和列\n        int rows = array.size();\n        int cols = array[0].size();\n        //首先选取数组中右上角的数字\n        int i = 0;\n        int j = cols-1;\n        bool result = false;\n        while(i<rows && j>=0)//注意二维数组行列的取值范围为[0~rows-1, 0~cols-1]\n        {\n            //如果该数字等于要查找的数字，则查找过程结束\n            if(array[i][j]== target)\n            {\n                result = true;\n                break;\n            }\n            //如果该数字大于要查找的数字，则去除该数字所在列\n            else if(array[i][j]>target)   \n            {\n                j--;\n            }\n            //如果该数字小于要查找的数字，则去除该数字所在行\n            else\n            {\n            \ti++;\n            }\n        }\n        return result;\n    }\n};\n```\n## 11. 数组中的逆序对\n**题目描述**\n在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007\n**输入描述**:\n题目保证输入的数组中没有的相同的数字\n**数据范围**：\n对于%50的数据,$size<=10^4$\n对于%75的数据,$size<=10^5$\n对于%100的数据,$size<=2\\*10^5$\n**示例**:\n输入\n1,2,3,4,5,6,7,0\n输出\n7\n**思路**：\n\n**代码**：\n```C++\n//不对，未完成\nclass Solution {\nprivate:\n    int count=0;\npublic:\n    int InversePairs(vector<int> data) {\n        int n = data.size();\n        return InversePairs2(data, n);\n    }\n    int InversePairs2(vector<int>& data, int n) \n    {\n\t\tif(n<2) return 0;//就是为了返回，返回的值无所谓\n        int leftLength= n/2;\n        int rightLength= n-leftLength;\n        vector<int> left;\n        vector<int> right;\n        for(int i = 0;i<leftLength;i++) left.push_back(data[i]);\n        for(int i = leftLength;i<n;i++) right.push_back(data[i]);\n        InversePairs2(left,leftLength);    //sorting the left subarray\n        InversePairs2(right,rightLength);  //sorting the right subarray\n        mergeNew(data,left,leftLength,right,rightLength); //merge left and right into A\n        return count%1000000007;\n    }\n    void mergeNew(vector<int>& data, vector<int>& left, int leftLength, vector<int>& right,int rightLength)\n    {\n        int i=leftLength+rightLength-1;\n\t\tint j = leftLength-1;\n        int k = rightLength-1;\n        while(j>=0 && k>=0)\n        {\n            if(left[j]>right[k]) \n            { \n            \tdata[i--] = left[j--];\n            \tcount+=(k+1);\n            }\n            else \n            {\n            \tdata[i--] = right[k--];\n            }\n        }\n        while(j>=0) data[i--]=left[j--];\n        while(k>=0) data[i--]=right[k--];\n    }\n};\n```\n## 12. 顺时针打印矩阵\n**题目描述**\n输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵： \n```\n1   2  3  4\n5   6  7  8\n9  10 11 12\n13 14 15 16\n```\n则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.\n**思路**：分解成若干个简单的问题。\n1.每次打印矩阵的一个圈。关键：循环继续的条件是：`cols>start*2 && row>start*2`\n2.将打印一圈分成四步：第一步，从左到右打印一行；第二步，从上到下打印一列；第三步；从右到左打印一行；第四步，从下到上打印一列。\n3.四步的前提条件：\n第一步总是需要；\n第二步的前提条件是终止行号大于起始行号；\n第三步的前提条件是该圈内至少两行两列，即终止行号大于起始行号，终止列号大于起始列号；\n第四步的前提条件：该圈内至少有三行二列，即终止行号比起始行号至少大2，终止列号大于起始列号。\n**代码**：\n```C++\nclass Solution {\npublic:\n    vector<int> printMatrix(vector<vector<int> > matrix) {\n\t\tvector<int> result;\n        int rows = matrix.size();\n        int cols = matrix[0].size();\n        if(rows<=0 || cols<=0) return result;\n        int start = 0;\n        //每次打印矩阵的一个圈\n        while(cols>start*2 && rows> start*2)\n        {\n            PrintMatrixInCircle(matrix,rows,cols,start,result);\n            start++;\n        }\n        return result;\n    }\n    void PrintMatrixInCircle(vector<vector<int>>& matrix,int rows,int cols,int start,vector<int>& result)\n    {\n        int endX = cols-start-1;\n        int endY = rows-start-1;\n        //1.从左到右打印矩阵\n        for(int i = start;i<=endX;i++)\n        {\n            result.push_back(matrix[start][i]);\n        }\n        //2.从上到下打印一列\n        if(start<endY)\n        {\n            for(int i = start+1;i<=endY;i++)\n            {\n                result.push_back(matrix[i][endX]);\n            }\n        }\n        //3.从右到左打印一行\n        if(start<endX && start< endY)\n        {\n            for(int i = endX-1;i>=start;i--)\n            {\n                result.push_back(matrix[endY][i]);\n            }\n        }\n        //4.从下到上打印一列\n        if(start<endX && start <endY -1)\n        {\n            for(int i = endY-1; i>=start+1;i--)\n            {\n                result.push_back(matrix[i][start]);\n            }\n        }\n    }\n};\n```\n--------\n# 六、排序\n## 1.数组中出现次数超过一半的数字\n题目描述\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。\n**思路**：结合数组特性：数组中有一个数字出现的次数超过了数组长度的一半，如果将这个数组排序，那么排序之后位于数组中间的数字一定就是那个出现次数超过数组长度一半的数字。这个数字就是统计学上的中位数，即长度为$n$的数组中第$n/2$大的数字。已经有成熟的时间复杂度为$O(n)$的算法得到数组中任意第$k$大的数字。\n第一，防御性编程，判断数组是否有效；第二，利用快速排序中的分割(partition)方法，选主元位置及重排数组。如果返回的主元位置(pIndex)小于数组中间位置((length-1)/2)，则对左半部分进行分割，否则对右半部分进行分割，直到返回的pIndex等于((length-1)/2)；第三，遍历数组，验证该数是否出现了超过一半的次数。\n<!-- more --> \n**代码**：\n```C++\nclass Solution {\npublic:\n    int MoreThanHalfNum_Solution(vector<int> numbers) {\n    \tint size = numbers.size();\n        //1.防御性编程，判断数组是否有效；\n        if(size==0) return 0;\n        int start = 0;\n        int end = size-1;\n        int middle = end/2;\n        //2.利用快速排序中的分割(partition)方法，选主元位置及重排数组\n        int pIndex = partition(numbers,start,end);\n        //直到返回的pIndex等于((length-1)/2)\n        while(pIndex!=middle)\n        {\n            if(pIndex<middle)\n            {\n                start = pIndex+1;\n                pIndex = partition(numbers,start,end);\n            }\n            else\n            {\n                end = pIndex-1;\n                pIndex = partition(numbers,start,end);\n            }\n        }\n        int result=numbers[middle];\n        //3.遍历数组，验证该数是否出现了超过一半的次数。\n        if(isMoreThanHalf(numbers,result,size))\n            return result;\n        else\n            return 0;\n    }\n    int partition(vector<int>& numbers, int start,int end)\n    {\n        int pivot = numbers[end];\n        int pIndex = start;\n        for(int i = start;i<end;i++)\n        {\n            if(numbers[i]<=pivot)\n            {\n                int temp = numbers[i];\n                numbers[i] = numbers[pIndex];\n                numbers[pIndex] = temp;\n                pIndex++;\n            }\n        }\n        int temp = numbers[pIndex];\n        numbers[pIndex] = pivot;\n        numbers[end] = temp;\n        return pIndex;\n    }\n    bool isMoreThanHalf(vector<int>& numbers,int result,int size)\n    {\n        int count = 0;\n        for(int i = 0;i<size;i++)\n        {\n            if(numbers[i]==result)\n                count++;\n        }\n        if(2*count<=size) return false;\n        else return true;\n    }\n};\n```\n## 2.最小的k个数\n**题目描述**：\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n**思路**：\n思路1：利用快速排序排序数组，位于前面的$k$个数即是最小的$k$个数。时间复杂度为$O(nlogn)$。\n第一，防御性编程，如果数组为空或$k>length$，则返回空；第二，利用快速排序，对数组进行排序；第三，输出数组中的前$k$个数。\n思路2：\n由上题“数组中出现次数超过一半的数字”得到启发，基于快速排序中的分割(partition)方法来解决问题。利用partiton函数，如果返回的$pIndex<(k-1)$，则对右半部分进行partition，否则，对左半部分进行partition，直到返回的主元位置pIndex等于$(k-1)$。这样调整后，位于数组中左边的k个数字就是最小的$k$个数字，但这$k$个数字不一定是排序的。时间复杂度为$O(n)$。\n**代码**：\n```C++\n//实现思路1\nclass Solution {\npublic:\n    vector<int> GetLeastNumbers_Solution(vector<int> input, int k) {\n        vector<int> result;\n        int size = input.size();\n        //1.防御性编程，如果数组为空或k>size，则返回\n        if(size==0 || k>size) return result;\n        int start = 0;\n        int end = size-1;\n        //2.利用快速排序，对数组进行排序\n        quickSort(input,start,end);\n        //3.输出数组中的前k个数\n        for(int i = 0;i<k;i++)\n        {\n            result.push_back(input[i]);\n        }\n        return result;\n    }\n    void quickSort(vector<int>& numbers, int start, int end)\n    {\n        if(start>end) return;\n        int pIndex = partition(numbers,start,end);\n        quickSort(numbers,start,pIndex-1);\n        quickSort(numbers,pIndex+1,end);\n    }\n    int partition(vector<int>& numbers, int start,int end)\n    {\n        int pivot = numbers[end];\n        int pIndex = start;\n        for(int i = start;i<end;i++)\n        {\n            if(numbers[i]<=pivot)\n            {\n                int temp = numbers[i];\n                numbers[i] = numbers[pIndex];\n                numbers[pIndex] = temp;\n                pIndex++;\n            }\n        }\n        int temp = numbers[pIndex];\n        numbers[pIndex] = pivot;\n        numbers[end] = temp;\n        return pIndex;\n    }\n};\n```\n\n# 七、位运算\n## 1.数组中只出现一次的数字（#56）\n**题目描述**\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n**思路**：核心思想：[异或去重](http://blog.csdn.net/ns_code/article/details/27568975)；异或的性质：交换律，结合律，以及`a^a=0`，`a^0=a`\n**1.考虑简单情况**：数组中只有一个数字`n`出现了一次，其他都出现了两次。\n将数组中所有元素逐个异或，则结果为只出现一次的`n`，即`a^a^b^b^...^n^...^c^c=n`。\n**2.本题求解思路**：故将数组分成两部分解决，一部分包含只出现一次的数字`n_1`，一部分包含只出现一次的数字`n_2`，同时保证出现两次的数字在同一数组,而不是分散在l不同的数组。对两数组分别逐元素异或，即分别得到`n_1`，`n_2`。\n**3.数组划分方法**：对整个数组，逐元素异或，则结果为`n_1^n_2`，即`n_1`和 `n_2`异或的结果。`n_1`和`n_2`不相同，故结果定不为0，则结果的二进制表示定至少有一位为1（即`n_1`和`n_2`的二进制表示的该位不相同），找出结果的二进制表示中第一次为1的下标索引`index`，通过这个下标索引`index`，对整个数组中的元素进行数组划分。数组中每个元素的二进制表示的第`index`位是1的分为一组，是0的分为另一组。这样保证了`n_1`和`n_2`分别在两个组，且出现两次的数字在同一个组，不会被分到不同的组(因此相同数字的二进制表示的`index`位必定是相同的)。\n**代码**：\n```C++\nclass Solution {\npublic:\n    void FindNumsAppearOnce(vector<int> data,int* num1,int *num2) {\n\t\tint length = data.size();\n        if(data.size()<2) return;\n        int result = 0; //初始值为0,a^0=a\n        // get num1 ^ num2\n        for(int i =0;i<length;i++)\n            result ^=data[i];\n        // get index of the first bit, which is 1 in resultExclusiveOR\n        unsigned int indexOf1 = FindFirstBitIs1(result);\n        *num1 = *num2 = 0;\n        // divide the numbers in data into two groups,\n        // the indexOf1 bit of numbers in the first group is 1,\n        // while in the second group is 0\n        for(int j=0;j<length;j++)\n        {\n            if(IsBit1(data[j],indexOf1))\n                *num1^=data[j];\n            else\n                *num2^=data[j];\n        }\n    }\n    //Find the index of first bit which is 1 in num (assuming not 0)\n    unsigned int FindFirstBitIs1(int num)\n    {\n        int indexBit=0;\n        while(((num&1)==0) && (indexBit<8*sizeof(int)))\n        {\n            num = num>>1;\n            ++indexBit;\n        }\n        return indexBit;\n    }\n    // Is the indexBit bit of num 1?\n    bool IsBit1(int num, unsigned int indexBit)\n    {\n        num=num>>indexBit;\n        return (num&1);\n    }\n};\n```\n## 2.二进制中1的个数\n**题目描述**\n输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。\n**思路**：\n**首先**，直观的思路是：先判断整数二进制表示中的最后一位是不是1；然后将整数右移一位，再次判断，直到整数变为0。判断二进制表示中最后一位是不是1的方法是：`n&1`，因为1的二进制表示中除了最后一位为1以外，其余全为0。\n**然后**，右移整数n的做法存在隐患，就是当n是负数的时候，[n右移会在开头补符号位1（算术右移）](http://blog.csdn.net/morewindows/article/details/7354571)，而不是补0。故采用将1循环左移的方法，逐个判断n的二进制表示的第0位到最高位是否为1。\n**代码**：\n```C++\nclass Solution {\npublic:\n     int  NumberOf1(int n) {\n         int count = 0;\n         unsigned int flag = 1;\n         //直到1的循环左移为0\n         while(flag)\n         {\n             if(n & flag)\n             \tcount++;\n             //左移1\n             flag =flag<<1;\n         }\n         return count;\n     }\n};\n```\n# 八、递归\n## 1.斐波那契数列（#10）\n**题目描述**\n大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。(n<=39)\n**注**：本题中`n=0`时，输出是0。斐波那契数列从第1项开始。即本题斐波那契数列是`0,1,1,2,3,5,...`\n**思路**：\n**思路1**：最直观的递归，返回`Fibonacci(n-1)+Fibonacci(n-2)`。但有大量冗余计算，时间复杂度过高，无法通过。\n**思路2**：带记忆的递归，用辅助数组存储下已经计算过的结果。\n**思路3**：迭代计算。\n**代码**：\n```C++\n//思路1：最直观的递归，时间复杂度过高\nclass Solution {\npublic:\n    int Fibonacci(int n) {\n        if(n<=1) return n;\n        return Fibonacci(n-1)+Fibonacci(n-2);\n    }\n};\n```\n```\n//思路2：带记忆的递归，用辅助数组存储下已经计算过的结果\nclass Solution {\nprivate:\n    int F[40];//默认为0\npublic:\n    int Fibonacci(int n) {\n        if(F[n]!= 0) \n            return F[n];\n        if(n<=1) \n        {\n         \tF[n]=n;\n        \treturn F[n];\n        }\n        else\n        {\n            F[n]=Fibonacci(n-1)+Fibonacci(n-2);\n        \treturn F[n];\n        }\n    }\n};\n```\n```\n//思路3：迭代计算。\nclass Solution {\npublic:\n    int Fibonacci(int n) {\n    \tint num1=0;\n    \tint num2=1;\n    \tint num3;\n        if(n<=1) \n            return n;\n\t\tfor(int i = 2;i<=n;i++)\n        {\n            num3 = num1+num2;\n            num1 = num2;\n            num2 = num3;\n        }\n        return num3;\n    }\n};\n```\n## 2. 青蛙跳台阶问题（#10）\n**题目描述**\n一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n**思路**：类似斐波那契数列\nf(n)=　1, (n=1)\n　　　 2, (n=2)\n　　　 f(n-1)+f(n-2) ,(n>2,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int jumpFloor(int number) {\n        if(number<=0) return number; //defensive\n        if(number==1) return 1;\n        if(number==2) return 2;\n        return jumpFloor(number-1)+jumpFloor(number-2);\n    }\n};\n```\n## 3.变态跳台阶（#10）\n**题目描述**\n一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n**思路**：\n因为n级台阶，第一步有n种跳法：跳1级，跳2级，...，跳n级\n跳1级，剩下n-1级，则剩下跳法是f(n-1)\n跳2级，剩下n-2级，则剩下跳法是f(n-2)\n所以f(n)=f(n-1)+f(n-2)+...+f(1)+f(0)\n因为f(n-1)=f(n-2)+f(n-3)+...+f(1)+f(0)\n所以f(n)=2xf(n-1)\n故：\nf(n)=　1, (n=1)\n　　　 2xf(n-1),(n>1,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int jumpFloorII(int number) {\n        if(number<=0) return number; //defensive\n\t\tif(number==1) return 1;\n        return 2*jumpFloorII(number-1);\n    }\n};\n```\n## 4.矩形覆盖（#10）\n**题目描述**\n我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？\n**思路**：仍旧是斐波那契数列\n第一块有两种方式：横着放和竖着放。\n横着放后，覆盖方法为f(n-2)，因为下方也被占用，下方必须也横着放。\n竖着放后，覆盖方法为f(n-1);\n所以总的覆盖方法为f(n)=f(n-1)+f(n-2);\n故：\nf(n)=　1, (n=1)\n　　　 2, (n=2)\n　　　 f(n-1)+f(n-2) ,(n>2,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int rectCover(int number) {\n \t\tif(number<=0) return number; //defensive\n        if(number==1) return 1;\n        if(number==2) return 2;\n        return rectCover(number-1)+rectCover(number-2);\n    }\n};\n```\n\n# 九、回溯\n\n# 十、动态规划与贪婪算法\n\n\n\n\n\n","source":"_posts/剑指Offer解题记录.md","raw":"---\ntitle: 剑指Offer解题记录\ndate: 2017-12-1 9:19:49\nmathjax: true\ntop: true\ncategories: \n- 数据结构与算法\ntags:\n---\n注：该记录中解题答案均为在牛客网进行[在线编程测试](https://www.nowcoder.net/ta/coding-interviews)时的答案记录，故未自己写测试代码。\n\n# 一、链表\n## 1. 两个链表的第一个公共结点\n**题目描述**：\n输入两个链表，找出它们的第一个公共结点。\n**思路**：\n- **关键点**：如果两个单链表有公共的结点，那么这两个链表从某一结点开始，它们的`next`指针都指向同一个结点，又由于是单向链表的结点，每个结点只有一个`next`指针，因此**从第一个公共结点开始，之后它们所有的结点都是重合的，不再出现分叉**。\n- **思路1**：\n - 对于对于链表一上的每一个结点，顺序遍历链表二上的每一个结点。\n - 若第一个链表的长度为$m$，第二个链表的长度为$n$，那么时间复杂度为$O(mn)$。\n- **思路2**：\n - 分别把两个链表的结点放入栈里，这样两个链表的尾结点就位于两个栈的栈顶，接下来比较两个栈顶的结点是否相同。如果相同，则把栈顶弹出接着比较下一个栈顶，直到找到最后一个相同的结点。\n - 该思路需要用到两个辅助栈，如果链表的长度分别为$m$和$n$，那么空间复杂度是$O(m+n)$，时间复杂度是$O(m+n)$。和思路1相比，时间效率得到了提高，相当于用空间消耗换取了时间效率。\n- **思路3**：\n - 首先遍历两个链表得到它们的长度。在第二次遍历时，在较长的链表上先走若干步，接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点。\n - 与思路2相比，该思路的时间复杂度为$O(m+n)$，但不需辅助栈，因此提高了空间效率。\n\n <!-- more --> \n\n**代码**：\n```C++\n//思路3\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x):val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) \n    {\n    \tif(pHead1==nullptr || pHead2==nullptr)\n            return nullptr;\n        //首先遍历两个链表得到它们的长度\n        int length1,length2;\n        length1=length2= 0;\n        ListNode* pTemp1 = pHead1;\n        ListNode* pTemp2 = pHead2;\n        while(pTemp1!=nullptr)\n        {\n            length1++;\n            pTemp1 = pTemp1->next;\n        }\n        while(pTemp2!=nullptr)\n        {\n            length2++;\n            pTemp2 = pTemp2->next;\n        }\n        //在第二次遍历时，在较长的链表上先走若干步\n        pTemp1 = pHead1;\n        pTemp2 = pHead2;\n        if(length1>length2)\n        {\n            int dif = length1-length2;\n            for(int i = 0;i<dif;i++)\n            {\n                pTemp1 = pTemp1->next;\n            }\n        }\n        else\n        {\n            int dif = length2-length1;\n            for(int i = 0;i<dif;i++)\n            {\n                pTemp2 = pTemp2->next;\n            }\n        }\n        //接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点\n        ListNode* pResult = nullptr;\n        while(pTemp1!=nullptr && pTemp2!=nullptr)\n        {\n        \tif(pTemp1 == pTemp2)\n            {\n            \tpResult = pTemp1;\n                break;\n            }\n            else\n            {\n                pTemp1 = pTemp1->next;\n                pTemp2 = pTemp2->next;\n            }\n        }\n        return pResult;\n    }\n};\n```\n## 2. 链表中环的入口结点\n**题目描述**：\n一个链表中包含环，请找出该链表的环的入口结点。\n**思路**：\n- **核心思想**：假定有环且已知环的结点个数为$y$，令指针`pTemp1`从首结点开始先走$y$步，再令`pTemp2`从首结点开始同`pTemp1`一起向前走，相遇处，即为环的入口结点。\n- **证明**：假定环的结点个数为$y$，环之前的结点个数为$x$。`pTemp1`先走$y$步，然后`pTemp2`从首结点开始同`pTemp1`一起再走$x$步，则`pTemp2`在第$(x+1)$个结点处，`pTemp1`在第$(x+y+1)$个结点处。$(x+1)$结点位置和$(x+y+1)$结点位置都是环的入口结点位置。因此，依上述核心思想的步骤，`pTemp1`与`pTemp2`定会相遇，相遇处恰好为环的入口结点。\n- **环的结点个数求法**：首先，令一指针`pFast`一次走两步，一指针`pSlow`一次走一步，若相遇，则有环，且相遇处定在环内。然后，`pFast`不动，令一指针`pSlow`继续走且计数，当`pSlow`与`pFast`再次相遇，即得出环的结点个数。\n- 注意，代码中充斥着防止指针为空的情况，繁琐但必不可少。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* EntryNodeOfLoop(ListNode* pHead)\n    {\n        if(pHead==nullptr)\n            return nullptr;\n        //通过getNumberOfLoop()获取环的结点个数，0则无环；大于0则有环\n        ListNode* pTemp1, *pTemp2;\n        pTemp1 = pTemp2 = pHead;\n        int num = getNumberOfLoop(pHead);\n        //若环结点数等于0，直接返回nullptr\n        if(num==0) \n            return nullptr;\n        //依照核心思想执行，获取pTemp1与pTemp2相遇处指针\n        for(int i = 0;i<num;i++)\n        {\n            pTemp1 = pTemp1->next;\n        }\n        while(pTemp1!=pTemp2)\n        {\n            pTemp1 = pTemp1->next;\n            pTemp2 = pTemp2->next;\n        }\n        return pTemp1;\n    }\n    int getNumberOfLoop(ListNode* pHead)\n    {\n        //1.令pFast一次走两步，pSlow一次走一步，若相遇，则有环，且相遇处定在环内\n        int num = 0;\n        ListNode* pFast, *pSlow;\n        pFast = pSlow = pHead;\n        pFast=pFast->next;    //为了下个while循环的判断条件，pFast先走一步\n        while(pFast!=pSlow)\n        {\n            if(pFast==nullptr)\n                break;\n            pFast = pFast->next;\n            if(pFast==nullptr)\n                break;\n            pFast = pFast->next;\n            if(pSlow==nullptr)\n                break;\n            pSlow=pSlow->next;\n        }\n        if(pFast==nullptr || pSlow==nullptr)\n            num=0;\n        //2.pFast不动，令pSlow继续走且计数，当pSlow与pFast再次相遇，即得出环的结点个数\n        else\n        {\n            pSlow=pSlow->next; //为了下个while循环的判断条件，pSlow先走一步\n            num++;\n            while(pSlow!=pFast)\n            {\n                pSlow=pSlow->next;\n                num++;\n            }\n        }\n        return num;\n    }\n};\n```\n\n## 3. 反转链表\n**题目描述**：\n给出一个链表`1->2->3->nullptr`，这个翻转后的链表为`3->2->1->nullptr`\n**思路**：\n- **方法1**：迭代实现。维护三个指针`pPrev`,`pCurrent`,`pNext`，通过迭代完成链表的反转（画图使思路清晰）：\n - 起始情况：`pPrev`为`nullptr`，`pCurrent`指向`pHead`\n - 终止情况：`pPrev`指向链表尾元素，`pCurrent`为`nullptr`\n- **方法2**：递归实现。利用递归走到链表的末端，然后再更新每一个结点的`next`指针 ，实现链表的反转。\n- **方法3**：用栈实现。将链表结点指针全部压入栈中。头指针指向链表末尾结点。将栈中结点指针反串起来，栈中最后结点指针指向`nullptr`。\n\n**代码**：\n```C++\n//方法1：迭代实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* ReverseList(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return nullptr;\n        ListNode* pPre, *pCurrent, *pNext;\n        pPre=nullptr;\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        {\n            pNext = pCurrent->next;\n            pCurrent->next = pPre;\n            pPre = pCurrent;\n            pCurrent = pNext;\n        }\n        pHead=pPre;\n        return pHead;\n    }\n};\n```\n```C++\n//方法2：递归实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* ReverseList(ListNode* pHead) \n    {\n        //如果链表为空或者链表中只有一个元素\n        if(pHead==NULL || pHead->next==NULL) \n            return pHead;\n        //先反转后面的链表，走到链表的末端结点，返回末端结点，作为新的头结点，保存起来\n        ListNode* pHeadReverse=ReverseList(pHead->next);\n        //再将当前节点设置为后面节点的后续节点\n        pHead->next->next = pHead;\n        //当前节点指向NULL\n        pHead->next=NULL;\n        //返回新的头结点\n        return pHeadReverse;\n    }\n};\n```\n```C++\n//方法3：用栈实现\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode * reverse(ListNode * head) \n    {\n        // write your code here\n        //防御性编程\n        if(head==NULL) return NULL;\n        //1.将链表结点指针全部压入栈中\n        stack<ListNode*> stack1;\n        ListNode* temp = head;\n        while(temp!=NULL) \n        {\n            stack1.push(temp);\n            temp=temp->next;\n        }\n        //2.头指针指向链表末尾结点\n        temp = stack1.top();\n        head=temp;\n        //3.将栈中结点指针反串起来，栈中最后结点指针指向NULL\n        while(!stack1.empty())\n        {\n            ListNode* pNode1 = stack1.top();\n            stack1.pop();\n            if(stack1.empty())\n            {\n                pNode1->next=NULL;\n                break;\n            }\n            ListNode* pNode2 = stack1.top();\n            pNode1->next = pNode2;\n        }\n        return head;\n    }\n};\n\n```\n## 4. 合并两个排序的链表\n**题目**：输入两个递增排序的链表，合并这两个链表并使新链表中的结点仍然是按照递增排序的。\n**思路**：\n- 依照归并排序中的`merge`函数的思想，`merge`两个链表：\n - 1.比较两个链表的头结点，较小的作为新链表的头结点`pHeadNew`；\n - 2.归并两个链表，迭代比较，较小者作为新的尾结点`pTailNew`。\n - 注意，直接改动每一结点的`next`指针，故不需另外的辅助空间。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    ListNode* Merge(ListNode* pHead1, ListNode* pHead2)\n    {\n        //防御性编程：若输入链表有任一为空，返回另一个\n        if(pHead1==nullptr)\n            return pHead2;\n        if(pHead2==nullptr)\n            return pHead1;\n        //1.找出新链表的头结点pHeadNew\n        ListNode* pHeadNew = nullptr;\n        ListNode* pTemp1 = pHead1;\n        ListNode* pTemp2 = pHead2;\n        if(pTemp1->val < pTemp2->val)\n        {\n            pHeadNew = pTemp1;\n            pTemp1 = pTemp1->next;\n        }\n        else\n        {\n            pHeadNew = pTemp2;\n            pTemp2 = pTemp2->next;\n        }\n        //2.归并两个链表，迭代比较，较小者作为新的尾结点pTailNew\n        //直接改动每一结点的next指针，故不需另外的辅助空间\n        ListNode* pTailNew = pHeadNew; \n        while(pTemp1!=nullptr && pTemp2!=nullptr)\n        {\n            if(pTemp1->val < pTemp2->val)\n            {\n                pTailNew->next = pTemp1;\n                pTailNew = pTemp1;\n                pTemp1 = pTemp1->next;\n            }\n            else\n            {\n                pTailNew->next = pTemp2;\n                pTailNew = pTemp2;\n                pTemp2 = pTemp2->next;\n            }    \n        }\n        if(pTemp1!=nullptr) pTailNew->next = pTemp1;\n        if(pTemp2!=nullptr) pTailNew->next = pTemp2;\n        return pHeadNew;\n    }\n};\n```\n\n## 5. 从尾到头打印链表\n**题目描述**：\n输入一个链表的头结点，从尾到头反过来打印出每个结点的值。\n**思路**：\n- 首先，假定不能改变链表结构，故不采用迭代反转链表，然后后再打印链表的方法。\n- **方法1**：遍历的顺序是从头到尾，输出的顺序是从尾到头，是典型的“后进先出”，用栈实现这种顺序：\n - 遍历链表，每经过一个结点的时候，把该结点压入辅助栈中。\n - 当遍历完整个链表后，再从栈顶开始逐个输出结点的值。\n- **方法2**：用递归方法反向打印链表。既然可以用栈实现，而递归本质上就是一个栈结构，故可用递归来实现：\n - 每访问到一个结点，先递归输出它后面的结点，再输出该结点自身，这样链表的输出结果就反过来了。\n- 注意，虽然基于递归的代码看起来很简洁，但有一个问题：当链表非常长的时候，就会导致函数调用的层级很深，从而有可能导致函数调用栈溢出。显然用栈基于循环实现的代码的鲁棒性要好一些（存放于自由存储的堆区）。\n \n**代码**：\n```C++\n//方法1\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    vector<int> result;    \n    stack<ListNode*> s;\npublic:\n    vector<int> printListFromTailToHead(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return result;\n        //遍历链表，每经过一个结点的时候，把该结点压入辅助栈中\n        ListNode* pTemp = pHead;\n        while(pTemp!=nullptr)\n        {\n            s.push(pTemp);\n            pTemp = pTemp->next;\n        }\n        //当遍历完整个链表后，再从栈顶开始逐个输出结点的值\n        while(!s.empty())\n        {\n            pTemp = s.top();\n            result.push_back(pTemp->val);\n            s.pop();\n        }\n        return result;\n    }\n};\n```\n```C++\n//方法2\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    vector<int> result;    \npublic:\n    vector<int> printListFromTailToHead(ListNode* pHead) \n    {\n        if(pHead==nullptr)\n            return result;\n        printListFromTailToHead(pHead->next);\n        result.push_back(pHead->val);\n        return result;\n    }\n};\n```\n## 6. 复杂链表的复制\n**题目描述**\n输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）\n**思路**：\n- **步骤1**：复制原始链表的任意结点$N$并创建新结点$N'$，再把$N'$链接到$N$的后面。如原来是`A->B->C`，则变成`A->A'->B->B'->C->C'`。\n- **步骤2**：设置复制出来的结点的`random`指针。如果原始链表上的结点$N$的`random`指针指向$S$，则它对应的复制结点$N'$的`ramdon`指针指向$S$的复制结点$S'$。如`A1->random = A->random->next;`\n- **步骤3**：把长链表拆分成两个链表：把奇数位置的结点用`next`指针链接起来就是原始链表，把偶数位置的结点用`next`指针链接起来就是复制出来的链表。\n\n**代码**：\n```C++\n/*\nstruct RandomListNode \n{\n    int label;\n    struct RandomListNode *next, *random;\n    RandomListNode(int x) :label(x), next(NULL), random(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    RandomListNode* Clone(RandomListNode* pHead)\n    {\n        if(pHead==nullptr)\n            return nullptr;\n        RandomListNode* pCurrent = pHead;\n        //1.复制原始链表的任一节点N并创建新节点N'，再把N'链接到N的后边\n        while(pCurrent!=nullptr)\n        {\n            RandomListNode* pClone = new RandomListNode(pCurrent->label);\n            pClone->next = pCurrent->next;\n            pCurrent->next = pClone;\n            pCurrent = pClone->next;\n        }\n        //2.如果原始链表上的节点N的random指向S，则对应的复制节点N'的random指向S的下一个节点S'\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        {\n            RandomListNode* pClone = pCurrent->next;\n            if(pCurrent->random!=nullptr)\n                pClone->random = pCurrent->random->next;\n            pCurrent = pClone->next;\n        }\n        //3.把得到的链表拆成两个链表，奇数位置上的结点组成原始链表，偶数位置上的结点组成复制出来的链表\n        RandomListNode* pCloneHead=pHead->next;\n        pCurrent = pHead;\n        while(pCurrent!=nullptr)\n        { \n            RandomListNode* pClone = pCurrent->next;\n            pCurrent->next = pClone->next;\n            pCurrent = pCurrent->next;\n            //pCurrent为nullptr，即pClone->next为nullptr，不用再继续，拆分结束。\n            if(pCurrent==nullptr)\n                break;\n            pClone->next = pCurrent->next;\n        }\n        return pCloneHead;\n    }\n};\n```\n\n## 7. 链表中倒数第k个结点\n**题目**：\n输入一个链表，输出该链表中倒数第$k$个结点。本题从1开始计数，即链表的尾结点是倒数第1个结点。例如一个链表有6个结点，从头结点开始它们的值依次是1、2、3、4、5、6。这个链表的倒数第3个结点是值为4的结点。\n**思路**：\n- 递归遍历链表，返回时通过`count`计数，当`count==k`时，当前`pHead`即为倒数第$K$个结点。\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x):val(x), next(NULL) {}\n};*/\nclass Solution \n{\n    int count = 0;\n    ListNode* pTarget=nullptr;\npublic:\n    ListNode* FindKthToTail(ListNode* pHead, unsigned int k) \n    {\n        if(pHead==nullptr)\n            return nullptr;\n        Find(pHead,k);\n        return pTarget;\n    }\n    void Find(ListNode* pHead, unsigned int k)\n    {\n        if(pHead==nullptr)\n            return;\n        Find(pHead->next,k);\n        count++;\n        if(count==k)\n            pTarget = pHead;\n    }\n};\n```\n## 8. 删除链表中的重复结点\n**题目**：\n在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表`1->2->3->3->4->4->5`，处理后为`1->2->5`\n**思路**：\n\n**代码**：\n```C++\n/*\nstruct ListNode \n{\n    int val;\n    struct ListNode *next;\n    ListNode(int x) :val(x), next(NULL) {}\n};\n*/\nclass Solution\n {\npublic:\n    ListNode* deleteDuplication(ListNode* pHead)\n    {\n        // 只有0个或1个结点，则返回\n        if(pHead==nullptr || pHead->next==nullptr) \n            return pHead;\n        ListNode* pNext = pHead->next;\n        // 当前结点是重复结点\n        if(pHead->val == pNext->val)\n        {\n            // 跳过值与当前结点相同的全部结点,找到第一个与当前结点不同的结点\n            while(pNext!=nullptr && pNext->val==pHead->val)\n            {\n                pNext = pNext->next;\n            }\n            // 从第一个与当前结点不同的结点开始递归\n            return deleteDuplication(pNext);\n        }\n         // 当前结点不是重复结点\n        else\n        {\n            // 保留当前结点，从下一个结点开始递归\n            pHead->next = deleteDuplication(pHead->next);\n            return pHead;\n        }\n    }\n};\n```\n-----------\n# 二、栈和队列\n## 1. 用两个栈实现队列\n**题目**：用两个栈来实现一个队列，完成队列的`push`和`pop`操作。队列中的元素为`int`类型。\n**思路**：\n- 栈是后进先出，队列是先进先出。\n- 利用栈`stack1`负责`push`操作。\n- 利用栈`stack2`负责`pop`操作：先将`stack1`中所有元素弹出到`stack2`中，然后`stack2`出栈一个元素，最后`stack2`中所有元素弹出到`stack1`。\n\n**代码**：\n```C++\nclass Solution\n{\nprivate:\n    stack<int> stack1;\n    stack<int> stack2;\npublic:\n    //利用栈stack1负责入栈操作\n    void push(int node) \n    {\n        stack1.push(node);\n    }\n    //利用栈stack2负责出栈操作\n    int pop() \n    {\n        //先将stack1中所有元素弹出到stack2中\n        while(!stack1.empty())\n        {\n            int temp = stack1.top();\n            stack2.push(temp);\n            stack1.pop();\n        }\n        //然后stack2出栈一个元素\n        int result = stack2.top();\n        stack2.pop();\n        //最后stack2中所有元素弹出到stack1\n        while(!stack2.empty())\n        {\n            int temp = stack2.top();\n            stack1.push(temp);\n            stack2.pop();\n        }\n        return result;\n    }\n};\n```\n\n## 2. 包含min函数的栈\n**题目**：定义栈的数据结构，请在该类型中实现一个能够得到栈的最小元素的`min`函数。在该栈中，调用`min`、`push`及`pop`的时间复杂度都是$O(1)$。\n**思路**：\n- 题目要求的是栈在进行任何的入栈和出栈操作后，都能调用`min`函数返回最小值。两种思路不可行：\n - 定义一个变量`value`存储最小值。因为栈一旦`pop`后，不知道最小值是什么。\n - 每次进栈出栈都重新对栈内元素进行排序。因为复杂度太高。\n- 正确解法：采用一个辅助栈，其栈顶保存主栈当前的最小值。主栈每一次`push`，辅助栈都将主栈当前的最小值压入栈顶。主栈每一次`pop`，辅助栈都`pop`。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    stack<int> s1; //主栈\n    stack<int> s2; //辅助栈\npublic:\n    //主栈stack1每一次push，辅助栈stack2都将主栈当前的最小值压入栈顶\n    void push(int value) \n    {\n        if(s1.empty())\n        {\n            s1.push(value);\n            s2.push(value);\n        }\n        else if(value<s2.top())\n        {\n            s1.push(value);\n            s2.push(value);\n        }\n        else\n        {\n            s1.push(value);\n            s2.push(s2.top());\n        }\n    }\n    //主栈stack1每一次pop，辅助栈stack2都pop\n    void pop() \n    {\n        s1.pop();\n        s2.pop();\n    }\n    int top() \n    {\n        return s1.top();\n    }\n    int min() \n    {\n        return s2.top();\n    }\n};\n```\n## 3. 栈的压入、弹出序列\n**题目描述**\n输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列$1,2,3,4,5$是某栈的压入顺序，序列$4,5,3,2,1$是该压栈序列对应的一个弹出序列，但$4,3,5,1,2$就不可能是该压栈序列的弹出序列。\n**思路**：\n- 判断一个序列是不是栈的弹出序列的规律：\n - 如果下一个弹出的数字刚好是栈顶数字，那么直接弹出；\n - 如果下一个弹出的数字不在栈顶，则把压栈序列中还没有入栈的数字压入辅助栈，直到把下一个需要弹出的数字压入栈为止；\n - 如果所有数字都压入栈后仍然没有找到下一个弹出的数字，那么该序列不可能是一个弹出序列。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    stack<int> s;\npublic:\n    bool IsPopOrder(vector<int> pushV,vector<int> popV) \n    {\n        if(pushV.size()==0 || popV.size()==0)\n            return false;\n        int i=0; //标记pushV\n        int j=0; //标记popV\n        while(i<pushV.size())\n        {\n            s.push(pushV[i++]);\n            while(!s.empty() && s.top()==popV[j])\n            {\n                s.pop();\n                j++;\n            }\n        }\n        return s.empty();\n    }\n};\n```\n--------\n# 三、树\n## 1. 二叉树的深度\n**题目描述**:\n输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。\n**思路**：\n**解法1**：\n- 前序遍历二叉树，计算每一叶结点的深度，找出最大的叶结点的深度，即树的高度。\n- 在两种情况下，当前深度变量`currentDepth`进行减一操作：\n - 当前结点是叶结点，则将`currentDepth`与最大的叶结点深度`maxDepth`比较，更新`maxDepth`。之后，`currentDepth`进行减一操作；\n - 任一结点的左右子树遍历完成，`currentDepth`进行减一操作。\n- 注：该题规定空树深度为0，根结点深度为1。\n\n**解法2**：\n- 将结点的深度从该角度计算：后序遍历时，结点的左右子树的深度较大值加一。\n- 因此，树的深度可以这样计算：后序遍历二叉树，较大子树的深度值加一。\n\n**代码**：\n```C++\n//解法1\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    int maxDepth=0;\n    int currentDepth=0;\npublic:\n    int TreeDepth(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return maxDepth;\n        currentDepth++;\n        //当前结点是叶结点\n        if(pRoot->left==nullptr && pRoot->right==nullptr)\n        {\n            //更新maxDepth\n            if(currentDepth>maxDepth)\n            {\n                maxDepth = currentDepth;\n            }\n            //currentDepth进行减一操作\n            currentDepth--;\n            return maxDepth;\n        }\n        TreeDepth(pRoot->left);\n        TreeDepth(pRoot->right);\n        //任一结点的左右子树遍历完成，currentDepth进行减一操作\n        currentDepth--;\n        return maxDepth;\n    }\n};\n```\n```C++\n//解法2\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    //递归后序遍历二叉树\n    int TreeDepth(TreeNode* pRoot)\n    {\n        //递归出口条件：若pRoot为nullptr，则返回0\n        if(pRoot==nullptr)\n            return 0;\n    \tint left=TreeDepth(pRoot->left);\n        int right=TreeDepth(pRoot->right);\n        //较大子树的深度值加一\n        if(left>right)\n            return left+1;\n        else\n            return right+1;\n    }\n};\n```\n## 2. 二叉树的镜像\n**题目描述**:\n操作给定的二叉树，将其变换为源二叉树的镜像。\n**输入描述**:\n二叉树的镜像定义：\n```\n源二叉树 \n    \t    8\n    \t   /  \\\n    \t  6   10\n    \t / \\  / \\\n    \t5  7 9  11\n镜像二叉树\n    \t    8\n    \t   /  \\\n    \t  10   6\n    \t / \\  / \\\n    \t11 9 7   5\n```\n**思路**：\n- 前序遍历二叉树，“访问”操作为：交换每一结点的左右子树（左右子树是`nullptr`也没关系，照样交换）。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    void Mirror(TreeNode *pRoot) \n    {\n        if(pRoot==nullptr)\n            return;\n        //交换左右子树\n        TreeNode* temp = pRoot->left;\n        pRoot->left = pRoot->right;\n        pRoot->right = temp;\n        Mirror(pRoot->left);\n        Mirror(pRoot->right);\n    }\n};\n```\n\n## 3. 平衡二叉树\n**题目描述**\n输入一棵二叉树，判断该二叉树是否是平衡二叉树。注意，空树默认为平衡二叉树。\n**思路**：\n- 依据#1题<二叉树的深度>中解法2的思想，将平衡二叉树的判断准则定为：每一结点的左右子树的深度值相差不超过1。\n- 后序遍历二叉树，计算每一结点的左右子树的深度，比较差值。\n\n**代码**：\n```C++\nclass Solution \n{\nprivate:\n    bool result=true;\npublic:\n    bool IsBalanced_Solution(TreeNode* pRoot) \n    {\n        if(pRoot==nullptr)\n            return true;\n        TreeDepth(pRoot);\n        return result;\n    }\n    //后序遍历二叉树，计算树的深度\n    int TreeDepth(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return 0;\n        int left = TreeDepth(pRoot->left);\n        int right = TreeDepth(pRoot->right);\n        //比较左右子树深度的差值\n        if(abs(left-right)>1)\n            result = false;\n        //计算每一结点的左右子树的深度\n        if(left>right)\n            return left+1;\n        else\n            return right+1;\n    }\n};\n```\n\n## 4. 把二叉树打印成多行\n**题目描述**：\n从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。\n**思路**：\n- 层序遍历二叉树，在每一层末尾加入一个换行符。\n- 通过变量`toBePrinted`记录当前层要打印结点个数,`nextLevel`记录下一层要打印结点个数。\n- 对于根结点，`toBePrinted`为1，在将根结点的左右子结点入队时记录`nextLevel`。\n- 当`toBePrinted`为0，则打印一个换行，`toBePrinted`置为`nextLevel`，`nextLevel`清零。接着，开始处理下一层。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    int toBePrinted=1;\n    int nextLevel = 0;\n    queue<TreeNode*> q; \n    vector<int> level;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> Print(TreeNode* pRoot) \n    {\n        if(pRoot==nullptr)\n            return result;\n        q.push(pRoot);\n        while(!q.empty())\n        {\n            TreeNode* pCurrent = q.front();\n            q.pop();\n            toBePrinted--;\n            level.push_back(pCurrent->val);\n            if(pCurrent->left!=nullptr)\n            {\n                q.push(pCurrent->left);\n                nextLevel++;\n            }\n            if(pCurrent->right != nullptr)\n            {\n                q.push(pCurrent->right);\n                nextLevel++;\n            }\n            if(toBePrinted==0)\n            {\n                toBePrinted=nextLevel;\n                nextLevel=0;\n                result.push_back(level);\n                level.clear();\n            }\n        }\n        return result; //注意，最后要return\n    }\n};\n```\n\n## 5. 对称的二叉树\n**题目描述**:\n请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。\n**思路**：\n- 一开始的想法：构建该二叉树的镜像二叉树，然后同时遍历两个树，逐一进行比较。但空间复杂度为$O(n)$，不可行。\n- 正确解法：前序遍历是`<root><left><right>`。定义一种新的和前序遍历对称的遍历方式`<root><right><left>`。对于对称的二叉树，前序遍历的结果，和新定义的遍历方式的结果应该是一样的。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    bool isSymmetrical(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return true;\n        return treversal(pRoot, pRoot);\n    }\n    bool treversal(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr && pRoot2==nullptr)\n            return true;\n        if(pRoot1==nullptr || pRoot2==nullptr)\n            return false;\n        if(pRoot1->val!=pRoot2->val)\n            return false;\n        bool result1=treversal(pRoot1->left, pRoot2->right);\n        bool result2=treversal(pRoot1->right, pRoot2->left);\n        return result1 && result2;\n    }\n};\n```\n\n## 6. 二叉树的下一个结点\n**题目描述**:\n给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，**同时包含指向父结点的指针**。\n**思路**：\n- 在中序遍历顺序`<left，root，right>`下，二叉树某一结点`pNode`的下一个结点规律如下：\n - 如果`pNode`含有右子树，则下一结点为`pNode`的**右子树中最深最左的那个结点**。\n - 如果`pNode`不含右子树，则下一结点为**使得`pNode`在其左子树中的最近的祖先结点**。\n 注：最极端情况是`pNode`是二叉树中序遍历的最后一个结点，即在二叉树的最右末端，直到回溯到根结点，`pNode`还是在右子树中，即没有满足题意的下一结点。根结点的父节点为`nullptr`，祖先结点为`nullptr`也是终止循环条件之一。\n \n**代码**：\n```C++\n/*\nstruct TreeLinkNode \n{\n    int val;\n    struct TreeLinkNode *left;\n    struct TreeLinkNode *right;\n    struct TreeLinkNode *next;\n    TreeLinkNode(int x) :val(x), left(NULL), right(NULL), next(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    TreeLinkNode* pNext=nullptr; //记录目标结点\npublic:\n    TreeLinkNode* GetNext(TreeLinkNode* pNode)\n    {\n        if(pNode==nullptr)\n            return nullptr;\n        //如果pNode含有右子树，则下一结点为pNode的右子树中最深最左的那个结点\n        if(pNode->right!=nullptr)\n        {\n            pNext=pNode->right;\n            while(pNext->left!=nullptr)\n            {\n                pNext=pNext->left;\n            }\n        }\n        //如果pNode不含右子树，则下一结点为使得pNode在其左子树中的最近的祖先结点\n        else if(pNode->right==nullptr)\n        {\n            TreeLinkNode* pParent = pNode->next;\n            //最极端情况：若到根节点还没找到\n            while(pParent!=nullptr)\n            {\n                if(pParent->left==pNode)\n                {\n                    pNext=pParent;\n                    break;\n                }\n                else\n                {\n                    pNode = pParent;\n                    pParent=pParent->next;\n                }\n            }\n        }\n        return pNext;\n    }\n};\n```\n\n## 7. 二叉搜索树与双向链表\n**题目描述**：\n输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。\n**思路**：\n- 首先，二叉搜索树的中序遍历结果即为有序序列。\n- 然后，在中序遍历的“访问”操作中进行如下操作完成双向链表的转换：\n - 维护双向链表的尾结点`pLastNode`，初始化为`nullptr`。 \n - 当前结点的`left`指针指向`pLastNode`，`pLastNode`的`right`指针指向当前结点，更新`pLastNode`。\n - 最终结果： `nullptr<-1<=>2<=>3<=>4<=>5->nullptr`（自己画图即可知）。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    TreeNode* Convert(TreeNode* pRoot)\n    {\n        if(pRoot==nullptr)\n            return nullptr;\n        //pLastNode表示双向链表中的最后一个结点\n        TreeNode* pLastNode=nullptr;\n        InorderTraversal(pRoot,&pLastNode);\n        TreeNode* pHead=pLastNode;\n        //找出双向链表中的头结点，并返回\n        while(pHead->left!=nullptr)\n        {\n            pHead=pHead->left;    \n        }\n        return pHead;\n    }\n    //中序遍历二叉搜索树\n    void InorderTraversal(TreeNode* pRoot,TreeNode** pLastNode)\n    {\n        if(pRoot==nullptr)\n            return;\n        InorderTraversal(pRoot->left,pLastNode);\n        //如果pLastNode为nullptr\n        if(*pLastNode==nullptr)\n        {\n            pRoot->left=*pLastNode;     //当前结点的left指针指向链表中最后一个结点\n            *pLastNode=pRoot;           //更新链表中最后一个结点\n        }\n        else\n        {\n            pRoot->left=*pLastNode;     //当前结点的left指针指向链表中最后一个结点\n            (*pLastNode)->right=pRoot;  //链表中最后一个结点的right指针指向当前结点\n            *pLastNode=pRoot;           //更新链表中最后一个结点\n        }\n        InorderTraversal(pRoot->right,pLastNode);\n    }\n};\n```\n\n## 8. 从上往下打印二叉树\n**题目描述**:\n从上往下打印出二叉树的每个节点，同层节点从左至右打印。\n**思路**：\n- 层序遍历二叉树。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    queue<TreeNode*> q;\n    vector<int> v;\npublic:\n    vector<int> PrintFromTopToBottom(TreeNode* root) \n    {\n        if(root == nullptr) \n            return v;\n        q.push(root);\n        while(!q.empty())\n        {\n            TreeNode* pCurrent = q.front();\n            q.pop();\n            v.push_back(pCurrent->val);\n            if(pCurrent->left!=nullptr)\n                q.push(pCurrent->left);\n            if(pCurrent->right!=nullptr)\n                q.push(pCurrent->right);\n        }\n        return v;\n    }\n};\n```\n## 9. 二叉树中和为某一值的路径\n**题目描述**:\n输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。\n**思路**：\n- 前序遍历二叉树，计算每一路径和，与期望值进行比较。\n- 在两种情况下，从当前状态存储变量（`currentSum`及 `path`）中移去当前结点：\n - 当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点(`path.pop_back()`,`currentSum-=root->val`)；\n - 任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点(`path.pop_back()`,`currentSum-=root->val`)。\n \n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    int currentSum=0;\n    vector<int> path;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> FindPath(TreeNode* root,int expectNumber) \n    {\n        if(root==nullptr)\n            return result;\n        preOrder(root,expectNumber);\n        return result;\n    }\n    //前序遍历二叉树，计算每一路径和。\n    void preOrder(TreeNode* root, int expectNumber)\n    {\n        if(root==nullptr)\n            return;\n        path.push_back(root->val);\n        currentSum+=root->val;\n        //1.当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点；\n        if(root->left==nullptr && root->right==nullptr)\n        {\n            if(currentSum==expectNumber)\n            {\n                result.push_back(path);\n            }\n            //下面该段可都不写，都留给情况2去处理，但若写，就需要return，否则会处理两次。\n            if(path.size()>0)\n                path.pop_back();\n            currentSum-=root->val;\n            return; //注意，需要return\n        }\n        preOrder(root->left,expectNumber);\n        preOrder(root->right,expectNumber);\n        //2.任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点。\n        currentSum-=root->val;\n        if(path.size()>0)\n            path.pop_back();\n    } \n};\n```\n\n## 10. 按之字形顺序打印二叉树\n**题目描述**：\n请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。\n**思路**：\n- 按之字形顺序打印二叉树需要两个栈。\n- 若当前打印的是奇数层（如第1层、第3层），则先保存左子节点再保存右子节点到第一个栈。\n- 若当前打印的是偶数层（如第2层、第4层），则先保存右子节点再保存左子节点到第二个栈。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    stack<TreeNode*> s1;\n    stack<TreeNode*> s2;\n    vector<int> level;\n    vector<vector<int>> result;\npublic:\n    vector<vector<int>> Print(TreeNode* pRoot) \n    {\n        if(pRoot==NULL) \n            return result;\n        s1.push(pRoot);\n        while(!s1.empty()||!s2.empty())\n        {\n            if(!s1.empty())\n            {\n                while(!s1.empty())\n                {\n                    TreeNode* pTemp = s1.top();\n                    s1.pop();\n                    level.push_back(pTemp->val);\n                    if(pTemp->left!=nullptr)\n                        s2.push(pTemp->left);\n                    if(pTemp->right!=nullptr)\n                        s2.push(pTemp->right);\n                }\n                result.push_back(level);\n                level.clear();\n            }\n            if(!s2.empty())\n            {\n                while(!s2.empty())\n                {\n                    TreeNode* pTemp = s2.top();\n                    s2.pop();\n                    level.push_back(pTemp->val);\n                    if(pTemp->right!=nullptr)\n                        s1.push(pTemp->right);\n                    if(pTemp->left!=nullptr)\n                        s1.push(pTemp->left);                 \n                }\n                result.push_back(level);\n                level.clear();\n            }\n        }\n        return result;\n    }\n};\n```\n\n## 11. 二叉搜索树的第k个结点\n**题目描述**:\n给定一颗二叉搜索树，请找出其中的第$k$大的结点。例如， 5 / \\ 3 7 / \\ / \\ 2 4 6 8 中，按结点数值大小顺序第三个结点的值为4。\n**思路**：\n- 中序遍历BST可得有序序列。\n- 在中序遍历的“访问”操作中计数。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\nprivate:\n    int num=0;\n    TreeNode* pNode=nullptr;\npublic:\n    TreeNode* KthNode(TreeNode* pRoot, int k)\n    {\n        if(pRoot==nullptr)\n            return pNode;\n        KthNode(pRoot->left,k);\n        //在“访问”操作中计数\n        num++;\n        if(num==k)\n        {\n            pNode=pRoot; \n            return pNode;\n        }\n        KthNode(pRoot->right,k);\n        return pNode;\n    }\n};\n```\n\n## 12. 二叉搜索树的后序遍历序列\n**题目描述**：\n输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。\n**思路**：\n- 后序遍历顺序：`<left，right，root>`。\n- 对于二叉搜索树的后续遍历序列，如果去掉最后一个元素x（也就是根）的序列为T，那么T满足：T可以分成两段，前一段（左子树）小于x，后一段（右子树）大于x，且这两段（子树）都是合法的后序序列。\n- 故以该规律，递归验证每一左右子树。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    bool VerifySquenceOfBST(vector<int> sequence) \n    {\n        if(sequence.empty())\n            return false;\n        return Check(sequence,0,sequence.size()-1);\n    }\n    bool Check(vector<int> sequence, int start, int end)\n    {\n        //递归出口条件1：一个或零个元素，返回true\n        if(start>=end)\n            return true;\n        int rootVal = sequence[end];\n        //分出左子树\n        int i = start;\n        for(;i<end;i++)\n        {\n            if(sequence[i]>rootVal)\n                break;\n        }\n        //验证右子树中所有元素都大于root值\n        for(int j = i;j<end;j++)\n        {\n            //递归出口条件2：右子树中存在小于root值的元素\n            if(sequence[j]<rootVal)\n            {\n                return false;\n            }\n        }\n        //递归验证左右子树，需都返回true\n        bool result1 = Check(sequence,start,i-1);\n        bool result2 = Check(sequence,i,end-1);\n        return result1 && result2;\n    }\n};\n```\n\n## 13. 树的子结构\n**题目描述**:\n输入两棵二叉树A，B，判断B是不是A的子结构。此外，约定空树不是任意一个树的子结构。\n**思路**：\n- 遍历树A，在树A中找出所有与树B的根节点值相等的结点，保存至vector容器`v`中。\n- 函数`bool Check(TreeNode* pTest, TreeNode* pRoot2)`：检验以`pTest`为根结点的树是否包含树B。**注意，左右子树都需返回`true`**。\n- 对于容器`v`中所有的`pTest`结点，逐一进行检验，**只要有一个成立即可**，即包含。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\nprivate:\n    vector<TreeNode*> v;\npublic:\n    bool HasSubtree(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr || pRoot2==nullptr)\n            return false;\n        //在树A中找出所有与树B的根节点值相等的结点，保存至容器v中\n        Find(pRoot1,pRoot2);\n        bool result = false;\n        //对于容器v中所有的pTest结点，逐一进行检验\n        for(int i = 0;i<v.size();i++)\n        {\n            result = Check(v[i],pRoot2);\n            //只要有一个成立即可，即包含\n            if(result==true) \n                break;\n        }\n        return result;\n    }\n    void Find(TreeNode* pRoot1, TreeNode* pRoot2)\n    {\n        if(pRoot1==nullptr)\n            return;\n        if(pRoot1->val==pRoot2->val)\n            v.push_back(pRoot1);\n        Find(pRoot1->left,pRoot2);\n        Find(pRoot1->right,pRoot2);\n    }\n    bool Check(TreeNode* pTest, TreeNode* pRoot2)\n    {\n        if(pTest==nullptr && pRoot2==nullptr)\n            return true;\n        if(pTest==nullptr)\n            return false;\n        if(pRoot2==nullptr)\n            return true;\n        if(pTest->val!=pRoot2->val)\n            return false;\n        bool result1 = Check(pTest->left,pRoot2->left);\n        bool result2 = Check(pTest->right,pRoot2->right);\n        return result1 && result2;\n    }\n};\n```\n\n## 14. 重建二叉树\n**题目描述**:\n输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列$$\\{1,2,4,7,3,5,6,8\\}$$和中序遍历序列$$\\{4,7,2,1,5,3,8,6\\}$$，则重建二叉树并返回。\n**思路**：\n- 首先，前序遍历序列的首元素给出根结点；然后，通过中序遍历序列得出左右子树长度；最后，可分割出左右子树各自的前序序列和中序序列。\n- 分别递归重建左子树和右子树，递归终止条件：\n - 当序列中只剩一元素(`start==end`)时，返回该根结点指针；\n - 当序列中无元素(`start>end`)时，返回`nullptr`。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};*/\nclass Solution \n{\npublic:\n    TreeNode* reConstructBinaryTree(vector<int> pre,vector<int> vin) \n    {\n        if(pre.empty() || vin.empty() || pre.size()!=vin.size())\n            return nullptr;\n        return reConstruct(pre, 0, pre.size()-1,vin,0, vin.size()-1);\n    }\n    TreeNode* reConstruct(vector<int> pre, int preStart, int preEnd,vector<int> vin,int vinStart, int vinEnd)\n    {\n        //递归出口条件1：当序列中只剩一结点，返回该结点指针\n        if(preStart==preEnd)\n        {\n            TreeNode* pNode = new TreeNode(pre[preStart]);\n            return pNode;\n        }\n        //递归出口条件2：当序列无结点时，返回nullptr\n        if(preStart>preEnd)\n            return nullptr;\n        //前序遍历序列的首元素给出根结点\n        int rootVal = pre[preStart];\n        TreeNode* pRoot = new TreeNode(rootVal);\n        //通过中序遍历序列得出左右子树长度\n        int i = vinStart;\n        for(;i<vinEnd;i++)\n        {\n            if(vin[i]==rootVal)\n                break;\n        }\n        int leftLength = i-vinStart; int rightLength = vinEnd-i;\n        //分割出左右子树各自的前序序列和中序序列\n        int preStartLeft = preStart+1;int preEndLeft=preStartLeft+leftLength-1;\n        int vinStartLeft=vinStart;int vinEndLeft=i-1;\n        int preStartRight = preEndLeft+1;int preEndRight=preEnd;\n        int vinStartRight = i+1;int vinEndRight=vinEnd;\n        //分别递归重建左子树和右子树\n        pRoot->left = reConstruct(pre,preStartLeft,preEndLeft,vin,vinStartLeft,vinEndLeft);\n        pRoot->right =reConstruct(pre,preStartRight,preEndRight,vin,vinStartRight,vinEndRight);\n        return pRoot;\n    }\n};\n```\n\n## 15. 序列化二叉树\n**题目描述**：\n请实现两个函数，分别用来序列化和反序列化二叉树\n**思路**：\n- 对于序列化：\n - 使用前序遍历，递归的将二叉树的值转化为字符，并且在每次二叉树的结点不为空时，在转化val所得的字符之后添加一个`'，'`作为分割。对于空节点则以 `'#'` 代替。\n- 对于反序列化：\n - 按照前序顺序，递归的使用字符串中的字符创建左右子树。注意：在递归时，递归函数的参数一定要是`char **`，这样才能保证每次递归后指向字符串的指针会随着递归的进行而移动。\n\n**代码**：\n```C++\n/*\nstruct TreeNode \n{\n    int val;\n    struct TreeNode *left;\n    struct TreeNode *right;\n    TreeNode(int x) :val(x), left(NULL), right(NULL) {}\n};\n*/\nclass Solution \n{\npublic:\n    char* Serialize(TreeNode *root) \n    {    \n        if(root==nullptr)\n            return nullptr;\n        string str;\n        Serialize2(root,str);\n        char* result = new char[str.size()+1];\n        for(int i = 0;i<str.size();i++)\n            result[i] = str[i];\n        result[str.size()] = '\\0';\n        return result;\n    }\n    void Serialize2(TreeNode* root, string& str)\n    {\n        if(root==nullptr)\n        {\n            str+='#';\n            return;\n        }\n        string r = to_string(root->val);\n        str+=r;\n        str+=',';\n        Serialize2(root->left, str);\n        Serialize2(root->right, str);\n    }\n    TreeNode* Deserialize(char *str) \n    {\n        if(str==nullptr)\n            return nullptr;\n        TreeNode* result = Deserialize2(&str);\n        return result;\n    }\n    TreeNode* Deserialize2(char** str) \n    {\n        if(**str=='#')\n        {\n            (*str)++;\n            return nullptr;\n        }\n        int num=0;\n        while(**str!= '\\0' && **str!=',')\n        {\n            num=num*10+((**str)-'0');\n            (*str)++;\n        }\n        TreeNode* pRoot = new TreeNode(num);\n        if(**str =='\\0')\n            return pRoot;\n        else\n            (*str)++;\n        pRoot->left = Deserialize2(str);\n        pRoot->right= Deserialize2(str);\n        return pRoot;\n    }\n};\n```\n---------\n# 四、字符串\n## 1. 替换空格\n**题目描述**：\n请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为\"We Are Happy.\"则经过替换之后的字符串为\"We%20Are%20Happy.\"\n**思路**：\n- **注意**：假设在原来的字符串上进行替换，并保证输入的字符串后面有足够多的空余内存。\n- **步骤**：从后向前替换：\n - 1.遍历字符串，得到原字符串的长度和空格的个数;\n - 2.计算新字符串的长度，新串长度为原串长度加上两倍的空格个数；\n - 3.从后向前替换：设置两个指针，p1指向原字符串末尾，p2指向新字符串末尾。前移指针p1，逐个把它指向的内容复制到p2指向的位置；\n- 所有字符串都只复制一次，时间复杂度：O(n)。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    void replaceSpace(char *str,int length) \n    {\n        if(str==nullptr || length<1)\n            return;\n        //1.遍历字符串，得到空格的个数\n        int numSpace = 0;\n        for(int i = 0;i<length;i++)\n        {\n            if(str[i]==' ')\n                numSpace++;\n        }\n        //2.计算新字符串的长度\n        int lengthNew = length+2*numSpace;\n        //3.从后向前替换：设置两个指针，i指向原字符串末尾，j指向新字符串末尾\n        int i = length-1;\n        int j = lengthNew-1;\n        //终止条件，i<0\n        while(i>=0)\n        {\n            if(str[i]==' ')\n            {\n                str[j--] = '0';\n                str[j--] = '2';\n                str[j--] = '%';\n                i--;\n            }\n            else\n            {\n                str[j--] = str[i--];\n            }\n        }\n    }\n};\n```\n## 2. 整数中1出现的次数（从1到n整数中1出现的次数）\n**题目描述**\n求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。\n**思路**：\n- 对1~n的每一个数：通过对10求余数判断整数的个位数字是不是1，如果这个数字大于10，则除以10之后再判断个位数字是不是1。\n- 对每个数字都要做除法和求余运算，以求出该数字中1出现的次数。如果输入数字为$n$，$n$有$O(logn)$位，我们需要判断每一位是不是1，那么它的时间复杂度是$O(nlogn)$。\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    int NumberOf1Between1AndN_Solution(int n)\n    {\n    \tint number=0;\n        for(unsigned int i = 1;i<=n;i++)\n            number+=NumberOf1(i);\n        return number;\n    }\n    int NumberOf1(unsigned int n)\n    {\n        int number=0;\n        while(n)\n        {\n            if(n%10 ==1)\n                number++;\n            n=n/10;\n        }\n        return number;\n    }\n};\n```\n## 3. 翻转单词顺序列\n**题目描述**:输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串\"I am a student.\"，则输出\"student. a am I\"。 \n**思路**：\n- 第一步翻转句子中所有的字符。比如翻转\"I am a student.\"中所有的字符得到\".tenduts a ma I\"，此时不但翻转了句子中单词的顺序，连单词内的字符顺序也被翻转了。\n- 第二步再翻转每个单词中字符的顺序，就得到了“studnet. a am I”。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    string ReverseSentence(string str) \n    {\n        //1.先整体翻转\n        ReverseWord(str,0,str.size()-1);\n        int i,start,end;\n        i=start=end=0;\n        while(i<str.size())\n        {\n            //空格跳过\n            while(i<str.size() && str[i]==' ')\n            {\n                i++;\n            }\n            //不是空格，找单词最后一个字符的位置\n            start = end = i;\n            while(i<str.size() && str[i]!=' ')\n            {\n                i++;\n                end++;\n            }\n            //2.局部翻转\n            ReverseWord(str,start,end-1);\n        }\n        return str;\n    }\n    void ReverseWord(string& str, int start, int end)\n    {\n        while(start<end)\n        {\n            swap(str[start++],str[end--]);\n        }\n    }\n};\n```\n## 4. 左旋转字符串\n**题目描述**\n汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！\n**思路**：\n-  以\"abcdefg\"为例，想把它的前两个字符移到后面，得到\"cdefgab\"。\n- 将前两个字符分到第一部分，将后面的所有字符分到第二部分。\n- 先分别翻转这两部分，于是得到“bagfedc”。\n- 接下来翻转整个字符串，得到“cdefgab”，刚好就是把原始字符串左旋转两位的结果。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    string LeftRotateString(string str, int n) \n    {\n        if(str.size()<1 || n>str.size() || n<0)\n            return str;\n        int startFirst = 0;\n        int endFirst = n-1;\n        int startSecond = n;\n        int endSecond = str.size()-1;\n        // 翻转字符串的前面n个字符\n        ReverseWord(str,startFirst,endFirst);\n        // 翻转字符串的后面部分\n        ReverseWord(str,startSecond,endSecond);\n        // 翻转整个字符串\n        ReverseWord(str,0,str.size()-1);\n        return str;\n    }\n    void ReverseWord(string& str, int start, int end)\n    {\n        while(start<end)\n        {\n            char temp = str[start];\n            str[start] = str[end];\n            str[end] = temp;\n            start++;\n            end--;\n        }\n    }\n};\n```\n## 5. 把字符串转换成整数\n**题目描述**\n将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0\n**输入描述**:\n输入一个字符串,包括数字字母符号,可以为空\n**输出描述**:\n如果是合法的数值表达则返回该数字，否则返回0\n**示例**:\n输入:\n+2147483647\n    1a33\n输出:\n2147483647\n    0\n**思路**：\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    \n    int StrToInt(string str) {\n        const char* cstr = str.c_str();\n        long long num = 0;\n        if((cstr != NULL) && (*cstr!= '\\0')) //字符串不为空\n        {\n            bool minus = false; //检查第一位是否为正负号\n            if(*cstr=='+')\n                cstr++;\n            else if(*cstr=='-')\n            {\n                cstr++;\n                minus = true;\n            }\n            if(*cstr!='\\0')\n                num = StrToIntCore(cstr,minus);\n        }\n        return num;\n    }\n    long long StrToIntCore(const char* digit, bool minus)\n    {\n        long long num = 0;\n        while(*digit!='\\0')\n        {   \n            //计算数字大小\n            if(*digit>='\\0' && *digit<='9')\n            {\n                int flag = minus? -1:1;\n                num = num*10+flag*(*digit-'0');\n                //溢出判断\n                if((!minus && num>0x7FFFFFFF) || (minus && num<(signed int)0x80000000))\n                {\n                    num=0;\n                    break;\n                }\n         \t\tdigit++;\n            }\n            //非法输入\n            else\n            {\n                num=0;\n                break;\n            }\n        }\n\t\treturn num;        \n    }\n};\n```\n\n\n## 6. 正则表达式匹配\n**题目描述**:\n请实现一个函数用来匹配包括'.'和'\\*'的正则表达式。模式中的字符'.'表示任意一个字符，而'\\*'表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串\"aaa\"与模式\"a.a\"和\"ab\\*ac\\*a\"匹配，但是与\"aa.a\"和\"ab\\*a\"均不匹配\n**思路**：\nA：下一个字符是`*`\n　　1.若当前字符匹配\n　　　　选择1：匹配了，但我当作0匹配(匹配0次)。`s不动，p加2`\n　　　　选择2：匹配了，匹配结束(匹配1次)。`s+1,p+2`\n　　　　选择3：匹配了，我继续匹配下一个(匹配多次)。`s+1，p不动`\n　　2.当前字符不匹配。`s不动，p加2`\nB:下一个字符不是`*`，当前字符匹配。`s+1,p+1`\nC:下一个字符不是`*`，当前字符不匹配。`返回false`\n递归出口条件：\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool match(char* str, char* pattern)\n    {\n    \tif(str==NULL || pattern==NULL)\n        \treturn false;\n        return matchCore(str,pattern);\n    }\n    bool matchCore(char* str, char* pattern)\n    {\n        //递归出口条件:字符串和模式串同时走完\n        if(*str=='\\0' && *pattern=='\\0')\n            return true;\n        //递归出口条件：字符串没走完，模式串走完，返回false\n        if(*str!='\\0' && *pattern=='\\0')\n            return false;\n        //A：下一个字符是*\n        if(*(pattern+1)=='*') \n        {\n            //1.若当前字符匹配\n            if(*pattern==*str || (*pattern=='.' && *str!='\\0'))\n            \treturn matchCore(str,pattern+2)    //选择1：匹配了，但我当作0匹配(匹配0次)\n            \t\t|| matchCore(str+1,pattern+2)  //选择2：匹配了，匹配结束(匹配1次)    \t\n            \t\t|| matchCore(str+1,pattern);    //选择3：匹配了，我继续匹配下一个(匹配多次)\n            //2.当前字符不匹配\n            else \n            \treturn matchCore(str,pattern+2); //匹配结束\n        }\n        //B:下一个字符不是*，当前字符匹配\n        if(*pattern==*str || (*pattern=='.' && *str!='\\0'))\n             \treturn matchCore(str+1,pattern+1);\n        //C:下一个字符不是*，当前字符不匹配\n\t\treturn false;           \n    }\n};\n```\n## 7. 表示数值的字符串\n**题目描述**\n请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串\"+100\",\"5e2\",\"-123\",\"3.1416\"和\"-1E-16\"都表示数值。 但是\"12e\",\"1a3.14\",\"1.2.3\",\"+-5\"和\"12e+4.3\"都不是。\n**思路**：\n- 表示数值的字符串: A`.`B`e/E`C 例如：“+123.45e+6”\n - 其中，A、C可能是以+/-开头的0~9的数位串，即整型；B也是0~9的数位串，但前面不能有正负号，即无符号整型。\n- 故步骤为：扫描A部分；遇到小数点`.`，扫描B部分；遇到`e/E`，扫描C部分。\n\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool isNumeric(char* str)\n    {\n        if(str==NULL)\n            return false;\n        bool numeric = scanInteger(&str);\n        if(*str=='.')\n        {\n            ++str;\n            numeric = scanUnsignedInteger(&str) || numeric;\n        }\n        if(*str=='e' || *str=='E')\n        {\n            ++str;\n            numeric = numeric && scanInteger(&str);\n        }\n        return numeric && *str=='\\0';\n    }\n\tbool scanInteger(char** str)\n    {\n        if(**str=='+' || **str=='-')\n            ++(*str);\n        return scanUnsignedInteger(str);\n    }\n    bool scanUnsignedInteger(char** str)\n    {\n        const char* before = *str;\n        while(**str!='\\0' && **str>='0' && **str<='9')\n            ++(*str);\n        return *str>before;\n    }\n};\n```\n## 8. 字符串的排列\n**题目描述**\n输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。\n**输入描述**:\n输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。\n**思路**：\n\n**代码**：\n```C++\n待\n```\n-----------\n# 五、数组\n## 1. 构建乘积数组\n**题目描述**\n给定一个数组A[0,1,...,n-1],请构建一个数组B[0,1,...,n-1],其中B中的元素`B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]`。不能使用除法。\n**思路**：\n- 把数组B看成一个矩阵来创建（见书中）。B[i]的值可以看作图中的矩阵中每行的乘积。\n- 下三角用自上而下的顺序计算，`C[i] =C[i-1]*A[i-1]`。\n- 上三角用自下而上的顺序计算，`D[i]= D[i+1]*A[i+1]`。\n- 因此，先算下三角中的连乘，即先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。\n\n**代码**：\n```C++\nclass Solution \n{\npublic:\n    vector<int> multiply(const vector<int>& A) \n    {\n    \tint length = A.size();\n        vector<int> B(length); //vector容器的构造函数\n        if(length<=0) return B;\n        //计算下三角连乘\n        B[0]=1;\n        for(int i = 1;i<length;i++)\n        {\n            B[i]=B[i-1]*A[i-1];\n        }\n        //计算上三角\n        int temp = 1;\n        for(int j=length-2;j>=0;j--)\n        {\n            temp *= A[j+1];\n            B[j] *= temp;\n        }\n        return B;\n    }\n};\n```\n## 2. 连续子数组的最大和\n**题目**：输入一个整型数组，数组里有正数也有负数。数组中一个或连续的多个整数组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为 O(n)。\n**说明**：例如输入的数组为{1, -2, 3, 10, -4, 7, 2, -5}，和最大的子数组为｛3, 10, -4, 7, 2}。因此输出为该子数组的和18。\n**思路**：\n- 从头到尾逐个累加数组中的每个数字。若加上`arr[i]`后的当前和`sumCurrent`小于`arr[i]`，则抛弃当前和`sumCurrent`及之前的所有数字，置当前和`sumCurrent`为`arr[i]`。同时每一步累加都记录下最大和`sumMax`。\n\n**代码**： \n```C++\nclass Solution \n{\npublic:\n    int FindGreatestSumOfSubArray(vector<int> array)\n    {\n    \tif(array.empty()) return 0;\n        int size = array.size();\n        int sumCurrent=0;\n        int sumMax = 0x80000000;//int的最小值\n        //从头到尾逐个累加数组中的每个数字\n        for(int i = 0; i<size;i++)\n        {\n            sumCurrent += array[i];\n            //若当前和sumCurrent小于arr[i]\n            if(array[i]>sumCurrent)\n                sumCurrent=array[i];\n            //记录下最大和sumMax\n            if(sumCurrent>sumMax) \n                sumMax = sumCurrent;\n        }\n        return sumMax;\n    }\n};\n```\n## 3. 旋转数组的最小数字\n**题目描述**\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序（递增，可能相等）的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。\n**思路**：\n**思路1**：顺序查找，遍历数组，找到`arr[i]>arr[i+1]`（稍微优化），时间复杂度$O(n)$，需改进。\n**思路2**：旋转数组是两个排序的子数组，采用二分查找。时间复杂度$O(logn)$：\n- **情况1**：\n - 用指针`p1`指向第一个数组的第一个元素，用指针`p2`指向第二个数组的第2个元素。对于旋转数组，有特性：`arr[p1]>arr[p2]`（`第一个数组>=第二个数组`）；\n - 计算中间元素为指针`p`，如果`arr[p]>=arr[p1]`，则指针`p`在第一个数组中，此时最小元素应该位于中间元素的后面，令`p1=p;`如果`arr[p]<=arr[p1]`，则指针`p`在第二个数组中，此时最小元素应该位于中间元素的前面，令`p2 = p;`；\n - `p1`始终在第一个数组，`p2`始终在第二个数组，故循环终止条件为：`(p1+1)=p2`，`arr[p2]`即为最小元素。\n- **情况2**：若旋转数组是将原来的0个元素搬到最后面，即数组有序，即`arr[p1]<arr[p2]`，该情况是情况1中的特例，情况1中的做法是不适用的，直接返回最小元素`arr[0]`。\n- **情况3**：当指针`p`，`p1`，`p2`指向的元素相同时，即`arr[p]==arr[p1] && arr[p]==arr[p2]`时，无法判断该将中间的数字是位于第一个数组还是第二个数组，无法继续用二分法，转而对`[p1，p2]`采用顺序查找法。\n\n**代码**：\n```C++\n//思路1：顺序查找，时间复杂度O(n)\nclass Solution \n{\npublic:\n    int minNumberInRotateArray(vector<int> rotateArray) \n    {\n        int min = 0;\n        if(!rotateArray.empty())\n        {\n            int size = rotateArray.size();\n            //顺序查找，遍历数组，找到arr[i+1]<arr[i]\n            for(int i = 0;i<size-1;i++)\n            {\n                if(rotateArray[i+1]<rotateArray[i])\n                {\n                    min = rotateArray[i+1];\n                    break;\n                }\n            }\n        }\n        return min;\n    }\n};\n```\n```C++\n//思路2：二分查找，时间复杂度O(logn)\nclass Solution {\npublic:\n    int minNumberInRotateArray(vector<int> rotateArray) {\n        if(rotateArray.empty())  return 0;\n        int size = rotateArray.size();\n        int p1 = 0;\n        int p2 = size-1;\n        int minIndex=0;\n        //情况2，数组有序，直接返回arr[0]\n        if(rotateArray[p1]<rotateArray[p2]) return rotateArray[0];\n        //情况1，二分查找\n        while((p1+1)!=p2)\n        {\n            int p = (p1+p2)/2;\n            //情况3，转为对[p1,p2]采用顺序查找\n            if(rotateArray[p1]==rotateArray[p] && rotateArray[p]==rotateArray[p2])\n                return MinInOrder(rotateArray,p1,p2);\n            if(rotateArray[p]>=rotateArray[p1]) p1 = p;\n            else if(rotateArray[p]<=rotateArray[p2]) p2 = p;\n        }\n        return rotateArray[p2];\n    }\n    int MinInOrder(vector<int>& rotateArray,int p1, int p2)\n    {\n        int min = 0;\n    \tfor(int i = p1;i<p2;i++)\n        {\n            \tif(rotateArray[i+1]<rotateArray[i])\n            \t{\n                \tmin = rotateArray[i+1];\n                \tbreak;\n            \t}\n        }\n        return min;\n    }\n    \n};\n```\n## 4. 数字在排序数组中出现的次数\n**题目描述**\n统计一个数字在排序数组中出现的次数。\n**思路**：\n- **思路1**：顺序遍历数组，时间复杂度$O(n)$，需改进。\n- **思路2**：有序数组，使用二分查找。分两次二分查找：\n - **第一次**找出该数字第一次出现的位置:`(mid==start) || (data[mid-1]!=target))`即已经是最左边的位置或其左边的一个数不等于该数；\n - **第二次**找出该数字最后一次出现的位置：`(mid==end) || (data[mid+1]!=target)`即已经是最右边的位置或其右边的一个数不等于该数。\n- 可用递归实现，也可以用循环实现。\n\n**代码**：\n```C++\n//思路2，递归实现\nclass Solution \n{\npublic:\n    int GetNumberOfK(vector<int> data ,int k) \n    {\n        int number = 0;\n        if(data.empty()) return number;\n        int size = data.size();\n        int firstIndex = getFirst(data,0,size-1,k);\n        int lastIndex = getLast(data,0,size-1,k);\n        if (firstIndex > -1 && lastIndex > -1)\n        {\n        \tnumber = lastIndex - firstIndex + 1;\n        }\n        return number;\n    }\n    int getFirst(vector<int>& data, int start, int end, int target)\n    {\n        if(start>end) return -1;\n        int mid = (start+end)/2;\n        if(data[mid]==target)\n        {\n            if((mid==start) || (data[mid-1]!=target))//让它是第一个出现的位置\n            //if((mid==start) || (mid-1>start&&data[mid-1]!=target))//等价\n                return mid;\n            else end = mid-1;\n        }\n        else if(data[mid]>target) end = mid-1;\n        else start = mid+1;\n        return getFirst(data,start,end,target);\n    }\n    int getLast(vector<int>& data, int start, int end, int target)\n    {\n        if(start>end) return -1;\n        int mid = (start+end)/2;\n        if(data[mid]==target)\n        {\n           if((mid==end) || (data[mid+1]!=target))//让它是最后一个出现的位置\n           //if((mid==end) || (mid+1<end&&data[mid+1]!=target))//等价\n                return mid;\n            else\n                start = mid+1;\n        }\n        else if(data[mid]>target) end = mid-1;\n        else start = mid+1;\n        return getLast(data,start,end,target);\n    }\n};\n```\n## 5. 数组中重复的数字\n题目描述\n在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。\n\n\n## 6. 数组中只出现一次的数字\n题目描述\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n\n## 7. 数组中出现次数超过一半的数字\n题目描述\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。\n\n## 8. 把数组排成最小的数\n**题目描述**\n输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。\n**思路**：\n**代码**：\n```C++\nclass Solution {\npublic:\n    string PrintMinNumber(vector<int> numbers) {\n        int length = numbers.size();\n        if(length==0) return \"\";\n        sort(numbers.begin(),numbers.end(),compare);\n        string result;\n        for(int i = 0; i<length;i++)\n            result += to_string(numbers[i]);\n        return result;\n    }\n    static bool compare(int a, int b)\n    {\n        string A = to_string(a)+to_string(b);\n        string B = to_string(b)+to_string(a);\n        return A<B;\n    }\n};\n```\n## 9. 调整数组顺序使奇数位于偶数前面\n**题目描述**\n输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。\n**思路**：\n1.剑指offer书中，是要求调整数组顺序，使得奇数位于偶数前面，没有要求奇数和奇数，偶数和偶数的相对位置不变。\n解法是：指针`p1`指向数组头部，`p1`只后移。指针`p2`指向数组尾部，`p2`只前移。当`arr[p1]`为偶数，`arr[p2]`为奇数，则交换。`p1`继续后移，`p2`继续前移，一直循环。终止条件是：`p1`与`p2`交叉。\n2.本题目中，要求奇数在前，偶数在后，且奇数相对于奇数，偶数相对于偶数的相对位置不变。则解法是：新建一个数组，先把原数组中的奇数push进去，再把偶数push进去，然后用新数组数据覆盖原数组即可。复杂度O(n)。\n**代码**：\n```C++\nclass Solution {\npublic:\n    void reOrderArray(vector<int> &array) {\n        if(array.empty()) return;\n        int size = array.size();\n        //新建一个数组\n        vector<int> result;\n        //先把原数组中的奇数push进去\n        for(int i = 0; i<size;i++)\n        {\n        \tif(array[i]%2==1)\n                result.push_back(array[i]);\n        }\n        //再把原数组中的偶数push进去\n        for(int i = 0; i<size;i++)\n        {\n        \tif(array[i]%2==0)\n                result.push_back(array[i]);\n        }\n        //用新数组覆盖原数组\n        array=result;\n    }\n};\n```\n## 10. 二维数组中的查找\n**题目描述**\n在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n**思路**：首先选取数组中右上角的数字。如果该数字等于要查找的数字，则查找过程结束；如果该数字大于要查找的数字，则去除该数字所在列；如果该数字小于要查找的数字，则去除该数字所在行。\n**代码**：\n```C++\nclass Solution {\npublic:\n    bool Find(int target, vector<vector<int>> array) {\n\t\t//防御型编程\n        if(array.empty()) return false;\n        //计算二维数组的行和列\n        int rows = array.size();\n        int cols = array[0].size();\n        //首先选取数组中右上角的数字\n        int i = 0;\n        int j = cols-1;\n        bool result = false;\n        while(i<rows && j>=0)//注意二维数组行列的取值范围为[0~rows-1, 0~cols-1]\n        {\n            //如果该数字等于要查找的数字，则查找过程结束\n            if(array[i][j]== target)\n            {\n                result = true;\n                break;\n            }\n            //如果该数字大于要查找的数字，则去除该数字所在列\n            else if(array[i][j]>target)   \n            {\n                j--;\n            }\n            //如果该数字小于要查找的数字，则去除该数字所在行\n            else\n            {\n            \ti++;\n            }\n        }\n        return result;\n    }\n};\n```\n## 11. 数组中的逆序对\n**题目描述**\n在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007\n**输入描述**:\n题目保证输入的数组中没有的相同的数字\n**数据范围**：\n对于%50的数据,$size<=10^4$\n对于%75的数据,$size<=10^5$\n对于%100的数据,$size<=2\\*10^5$\n**示例**:\n输入\n1,2,3,4,5,6,7,0\n输出\n7\n**思路**：\n\n**代码**：\n```C++\n//不对，未完成\nclass Solution {\nprivate:\n    int count=0;\npublic:\n    int InversePairs(vector<int> data) {\n        int n = data.size();\n        return InversePairs2(data, n);\n    }\n    int InversePairs2(vector<int>& data, int n) \n    {\n\t\tif(n<2) return 0;//就是为了返回，返回的值无所谓\n        int leftLength= n/2;\n        int rightLength= n-leftLength;\n        vector<int> left;\n        vector<int> right;\n        for(int i = 0;i<leftLength;i++) left.push_back(data[i]);\n        for(int i = leftLength;i<n;i++) right.push_back(data[i]);\n        InversePairs2(left,leftLength);    //sorting the left subarray\n        InversePairs2(right,rightLength);  //sorting the right subarray\n        mergeNew(data,left,leftLength,right,rightLength); //merge left and right into A\n        return count%1000000007;\n    }\n    void mergeNew(vector<int>& data, vector<int>& left, int leftLength, vector<int>& right,int rightLength)\n    {\n        int i=leftLength+rightLength-1;\n\t\tint j = leftLength-1;\n        int k = rightLength-1;\n        while(j>=0 && k>=0)\n        {\n            if(left[j]>right[k]) \n            { \n            \tdata[i--] = left[j--];\n            \tcount+=(k+1);\n            }\n            else \n            {\n            \tdata[i--] = right[k--];\n            }\n        }\n        while(j>=0) data[i--]=left[j--];\n        while(k>=0) data[i--]=right[k--];\n    }\n};\n```\n## 12. 顺时针打印矩阵\n**题目描述**\n输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵： \n```\n1   2  3  4\n5   6  7  8\n9  10 11 12\n13 14 15 16\n```\n则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.\n**思路**：分解成若干个简单的问题。\n1.每次打印矩阵的一个圈。关键：循环继续的条件是：`cols>start*2 && row>start*2`\n2.将打印一圈分成四步：第一步，从左到右打印一行；第二步，从上到下打印一列；第三步；从右到左打印一行；第四步，从下到上打印一列。\n3.四步的前提条件：\n第一步总是需要；\n第二步的前提条件是终止行号大于起始行号；\n第三步的前提条件是该圈内至少两行两列，即终止行号大于起始行号，终止列号大于起始列号；\n第四步的前提条件：该圈内至少有三行二列，即终止行号比起始行号至少大2，终止列号大于起始列号。\n**代码**：\n```C++\nclass Solution {\npublic:\n    vector<int> printMatrix(vector<vector<int> > matrix) {\n\t\tvector<int> result;\n        int rows = matrix.size();\n        int cols = matrix[0].size();\n        if(rows<=0 || cols<=0) return result;\n        int start = 0;\n        //每次打印矩阵的一个圈\n        while(cols>start*2 && rows> start*2)\n        {\n            PrintMatrixInCircle(matrix,rows,cols,start,result);\n            start++;\n        }\n        return result;\n    }\n    void PrintMatrixInCircle(vector<vector<int>>& matrix,int rows,int cols,int start,vector<int>& result)\n    {\n        int endX = cols-start-1;\n        int endY = rows-start-1;\n        //1.从左到右打印矩阵\n        for(int i = start;i<=endX;i++)\n        {\n            result.push_back(matrix[start][i]);\n        }\n        //2.从上到下打印一列\n        if(start<endY)\n        {\n            for(int i = start+1;i<=endY;i++)\n            {\n                result.push_back(matrix[i][endX]);\n            }\n        }\n        //3.从右到左打印一行\n        if(start<endX && start< endY)\n        {\n            for(int i = endX-1;i>=start;i--)\n            {\n                result.push_back(matrix[endY][i]);\n            }\n        }\n        //4.从下到上打印一列\n        if(start<endX && start <endY -1)\n        {\n            for(int i = endY-1; i>=start+1;i--)\n            {\n                result.push_back(matrix[i][start]);\n            }\n        }\n    }\n};\n```\n--------\n# 六、排序\n## 1.数组中出现次数超过一半的数字\n题目描述\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。\n**思路**：结合数组特性：数组中有一个数字出现的次数超过了数组长度的一半，如果将这个数组排序，那么排序之后位于数组中间的数字一定就是那个出现次数超过数组长度一半的数字。这个数字就是统计学上的中位数，即长度为$n$的数组中第$n/2$大的数字。已经有成熟的时间复杂度为$O(n)$的算法得到数组中任意第$k$大的数字。\n第一，防御性编程，判断数组是否有效；第二，利用快速排序中的分割(partition)方法，选主元位置及重排数组。如果返回的主元位置(pIndex)小于数组中间位置((length-1)/2)，则对左半部分进行分割，否则对右半部分进行分割，直到返回的pIndex等于((length-1)/2)；第三，遍历数组，验证该数是否出现了超过一半的次数。\n<!-- more --> \n**代码**：\n```C++\nclass Solution {\npublic:\n    int MoreThanHalfNum_Solution(vector<int> numbers) {\n    \tint size = numbers.size();\n        //1.防御性编程，判断数组是否有效；\n        if(size==0) return 0;\n        int start = 0;\n        int end = size-1;\n        int middle = end/2;\n        //2.利用快速排序中的分割(partition)方法，选主元位置及重排数组\n        int pIndex = partition(numbers,start,end);\n        //直到返回的pIndex等于((length-1)/2)\n        while(pIndex!=middle)\n        {\n            if(pIndex<middle)\n            {\n                start = pIndex+1;\n                pIndex = partition(numbers,start,end);\n            }\n            else\n            {\n                end = pIndex-1;\n                pIndex = partition(numbers,start,end);\n            }\n        }\n        int result=numbers[middle];\n        //3.遍历数组，验证该数是否出现了超过一半的次数。\n        if(isMoreThanHalf(numbers,result,size))\n            return result;\n        else\n            return 0;\n    }\n    int partition(vector<int>& numbers, int start,int end)\n    {\n        int pivot = numbers[end];\n        int pIndex = start;\n        for(int i = start;i<end;i++)\n        {\n            if(numbers[i]<=pivot)\n            {\n                int temp = numbers[i];\n                numbers[i] = numbers[pIndex];\n                numbers[pIndex] = temp;\n                pIndex++;\n            }\n        }\n        int temp = numbers[pIndex];\n        numbers[pIndex] = pivot;\n        numbers[end] = temp;\n        return pIndex;\n    }\n    bool isMoreThanHalf(vector<int>& numbers,int result,int size)\n    {\n        int count = 0;\n        for(int i = 0;i<size;i++)\n        {\n            if(numbers[i]==result)\n                count++;\n        }\n        if(2*count<=size) return false;\n        else return true;\n    }\n};\n```\n## 2.最小的k个数\n**题目描述**：\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n**思路**：\n思路1：利用快速排序排序数组，位于前面的$k$个数即是最小的$k$个数。时间复杂度为$O(nlogn)$。\n第一，防御性编程，如果数组为空或$k>length$，则返回空；第二，利用快速排序，对数组进行排序；第三，输出数组中的前$k$个数。\n思路2：\n由上题“数组中出现次数超过一半的数字”得到启发，基于快速排序中的分割(partition)方法来解决问题。利用partiton函数，如果返回的$pIndex<(k-1)$，则对右半部分进行partition，否则，对左半部分进行partition，直到返回的主元位置pIndex等于$(k-1)$。这样调整后，位于数组中左边的k个数字就是最小的$k$个数字，但这$k$个数字不一定是排序的。时间复杂度为$O(n)$。\n**代码**：\n```C++\n//实现思路1\nclass Solution {\npublic:\n    vector<int> GetLeastNumbers_Solution(vector<int> input, int k) {\n        vector<int> result;\n        int size = input.size();\n        //1.防御性编程，如果数组为空或k>size，则返回\n        if(size==0 || k>size) return result;\n        int start = 0;\n        int end = size-1;\n        //2.利用快速排序，对数组进行排序\n        quickSort(input,start,end);\n        //3.输出数组中的前k个数\n        for(int i = 0;i<k;i++)\n        {\n            result.push_back(input[i]);\n        }\n        return result;\n    }\n    void quickSort(vector<int>& numbers, int start, int end)\n    {\n        if(start>end) return;\n        int pIndex = partition(numbers,start,end);\n        quickSort(numbers,start,pIndex-1);\n        quickSort(numbers,pIndex+1,end);\n    }\n    int partition(vector<int>& numbers, int start,int end)\n    {\n        int pivot = numbers[end];\n        int pIndex = start;\n        for(int i = start;i<end;i++)\n        {\n            if(numbers[i]<=pivot)\n            {\n                int temp = numbers[i];\n                numbers[i] = numbers[pIndex];\n                numbers[pIndex] = temp;\n                pIndex++;\n            }\n        }\n        int temp = numbers[pIndex];\n        numbers[pIndex] = pivot;\n        numbers[end] = temp;\n        return pIndex;\n    }\n};\n```\n\n# 七、位运算\n## 1.数组中只出现一次的数字（#56）\n**题目描述**\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n**思路**：核心思想：[异或去重](http://blog.csdn.net/ns_code/article/details/27568975)；异或的性质：交换律，结合律，以及`a^a=0`，`a^0=a`\n**1.考虑简单情况**：数组中只有一个数字`n`出现了一次，其他都出现了两次。\n将数组中所有元素逐个异或，则结果为只出现一次的`n`，即`a^a^b^b^...^n^...^c^c=n`。\n**2.本题求解思路**：故将数组分成两部分解决，一部分包含只出现一次的数字`n_1`，一部分包含只出现一次的数字`n_2`，同时保证出现两次的数字在同一数组,而不是分散在l不同的数组。对两数组分别逐元素异或，即分别得到`n_1`，`n_2`。\n**3.数组划分方法**：对整个数组，逐元素异或，则结果为`n_1^n_2`，即`n_1`和 `n_2`异或的结果。`n_1`和`n_2`不相同，故结果定不为0，则结果的二进制表示定至少有一位为1（即`n_1`和`n_2`的二进制表示的该位不相同），找出结果的二进制表示中第一次为1的下标索引`index`，通过这个下标索引`index`，对整个数组中的元素进行数组划分。数组中每个元素的二进制表示的第`index`位是1的分为一组，是0的分为另一组。这样保证了`n_1`和`n_2`分别在两个组，且出现两次的数字在同一个组，不会被分到不同的组(因此相同数字的二进制表示的`index`位必定是相同的)。\n**代码**：\n```C++\nclass Solution {\npublic:\n    void FindNumsAppearOnce(vector<int> data,int* num1,int *num2) {\n\t\tint length = data.size();\n        if(data.size()<2) return;\n        int result = 0; //初始值为0,a^0=a\n        // get num1 ^ num2\n        for(int i =0;i<length;i++)\n            result ^=data[i];\n        // get index of the first bit, which is 1 in resultExclusiveOR\n        unsigned int indexOf1 = FindFirstBitIs1(result);\n        *num1 = *num2 = 0;\n        // divide the numbers in data into two groups,\n        // the indexOf1 bit of numbers in the first group is 1,\n        // while in the second group is 0\n        for(int j=0;j<length;j++)\n        {\n            if(IsBit1(data[j],indexOf1))\n                *num1^=data[j];\n            else\n                *num2^=data[j];\n        }\n    }\n    //Find the index of first bit which is 1 in num (assuming not 0)\n    unsigned int FindFirstBitIs1(int num)\n    {\n        int indexBit=0;\n        while(((num&1)==0) && (indexBit<8*sizeof(int)))\n        {\n            num = num>>1;\n            ++indexBit;\n        }\n        return indexBit;\n    }\n    // Is the indexBit bit of num 1?\n    bool IsBit1(int num, unsigned int indexBit)\n    {\n        num=num>>indexBit;\n        return (num&1);\n    }\n};\n```\n## 2.二进制中1的个数\n**题目描述**\n输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。\n**思路**：\n**首先**，直观的思路是：先判断整数二进制表示中的最后一位是不是1；然后将整数右移一位，再次判断，直到整数变为0。判断二进制表示中最后一位是不是1的方法是：`n&1`，因为1的二进制表示中除了最后一位为1以外，其余全为0。\n**然后**，右移整数n的做法存在隐患，就是当n是负数的时候，[n右移会在开头补符号位1（算术右移）](http://blog.csdn.net/morewindows/article/details/7354571)，而不是补0。故采用将1循环左移的方法，逐个判断n的二进制表示的第0位到最高位是否为1。\n**代码**：\n```C++\nclass Solution {\npublic:\n     int  NumberOf1(int n) {\n         int count = 0;\n         unsigned int flag = 1;\n         //直到1的循环左移为0\n         while(flag)\n         {\n             if(n & flag)\n             \tcount++;\n             //左移1\n             flag =flag<<1;\n         }\n         return count;\n     }\n};\n```\n# 八、递归\n## 1.斐波那契数列（#10）\n**题目描述**\n大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。(n<=39)\n**注**：本题中`n=0`时，输出是0。斐波那契数列从第1项开始。即本题斐波那契数列是`0,1,1,2,3,5,...`\n**思路**：\n**思路1**：最直观的递归，返回`Fibonacci(n-1)+Fibonacci(n-2)`。但有大量冗余计算，时间复杂度过高，无法通过。\n**思路2**：带记忆的递归，用辅助数组存储下已经计算过的结果。\n**思路3**：迭代计算。\n**代码**：\n```C++\n//思路1：最直观的递归，时间复杂度过高\nclass Solution {\npublic:\n    int Fibonacci(int n) {\n        if(n<=1) return n;\n        return Fibonacci(n-1)+Fibonacci(n-2);\n    }\n};\n```\n```\n//思路2：带记忆的递归，用辅助数组存储下已经计算过的结果\nclass Solution {\nprivate:\n    int F[40];//默认为0\npublic:\n    int Fibonacci(int n) {\n        if(F[n]!= 0) \n            return F[n];\n        if(n<=1) \n        {\n         \tF[n]=n;\n        \treturn F[n];\n        }\n        else\n        {\n            F[n]=Fibonacci(n-1)+Fibonacci(n-2);\n        \treturn F[n];\n        }\n    }\n};\n```\n```\n//思路3：迭代计算。\nclass Solution {\npublic:\n    int Fibonacci(int n) {\n    \tint num1=0;\n    \tint num2=1;\n    \tint num3;\n        if(n<=1) \n            return n;\n\t\tfor(int i = 2;i<=n;i++)\n        {\n            num3 = num1+num2;\n            num1 = num2;\n            num2 = num3;\n        }\n        return num3;\n    }\n};\n```\n## 2. 青蛙跳台阶问题（#10）\n**题目描述**\n一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n**思路**：类似斐波那契数列\nf(n)=　1, (n=1)\n　　　 2, (n=2)\n　　　 f(n-1)+f(n-2) ,(n>2,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int jumpFloor(int number) {\n        if(number<=0) return number; //defensive\n        if(number==1) return 1;\n        if(number==2) return 2;\n        return jumpFloor(number-1)+jumpFloor(number-2);\n    }\n};\n```\n## 3.变态跳台阶（#10）\n**题目描述**\n一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。\n**思路**：\n因为n级台阶，第一步有n种跳法：跳1级，跳2级，...，跳n级\n跳1级，剩下n-1级，则剩下跳法是f(n-1)\n跳2级，剩下n-2级，则剩下跳法是f(n-2)\n所以f(n)=f(n-1)+f(n-2)+...+f(1)+f(0)\n因为f(n-1)=f(n-2)+f(n-3)+...+f(1)+f(0)\n所以f(n)=2xf(n-1)\n故：\nf(n)=　1, (n=1)\n　　　 2xf(n-1),(n>1,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int jumpFloorII(int number) {\n        if(number<=0) return number; //defensive\n\t\tif(number==1) return 1;\n        return 2*jumpFloorII(number-1);\n    }\n};\n```\n## 4.矩形覆盖（#10）\n**题目描述**\n我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？\n**思路**：仍旧是斐波那契数列\n第一块有两种方式：横着放和竖着放。\n横着放后，覆盖方法为f(n-2)，因为下方也被占用，下方必须也横着放。\n竖着放后，覆盖方法为f(n-1);\n所以总的覆盖方法为f(n)=f(n-1)+f(n-2);\n故：\nf(n)=　1, (n=1)\n　　　 2, (n=2)\n　　　 f(n-1)+f(n-2) ,(n>2,n为整数)\n**代码**：\n```C++\nclass Solution {\npublic:\n    int rectCover(int number) {\n \t\tif(number<=0) return number; //defensive\n        if(number==1) return 1;\n        if(number==2) return 2;\n        return rectCover(number-1)+rectCover(number-2);\n    }\n};\n```\n\n# 九、回溯\n\n# 十、动态规划与贪婪算法\n\n\n\n\n\n","slug":"剑指Offer解题记录","published":1,"updated":"2018-02-20T11:37:58.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjqxl4w4g006hqslp5b3a4i9n","content":"<p>注：该记录中解题答案均为在牛客网进行<a href=\"https://www.nowcoder.net/ta/coding-interviews\" target=\"_blank\" rel=\"noopener\">在线编程测试</a>时的答案记录，故未自己写测试代码。</p>\n<h1 id=\"一、链表\"><a href=\"#一、链表\" class=\"headerlink\" title=\"一、链表\"></a>一、链表</h1><h2 id=\"1-两个链表的第一个公共结点\"><a href=\"#1-两个链表的第一个公共结点\" class=\"headerlink\" title=\"1. 两个链表的第一个公共结点\"></a>1. 两个链表的第一个公共结点</h2><p><strong>题目描述</strong>：<br>输入两个链表，找出它们的第一个公共结点。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>关键点</strong>：如果两个单链表有公共的结点，那么这两个链表从某一结点开始，它们的<code>next</code>指针都指向同一个结点，又由于是单向链表的结点，每个结点只有一个<code>next</code>指针，因此<strong>从第一个公共结点开始，之后它们所有的结点都是重合的，不再出现分叉</strong>。</li>\n<li><strong>思路1</strong>：<ul>\n<li>对于对于链表一上的每一个结点，顺序遍历链表二上的每一个结点。</li>\n<li>若第一个链表的长度为$m$，第二个链表的长度为$n$，那么时间复杂度为$O(mn)$。</li>\n</ul>\n</li>\n<li><strong>思路2</strong>：<ul>\n<li>分别把两个链表的结点放入栈里，这样两个链表的尾结点就位于两个栈的栈顶，接下来比较两个栈顶的结点是否相同。如果相同，则把栈顶弹出接着比较下一个栈顶，直到找到最后一个相同的结点。</li>\n<li>该思路需要用到两个辅助栈，如果链表的长度分别为$m$和$n$，那么空间复杂度是$O(m+n)$，时间复杂度是$O(m+n)$。和思路1相比，时间效率得到了提高，相当于用空间消耗换取了时间效率。</li>\n</ul>\n</li>\n<li><p><strong>思路3</strong>：</p>\n<ul>\n<li>首先遍历两个链表得到它们的长度。在第二次遍历时，在较长的链表上先走若干步，接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点。</li>\n<li>与思路2相比，该思路的时间复杂度为$O(m+n)$，但不需辅助栈，因此提高了空间效率。</li>\n</ul>\n<a id=\"more\"></a> \n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路3</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x):val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">FindFirstCommonNode</span><span class=\"params\">( ListNode* pHead1, ListNode* pHead2)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(pHead1==<span class=\"literal\">nullptr</span> || pHead2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//首先遍历两个链表得到它们的长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> length1,length2;</span><br><span class=\"line\">        length1=length2= <span class=\"number\">0</span>;</span><br><span class=\"line\">        ListNode* pTemp1 = pHead1;</span><br><span class=\"line\">        ListNode* pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            length1++;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            length2++;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//在第二次遍历时，在较长的链表上先走若干步</span></span><br><span class=\"line\">        pTemp1 = pHead1;</span><br><span class=\"line\">        pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length1&gt;length2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> dif = length1-length2;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;dif;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> dif = length2-length1;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;dif;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点</span></span><br><span class=\"line\">        ListNode* pResult = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span> &amp;&amp; pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(pTemp1 == pTemp2)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tpResult = pTemp1;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pResult;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-链表中环的入口结点\"><a href=\"#2-链表中环的入口结点\" class=\"headerlink\" title=\"2. 链表中环的入口结点\"></a>2. 链表中环的入口结点</h2><p><strong>题目描述</strong>：<br>一个链表中包含环，请找出该链表的环的入口结点。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>核心思想</strong>：假定有环且已知环的结点个数为$y$，令指针<code>pTemp1</code>从首结点开始先走$y$步，再令<code>pTemp2</code>从首结点开始同<code>pTemp1</code>一起向前走，相遇处，即为环的入口结点。</li>\n<li><strong>证明</strong>：假定环的结点个数为$y$，环之前的结点个数为$x$。<code>pTemp1</code>先走$y$步，然后<code>pTemp2</code>从首结点开始同<code>pTemp1</code>一起再走$x$步，则<code>pTemp2</code>在第$(x+1)$个结点处，<code>pTemp1</code>在第$(x+y+1)$个结点处。$(x+1)$结点位置和$(x+y+1)$结点位置都是环的入口结点位置。因此，依上述核心思想的步骤，<code>pTemp1</code>与<code>pTemp2</code>定会相遇，相遇处恰好为环的入口结点。</li>\n<li><strong>环的结点个数求法</strong>：首先，令一指针<code>pFast</code>一次走两步，一指针<code>pSlow</code>一次走一步，若相遇，则有环，且相遇处定在环内。然后，<code>pFast</code>不动，令一指针<code>pSlow</code>继续走且计数，当<code>pSlow</code>与<code>pFast</code>再次相遇，即得出环的结点个数。</li>\n<li>注意，代码中充斥着防止指针为空的情况，繁琐但必不可少。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">EntryNodeOfLoop</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//通过getNumberOfLoop()获取环的结点个数，0则无环；大于0则有环</span></span><br><span class=\"line\">        ListNode* pTemp1, *pTemp2;</span><br><span class=\"line\">        pTemp1 = pTemp2 = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> num = getNumberOfLoop(pHead);</span><br><span class=\"line\">        <span class=\"comment\">//若环结点数等于0，直接返回nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(num==<span class=\"number\">0</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//依照核心思想执行，获取pTemp1与pTemp2相遇处指针</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;num;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=pTemp2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pTemp1;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getNumberOfLoop</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//1.令pFast一次走两步，pSlow一次走一步，若相遇，则有环，且相遇处定在环内</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        ListNode* pFast, *pSlow;</span><br><span class=\"line\">        pFast = pSlow = pHead;</span><br><span class=\"line\">        pFast=pFast-&gt;next;    <span class=\"comment\">//为了下个while循环的判断条件，pFast先走一步</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pFast!=pSlow)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pFast = pFast-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pFast = pFast-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pSlow==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pSlow=pSlow-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span> || pSlow==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            num=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.pFast不动，令pSlow继续走且计数，当pSlow与pFast再次相遇，即得出环的结点个数</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pSlow=pSlow-&gt;next; <span class=\"comment\">//为了下个while循环的判断条件，pSlow先走一步</span></span><br><span class=\"line\">            num++;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pSlow!=pFast)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pSlow=pSlow-&gt;next;</span><br><span class=\"line\">                num++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-反转链表\"><a href=\"#3-反转链表\" class=\"headerlink\" title=\"3. 反转链表\"></a>3. 反转链表</h2><p><strong>题目描述</strong>：<br>给出一个链表<code>1-&gt;2-&gt;3-&gt;nullptr</code>，这个翻转后的链表为<code>3-&gt;2-&gt;1-&gt;nullptr</code><br><strong>思路</strong>：</p>\n<ul>\n<li><strong>方法1</strong>：迭代实现。维护三个指针<code>pPrev</code>,<code>pCurrent</code>,<code>pNext</code>，通过迭代完成链表的反转（画图使思路清晰）：<ul>\n<li>起始情况：<code>pPrev</code>为<code>nullptr</code>，<code>pCurrent</code>指向<code>pHead</code></li>\n<li>终止情况：<code>pPrev</code>指向链表尾元素，<code>pCurrent</code>为<code>nullptr</code></li>\n</ul>\n</li>\n<li><strong>方法2</strong>：递归实现。利用递归走到链表的末端，然后再更新每一个结点的<code>next</code>指针 ，实现链表的反转。</li>\n<li><strong>方法3</strong>：用栈实现。将链表结点指针全部压入栈中。头指针指向链表末尾结点。将栈中结点指针反串起来，栈中最后结点指针指向<code>nullptr</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法1：迭代实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode* pHead)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        ListNode* pPre, *pCurrent, *pNext;</span><br><span class=\"line\">        pPre=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNext = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pPre;</span><br><span class=\"line\">            pPre = pCurrent;</span><br><span class=\"line\">            pCurrent = pNext;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pHead=pPre;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法2：递归实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode* pHead)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果链表为空或者链表中只有一个元素</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">NULL</span> || pHead-&gt;next==<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        <span class=\"comment\">//先反转后面的链表，走到链表的末端结点，返回末端结点，作为新的头结点，保存起来</span></span><br><span class=\"line\">        ListNode* pHeadReverse=ReverseList(pHead-&gt;next);</span><br><span class=\"line\">        <span class=\"comment\">//再将当前节点设置为后面节点的后续节点</span></span><br><span class=\"line\">        pHead-&gt;next-&gt;next = pHead;</span><br><span class=\"line\">        <span class=\"comment\">//当前节点指向NULL</span></span><br><span class=\"line\">        pHead-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"comment\">//返回新的头结点</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHeadReverse;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法3：用栈实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode * <span class=\"title\">reverse</span><span class=\"params\">(ListNode * head)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// write your code here</span></span><br><span class=\"line\">        <span class=\"comment\">//防御性编程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(head==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.将链表结点指针全部压入栈中</span></span><br><span class=\"line\">        <span class=\"built_in\">stack</span>&lt;ListNode*&gt; stack1;</span><br><span class=\"line\">        ListNode* temp = head;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(temp!=<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            stack1.push(temp);</span><br><span class=\"line\">            temp=temp-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.头指针指向链表末尾结点</span></span><br><span class=\"line\">        temp = stack1.top();</span><br><span class=\"line\">        head=temp;</span><br><span class=\"line\">        <span class=\"comment\">//3.将栈中结点指针反串起来，栈中最后结点指针指向NULL</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ListNode* pNode1 = stack1.top();</span><br><span class=\"line\">            stack1.pop();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(stack1.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNode1-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            ListNode* pNode2 = stack1.top();</span><br><span class=\"line\">            pNode1-&gt;next = pNode2;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-合并两个排序的链表\"><a href=\"#4-合并两个排序的链表\" class=\"headerlink\" title=\"4. 合并两个排序的链表\"></a>4. 合并两个排序的链表</h2><p><strong>题目</strong>：输入两个递增排序的链表，合并这两个链表并使新链表中的结点仍然是按照递增排序的。<br><strong>思路</strong>：</p>\n<ul>\n<li>依照归并排序中的<code>merge</code>函数的思想，<code>merge</code>两个链表：<ul>\n<li>1.比较两个链表的头结点，较小的作为新链表的头结点<code>pHeadNew</code>；</li>\n<li>2.归并两个链表，迭代比较，较小者作为新的尾结点<code>pTailNew</code>。</li>\n<li>注意，直接改动每一结点的<code>next</code>指针，故不需另外的辅助空间。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">Merge</span><span class=\"params\">(ListNode* pHead1, ListNode* pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//防御性编程：若输入链表有任一为空，返回另一个</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead1==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">        <span class=\"comment\">//1.找出新链表的头结点pHeadNew</span></span><br><span class=\"line\">        ListNode* pHeadNew = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        ListNode* pTemp1 = pHead1;</span><br><span class=\"line\">        ListNode* pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp1-&gt;val &lt; pTemp2-&gt;val)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHeadNew = pTemp1;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHeadNew = pTemp2;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.归并两个链表，迭代比较，较小者作为新的尾结点pTailNew</span></span><br><span class=\"line\">        <span class=\"comment\">//直接改动每一结点的next指针，故不需另外的辅助空间</span></span><br><span class=\"line\">        ListNode* pTailNew = pHeadNew; </span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span> &amp;&amp; pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pTemp1-&gt;val &lt; pTemp2-&gt;val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTailNew-&gt;next = pTemp1;</span><br><span class=\"line\">                pTailNew = pTemp1;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTailNew-&gt;next = pTemp2;</span><br><span class=\"line\">                pTailNew = pTemp2;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;    </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp1!=<span class=\"literal\">nullptr</span>) pTailNew-&gt;next = pTemp1;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp2!=<span class=\"literal\">nullptr</span>) pTailNew-&gt;next = pTemp2;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHeadNew;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-从尾到头打印链表\"><a href=\"#5-从尾到头打印链表\" class=\"headerlink\" title=\"5. 从尾到头打印链表\"></a>5. 从尾到头打印链表</h2><p><strong>题目描述</strong>：<br>输入一个链表的头结点，从尾到头反过来打印出每个结点的值。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，假定不能改变链表结构，故不采用迭代反转链表，然后后再打印链表的方法。</li>\n<li><strong>方法1</strong>：遍历的顺序是从头到尾，输出的顺序是从尾到头，是典型的“后进先出”，用栈实现这种顺序：<ul>\n<li>遍历链表，每经过一个结点的时候，把该结点压入辅助栈中。</li>\n<li>当遍历完整个链表后，再从栈顶开始逐个输出结点的值。</li>\n</ul>\n</li>\n<li><strong>方法2</strong>：用递归方法反向打印链表。既然可以用栈实现，而递归本质上就是一个栈结构，故可用递归来实现：<ul>\n<li>每访问到一个结点，先递归输出它后面的结点，再输出该结点自身，这样链表的输出结果就反过来了。</li>\n</ul>\n</li>\n<li>注意，虽然基于递归的代码看起来很简洁，但有一个问题：当链表非常长的时候，就会导致函数调用的层级很深，从而有可能导致函数调用栈溢出。显然用栈基于循环实现的代码的鲁棒性要好一些（存放于自由存储的堆区）。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法1</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;    </span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;ListNode*&gt; s;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printListFromTailToHead(ListNode* pHead) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"comment\">//遍历链表，每经过一个结点的时候，把该结点压入辅助栈中</span></span><br><span class=\"line\">        ListNode* pTemp = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(pTemp);</span><br><span class=\"line\">            pTemp = pTemp-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//当遍历完整个链表后，再从栈顶开始逐个输出结点的值</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp = s.top();</span><br><span class=\"line\">            result.push_back(pTemp-&gt;val);</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法2</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;    </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printListFromTailToHead(ListNode* pHead) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        printListFromTailToHead(pHead-&gt;next);</span><br><span class=\"line\">        result.push_back(pHead-&gt;val);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-复杂链表的复制\"><a href=\"#6-复杂链表的复制\" class=\"headerlink\" title=\"6. 复杂链表的复制\"></a>6. 复杂链表的复制</h2><p><strong>题目描述</strong><br>输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>步骤1</strong>：复制原始链表的任意结点$N$并创建新结点$N’$，再把$N’$链接到$N$的后面。如原来是<code>A-&gt;B-&gt;C</code>，则变成<code>A-&gt;A&#39;-&gt;B-&gt;B&#39;-&gt;C-&gt;C&#39;</code>。</li>\n<li><strong>步骤2</strong>：设置复制出来的结点的<code>random</code>指针。如果原始链表上的结点$N$的<code>random</code>指针指向$S$，则它对应的复制结点$N’$的<code>ramdon</code>指针指向$S$的复制结点$S’$。如<code>A1-&gt;random = A-&gt;random-&gt;next;</code></li>\n<li><strong>步骤3</strong>：把长链表拆分成两个链表：把奇数位置的结点用<code>next</code>指针链接起来就是原始链表，把偶数位置的结点用<code>next</code>指针链接起来就是复制出来的链表。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct RandomListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int label;</span></span><br><span class=\"line\"><span class=\"comment\">    struct RandomListNode *next, *random;</span></span><br><span class=\"line\"><span class=\"comment\">    RandomListNode(int x) :label(x), next(NULL), random(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">RandomListNode* <span class=\"title\">Clone</span><span class=\"params\">(RandomListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        RandomListNode* pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"comment\">//1.复制原始链表的任一节点N并创建新节点N'，再把N'链接到N的后边</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            RandomListNode* pClone = <span class=\"keyword\">new</span> RandomListNode(pCurrent-&gt;label);</span><br><span class=\"line\">            pClone-&gt;next = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pClone;</span><br><span class=\"line\">            pCurrent = pClone-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.如果原始链表上的节点N的random指向S，则对应的复制节点N'的random指向S的下一个节点S'</span></span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            RandomListNode* pClone = pCurrent-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;random!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                pClone-&gt;random = pCurrent-&gt;random-&gt;next;</span><br><span class=\"line\">            pCurrent = pClone-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//3.把得到的链表拆成两个链表，奇数位置上的结点组成原始链表，偶数位置上的结点组成复制出来的链表</span></span><br><span class=\"line\">        RandomListNode* pCloneHead=pHead-&gt;next;</span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123; </span><br><span class=\"line\">            RandomListNode* pClone = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pClone-&gt;next;</span><br><span class=\"line\">            pCurrent = pCurrent-&gt;next;</span><br><span class=\"line\">            <span class=\"comment\">//pCurrent为nullptr，即pClone-&gt;next为nullptr，不用再继续，拆分结束。</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pClone-&gt;next = pCurrent-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pCloneHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-链表中倒数第k个结点\"><a href=\"#7-链表中倒数第k个结点\" class=\"headerlink\" title=\"7. 链表中倒数第k个结点\"></a>7. 链表中倒数第k个结点</h2><p><strong>题目</strong>：<br>输入一个链表，输出该链表中倒数第$k$个结点。本题从1开始计数，即链表的尾结点是倒数第1个结点。例如一个链表有6个结点，从头结点开始它们的值依次是1、2、3、4、5、6。这个链表的倒数第3个结点是值为4的结点。<br><strong>思路</strong>：</p>\n<ul>\n<li>递归遍历链表，返回时通过<code>count</code>计数，当<code>count==k</code>时，当前<code>pHead</code>即为倒数第$K$个结点。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x):val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">    ListNode* pTarget=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">FindKthToTail</span><span class=\"params\">(ListNode* pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        Find(pHead,k);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pTarget;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Find</span><span class=\"params\">(ListNode* pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        Find(pHead-&gt;next,k);</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(count==k)</span><br><span class=\"line\">            pTarget = pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-删除链表中的重复结点\"><a href=\"#8-删除链表中的重复结点\" class=\"headerlink\" title=\"8. 删除链表中的重复结点\"></a>8. 删除链表中的重复结点</h2><p><strong>题目</strong>：<br>在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表<code>1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5</code>，处理后为<code>1-&gt;2-&gt;5</code><br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span></span></span><br><span class=\"line\"><span class=\"class\"> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">deleteDuplication</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 只有0个或1个结点，则返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span> || pHead-&gt;next==<span class=\"literal\">nullptr</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        ListNode* pNext = pHead-&gt;next;</span><br><span class=\"line\">        <span class=\"comment\">// 当前结点是重复结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead-&gt;val == pNext-&gt;val)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 跳过值与当前结点相同的全部结点,找到第一个与当前结点不同的结点</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pNext!=<span class=\"literal\">nullptr</span> &amp;&amp; pNext-&gt;val==pHead-&gt;val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNext = pNext-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 从第一个与当前结点不同的结点开始递归</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> deleteDuplication(pNext);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">         <span class=\"comment\">// 当前结点不是重复结点</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 保留当前结点，从下一个结点开始递归</span></span><br><span class=\"line\">            pHead-&gt;next = deleteDuplication(pHead-&gt;next);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"二、栈和队列\"><a href=\"#二、栈和队列\" class=\"headerlink\" title=\"二、栈和队列\"></a>二、栈和队列</h1><h2 id=\"1-用两个栈实现队列\"><a href=\"#1-用两个栈实现队列\" class=\"headerlink\" title=\"1. 用两个栈实现队列\"></a>1. 用两个栈实现队列</h2><p><strong>题目</strong>：用两个栈来实现一个队列，完成队列的<code>push</code>和<code>pop</code>操作。队列中的元素为<code>int</code>类型。<br><strong>思路</strong>：</p>\n<ul>\n<li>栈是后进先出，队列是先进先出。</li>\n<li>利用栈<code>stack1</code>负责<code>push</code>操作。</li>\n<li>利用栈<code>stack2</code>负责<code>pop</code>操作：先将<code>stack1</code>中所有元素弹出到<code>stack2</code>中，然后<code>stack2</code>出栈一个元素，最后<code>stack2</code>中所有元素弹出到<code>stack1</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; stack1;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; stack2;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//利用栈stack1负责入栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> node)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        stack1.push(node);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//利用栈stack2负责出栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">pop</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//先将stack1中所有元素弹出到stack2中</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> temp = stack1.top();</span><br><span class=\"line\">            stack2.push(temp);</span><br><span class=\"line\">            stack1.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//然后stack2出栈一个元素</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> result = stack2.top();</span><br><span class=\"line\">        stack2.pop();</span><br><span class=\"line\">        <span class=\"comment\">//最后stack2中所有元素弹出到stack1</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack2.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> temp = stack2.top();</span><br><span class=\"line\">            stack1.push(temp);</span><br><span class=\"line\">            stack2.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-包含min函数的栈\"><a href=\"#2-包含min函数的栈\" class=\"headerlink\" title=\"2. 包含min函数的栈\"></a>2. 包含min函数的栈</h2><p><strong>题目</strong>：定义栈的数据结构，请在该类型中实现一个能够得到栈的最小元素的<code>min</code>函数。在该栈中，调用<code>min</code>、<code>push</code>及<code>pop</code>的时间复杂度都是$O(1)$。<br><strong>思路</strong>：</p>\n<ul>\n<li>题目要求的是栈在进行任何的入栈和出栈操作后，都能调用<code>min</code>函数返回最小值。两种思路不可行：<ul>\n<li>定义一个变量<code>value</code>存储最小值。因为栈一旦<code>pop</code>后，不知道最小值是什么。</li>\n<li>每次进栈出栈都重新对栈内元素进行排序。因为复杂度太高。</li>\n</ul>\n</li>\n<li>正确解法：采用一个辅助栈，其栈顶保存主栈当前的最小值。主栈每一次<code>push</code>，辅助栈都将主栈当前的最小值压入栈顶。主栈每一次<code>pop</code>，辅助栈都<code>pop</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s1; <span class=\"comment\">//主栈</span></span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s2; <span class=\"comment\">//辅助栈</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//主栈stack1每一次push，辅助栈stack2都将主栈当前的最小值压入栈顶</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> value)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(s1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(value);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(value&lt;s2.top())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(value);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(s2.top());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//主栈stack1每一次pop，辅助栈stack2都pop</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">pop</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        s1.pop();</span><br><span class=\"line\">        s2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">top</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s1.top();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s2.top();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-栈的压入、弹出序列\"><a href=\"#3-栈的压入、弹出序列\" class=\"headerlink\" title=\"3. 栈的压入、弹出序列\"></a>3. 栈的压入、弹出序列</h2><p><strong>题目描述</strong><br>输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列$1,2,3,4,5$是某栈的压入顺序，序列$4,5,3,2,1$是该压栈序列对应的一个弹出序列，但$4,3,5,1,2$就不可能是该压栈序列的弹出序列。<br><strong>思路</strong>：</p>\n<ul>\n<li>判断一个序列是不是栈的弹出序列的规律：<ul>\n<li>如果下一个弹出的数字刚好是栈顶数字，那么直接弹出；</li>\n<li>如果下一个弹出的数字不在栈顶，则把压栈序列中还没有入栈的数字压入辅助栈，直到把下一个需要弹出的数字压入栈为止；</li>\n<li>如果所有数字都压入栈后仍然没有找到下一个弹出的数字，那么该序列不可能是一个弹出序列。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsPopOrder</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pushV,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; popV)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pushV.size()==<span class=\"number\">0</span> || popV.size()==<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; <span class=\"comment\">//标记pushV</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; <span class=\"comment\">//标记popV</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;pushV.size())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(pushV[i++]);</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(!s.empty() &amp;&amp; s.top()==popV[j])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                s.pop();</span><br><span class=\"line\">                j++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s.empty();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"三、树\"><a href=\"#三、树\" class=\"headerlink\" title=\"三、树\"></a>三、树</h1><h2 id=\"1-二叉树的深度\"><a href=\"#1-二叉树的深度\" class=\"headerlink\" title=\"1. 二叉树的深度\"></a>1. 二叉树的深度</h2><p><strong>题目描述</strong>:<br>输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。<br><strong>思路</strong>：<br><strong>解法1</strong>：</p>\n<ul>\n<li>前序遍历二叉树，计算每一叶结点的深度，找出最大的叶结点的深度，即树的高度。</li>\n<li>在两种情况下，当前深度变量<code>currentDepth</code>进行减一操作：<ul>\n<li>当前结点是叶结点，则将<code>currentDepth</code>与最大的叶结点深度<code>maxDepth</code>比较，更新<code>maxDepth</code>。之后，<code>currentDepth</code>进行减一操作；</li>\n<li>任一结点的左右子树遍历完成，<code>currentDepth</code>进行减一操作。</li>\n</ul>\n</li>\n<li>注：该题规定空树深度为0，根结点深度为1。</li>\n</ul>\n<p><strong>解法2</strong>：</p>\n<ul>\n<li>将结点的深度从该角度计算：后序遍历时，结点的左右子树的深度较大值加一。</li>\n<li>因此，树的深度可以这样计算：后序遍历二叉树，较大子树的深度值加一。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//解法1</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> maxDepth=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> currentDepth=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">        currentDepth++;</span><br><span class=\"line\">        <span class=\"comment\">//当前结点是叶结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot-&gt;left==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//更新maxDepth</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(currentDepth&gt;maxDepth)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                maxDepth = currentDepth;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//currentDepth进行减一操作</span></span><br><span class=\"line\">            currentDepth--;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//任一结点的左右子树遍历完成，currentDepth进行减一操作</span></span><br><span class=\"line\">        currentDepth--;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//解法2</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//递归后序遍历二叉树</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件：若pRoot为nullptr，则返回0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> left=TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> right=TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//较大子树的深度值加一</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(left&gt;right)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> left+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> right+<span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-二叉树的镜像\"><a href=\"#2-二叉树的镜像\" class=\"headerlink\" title=\"2. 二叉树的镜像\"></a>2. 二叉树的镜像</h2><p><strong>题目描述</strong>:<br>操作给定的二叉树，将其变换为源二叉树的镜像。<br><strong>输入描述</strong>:<br>二叉树的镜像定义：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">源二叉树 </span><br><span class=\"line\">    \t    8</span><br><span class=\"line\">    \t   /  \\</span><br><span class=\"line\">    \t  6   10</span><br><span class=\"line\">    \t / \\  / \\</span><br><span class=\"line\">    \t5  7 9  11</span><br><span class=\"line\">镜像二叉树</span><br><span class=\"line\">    \t    8</span><br><span class=\"line\">    \t   /  \\</span><br><span class=\"line\">    \t  10   6</span><br><span class=\"line\">    \t / \\  / \\</span><br><span class=\"line\">    \t11 9 7   5</span><br></pre></td></tr></table></figure></p>\n<p><strong>思路</strong>：</p>\n<ul>\n<li>前序遍历二叉树，“访问”操作为：交换每一结点的左右子树（左右子树是<code>nullptr</code>也没关系，照样交换）。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Mirror</span><span class=\"params\">(TreeNode *pRoot)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">//交换左右子树</span></span><br><span class=\"line\">        TreeNode* temp = pRoot-&gt;left;</span><br><span class=\"line\">        pRoot-&gt;left = pRoot-&gt;right;</span><br><span class=\"line\">        pRoot-&gt;right = temp;</span><br><span class=\"line\">        Mirror(pRoot-&gt;left);</span><br><span class=\"line\">        Mirror(pRoot-&gt;right);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-平衡二叉树\"><a href=\"#3-平衡二叉树\" class=\"headerlink\" title=\"3. 平衡二叉树\"></a>3. 平衡二叉树</h2><p><strong>题目描述</strong><br>输入一棵二叉树，判断该二叉树是否是平衡二叉树。注意，空树默认为平衡二叉树。<br><strong>思路</strong>：</p>\n<ul>\n<li>依据#1题&lt;二叉树的深度&gt;中解法2的思想，将平衡二叉树的判断准则定为：每一结点的左右子树的深度值相差不超过1。</li>\n<li>后序遍历二叉树，计算每一结点的左右子树的深度，比较差值。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> result=<span class=\"literal\">true</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsBalanced_Solution</span><span class=\"params\">(TreeNode* pRoot)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        TreeDepth(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//后序遍历二叉树，计算树的深度</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> left = TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> right = TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//比较左右子树深度的差值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(left-right)&gt;<span class=\"number\">1</span>)</span><br><span class=\"line\">            result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//计算每一结点的左右子树的深度</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(left&gt;right)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> left+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> right+<span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-把二叉树打印成多行\"><a href=\"#4-把二叉树打印成多行\" class=\"headerlink\" title=\"4. 把二叉树打印成多行\"></a>4. 把二叉树打印成多行</h2><p><strong>题目描述</strong>：<br>从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。<br><strong>思路</strong>：</p>\n<ul>\n<li>层序遍历二叉树，在每一层末尾加入一个换行符。</li>\n<li>通过变量<code>toBePrinted</code>记录当前层要打印结点个数,<code>nextLevel</code>记录下一层要打印结点个数。</li>\n<li>对于根结点，<code>toBePrinted</code>为1，在将根结点的左右子结点入队时记录<code>nextLevel</code>。</li>\n<li>当<code>toBePrinted</code>为0，则打印一个换行，<code>toBePrinted</code>置为<code>nextLevel</code>，<code>nextLevel</code>清零。接着，开始处理下一层。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> toBePrinted=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> nextLevel = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;TreeNode*&gt; q; </span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; level;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; Print(TreeNode* pRoot) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        q.push(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pCurrent = q.front();</span><br><span class=\"line\">            q.pop();</span><br><span class=\"line\">            toBePrinted--;</span><br><span class=\"line\">            level.push_back(pCurrent-&gt;val);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                q.push(pCurrent-&gt;left);</span><br><span class=\"line\">                nextLevel++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;right != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                q.push(pCurrent-&gt;right);</span><br><span class=\"line\">                nextLevel++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(toBePrinted==<span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                toBePrinted=nextLevel;</span><br><span class=\"line\">                nextLevel=<span class=\"number\">0</span>;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result; <span class=\"comment\">//注意，最后要return</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-对称的二叉树\"><a href=\"#5-对称的二叉树\" class=\"headerlink\" title=\"5. 对称的二叉树\"></a>5. 对称的二叉树</h2><p><strong>题目描述</strong>:<br>请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。<br><strong>思路</strong>：</p>\n<ul>\n<li>一开始的想法：构建该二叉树的镜像二叉树，然后同时遍历两个树，逐一进行比较。但空间复杂度为$O(n)$，不可行。</li>\n<li>正确解法：前序遍历是<code>&lt;root&gt;&lt;left&gt;&lt;right&gt;</code>。定义一种新的和前序遍历对称的遍历方式<code>&lt;root&gt;&lt;right&gt;&lt;left&gt;</code>。对于对称的二叉树，前序遍历的结果，和新定义的遍历方式的结果应该是一样的。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isSymmetrical</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> treversal(pRoot, pRoot);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">treversal</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> || pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1-&gt;val!=pRoot2-&gt;val)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1=treversal(pRoot1-&gt;left, pRoot2-&gt;right);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2=treversal(pRoot1-&gt;right, pRoot2-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"6-二叉树的下一个结点\"><a href=\"#6-二叉树的下一个结点\" class=\"headerlink\" title=\"6. 二叉树的下一个结点\"></a>6. 二叉树的下一个结点</h2><p><strong>题目描述</strong>:<br>给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，<strong>同时包含指向父结点的指针</strong>。<br><strong>思路</strong>：</p>\n<ul>\n<li>在中序遍历顺序<code>&lt;left，root，right&gt;</code>下，二叉树某一结点<code>pNode</code>的下一个结点规律如下：<ul>\n<li>如果<code>pNode</code>含有右子树，则下一结点为<code>pNode</code>的<strong>右子树中最深最左的那个结点</strong>。</li>\n<li>如果<code>pNode</code>不含右子树，则下一结点为<strong>使得<code>pNode</code>在其左子树中的最近的祖先结点</strong>。<br>注：最极端情况是<code>pNode</code>是二叉树中序遍历的最后一个结点，即在二叉树的最右末端，直到回溯到根结点，<code>pNode</code>还是在右子树中，即没有满足题意的下一结点。根结点的父节点为<code>nullptr</code>，祖先结点为<code>nullptr</code>也是终止循环条件之一。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeLinkNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeLinkNode(int x) :val(x), left(NULL), right(NULL), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    TreeLinkNode* pNext=<span class=\"literal\">nullptr</span>; <span class=\"comment\">//记录目标结点</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeLinkNode* <span class=\"title\">GetNext</span><span class=\"params\">(TreeLinkNode* pNode)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pNode==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//如果pNode含有右子树，则下一结点为pNode的右子树中最深最左的那个结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pNode-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNext=pNode-&gt;right;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pNext-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNext=pNext-&gt;left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//如果pNode不含右子树，则下一结点为使得pNode在其左子树中的最近的祖先结点</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pNode-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeLinkNode* pParent = pNode-&gt;next;</span><br><span class=\"line\">            <span class=\"comment\">//最极端情况：若到根节点还没找到</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pParent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(pParent-&gt;left==pNode)</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    pNext=pParent;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">else</span></span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    pNode = pParent;</span><br><span class=\"line\">                    pParent=pParent-&gt;next;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pNext;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-二叉搜索树与双向链表\"><a href=\"#7-二叉搜索树与双向链表\" class=\"headerlink\" title=\"7. 二叉搜索树与双向链表\"></a>7. 二叉搜索树与双向链表</h2><p><strong>题目描述</strong>：<br>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，二叉搜索树的中序遍历结果即为有序序列。</li>\n<li>然后，在中序遍历的“访问”操作中进行如下操作完成双向链表的转换：<ul>\n<li>维护双向链表的尾结点<code>pLastNode</code>，初始化为<code>nullptr</code>。 </li>\n<li>当前结点的<code>left</code>指针指向<code>pLastNode</code>，<code>pLastNode</code>的<code>right</code>指针指向当前结点，更新<code>pLastNode</code>。</li>\n<li>最终结果： <code>nullptr&lt;-1&lt;=&gt;2&lt;=&gt;3&lt;=&gt;4&lt;=&gt;5-&gt;nullptr</code>（自己画图即可知）。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Convert</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//pLastNode表示双向链表中的最后一个结点</span></span><br><span class=\"line\">        TreeNode* pLastNode=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        InorderTraversal(pRoot,&amp;pLastNode);</span><br><span class=\"line\">        TreeNode* pHead=pLastNode;</span><br><span class=\"line\">        <span class=\"comment\">//找出双向链表中的头结点，并返回</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pHead-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHead=pHead-&gt;left;    </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//中序遍历二叉搜索树</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InorderTraversal</span><span class=\"params\">(TreeNode* pRoot,TreeNode** pLastNode)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        InorderTraversal(pRoot-&gt;left,pLastNode);</span><br><span class=\"line\">        <span class=\"comment\">//如果pLastNode为nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*pLastNode==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pRoot-&gt;left=*pLastNode;     <span class=\"comment\">//当前结点的left指针指向链表中最后一个结点</span></span><br><span class=\"line\">            *pLastNode=pRoot;           <span class=\"comment\">//更新链表中最后一个结点</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pRoot-&gt;left=*pLastNode;     <span class=\"comment\">//当前结点的left指针指向链表中最后一个结点</span></span><br><span class=\"line\">            (*pLastNode)-&gt;right=pRoot;  <span class=\"comment\">//链表中最后一个结点的right指针指向当前结点</span></span><br><span class=\"line\">            *pLastNode=pRoot;           <span class=\"comment\">//更新链表中最后一个结点</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        InorderTraversal(pRoot-&gt;right,pLastNode);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-从上往下打印二叉树\"><a href=\"#8-从上往下打印二叉树\" class=\"headerlink\" title=\"8. 从上往下打印二叉树\"></a>8. 从上往下打印二叉树</h2><p><strong>题目描述</strong>:<br>从上往下打印出二叉树的每个节点，同层节点从左至右打印。<br><strong>思路</strong>：</p>\n<ul>\n<li>层序遍历二叉树。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;TreeNode*&gt; q;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; PrintFromTopToBottom(TreeNode* root) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root == <span class=\"literal\">nullptr</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> v;</span><br><span class=\"line\">        q.push(root);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pCurrent = q.front();</span><br><span class=\"line\">            q.pop();</span><br><span class=\"line\">            v.push_back(pCurrent-&gt;val);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                q.push(pCurrent-&gt;left);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                q.push(pCurrent-&gt;right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> v;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"9-二叉树中和为某一值的路径\"><a href=\"#9-二叉树中和为某一值的路径\" class=\"headerlink\" title=\"9. 二叉树中和为某一值的路径\"></a>9. 二叉树中和为某一值的路径</h2><p><strong>题目描述</strong>:<br>输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。<br><strong>思路</strong>：</p>\n<ul>\n<li>前序遍历二叉树，计算每一路径和，与期望值进行比较。</li>\n<li>在两种情况下，从当前状态存储变量（<code>currentSum</code>及 <code>path</code>）中移去当前结点：<ul>\n<li>当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点(<code>path.pop_back()</code>,<code>currentSum-=root-&gt;val</code>)；</li>\n<li>任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点(<code>path.pop_back()</code>,<code>currentSum-=root-&gt;val</code>)。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> currentSum=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; path;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; FindPath(TreeNode* root,<span class=\"keyword\">int</span> expectNumber) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        preOrder(root,expectNumber);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//前序遍历二叉树，计算每一路径和。</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(TreeNode* root, <span class=\"keyword\">int</span> expectNumber)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        path.push_back(root-&gt;val);</span><br><span class=\"line\">        currentSum+=root-&gt;val;</span><br><span class=\"line\">        <span class=\"comment\">//1.当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点；</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root-&gt;left==<span class=\"literal\">nullptr</span> &amp;&amp; root-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(currentSum==expectNumber)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(path);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//下面该段可都不写，都留给情况2去处理，但若写，就需要return，否则会处理两次。</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(path.size()&gt;<span class=\"number\">0</span>)</span><br><span class=\"line\">                path.pop_back();</span><br><span class=\"line\">            currentSum-=root-&gt;val;</span><br><span class=\"line\">            <span class=\"keyword\">return</span>; <span class=\"comment\">//注意，需要return</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        preOrder(root-&gt;left,expectNumber);</span><br><span class=\"line\">        preOrder(root-&gt;right,expectNumber);</span><br><span class=\"line\">        <span class=\"comment\">//2.任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点。</span></span><br><span class=\"line\">        currentSum-=root-&gt;val;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(path.size()&gt;<span class=\"number\">0</span>)</span><br><span class=\"line\">            path.pop_back();</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"10-按之字形顺序打印二叉树\"><a href=\"#10-按之字形顺序打印二叉树\" class=\"headerlink\" title=\"10. 按之字形顺序打印二叉树\"></a>10. 按之字形顺序打印二叉树</h2><p><strong>题目描述</strong>：<br>请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。<br><strong>思路</strong>：</p>\n<ul>\n<li>按之字形顺序打印二叉树需要两个栈。</li>\n<li>若当前打印的是奇数层（如第1层、第3层），则先保存左子节点再保存右子节点到第一个栈。</li>\n<li>若当前打印的是偶数层（如第2层、第4层），则先保存右子节点再保存左子节点到第二个栈。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;TreeNode*&gt; s1;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;TreeNode*&gt; s2;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; level;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; Print(TreeNode* pRoot) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        s1.push(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!s1.empty()||!s2.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s1.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(!s1.empty())</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    TreeNode* pTemp = s1.top();</span><br><span class=\"line\">                    s1.pop();</span><br><span class=\"line\">                    level.push_back(pTemp-&gt;val);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s2.push(pTemp-&gt;left);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s2.push(pTemp-&gt;right);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s2.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(!s2.empty())</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    TreeNode* pTemp = s2.top();</span><br><span class=\"line\">                    s2.pop();</span><br><span class=\"line\">                    level.push_back(pTemp-&gt;val);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s1.push(pTemp-&gt;right);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s1.push(pTemp-&gt;left);                 </span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"11-二叉搜索树的第k个结点\"><a href=\"#11-二叉搜索树的第k个结点\" class=\"headerlink\" title=\"11. 二叉搜索树的第k个结点\"></a>11. 二叉搜索树的第k个结点</h2><p><strong>题目描述</strong>:<br>给定一颗二叉搜索树，请找出其中的第$k$大的结点。例如， 5 / \\ 3 7 / \\ / \\ 2 4 6 8 中，按结点数值大小顺序第三个结点的值为4。<br><strong>思路</strong>：</p>\n<ul>\n<li>中序遍历BST可得有序序列。</li>\n<li>在中序遍历的“访问”操作中计数。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num=<span class=\"number\">0</span>;</span><br><span class=\"line\">    TreeNode* pNode=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">KthNode</span><span class=\"params\">(TreeNode* pRoot, <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        KthNode(pRoot-&gt;left,k);</span><br><span class=\"line\">        <span class=\"comment\">//在“访问”操作中计数</span></span><br><span class=\"line\">        num++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(num==k)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNode=pRoot; </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        KthNode(pRoot-&gt;right,k);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"12-二叉搜索树的后序遍历序列\"><a href=\"#12-二叉搜索树的后序遍历序列\" class=\"headerlink\" title=\"12. 二叉搜索树的后序遍历序列\"></a>12. 二叉搜索树的后序遍历序列</h2><p><strong>题目描述</strong>：<br>输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。<br><strong>思路</strong>：</p>\n<ul>\n<li>后序遍历顺序：<code>&lt;left，right，root&gt;</code>。</li>\n<li>对于二叉搜索树的后续遍历序列，如果去掉最后一个元素x（也就是根）的序列为T，那么T满足：T可以分成两段，前一段（左子树）小于x，后一段（右子树）大于x，且这两段（子树）都是合法的后序序列。</li>\n<li>故以该规律，递归验证每一左右子树。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">VerifySquenceOfBST</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sequence)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(sequence.empty())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Check(sequence,<span class=\"number\">0</span>,sequence.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Check</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sequence, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件1：一个或零个元素，返回true</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;=end)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rootVal = sequence[end];</span><br><span class=\"line\">        <span class=\"comment\">//分出左子树</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sequence[i]&gt;rootVal)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//验证右子树中所有元素都大于root值</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j = i;j&lt;end;j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//递归出口条件2：右子树中存在小于root值的元素</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sequence[j]&lt;rootVal)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//递归验证左右子树，需都返回true</span></span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1 = Check(sequence,start,i<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2 = Check(sequence,i,end<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"13-树的子结构\"><a href=\"#13-树的子结构\" class=\"headerlink\" title=\"13. 树的子结构\"></a>13. 树的子结构</h2><p><strong>题目描述</strong>:<br>输入两棵二叉树A，B，判断B是不是A的子结构。此外，约定空树不是任意一个树的子结构。<br><strong>思路</strong>：</p>\n<ul>\n<li>遍历树A，在树A中找出所有与树B的根节点值相等的结点，保存至vector容器<code>v</code>中。</li>\n<li>函数<code>bool Check(TreeNode* pTest, TreeNode* pRoot2)</code>：检验以<code>pTest</code>为根结点的树是否包含树B。<strong>注意，左右子树都需返回<code>true</code></strong>。</li>\n<li>对于容器<code>v</code>中所有的<code>pTest</code>结点，逐一进行检验，<strong>只要有一个成立即可</strong>，即包含。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;TreeNode*&gt; v;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasSubtree</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> || pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//在树A中找出所有与树B的根节点值相等的结点，保存至容器v中</span></span><br><span class=\"line\">        Find(pRoot1,pRoot2);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//对于容器v中所有的pTest结点，逐一进行检验</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;v.size();i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result = Check(v[i],pRoot2);</span><br><span class=\"line\">            <span class=\"comment\">//只要有一个成立即可，即包含</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(result==<span class=\"literal\">true</span>) </span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Find</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1-&gt;val==pRoot2-&gt;val)</span><br><span class=\"line\">            v.push_back(pRoot1);</span><br><span class=\"line\">        Find(pRoot1-&gt;left,pRoot2);</span><br><span class=\"line\">        Find(pRoot1-&gt;right,pRoot2);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Check</span><span class=\"params\">(TreeNode* pTest, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest-&gt;val!=pRoot2-&gt;val)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1 = Check(pTest-&gt;left,pRoot2-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2 = Check(pTest-&gt;right,pRoot2-&gt;right);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"14-重建二叉树\"><a href=\"#14-重建二叉树\" class=\"headerlink\" title=\"14. 重建二叉树\"></a>14. 重建二叉树</h2><p><strong>题目描述</strong>:<br>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列<script type=\"math/tex\">\\{1,2,4,7,3,5,6,8\\}</script>和中序遍历序列<script type=\"math/tex\">\\{4,7,2,1,5,3,8,6\\}</script>，则重建二叉树并返回。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，前序遍历序列的首元素给出根结点；然后，通过中序遍历序列得出左右子树长度；最后，可分割出左右子树各自的前序序列和中序序列。</li>\n<li>分别递归重建左子树和右子树，递归终止条件：<ul>\n<li>当序列中只剩一元素(<code>start==end</code>)时，返回该根结点指针；</li>\n<li>当序列中无元素(<code>start&gt;end</code>)时，返回<code>nullptr</code>。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">reConstructBinaryTree</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pre,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; vin)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pre.empty() || vin.empty() || pre.size()!=vin.size())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reConstruct(pre, <span class=\"number\">0</span>, pre.size()<span class=\"number\">-1</span>,vin,<span class=\"number\">0</span>, vin.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">reConstruct</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pre, <span class=\"keyword\">int</span> preStart, <span class=\"keyword\">int</span> preEnd,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; vin,<span class=\"keyword\">int</span> vinStart, <span class=\"keyword\">int</span> vinEnd)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件1：当序列中只剩一结点，返回该结点指针</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(preStart==preEnd)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pNode = <span class=\"keyword\">new</span> TreeNode(pre[preStart]);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件2：当序列无结点时，返回nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(preStart&gt;preEnd)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//前序遍历序列的首元素给出根结点</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> rootVal = pre[preStart];</span><br><span class=\"line\">        TreeNode* pRoot = <span class=\"keyword\">new</span> TreeNode(rootVal);</span><br><span class=\"line\">        <span class=\"comment\">//通过中序遍历序列得出左右子树长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = vinStart;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(;i&lt;vinEnd;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(vin[i]==rootVal)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> leftLength = i-vinStart; <span class=\"keyword\">int</span> rightLength = vinEnd-i;</span><br><span class=\"line\">        <span class=\"comment\">//分割出左右子树各自的前序序列和中序序列</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> preStartLeft = preStart+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> preEndLeft=preStartLeft+leftLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> vinStartLeft=vinStart;<span class=\"keyword\">int</span> vinEndLeft=i<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> preStartRight = preEndLeft+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> preEndRight=preEnd;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> vinStartRight = i+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> vinEndRight=vinEnd;</span><br><span class=\"line\">        <span class=\"comment\">//分别递归重建左子树和右子树</span></span><br><span class=\"line\">        pRoot-&gt;left = reConstruct(pre,preStartLeft,preEndLeft,vin,vinStartLeft,vinEndLeft);</span><br><span class=\"line\">        pRoot-&gt;right =reConstruct(pre,preStartRight,preEndRight,vin,vinStartRight,vinEndRight);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"15-序列化二叉树\"><a href=\"#15-序列化二叉树\" class=\"headerlink\" title=\"15. 序列化二叉树\"></a>15. 序列化二叉树</h2><p><strong>题目描述</strong>：<br>请实现两个函数，分别用来序列化和反序列化二叉树<br><strong>思路</strong>：</p>\n<ul>\n<li>对于序列化：<ul>\n<li>使用前序遍历，递归的将二叉树的值转化为字符，并且在每次二叉树的结点不为空时，在转化val所得的字符之后添加一个<code>&#39;，&#39;</code>作为分割。对于空节点则以 <code>&#39;#&#39;</code> 代替。</li>\n</ul>\n</li>\n<li>对于反序列化：<ul>\n<li>按照前序顺序，递归的使用字符串中的字符创建左右子树。注意：在递归时，递归函数的参数一定要是<code>char **</code>，这样才能保证每次递归后指向字符串的指针会随着递归的进行而移动。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">char</span>* <span class=\"title\">Serialize</span><span class=\"params\">(TreeNode *root)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;    </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> str;</span><br><span class=\"line\">        Serialize2(root,str);</span><br><span class=\"line\">        <span class=\"keyword\">char</span>* result = <span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[str.size()+<span class=\"number\">1</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;str.size();i++)</span><br><span class=\"line\">            result[i] = str[i];</span><br><span class=\"line\">        result[str.size()] = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Serialize2</span><span class=\"params\">(TreeNode* root, <span class=\"built_in\">string</span>&amp; str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            str+=<span class=\"string\">'#'</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> r = to_string(root-&gt;val);</span><br><span class=\"line\">        str+=r;</span><br><span class=\"line\">        str+=<span class=\"string\">','</span>;</span><br><span class=\"line\">        Serialize2(root-&gt;left, str);</span><br><span class=\"line\">        Serialize2(root-&gt;right, str);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Deserialize</span><span class=\"params\">(<span class=\"keyword\">char</span> *str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        TreeNode* result = Deserialize2(&amp;str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Deserialize2</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str==<span class=\"string\">'#'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> num=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(**str!= <span class=\"string\">'\\0'</span> &amp;&amp; **str!=<span class=\"string\">','</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num=num*<span class=\"number\">10</span>+((**str)-<span class=\"string\">'0'</span>);</span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        TreeNode* pRoot = <span class=\"keyword\">new</span> TreeNode(num);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str ==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">        pRoot-&gt;left = Deserialize2(str);</span><br><span class=\"line\">        pRoot-&gt;right= Deserialize2(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"四、字符串\"><a href=\"#四、字符串\" class=\"headerlink\" title=\"四、字符串\"></a>四、字符串</h1><h2 id=\"1-替换空格\"><a href=\"#1-替换空格\" class=\"headerlink\" title=\"1. 替换空格\"></a>1. 替换空格</h2><p><strong>题目描述</strong>：<br>请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为”We Are Happy.”则经过替换之后的字符串为”We%20Are%20Happy.”<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>注意</strong>：假设在原来的字符串上进行替换，并保证输入的字符串后面有足够多的空余内存。</li>\n<li><strong>步骤</strong>：从后向前替换：<ul>\n<li>1.遍历字符串，得到原字符串的长度和空格的个数;</li>\n<li>2.计算新字符串的长度，新串长度为原串长度加上两倍的空格个数；</li>\n<li>3.从后向前替换：设置两个指针，p1指向原字符串末尾，p2指向新字符串末尾。前移指针p1，逐个把它指向的内容复制到p2指向的位置；</li>\n</ul>\n</li>\n<li>所有字符串都只复制一次，时间复杂度：O(n)。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">replaceSpace</span><span class=\"params\">(<span class=\"keyword\">char</span> *str,<span class=\"keyword\">int</span> length)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">nullptr</span> || length&lt;<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.遍历字符串，得到空格的个数</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> numSpace = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;length;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">                numSpace++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.计算新字符串的长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> lengthNew = length+<span class=\"number\">2</span>*numSpace;</span><br><span class=\"line\">        <span class=\"comment\">//3.从后向前替换：设置两个指针，i指向原字符串末尾，j指向新字符串末尾</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = length<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> j = lengthNew<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//终止条件，i&lt;0</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&gt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'0'</span>;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'2'</span>;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'%'</span>;</span><br><span class=\"line\">                i--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                str[j--] = str[i--];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-整数中1出现的次数（从1到n整数中1出现的次数）\"><a href=\"#2-整数中1出现的次数（从1到n整数中1出现的次数）\" class=\"headerlink\" title=\"2. 整数中1出现的次数（从1到n整数中1出现的次数）\"></a>2. 整数中1出现的次数（从1到n整数中1出现的次数）</h2><p><strong>题目描述</strong><br>求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。<br><strong>思路</strong>：</p>\n<ul>\n<li>对1~n的每一个数：通过对10求余数判断整数的个位数字是不是1，如果这个数字大于10，则除以10之后再判断个位数字是不是1。</li>\n<li>对每个数字都要做除法和求余运算，以求出该数字中1出现的次数。如果输入数字为$n$，$n$有$O(logn)$位，我们需要判断每一位是不是1，那么它的时间复杂度是$O(nlogn)$。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">NumberOf1Between1AndN_Solution</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> number=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">            number+=NumberOf1(i);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">NumberOf1</span><span class=\"params\">(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> number=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(n)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(n%<span class=\"number\">10</span> ==<span class=\"number\">1</span>)</span><br><span class=\"line\">                number++;</span><br><span class=\"line\">            n=n/<span class=\"number\">10</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-翻转单词顺序列\"><a href=\"#3-翻转单词顺序列\" class=\"headerlink\" title=\"3. 翻转单词顺序列\"></a>3. 翻转单词顺序列</h2><p><strong>题目描述</strong>:输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串”I am a student.”，则输出”student. a am I”。<br><strong>思路</strong>：</p>\n<ul>\n<li>第一步翻转句子中所有的字符。比如翻转”I am a student.”中所有的字符得到”.tenduts a ma I”，此时不但翻转了句子中单词的顺序，连单词内的字符顺序也被翻转了。</li>\n<li>第二步再翻转每个单词中字符的顺序，就得到了“studnet. a am I”。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">ReverseSentence</span><span class=\"params\">(<span class=\"built_in\">string</span> str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//1.先整体翻转</span></span><br><span class=\"line\">        ReverseWord(str,<span class=\"number\">0</span>,str.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i,start,end;</span><br><span class=\"line\">        i=start=end=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;str.size())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//空格跳过</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(i&lt;str.size() &amp;&amp; str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//不是空格，找单词最后一个字符的位置</span></span><br><span class=\"line\">            start = end = i;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(i&lt;str.size() &amp;&amp; str[i]!=<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">                end++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//2.局部翻转</span></span><br><span class=\"line\">            ReverseWord(str,start,end<span class=\"number\">-1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReverseWord</span><span class=\"params\">(<span class=\"built_in\">string</span>&amp; str, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(start&lt;end)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(str[start++],str[end--]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-左旋转字符串\"><a href=\"#4-左旋转字符串\" class=\"headerlink\" title=\"4. 左旋转字符串\"></a>4. 左旋转字符串</h2><p><strong>题目描述</strong><br>汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！<br><strong>思路</strong>：</p>\n<ul>\n<li>以”abcdefg”为例，想把它的前两个字符移到后面，得到”cdefgab”。</li>\n<li>将前两个字符分到第一部分，将后面的所有字符分到第二部分。</li>\n<li>先分别翻转这两部分，于是得到“bagfedc”。</li>\n<li>接下来翻转整个字符串，得到“cdefgab”，刚好就是把原始字符串左旋转两位的结果。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">LeftRotateString</span><span class=\"params\">(<span class=\"built_in\">string</span> str, <span class=\"keyword\">int</span> n)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str.size()&lt;<span class=\"number\">1</span> || n&gt;str.size() || n&lt;<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> startFirst = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endFirst = n<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> startSecond = n;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endSecond = str.size()<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 翻转字符串的前面n个字符</span></span><br><span class=\"line\">        ReverseWord(str,startFirst,endFirst);</span><br><span class=\"line\">        <span class=\"comment\">// 翻转字符串的后面部分</span></span><br><span class=\"line\">        ReverseWord(str,startSecond,endSecond);</span><br><span class=\"line\">        <span class=\"comment\">// 翻转整个字符串</span></span><br><span class=\"line\">        ReverseWord(str,<span class=\"number\">0</span>,str.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReverseWord</span><span class=\"params\">(<span class=\"built_in\">string</span>&amp; str, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(start&lt;end)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">char</span> temp = str[start];</span><br><span class=\"line\">            str[start] = str[end];</span><br><span class=\"line\">            str[end] = temp;</span><br><span class=\"line\">            start++;</span><br><span class=\"line\">            end--;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-把字符串转换成整数\"><a href=\"#5-把字符串转换成整数\" class=\"headerlink\" title=\"5. 把字符串转换成整数\"></a>5. 把字符串转换成整数</h2><p><strong>题目描述</strong><br>将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0<br><strong>输入描述</strong>:<br>输入一个字符串,包括数字字母符号,可以为空<br><strong>输出描述</strong>:<br>如果是合法的数值表达则返回该数字，否则返回0<br><strong>示例</strong>:<br>输入:<br>+2147483647<br>    1a33<br>输出:<br>2147483647<br>    0<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">StrToInt</span><span class=\"params\">(<span class=\"built_in\">string</span> str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* cstr = str.c_str();</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>((cstr != <span class=\"literal\">NULL</span>) &amp;&amp; (*cstr!= <span class=\"string\">'\\0'</span>)) <span class=\"comment\">//字符串不为空</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">bool</span> minus = <span class=\"literal\">false</span>; <span class=\"comment\">//检查第一位是否为正负号</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*cstr==<span class=\"string\">'+'</span>)</span><br><span class=\"line\">                cstr++;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(*cstr==<span class=\"string\">'-'</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                cstr++;</span><br><span class=\"line\">                minus = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*cstr!=<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">                num = StrToIntCore(cstr,minus);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">long</span> <span class=\"keyword\">long</span> <span class=\"title\">StrToIntCore</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* digit, <span class=\"keyword\">bool</span> minus)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(*digit!=<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">        &#123;   </span><br><span class=\"line\">            <span class=\"comment\">//计算数字大小</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*digit&gt;=<span class=\"string\">'\\0'</span> &amp;&amp; *digit&lt;=<span class=\"string\">'9'</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> flag = minus? <span class=\"number\">-1</span>:<span class=\"number\">1</span>;</span><br><span class=\"line\">                num = num*<span class=\"number\">10</span>+flag*(*digit-<span class=\"string\">'0'</span>);</span><br><span class=\"line\">                <span class=\"comment\">//溢出判断</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span>((!minus &amp;&amp; num&gt;<span class=\"number\">0x7FFFFFFF</span>) || (minus &amp;&amp; num&lt;(<span class=\"keyword\">signed</span> <span class=\"keyword\">int</span>)<span class=\"number\">0x80000000</span>))</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    num=<span class=\"number\">0</span>;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">         \t\tdigit++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//非法输入</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                num=<span class=\"number\">0</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">truetrue<span class=\"keyword\">return</span> num;        </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"6-正则表达式匹配\"><a href=\"#6-正则表达式匹配\" class=\"headerlink\" title=\"6. 正则表达式匹配\"></a>6. 正则表达式匹配</h2><p><strong>题目描述</strong>:<br>请实现一个函数用来匹配包括’.’和’*‘的正则表达式。模式中的字符’.’表示任意一个字符，而’*‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”ab*ac*a”匹配，但是与”aa.a”和”ab*a”均不匹配<br><strong>思路</strong>：<br>A：下一个字符是<code>*</code><br>　　1.若当前字符匹配<br>　　　　选择1：匹配了，但我当作0匹配(匹配0次)。<code>s不动，p加2</code><br>　　　　选择2：匹配了，匹配结束(匹配1次)。<code>s+1,p+2</code><br>　　　　选择3：匹配了，我继续匹配下一个(匹配多次)。<code>s+1，p不动</code><br>　　2.当前字符不匹配。<code>s不动，p加2</code><br>B:下一个字符不是<code>*</code>，当前字符匹配。<code>s+1,p+1</code><br>C:下一个字符不是<code>*</code>，当前字符不匹配。<code>返回false</code><br>递归出口条件：<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">match</span><span class=\"params\">(<span class=\"keyword\">char</span>* str, <span class=\"keyword\">char</span>* pattern)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(str==<span class=\"literal\">NULL</span> || pattern==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        \t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> matchCore(str,pattern);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">matchCore</span><span class=\"params\">(<span class=\"keyword\">char</span>* str, <span class=\"keyword\">char</span>* pattern)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件:字符串和模式串同时走完</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'\\0'</span> &amp;&amp; *pattern==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件：字符串没走完，模式串走完，返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str!=<span class=\"string\">'\\0'</span> &amp;&amp; *pattern==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//A：下一个字符是*</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*(pattern+<span class=\"number\">1</span>)==<span class=\"string\">'*'</span>) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//1.若当前字符匹配</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*pattern==*str || (*pattern==<span class=\"string\">'.'</span> &amp;&amp; *str!=<span class=\"string\">'\\0'</span>))</span><br><span class=\"line\">            \t<span class=\"keyword\">return</span> matchCore(str,pattern+<span class=\"number\">2</span>)    <span class=\"comment\">//选择1：匹配了，但我当作0匹配(匹配0次)</span></span><br><span class=\"line\">            \t\t|| matchCore(str+<span class=\"number\">1</span>,pattern+<span class=\"number\">2</span>)  <span class=\"comment\">//选择2：匹配了，匹配结束(匹配1次)    \t</span></span><br><span class=\"line\">            \t\t|| matchCore(str+<span class=\"number\">1</span>,pattern);    <span class=\"comment\">//选择3：匹配了，我继续匹配下一个(匹配多次)</span></span><br><span class=\"line\">            <span class=\"comment\">//2.当前字符不匹配</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> </span><br><span class=\"line\">            \t<span class=\"keyword\">return</span> matchCore(str,pattern+<span class=\"number\">2</span>); <span class=\"comment\">//匹配结束</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//B:下一个字符不是*，当前字符匹配</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*pattern==*str || (*pattern==<span class=\"string\">'.'</span> &amp;&amp; *str!=<span class=\"string\">'\\0'</span>))</span><br><span class=\"line\">             \t<span class=\"keyword\">return</span> matchCore(str+<span class=\"number\">1</span>,pattern+<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"comment\">//C:下一个字符不是*，当前字符不匹配</span></span><br><span class=\"line\">truetrue<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;           </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-表示数值的字符串\"><a href=\"#7-表示数值的字符串\" class=\"headerlink\" title=\"7. 表示数值的字符串\"></a>7. 表示数值的字符串</h2><p><strong>题目描述</strong><br>请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。<br><strong>思路</strong>：</p>\n<ul>\n<li>表示数值的字符串: A<code>.</code>B<code>e/E</code>C 例如：“+123.45e+6”<ul>\n<li>其中，A、C可能是以+/-开头的0~9的数位串，即整型；B也是0~9的数位串，但前面不能有正负号，即无符号整型。</li>\n</ul>\n</li>\n<li>故步骤为：扫描A部分；遇到小数点<code>.</code>，扫描B部分；遇到<code>e/E</code>，扫描C部分。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isNumeric</span><span class=\"params\">(<span class=\"keyword\">char</span>* str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> numeric = scanInteger(&amp;str);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'.'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ++str;</span><br><span class=\"line\">            numeric = scanUnsignedInteger(&amp;str) || numeric;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'e'</span> || *str==<span class=\"string\">'E'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ++str;</span><br><span class=\"line\">            numeric = numeric &amp;&amp; scanInteger(&amp;str);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> numeric &amp;&amp; *str==<span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">true<span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">scanInteger</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str==<span class=\"string\">'+'</span> || **str==<span class=\"string\">'-'</span>)</span><br><span class=\"line\">            ++(*str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> scanUnsignedInteger(str);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">scanUnsignedInteger</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* before = *str;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(**str!=<span class=\"string\">'\\0'</span> &amp;&amp; **str&gt;=<span class=\"string\">'0'</span> &amp;&amp; **str&lt;=<span class=\"string\">'9'</span>)</span><br><span class=\"line\">            ++(*str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *str&gt;before;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-字符串的排列\"><a href=\"#8-字符串的排列\" class=\"headerlink\" title=\"8. 字符串的排列\"></a>8. 字符串的排列</h2><p><strong>题目描述</strong><br>输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。<br><strong>输入描述</strong>:<br>输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">待</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"五、数组\"><a href=\"#五、数组\" class=\"headerlink\" title=\"五、数组\"></a>五、数组</h1><h2 id=\"1-构建乘积数组\"><a href=\"#1-构建乘积数组\" class=\"headerlink\" title=\"1. 构建乘积数组\"></a>1. 构建乘积数组</h2><p><strong>题目描述</strong><br>给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素<code>B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]</code>。不能使用除法。<br><strong>思路</strong>：</p>\n<ul>\n<li>把数组B看成一个矩阵来创建（见书中）。B[i]的值可以看作图中的矩阵中每行的乘积。</li>\n<li>下三角用自上而下的顺序计算，<code>C[i] =C[i-1]*A[i-1]</code>。</li>\n<li>上三角用自下而上的顺序计算，<code>D[i]= D[i+1]*A[i+1]</code>。</li>\n<li>因此，先算下三角中的连乘，即先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; multiply(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; A) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> length = A.size();</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; B(length); <span class=\"comment\">//vector容器的构造函数</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> B;</span><br><span class=\"line\">        <span class=\"comment\">//计算下三角连乘</span></span><br><span class=\"line\">        B[<span class=\"number\">0</span>]=<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i&lt;length;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            B[i]=B[i<span class=\"number\">-1</span>]*A[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//计算上三角</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=length<span class=\"number\">-2</span>;j&gt;=<span class=\"number\">0</span>;j--)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            temp *= A[j+<span class=\"number\">1</span>];</span><br><span class=\"line\">            B[j] *= temp;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> B;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-连续子数组的最大和\"><a href=\"#2-连续子数组的最大和\" class=\"headerlink\" title=\"2. 连续子数组的最大和\"></a>2. 连续子数组的最大和</h2><p><strong>题目</strong>：输入一个整型数组，数组里有正数也有负数。数组中一个或连续的多个整数组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为 O(n)。<br><strong>说明</strong>：例如输入的数组为{1, -2, 3, 10, -4, 7, 2, -5}，和最大的子数组为｛3, 10, -4, 7, 2}。因此输出为该子数组的和18。<br><strong>思路</strong>：</p>\n<ul>\n<li>从头到尾逐个累加数组中的每个数字。若加上<code>arr[i]</code>后的当前和<code>sumCurrent</code>小于<code>arr[i]</code>，则抛弃当前和<code>sumCurrent</code>及之前的所有数字，置当前和<code>sumCurrent</code>为<code>arr[i]</code>。同时每一步累加都记录下最大和<code>sumMax</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">FindGreatestSumOfSubArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">array</span>)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> sumCurrent=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> sumMax = <span class=\"number\">0x80000000</span>;<span class=\"comment\">//int的最小值</span></span><br><span class=\"line\">        <span class=\"comment\">//从头到尾逐个累加数组中的每个数字</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            sumCurrent += <span class=\"built_in\">array</span>[i];</span><br><span class=\"line\">            <span class=\"comment\">//若当前和sumCurrent小于arr[i]</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]&gt;sumCurrent)</span><br><span class=\"line\">                sumCurrent=<span class=\"built_in\">array</span>[i];</span><br><span class=\"line\">            <span class=\"comment\">//记录下最大和sumMax</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sumCurrent&gt;sumMax) </span><br><span class=\"line\">                sumMax = sumCurrent;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sumMax;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-旋转数组的最小数字\"><a href=\"#3-旋转数组的最小数字\" class=\"headerlink\" title=\"3. 旋转数组的最小数字\"></a>3. 旋转数组的最小数字</h2><p><strong>题目描述</strong><br>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序（递增，可能相等）的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。<br><strong>思路</strong>：<br><strong>思路1</strong>：顺序查找，遍历数组，找到<code>arr[i]&gt;arr[i+1]</code>（稍微优化），时间复杂度$O(n)$，需改进。<br><strong>思路2</strong>：旋转数组是两个排序的子数组，采用二分查找。时间复杂度$O(logn)$：</p>\n<ul>\n<li><strong>情况1</strong>：<ul>\n<li>用指针<code>p1</code>指向第一个数组的第一个元素，用指针<code>p2</code>指向第二个数组的第2个元素。对于旋转数组，有特性：<code>arr[p1]&gt;arr[p2]</code>（<code>第一个数组&gt;=第二个数组</code>）；</li>\n<li>计算中间元素为指针<code>p</code>，如果<code>arr[p]&gt;=arr[p1]</code>，则指针<code>p</code>在第一个数组中，此时最小元素应该位于中间元素的后面，令<code>p1=p;</code>如果<code>arr[p]&lt;=arr[p1]</code>，则指针<code>p</code>在第二个数组中，此时最小元素应该位于中间元素的前面，令<code>p2 = p;</code>；</li>\n<li><code>p1</code>始终在第一个数组，<code>p2</code>始终在第二个数组，故循环终止条件为：<code>(p1+1)=p2</code>，<code>arr[p2]</code>即为最小元素。</li>\n</ul>\n</li>\n<li><strong>情况2</strong>：若旋转数组是将原来的0个元素搬到最后面，即数组有序，即<code>arr[p1]&lt;arr[p2]</code>，该情况是情况1中的特例，情况1中的做法是不适用的，直接返回最小元素<code>arr[0]</code>。</li>\n<li><strong>情况3</strong>：当指针<code>p</code>，<code>p1</code>，<code>p2</code>指向的元素相同时，即<code>arr[p]==arr[p1] &amp;&amp; arr[p]==arr[p2]</code>时，无法判断该将中间的数字是位于第一个数组还是第二个数组，无法继续用二分法，转而对<code>[p1，p2]</code>采用顺序查找法。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路1：顺序查找，时间复杂度O(n)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">minNumberInRotateArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; rotateArray)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> min = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!rotateArray.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> size = rotateArray.size();</span><br><span class=\"line\">            <span class=\"comment\">//顺序查找，遍历数组，找到arr[i+1]&lt;arr[i]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;size<span class=\"number\">-1</span>;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(rotateArray[i+<span class=\"number\">1</span>]&lt;rotateArray[i])</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    min = rotateArray[i+<span class=\"number\">1</span>];</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路2：二分查找，时间复杂度O(logn)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">minNumberInRotateArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; rotateArray)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rotateArray.empty())  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = rotateArray.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> p1 = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> p2 = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> minIndex=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//情况2，数组有序，直接返回arr[0]</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rotateArray[p1]&lt;rotateArray[p2]) <span class=\"keyword\">return</span> rotateArray[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"comment\">//情况1，二分查找</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>((p1+<span class=\"number\">1</span>)!=p2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> p = (p1+p2)/<span class=\"number\">2</span>;</span><br><span class=\"line\">            <span class=\"comment\">//情况3，转为对[p1,p2]采用顺序查找</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rotateArray[p1]==rotateArray[p] &amp;&amp; rotateArray[p]==rotateArray[p2])</span><br><span class=\"line\">                <span class=\"keyword\">return</span> MinInOrder(rotateArray,p1,p2);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rotateArray[p]&gt;=rotateArray[p1]) p1 = p;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(rotateArray[p]&lt;=rotateArray[p2]) p2 = p;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> rotateArray[p2];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MinInOrder</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; rotateArray,<span class=\"keyword\">int</span> p1, <span class=\"keyword\">int</span> p2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> min = <span class=\"number\">0</span>;</span><br><span class=\"line\">    \t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = p1;i&lt;p2;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            \t<span class=\"keyword\">if</span>(rotateArray[i+<span class=\"number\">1</span>]&lt;rotateArray[i])</span><br><span class=\"line\">            \t&#123;</span><br><span class=\"line\">                \tmin = rotateArray[i+<span class=\"number\">1</span>];</span><br><span class=\"line\">                \t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">            \t&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-数字在排序数组中出现的次数\"><a href=\"#4-数字在排序数组中出现的次数\" class=\"headerlink\" title=\"4. 数字在排序数组中出现的次数\"></a>4. 数字在排序数组中出现的次数</h2><p><strong>题目描述</strong><br>统计一个数字在排序数组中出现的次数。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>思路1</strong>：顺序遍历数组，时间复杂度$O(n)$，需改进。</li>\n<li><strong>思路2</strong>：有序数组，使用二分查找。分两次二分查找：<ul>\n<li><strong>第一次</strong>找出该数字第一次出现的位置:<code>(mid==start) || (data[mid-1]!=target))</code>即已经是最左边的位置或其左边的一个数不等于该数；</li>\n<li><strong>第二次</strong>找出该数字最后一次出现的位置：<code>(mid==end) || (data[mid+1]!=target)</code>即已经是最右边的位置或其右边的一个数不等于该数。</li>\n</ul>\n</li>\n<li>可用递归实现，也可以用循环实现。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路2，递归实现</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetNumberOfK</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data ,<span class=\"keyword\">int</span> k)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> number = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data.empty()) <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> firstIndex = getFirst(data,<span class=\"number\">0</span>,size<span class=\"number\">-1</span>,k);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> lastIndex = getLast(data,<span class=\"number\">0</span>,size<span class=\"number\">-1</span>,k);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (firstIndex &gt; <span class=\"number\">-1</span> &amp;&amp; lastIndex &gt; <span class=\"number\">-1</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \tnumber = lastIndex - firstIndex + <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getFirst</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end, <span class=\"keyword\">int</span> target)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mid = (start+end)/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data[mid]==target)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>((mid==start) || (data[mid<span class=\"number\">-1</span>]!=target))<span class=\"comment\">//让它是第一个出现的位置</span></span><br><span class=\"line\">            <span class=\"comment\">//if((mid==start) || (mid-1&gt;start&amp;&amp;data[mid-1]!=target))//等价</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> mid;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(data[mid]&gt;target) end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> getFirst(data,start,end,target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getLast</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end, <span class=\"keyword\">int</span> target)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mid = (start+end)/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data[mid]==target)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">           <span class=\"keyword\">if</span>((mid==end) || (data[mid+<span class=\"number\">1</span>]!=target))<span class=\"comment\">//让它是最后一个出现的位置</span></span><br><span class=\"line\">           <span class=\"comment\">//if((mid==end) || (mid+1&lt;end&amp;&amp;data[mid+1]!=target))//等价</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> mid;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(data[mid]&gt;target) end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> getLast(data,start,end,target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-数组中重复的数字\"><a href=\"#5-数组中重复的数字\" class=\"headerlink\" title=\"5. 数组中重复的数字\"></a>5. 数组中重复的数字</h2><p>题目描述<br>在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。</p>\n<h2 id=\"6-数组中只出现一次的数字\"><a href=\"#6-数组中只出现一次的数字\" class=\"headerlink\" title=\"6. 数组中只出现一次的数字\"></a>6. 数组中只出现一次的数字</h2><p>题目描述<br>一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。</p>\n<h2 id=\"7-数组中出现次数超过一半的数字\"><a href=\"#7-数组中出现次数超过一半的数字\" class=\"headerlink\" title=\"7. 数组中出现次数超过一半的数字\"></a>7. 数组中出现次数超过一半的数字</h2><p>题目描述<br>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。</p>\n<h2 id=\"8-把数组排成最小的数\"><a href=\"#8-把数组排成最小的数\" class=\"headerlink\" title=\"8. 把数组排成最小的数\"></a>8. 把数组排成最小的数</h2><p><strong>题目描述</strong><br>输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。<br><strong>思路</strong>：<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">PrintMinNumber</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; numbers)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> length = numbers.size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length==<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"string\">\"\"</span>;</span><br><span class=\"line\">        sort(numbers.begin(),numbers.end(),compare);</span><br><span class=\"line\">        <span class=\"built_in\">string</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;length;i++)</span><br><span class=\"line\">            result += to_string(numbers[i]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">bool</span> <span class=\"title\">compare</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> A = to_string(a)+to_string(b);</span><br><span class=\"line\">        <span class=\"built_in\">string</span> B = to_string(b)+to_string(a);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> A&lt;B;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"9-调整数组顺序使奇数位于偶数前面\"><a href=\"#9-调整数组顺序使奇数位于偶数前面\" class=\"headerlink\" title=\"9. 调整数组顺序使奇数位于偶数前面\"></a>9. 调整数组顺序使奇数位于偶数前面</h2><p><strong>题目描述</strong><br>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。<br><strong>思路</strong>：<br>1.剑指offer书中，是要求调整数组顺序，使得奇数位于偶数前面，没有要求奇数和奇数，偶数和偶数的相对位置不变。<br>解法是：指针<code>p1</code>指向数组头部，<code>p1</code>只后移。指针<code>p2</code>指向数组尾部，<code>p2</code>只前移。当<code>arr[p1]</code>为偶数，<code>arr[p2]</code>为奇数，则交换。<code>p1</code>继续后移，<code>p2</code>继续前移，一直循环。终止条件是：<code>p1</code>与<code>p2</code>交叉。<br>2.本题目中，要求奇数在前，偶数在后，且奇数相对于奇数，偶数相对于偶数的相对位置不变。则解法是：新建一个数组，先把原数组中的奇数push进去，再把偶数push进去，然后用新数组数据覆盖原数组即可。复杂度O(n)。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">reOrderArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;<span class=\"built_in\">array</span>)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"comment\">//新建一个数组</span></span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"comment\">//先把原数组中的奇数push进去</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]%<span class=\"number\">2</span>==<span class=\"number\">1</span>)</span><br><span class=\"line\">                result.push_back(<span class=\"built_in\">array</span>[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//再把原数组中的偶数push进去</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]%<span class=\"number\">2</span>==<span class=\"number\">0</span>)</span><br><span class=\"line\">                result.push_back(<span class=\"built_in\">array</span>[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//用新数组覆盖原数组</span></span><br><span class=\"line\">        <span class=\"built_in\">array</span>=result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"10-二维数组中的查找\"><a href=\"#10-二维数组中的查找\" class=\"headerlink\" title=\"10. 二维数组中的查找\"></a>10. 二维数组中的查找</h2><p><strong>题目描述</strong><br>在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。<br><strong>思路</strong>：首先选取数组中右上角的数字。如果该数字等于要查找的数字，则查找过程结束；如果该数字大于要查找的数字，则去除该数字所在列；如果该数字小于要查找的数字，则去除该数字所在行。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Find</span><span class=\"params\">(<span class=\"keyword\">int</span> target, <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; <span class=\"built_in\">array</span>)</span> </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"comment\">//防御型编程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//计算二维数组的行和列</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols = <span class=\"built_in\">array</span>[<span class=\"number\">0</span>].size();</span><br><span class=\"line\">        <span class=\"comment\">//首先选取数组中右上角的数字</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> j = cols<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;rows &amp;&amp; j&gt;=<span class=\"number\">0</span>)<span class=\"comment\">//注意二维数组行列的取值范围为[0~rows-1, 0~cols-1]</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字等于要查找的数字，则查找过程结束</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i][j]== target)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字大于要查找的数字，则去除该数字所在列</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i][j]&gt;target)   </span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                j--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字小于要查找的数字，则去除该数字所在行</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \ti++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"11-数组中的逆序对\"><a href=\"#11-数组中的逆序对\" class=\"headerlink\" title=\"11. 数组中的逆序对\"></a>11. 数组中的逆序对</h2><p><strong>题目描述</strong><br>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007<br><strong>输入描述</strong>:<br>题目保证输入的数组中没有的相同的数字<br><strong>数据范围</strong>：<br>对于%50的数据,$size&lt;=10^4$<br>对于%75的数据,$size&lt;=10^5$<br>对于%100的数据,$size&lt;=2*10^5$<br><strong>示例</strong>:<br>输入<br>1,2,3,4,5,6,7,0<br>输出<br>7<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//不对，未完成</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">InversePairs</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> n = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> InversePairs2(data, n);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">InversePairs2</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> n)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"keyword\">if</span>(n&lt;<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;<span class=\"comment\">//就是为了返回，返回的值无所谓</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> leftLength= n/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rightLength= n-leftLength;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; left;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; right;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;leftLength;i++) left.push_back(data[i]);</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = leftLength;i&lt;n;i++) right.push_back(data[i]);</span><br><span class=\"line\">        InversePairs2(left,leftLength);    <span class=\"comment\">//sorting the left subarray</span></span><br><span class=\"line\">        InversePairs2(right,rightLength);  <span class=\"comment\">//sorting the right subarray</span></span><br><span class=\"line\">        mergeNew(data,left,leftLength,right,rightLength); <span class=\"comment\">//merge left and right into A</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> count%<span class=\"number\">1000000007</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mergeNew</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; left, <span class=\"keyword\">int</span> leftLength, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; right,<span class=\"keyword\">int</span> rightLength)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i=leftLength+rightLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">truetrue<span class=\"keyword\">int</span> j = leftLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> k = rightLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&gt;=<span class=\"number\">0</span> &amp;&amp; k&gt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(left[j]&gt;right[k]) </span><br><span class=\"line\">            &#123; </span><br><span class=\"line\">            \tdata[i--] = left[j--];</span><br><span class=\"line\">            \tcount+=(k+<span class=\"number\">1</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> </span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tdata[i--] = right[k--];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&gt;=<span class=\"number\">0</span>) data[i--]=left[j--];</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(k&gt;=<span class=\"number\">0</span>) data[i--]=right[k--];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"12-顺时针打印矩阵\"><a href=\"#12-顺时针打印矩阵\" class=\"headerlink\" title=\"12. 顺时针打印矩阵\"></a>12. 顺时针打印矩阵</h2><p><strong>题目描述</strong><br>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1   2  3  4</span><br><span class=\"line\">5   6  7  8</span><br><span class=\"line\">9  10 11 12</span><br><span class=\"line\">13 14 15 16</span><br></pre></td></tr></table></figure></p>\n<p>则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.<br><strong>思路</strong>：分解成若干个简单的问题。<br>1.每次打印矩阵的一个圈。关键：循环继续的条件是：<code>cols&gt;start*2 &amp;&amp; row&gt;start*2</code><br>2.将打印一圈分成四步：第一步，从左到右打印一行；第二步，从上到下打印一列；第三步；从右到左打印一行；第四步，从下到上打印一列。<br>3.四步的前提条件：<br>第一步总是需要；<br>第二步的前提条件是终止行号大于起始行号；<br>第三步的前提条件是该圈内至少两行两列，即终止行号大于起始行号，终止列号大于起始列号；<br>第四步的前提条件：该圈内至少有三行二列，即终止行号比起始行号至少大2，终止列号大于起始列号。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printMatrix(<span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &gt; matrix) &#123;</span><br><span class=\"line\">truetrue<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows = matrix.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols = matrix[<span class=\"number\">0</span>].size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rows&lt;=<span class=\"number\">0</span> || cols&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//每次打印矩阵的一个圈</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(cols&gt;start*<span class=\"number\">2</span> &amp;&amp; rows&gt; start*<span class=\"number\">2</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            PrintMatrixInCircle(matrix,rows,cols,start,result);</span><br><span class=\"line\">            start++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintMatrixInCircle</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt;&amp; matrix,<span class=\"keyword\">int</span> rows,<span class=\"keyword\">int</span> cols,<span class=\"keyword\">int</span> start,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; result)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endX = cols-start<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endY = rows-start<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.从左到右打印矩阵</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;=endX;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result.push_back(matrix[start][i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.从上到下打印一列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endY)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start+<span class=\"number\">1</span>;i&lt;=endY;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[i][endX]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//3.从右到左打印一行</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endX &amp;&amp; start&lt; endY)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = endX<span class=\"number\">-1</span>;i&gt;=start;i--)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[endY][i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//4.从下到上打印一列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endX &amp;&amp; start &lt;endY <span class=\"number\">-1</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = endY<span class=\"number\">-1</span>; i&gt;=start+<span class=\"number\">1</span>;i--)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[i][start]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"六、排序\"><a href=\"#六、排序\" class=\"headerlink\" title=\"六、排序\"></a>六、排序</h1><h2 id=\"1-数组中出现次数超过一半的数字\"><a href=\"#1-数组中出现次数超过一半的数字\" class=\"headerlink\" title=\"1.数组中出现次数超过一半的数字\"></a>1.数组中出现次数超过一半的数字</h2><p>题目描述<br>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。<br><strong>思路</strong>：结合数组特性：数组中有一个数字出现的次数超过了数组长度的一半，如果将这个数组排序，那么排序之后位于数组中间的数字一定就是那个出现次数超过数组长度一半的数字。这个数字就是统计学上的中位数，即长度为$n$的数组中第$n/2$大的数字。已经有成熟的时间复杂度为$O(n)$的算法得到数组中任意第$k$大的数字。<br>第一，防御性编程，判断数组是否有效；第二，利用快速排序中的分割(partition)方法，选主元位置及重排数组。如果返回的主元位置(pIndex)小于数组中间位置((length-1)/2)，则对左半部分进行分割，否则对右半部分进行分割，直到返回的pIndex等于((length-1)/2)；第三，遍历数组，验证该数是否出现了超过一半的次数。<br><!-- more --><br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MoreThanHalfNum_Solution</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; numbers)</span> </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> size = numbers.size();</span><br><span class=\"line\">        <span class=\"comment\">//1.防御性编程，判断数组是否有效；</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(size==<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> end = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> middle = end/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.利用快速排序中的分割(partition)方法，选主元位置及重排数组</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = partition(numbers,start,end);</span><br><span class=\"line\">        <span class=\"comment\">//直到返回的pIndex等于((length-1)/2)</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pIndex!=middle)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pIndex&lt;middle)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                start = pIndex+<span class=\"number\">1</span>;</span><br><span class=\"line\">                pIndex = partition(numbers,start,end);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                end = pIndex<span class=\"number\">-1</span>;</span><br><span class=\"line\">                pIndex = partition(numbers,start,end);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> result=numbers[middle];</span><br><span class=\"line\">        <span class=\"comment\">//3.遍历数组，验证该数是否出现了超过一半的次数。</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(isMoreThanHalf(numbers,result,size))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start,<span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pivot = numbers[end];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]&lt;=pivot)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = numbers[i];</span><br><span class=\"line\">                numbers[i] = numbers[pIndex];</span><br><span class=\"line\">                numbers[pIndex] = temp;</span><br><span class=\"line\">                pIndex++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = numbers[pIndex];</span><br><span class=\"line\">        numbers[pIndex] = pivot;</span><br><span class=\"line\">        numbers[end] = temp;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isMoreThanHalf</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers,<span class=\"keyword\">int</span> result,<span class=\"keyword\">int</span> size)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]==result)</span><br><span class=\"line\">                count++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"number\">2</span>*count&lt;=size) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-最小的k个数\"><a href=\"#2-最小的k个数\" class=\"headerlink\" title=\"2.最小的k个数\"></a>2.最小的k个数</h2><p><strong>题目描述</strong>：<br>输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。<br><strong>思路</strong>：<br>思路1：利用快速排序排序数组，位于前面的$k$个数即是最小的$k$个数。时间复杂度为$O(nlogn)$。<br>第一，防御性编程，如果数组为空或$k&gt;length$，则返回空；第二，利用快速排序，对数组进行排序；第三，输出数组中的前$k$个数。<br>思路2：<br>由上题“数组中出现次数超过一半的数字”得到启发，基于快速排序中的分割(partition)方法来解决问题。利用partiton函数，如果返回的$pIndex&lt;(k-1)$，则对右半部分进行partition，否则，对左半部分进行partition，直到返回的主元位置pIndex等于$(k-1)$。这样调整后，位于数组中左边的k个数字就是最小的$k$个数字，但这$k$个数字不一定是排序的。时间复杂度为$O(n)$。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//实现思路1</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; GetLeastNumbers_Solution(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; input, <span class=\"keyword\">int</span> k) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = input.size();</span><br><span class=\"line\">        <span class=\"comment\">//1.防御性编程，如果数组为空或k&gt;size，则返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(size==<span class=\"number\">0</span> || k&gt;size) <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> end = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.利用快速排序，对数组进行排序</span></span><br><span class=\"line\">        quickSort(input,start,end);</span><br><span class=\"line\">        <span class=\"comment\">//3.输出数组中的前k个数</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;k;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result.push_back(input[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = partition(numbers,start,end);</span><br><span class=\"line\">        quickSort(numbers,start,pIndex<span class=\"number\">-1</span>);</span><br><span class=\"line\">        quickSort(numbers,pIndex+<span class=\"number\">1</span>,end);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start,<span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pivot = numbers[end];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]&lt;=pivot)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = numbers[i];</span><br><span class=\"line\">                numbers[i] = numbers[pIndex];</span><br><span class=\"line\">                numbers[pIndex] = temp;</span><br><span class=\"line\">                pIndex++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = numbers[pIndex];</span><br><span class=\"line\">        numbers[pIndex] = pivot;</span><br><span class=\"line\">        numbers[end] = temp;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"七、位运算\"><a href=\"#七、位运算\" class=\"headerlink\" title=\"七、位运算\"></a>七、位运算</h1><h2 id=\"1-数组中只出现一次的数字（-56）\"><a href=\"#1-数组中只出现一次的数字（-56）\" class=\"headerlink\" title=\"1.数组中只出现一次的数字（#56）\"></a>1.数组中只出现一次的数字（#56）</h2><p><strong>题目描述</strong><br>一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。<br><strong>思路</strong>：核心思想：<a href=\"http://blog.csdn.net/ns_code/article/details/27568975\" target=\"_blank\" rel=\"noopener\">异或去重</a>；异或的性质：交换律，结合律，以及<code>a^a=0</code>，<code>a^0=a</code><br><strong>1.考虑简单情况</strong>：数组中只有一个数字<code>n</code>出现了一次，其他都出现了两次。<br>将数组中所有元素逐个异或，则结果为只出现一次的<code>n</code>，即<code>a^a^b^b^...^n^...^c^c=n</code>。<br><strong>2.本题求解思路</strong>：故将数组分成两部分解决，一部分包含只出现一次的数字<code>n_1</code>，一部分包含只出现一次的数字<code>n_2</code>，同时保证出现两次的数字在同一数组,而不是分散在l不同的数组。对两数组分别逐元素异或，即分别得到<code>n_1</code>，<code>n_2</code>。<br><strong>3.数组划分方法</strong>：对整个数组，逐元素异或，则结果为<code>n_1^n_2</code>，即<code>n_1</code>和 <code>n_2</code>异或的结果。<code>n_1</code>和<code>n_2</code>不相同，故结果定不为0，则结果的二进制表示定至少有一位为1（即<code>n_1</code>和<code>n_2</code>的二进制表示的该位不相同），找出结果的二进制表示中第一次为1的下标索引<code>index</code>，通过这个下标索引<code>index</code>，对整个数组中的元素进行数组划分。数组中每个元素的二进制表示的第<code>index</code>位是1的分为一组，是0的分为另一组。这样保证了<code>n_1</code>和<code>n_2</code>分别在两个组，且出现两次的数字在同一个组，不会被分到不同的组(因此相同数字的二进制表示的<code>index</code>位必定是相同的)。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">FindNumsAppearOnce</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data,<span class=\"keyword\">int</span>* num1,<span class=\"keyword\">int</span> *num2)</span> </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"keyword\">int</span> length = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data.size()&lt;<span class=\"number\">2</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> result = <span class=\"number\">0</span>; <span class=\"comment\">//初始值为0,a^0=a</span></span><br><span class=\"line\">        <span class=\"comment\">// get num1 ^ num2</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i =<span class=\"number\">0</span>;i&lt;length;i++)</span><br><span class=\"line\">            result ^=data[i];</span><br><span class=\"line\">        <span class=\"comment\">// get index of the first bit, which is 1 in resultExclusiveOR</span></span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> indexOf1 = FindFirstBitIs1(result);</span><br><span class=\"line\">        *num1 = *num2 = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">// divide the numbers in data into two groups,</span></span><br><span class=\"line\">        <span class=\"comment\">// the indexOf1 bit of numbers in the first group is 1,</span></span><br><span class=\"line\">        <span class=\"comment\">// while in the second group is 0</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;length;j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(IsBit1(data[j],indexOf1))</span><br><span class=\"line\">                *num1^=data[j];</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                *num2^=data[j];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//Find the index of first bit which is 1 in num (assuming not 0)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">FindFirstBitIs1</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> indexBit=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(((num&amp;<span class=\"number\">1</span>)==<span class=\"number\">0</span>) &amp;&amp; (indexBit&lt;<span class=\"number\">8</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">int</span>)))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num = num&gt;&gt;<span class=\"number\">1</span>;</span><br><span class=\"line\">            ++indexBit;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> indexBit;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Is the indexBit bit of num 1?</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsBit1</span><span class=\"params\">(<span class=\"keyword\">int</span> num, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> indexBit)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        num=num&gt;&gt;indexBit;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (num&amp;<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-二进制中1的个数\"><a href=\"#2-二进制中1的个数\" class=\"headerlink\" title=\"2.二进制中1的个数\"></a>2.二进制中1的个数</h2><p><strong>题目描述</strong><br>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。<br><strong>思路</strong>：<br><strong>首先</strong>，直观的思路是：先判断整数二进制表示中的最后一位是不是1；然后将整数右移一位，再次判断，直到整数变为0。判断二进制表示中最后一位是不是1的方法是：<code>n&amp;1</code>，因为1的二进制表示中除了最后一位为1以外，其余全为0。<br><strong>然后</strong>，右移整数n的做法存在隐患，就是当n是负数的时候，<a href=\"http://blog.csdn.net/morewindows/article/details/7354571\" target=\"_blank\" rel=\"noopener\">n右移会在开头补符号位1（算术右移）</a>，而不是补0。故采用将1循环左移的方法，逐个判断n的二进制表示的第0位到最高位是否为1。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">int</span>  <span class=\"title\">NumberOf1</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span> </span>&#123;</span><br><span class=\"line\">         <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">         <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> flag = <span class=\"number\">1</span>;</span><br><span class=\"line\">         <span class=\"comment\">//直到1的循环左移为0</span></span><br><span class=\"line\">         <span class=\"keyword\">while</span>(flag)</span><br><span class=\"line\">         &#123;</span><br><span class=\"line\">             <span class=\"keyword\">if</span>(n &amp; flag)</span><br><span class=\"line\">             \tcount++;</span><br><span class=\"line\">             <span class=\"comment\">//左移1</span></span><br><span class=\"line\">             flag =flag&lt;&lt;<span class=\"number\">1</span>;</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"八、递归\"><a href=\"#八、递归\" class=\"headerlink\" title=\"八、递归\"></a>八、递归</h1><h2 id=\"1-斐波那契数列（-10）\"><a href=\"#1-斐波那契数列（-10）\" class=\"headerlink\" title=\"1.斐波那契数列（#10）\"></a>1.斐波那契数列（#10）</h2><p><strong>题目描述</strong><br>大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。(n&lt;=39)<br><strong>注</strong>：本题中<code>n=0</code>时，输出是0。斐波那契数列从第1项开始。即本题斐波那契数列是<code>0,1,1,2,3,5,...</code><br><strong>思路</strong>：<br><strong>思路1</strong>：最直观的递归，返回<code>Fibonacci(n-1)+Fibonacci(n-2)</code>。但有大量冗余计算，时间复杂度过高，无法通过。<br><strong>思路2</strong>：带记忆的递归，用辅助数组存储下已经计算过的结果。<br><strong>思路3</strong>：迭代计算。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路1：最直观的递归，时间复杂度过高</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Fibonacci</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(n&lt;=<span class=\"number\">1</span>) <span class=\"keyword\">return</span> n;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Fibonacci(n<span class=\"number\">-1</span>)+Fibonacci(n<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//思路2：带记忆的递归，用辅助数组存储下已经计算过的结果</span><br><span class=\"line\">class Solution &#123;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    int F[40];//默认为0</span><br><span class=\"line\">public:</span><br><span class=\"line\">    int Fibonacci(int n) &#123;</span><br><span class=\"line\">        if(F[n]!= 0) </span><br><span class=\"line\">            return F[n];</span><br><span class=\"line\">        if(n&lt;=1) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         \tF[n]=n;</span><br><span class=\"line\">        \treturn F[n];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        else</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            F[n]=Fibonacci(n-1)+Fibonacci(n-2);</span><br><span class=\"line\">        \treturn F[n];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//思路3：迭代计算。</span><br><span class=\"line\">class Solution &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    int Fibonacci(int n) &#123;</span><br><span class=\"line\">    \tint num1=0;</span><br><span class=\"line\">    \tint num2=1;</span><br><span class=\"line\">    \tint num3;</span><br><span class=\"line\">        if(n&lt;=1) </span><br><span class=\"line\">            return n;</span><br><span class=\"line\">truetruefor(int i = 2;i&lt;=n;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num3 = num1+num2;</span><br><span class=\"line\">            num1 = num2;</span><br><span class=\"line\">            num2 = num3;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return num3;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-青蛙跳台阶问题（-10）\"><a href=\"#2-青蛙跳台阶问题（-10）\" class=\"headerlink\" title=\"2. 青蛙跳台阶问题（#10）\"></a>2. 青蛙跳台阶问题（#10）</h2><p><strong>题目描述</strong><br>一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。<br><strong>思路</strong>：类似斐波那契数列<br>f(n)=　1, (n=1)<br>　　　 2, (n=2)<br>　　　 f(n-1)+f(n-2) ,(n&gt;2,n为整数)<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">jumpFloor</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jumpFloor(number<span class=\"number\">-1</span>)+jumpFloor(number<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-变态跳台阶（-10）\"><a href=\"#3-变态跳台阶（-10）\" class=\"headerlink\" title=\"3.变态跳台阶（#10）\"></a>3.变态跳台阶（#10）</h2><p><strong>题目描述</strong><br>一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。<br><strong>思路</strong>：<br>因为n级台阶，第一步有n种跳法：跳1级，跳2级，…，跳n级<br>跳1级，剩下n-1级，则剩下跳法是f(n-1)<br>跳2级，剩下n-2级，则剩下跳法是f(n-2)<br>所以f(n)=f(n-1)+f(n-2)+…+f(1)+f(0)<br>因为f(n-1)=f(n-2)+f(n-3)+…+f(1)+f(0)<br>所以f(n)=2xf(n-1)<br>故：<br>f(n)=　1, (n=1)<br>　　　 2xf(n-1),(n&gt;1,n为整数)<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">jumpFloorII</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">truetrue<span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">2</span>*jumpFloorII(number<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-矩形覆盖（-10）\"><a href=\"#4-矩形覆盖（-10）\" class=\"headerlink\" title=\"4.矩形覆盖（#10）\"></a>4.矩形覆盖（#10）</h2><p><strong>题目描述</strong><br>我们可以用2<em>1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2</em>1的小矩形无重叠地覆盖一个2<em>n的大矩形，总共有多少种方法？<br><strong>思路</strong>：仍旧是斐波那契数列<br>第一块有两种方式：横着放和竖着放。<br>横着放后，覆盖方法为f(n-2)，因为下方也被占用，下方必须也横着放。<br>竖着放后，覆盖方法为f(n-1);<br>所以总的覆盖方法为f(n)=f(n-1)+f(n-2);<br>故：<br>f(n)=　1, (n=1)<br>　　　 2, (n=2)<br>　　　 f(n-1)+f(n-2) ,(n&gt;2,n为整数)<br><em>*代码</em></em>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rectCover</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\"> \t\t<span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> rectCover(number<span class=\"number\">-1</span>)+rectCover(number<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"九、回溯\"><a href=\"#九、回溯\" class=\"headerlink\" title=\"九、回溯\"></a>九、回溯</h1><h1 id=\"十、动态规划与贪婪算法\"><a href=\"#十、动态规划与贪婪算法\" class=\"headerlink\" title=\"十、动态规划与贪婪算法\"></a>十、动态规划与贪婪算法</h1>","site":{"data":{}},"excerpt":"<p>注：该记录中解题答案均为在牛客网进行<a href=\"https://www.nowcoder.net/ta/coding-interviews\" target=\"_blank\" rel=\"noopener\">在线编程测试</a>时的答案记录，故未自己写测试代码。</p>\n<h1 id=\"一、链表\"><a href=\"#一、链表\" class=\"headerlink\" title=\"一、链表\"></a>一、链表</h1><h2 id=\"1-两个链表的第一个公共结点\"><a href=\"#1-两个链表的第一个公共结点\" class=\"headerlink\" title=\"1. 两个链表的第一个公共结点\"></a>1. 两个链表的第一个公共结点</h2><p><strong>题目描述</strong>：<br>输入两个链表，找出它们的第一个公共结点。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>关键点</strong>：如果两个单链表有公共的结点，那么这两个链表从某一结点开始，它们的<code>next</code>指针都指向同一个结点，又由于是单向链表的结点，每个结点只有一个<code>next</code>指针，因此<strong>从第一个公共结点开始，之后它们所有的结点都是重合的，不再出现分叉</strong>。</li>\n<li><strong>思路1</strong>：<ul>\n<li>对于对于链表一上的每一个结点，顺序遍历链表二上的每一个结点。</li>\n<li>若第一个链表的长度为$m$，第二个链表的长度为$n$，那么时间复杂度为$O(mn)$。</li>\n</ul>\n</li>\n<li><strong>思路2</strong>：<ul>\n<li>分别把两个链表的结点放入栈里，这样两个链表的尾结点就位于两个栈的栈顶，接下来比较两个栈顶的结点是否相同。如果相同，则把栈顶弹出接着比较下一个栈顶，直到找到最后一个相同的结点。</li>\n<li>该思路需要用到两个辅助栈，如果链表的长度分别为$m$和$n$，那么空间复杂度是$O(m+n)$，时间复杂度是$O(m+n)$。和思路1相比，时间效率得到了提高，相当于用空间消耗换取了时间效率。</li>\n</ul>\n</li>\n<li><p><strong>思路3</strong>：</p>\n<ul>\n<li>首先遍历两个链表得到它们的长度。在第二次遍历时，在较长的链表上先走若干步，接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点。</li>\n<li>与思路2相比，该思路的时间复杂度为$O(m+n)$，但不需辅助栈，因此提高了空间效率。</li>\n</ul>","more":"</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路3</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x):val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">FindFirstCommonNode</span><span class=\"params\">( ListNode* pHead1, ListNode* pHead2)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(pHead1==<span class=\"literal\">nullptr</span> || pHead2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//首先遍历两个链表得到它们的长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> length1,length2;</span><br><span class=\"line\">        length1=length2= <span class=\"number\">0</span>;</span><br><span class=\"line\">        ListNode* pTemp1 = pHead1;</span><br><span class=\"line\">        ListNode* pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            length1++;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            length2++;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//在第二次遍历时，在较长的链表上先走若干步</span></span><br><span class=\"line\">        pTemp1 = pHead1;</span><br><span class=\"line\">        pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length1&gt;length2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> dif = length1-length2;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;dif;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> dif = length2-length1;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;dif;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//接着同时在两个链表上遍历，找到的第一个相同的结点就是它们的第一个公共结点</span></span><br><span class=\"line\">        ListNode* pResult = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span> &amp;&amp; pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(pTemp1 == pTemp2)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tpResult = pTemp1;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pResult;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-链表中环的入口结点\"><a href=\"#2-链表中环的入口结点\" class=\"headerlink\" title=\"2. 链表中环的入口结点\"></a>2. 链表中环的入口结点</h2><p><strong>题目描述</strong>：<br>一个链表中包含环，请找出该链表的环的入口结点。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>核心思想</strong>：假定有环且已知环的结点个数为$y$，令指针<code>pTemp1</code>从首结点开始先走$y$步，再令<code>pTemp2</code>从首结点开始同<code>pTemp1</code>一起向前走，相遇处，即为环的入口结点。</li>\n<li><strong>证明</strong>：假定环的结点个数为$y$，环之前的结点个数为$x$。<code>pTemp1</code>先走$y$步，然后<code>pTemp2</code>从首结点开始同<code>pTemp1</code>一起再走$x$步，则<code>pTemp2</code>在第$(x+1)$个结点处，<code>pTemp1</code>在第$(x+y+1)$个结点处。$(x+1)$结点位置和$(x+y+1)$结点位置都是环的入口结点位置。因此，依上述核心思想的步骤，<code>pTemp1</code>与<code>pTemp2</code>定会相遇，相遇处恰好为环的入口结点。</li>\n<li><strong>环的结点个数求法</strong>：首先，令一指针<code>pFast</code>一次走两步，一指针<code>pSlow</code>一次走一步，若相遇，则有环，且相遇处定在环内。然后，<code>pFast</code>不动，令一指针<code>pSlow</code>继续走且计数，当<code>pSlow</code>与<code>pFast</code>再次相遇，即得出环的结点个数。</li>\n<li>注意，代码中充斥着防止指针为空的情况，繁琐但必不可少。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">EntryNodeOfLoop</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//通过getNumberOfLoop()获取环的结点个数，0则无环；大于0则有环</span></span><br><span class=\"line\">        ListNode* pTemp1, *pTemp2;</span><br><span class=\"line\">        pTemp1 = pTemp2 = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> num = getNumberOfLoop(pHead);</span><br><span class=\"line\">        <span class=\"comment\">//若环结点数等于0，直接返回nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(num==<span class=\"number\">0</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//依照核心思想执行，获取pTemp1与pTemp2相遇处指针</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;num;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=pTemp2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pTemp1;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getNumberOfLoop</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//1.令pFast一次走两步，pSlow一次走一步，若相遇，则有环，且相遇处定在环内</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        ListNode* pFast, *pSlow;</span><br><span class=\"line\">        pFast = pSlow = pHead;</span><br><span class=\"line\">        pFast=pFast-&gt;next;    <span class=\"comment\">//为了下个while循环的判断条件，pFast先走一步</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pFast!=pSlow)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pFast = pFast-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pFast = pFast-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pSlow==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pSlow=pSlow-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pFast==<span class=\"literal\">nullptr</span> || pSlow==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            num=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.pFast不动，令pSlow继续走且计数，当pSlow与pFast再次相遇，即得出环的结点个数</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pSlow=pSlow-&gt;next; <span class=\"comment\">//为了下个while循环的判断条件，pSlow先走一步</span></span><br><span class=\"line\">            num++;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pSlow!=pFast)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pSlow=pSlow-&gt;next;</span><br><span class=\"line\">                num++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-反转链表\"><a href=\"#3-反转链表\" class=\"headerlink\" title=\"3. 反转链表\"></a>3. 反转链表</h2><p><strong>题目描述</strong>：<br>给出一个链表<code>1-&gt;2-&gt;3-&gt;nullptr</code>，这个翻转后的链表为<code>3-&gt;2-&gt;1-&gt;nullptr</code><br><strong>思路</strong>：</p>\n<ul>\n<li><strong>方法1</strong>：迭代实现。维护三个指针<code>pPrev</code>,<code>pCurrent</code>,<code>pNext</code>，通过迭代完成链表的反转（画图使思路清晰）：<ul>\n<li>起始情况：<code>pPrev</code>为<code>nullptr</code>，<code>pCurrent</code>指向<code>pHead</code></li>\n<li>终止情况：<code>pPrev</code>指向链表尾元素，<code>pCurrent</code>为<code>nullptr</code></li>\n</ul>\n</li>\n<li><strong>方法2</strong>：递归实现。利用递归走到链表的末端，然后再更新每一个结点的<code>next</code>指针 ，实现链表的反转。</li>\n<li><strong>方法3</strong>：用栈实现。将链表结点指针全部压入栈中。头指针指向链表末尾结点。将栈中结点指针反串起来，栈中最后结点指针指向<code>nullptr</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法1：迭代实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode* pHead)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        ListNode* pPre, *pCurrent, *pNext;</span><br><span class=\"line\">        pPre=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNext = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pPre;</span><br><span class=\"line\">            pPre = pCurrent;</span><br><span class=\"line\">            pCurrent = pNext;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pHead=pPre;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法2：递归实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">ReverseList</span><span class=\"params\">(ListNode* pHead)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果链表为空或者链表中只有一个元素</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">NULL</span> || pHead-&gt;next==<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        <span class=\"comment\">//先反转后面的链表，走到链表的末端结点，返回末端结点，作为新的头结点，保存起来</span></span><br><span class=\"line\">        ListNode* pHeadReverse=ReverseList(pHead-&gt;next);</span><br><span class=\"line\">        <span class=\"comment\">//再将当前节点设置为后面节点的后续节点</span></span><br><span class=\"line\">        pHead-&gt;next-&gt;next = pHead;</span><br><span class=\"line\">        <span class=\"comment\">//当前节点指向NULL</span></span><br><span class=\"line\">        pHead-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"comment\">//返回新的头结点</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHeadReverse;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法3：用栈实现</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode * <span class=\"title\">reverse</span><span class=\"params\">(ListNode * head)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// write your code here</span></span><br><span class=\"line\">        <span class=\"comment\">//防御性编程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(head==<span class=\"literal\">NULL</span>) <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.将链表结点指针全部压入栈中</span></span><br><span class=\"line\">        <span class=\"built_in\">stack</span>&lt;ListNode*&gt; stack1;</span><br><span class=\"line\">        ListNode* temp = head;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(temp!=<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            stack1.push(temp);</span><br><span class=\"line\">            temp=temp-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.头指针指向链表末尾结点</span></span><br><span class=\"line\">        temp = stack1.top();</span><br><span class=\"line\">        head=temp;</span><br><span class=\"line\">        <span class=\"comment\">//3.将栈中结点指针反串起来，栈中最后结点指针指向NULL</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ListNode* pNode1 = stack1.top();</span><br><span class=\"line\">            stack1.pop();</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(stack1.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNode1-&gt;next=<span class=\"literal\">NULL</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            ListNode* pNode2 = stack1.top();</span><br><span class=\"line\">            pNode1-&gt;next = pNode2;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> head;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-合并两个排序的链表\"><a href=\"#4-合并两个排序的链表\" class=\"headerlink\" title=\"4. 合并两个排序的链表\"></a>4. 合并两个排序的链表</h2><p><strong>题目</strong>：输入两个递增排序的链表，合并这两个链表并使新链表中的结点仍然是按照递增排序的。<br><strong>思路</strong>：</p>\n<ul>\n<li>依照归并排序中的<code>merge</code>函数的思想，<code>merge</code>两个链表：<ul>\n<li>1.比较两个链表的头结点，较小的作为新链表的头结点<code>pHeadNew</code>；</li>\n<li>2.归并两个链表，迭代比较，较小者作为新的尾结点<code>pTailNew</code>。</li>\n<li>注意，直接改动每一结点的<code>next</code>指针，故不需另外的辅助空间。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">Merge</span><span class=\"params\">(ListNode* pHead1, ListNode* pHead2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//防御性编程：若输入链表有任一为空，返回另一个</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead1==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead1;</span><br><span class=\"line\">        <span class=\"comment\">//1.找出新链表的头结点pHeadNew</span></span><br><span class=\"line\">        ListNode* pHeadNew = <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        ListNode* pTemp1 = pHead1;</span><br><span class=\"line\">        ListNode* pTemp2 = pHead2;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp1-&gt;val &lt; pTemp2-&gt;val)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHeadNew = pTemp1;</span><br><span class=\"line\">            pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHeadNew = pTemp2;</span><br><span class=\"line\">            pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.归并两个链表，迭代比较，较小者作为新的尾结点pTailNew</span></span><br><span class=\"line\">        <span class=\"comment\">//直接改动每一结点的next指针，故不需另外的辅助空间</span></span><br><span class=\"line\">        ListNode* pTailNew = pHeadNew; </span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp1!=<span class=\"literal\">nullptr</span> &amp;&amp; pTemp2!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pTemp1-&gt;val &lt; pTemp2-&gt;val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTailNew-&gt;next = pTemp1;</span><br><span class=\"line\">                pTailNew = pTemp1;</span><br><span class=\"line\">                pTemp1 = pTemp1-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pTailNew-&gt;next = pTemp2;</span><br><span class=\"line\">                pTailNew = pTemp2;</span><br><span class=\"line\">                pTemp2 = pTemp2-&gt;next;</span><br><span class=\"line\">            &#125;    </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp1!=<span class=\"literal\">nullptr</span>) pTailNew-&gt;next = pTemp1;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTemp2!=<span class=\"literal\">nullptr</span>) pTailNew-&gt;next = pTemp2;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHeadNew;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-从尾到头打印链表\"><a href=\"#5-从尾到头打印链表\" class=\"headerlink\" title=\"5. 从尾到头打印链表\"></a>5. 从尾到头打印链表</h2><p><strong>题目描述</strong>：<br>输入一个链表的头结点，从尾到头反过来打印出每个结点的值。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，假定不能改变链表结构，故不采用迭代反转链表，然后后再打印链表的方法。</li>\n<li><strong>方法1</strong>：遍历的顺序是从头到尾，输出的顺序是从尾到头，是典型的“后进先出”，用栈实现这种顺序：<ul>\n<li>遍历链表，每经过一个结点的时候，把该结点压入辅助栈中。</li>\n<li>当遍历完整个链表后，再从栈顶开始逐个输出结点的值。</li>\n</ul>\n</li>\n<li><strong>方法2</strong>：用递归方法反向打印链表。既然可以用栈实现，而递归本质上就是一个栈结构，故可用递归来实现：<ul>\n<li>每访问到一个结点，先递归输出它后面的结点，再输出该结点自身，这样链表的输出结果就反过来了。</li>\n</ul>\n</li>\n<li>注意，虽然基于递归的代码看起来很简洁，但有一个问题：当链表非常长的时候，就会导致函数调用的层级很深，从而有可能导致函数调用栈溢出。显然用栈基于循环实现的代码的鲁棒性要好一些（存放于自由存储的堆区）。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法1</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;    </span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;ListNode*&gt; s;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printListFromTailToHead(ListNode* pHead) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"comment\">//遍历链表，每经过一个结点的时候，把该结点压入辅助栈中</span></span><br><span class=\"line\">        ListNode* pTemp = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pTemp!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(pTemp);</span><br><span class=\"line\">            pTemp = pTemp-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//当遍历完整个链表后，再从栈顶开始逐个输出结点的值</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!s.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pTemp = s.top();</span><br><span class=\"line\">            result.push_back(pTemp-&gt;val);</span><br><span class=\"line\">            s.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//方法2</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;    </span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printListFromTailToHead(ListNode* pHead) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        printListFromTailToHead(pHead-&gt;next);</span><br><span class=\"line\">        result.push_back(pHead-&gt;val);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-复杂链表的复制\"><a href=\"#6-复杂链表的复制\" class=\"headerlink\" title=\"6. 复杂链表的复制\"></a>6. 复杂链表的复制</h2><p><strong>题目描述</strong><br>输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>步骤1</strong>：复制原始链表的任意结点$N$并创建新结点$N’$，再把$N’$链接到$N$的后面。如原来是<code>A-&gt;B-&gt;C</code>，则变成<code>A-&gt;A&#39;-&gt;B-&gt;B&#39;-&gt;C-&gt;C&#39;</code>。</li>\n<li><strong>步骤2</strong>：设置复制出来的结点的<code>random</code>指针。如果原始链表上的结点$N$的<code>random</code>指针指向$S$，则它对应的复制结点$N’$的<code>ramdon</code>指针指向$S$的复制结点$S’$。如<code>A1-&gt;random = A-&gt;random-&gt;next;</code></li>\n<li><strong>步骤3</strong>：把长链表拆分成两个链表：把奇数位置的结点用<code>next</code>指针链接起来就是原始链表，把偶数位置的结点用<code>next</code>指针链接起来就是复制出来的链表。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct RandomListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int label;</span></span><br><span class=\"line\"><span class=\"comment\">    struct RandomListNode *next, *random;</span></span><br><span class=\"line\"><span class=\"comment\">    RandomListNode(int x) :label(x), next(NULL), random(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">RandomListNode* <span class=\"title\">Clone</span><span class=\"params\">(RandomListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        RandomListNode* pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"comment\">//1.复制原始链表的任一节点N并创建新节点N'，再把N'链接到N的后边</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            RandomListNode* pClone = <span class=\"keyword\">new</span> RandomListNode(pCurrent-&gt;label);</span><br><span class=\"line\">            pClone-&gt;next = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pClone;</span><br><span class=\"line\">            pCurrent = pClone-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.如果原始链表上的节点N的random指向S，则对应的复制节点N'的random指向S的下一个节点S'</span></span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            RandomListNode* pClone = pCurrent-&gt;next;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;random!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                pClone-&gt;random = pCurrent-&gt;random-&gt;next;</span><br><span class=\"line\">            pCurrent = pClone-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//3.把得到的链表拆成两个链表，奇数位置上的结点组成原始链表，偶数位置上的结点组成复制出来的链表</span></span><br><span class=\"line\">        RandomListNode* pCloneHead=pHead-&gt;next;</span><br><span class=\"line\">        pCurrent = pHead;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pCurrent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123; </span><br><span class=\"line\">            RandomListNode* pClone = pCurrent-&gt;next;</span><br><span class=\"line\">            pCurrent-&gt;next = pClone-&gt;next;</span><br><span class=\"line\">            pCurrent = pCurrent-&gt;next;</span><br><span class=\"line\">            <span class=\"comment\">//pCurrent为nullptr，即pClone-&gt;next为nullptr，不用再继续，拆分结束。</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            pClone-&gt;next = pCurrent-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pCloneHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-链表中倒数第k个结点\"><a href=\"#7-链表中倒数第k个结点\" class=\"headerlink\" title=\"7. 链表中倒数第k个结点\"></a>7. 链表中倒数第k个结点</h2><p><strong>题目</strong>：<br>输入一个链表，输出该链表中倒数第$k$个结点。本题从1开始计数，即链表的尾结点是倒数第1个结点。例如一个链表有6个结点，从头结点开始它们的值依次是1、2、3、4、5、6。这个链表的倒数第3个结点是值为4的结点。<br><strong>思路</strong>：</p>\n<ul>\n<li>递归遍历链表，返回时通过<code>count</code>计数，当<code>count==k</code>时，当前<code>pHead</code>即为倒数第$K$个结点。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x):val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">    ListNode* pTarget=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">FindKthToTail</span><span class=\"params\">(ListNode* pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        Find(pHead,k);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pTarget;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Find</span><span class=\"params\">(ListNode* pHead, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        Find(pHead-&gt;next,k);</span><br><span class=\"line\">        count++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(count==k)</span><br><span class=\"line\">            pTarget = pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-删除链表中的重复结点\"><a href=\"#8-删除链表中的重复结点\" class=\"headerlink\" title=\"8. 删除链表中的重复结点\"></a>8. 删除链表中的重复结点</h2><p><strong>题目</strong>：<br>在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表<code>1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5</code>，处理后为<code>1-&gt;2-&gt;5</code><br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct ListNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    ListNode(int x) :val(x), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span></span></span><br><span class=\"line\"><span class=\"class\"> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">ListNode* <span class=\"title\">deleteDuplication</span><span class=\"params\">(ListNode* pHead)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 只有0个或1个结点，则返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead==<span class=\"literal\">nullptr</span> || pHead-&gt;next==<span class=\"literal\">nullptr</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        ListNode* pNext = pHead-&gt;next;</span><br><span class=\"line\">        <span class=\"comment\">// 当前结点是重复结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pHead-&gt;val == pNext-&gt;val)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 跳过值与当前结点相同的全部结点,找到第一个与当前结点不同的结点</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pNext!=<span class=\"literal\">nullptr</span> &amp;&amp; pNext-&gt;val==pHead-&gt;val)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNext = pNext-&gt;next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 从第一个与当前结点不同的结点开始递归</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> deleteDuplication(pNext);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">         <span class=\"comment\">// 当前结点不是重复结点</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 保留当前结点，从下一个结点开始递归</span></span><br><span class=\"line\">            pHead-&gt;next = deleteDuplication(pHead-&gt;next);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"二、栈和队列\"><a href=\"#二、栈和队列\" class=\"headerlink\" title=\"二、栈和队列\"></a>二、栈和队列</h1><h2 id=\"1-用两个栈实现队列\"><a href=\"#1-用两个栈实现队列\" class=\"headerlink\" title=\"1. 用两个栈实现队列\"></a>1. 用两个栈实现队列</h2><p><strong>题目</strong>：用两个栈来实现一个队列，完成队列的<code>push</code>和<code>pop</code>操作。队列中的元素为<code>int</code>类型。<br><strong>思路</strong>：</p>\n<ul>\n<li>栈是后进先出，队列是先进先出。</li>\n<li>利用栈<code>stack1</code>负责<code>push</code>操作。</li>\n<li>利用栈<code>stack2</code>负责<code>pop</code>操作：先将<code>stack1</code>中所有元素弹出到<code>stack2</code>中，然后<code>stack2</code>出栈一个元素，最后<code>stack2</code>中所有元素弹出到<code>stack1</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; stack1;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; stack2;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//利用栈stack1负责入栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> node)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        stack1.push(node);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//利用栈stack2负责出栈操作</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">pop</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//先将stack1中所有元素弹出到stack2中</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> temp = stack1.top();</span><br><span class=\"line\">            stack2.push(temp);</span><br><span class=\"line\">            stack1.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//然后stack2出栈一个元素</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> result = stack2.top();</span><br><span class=\"line\">        stack2.pop();</span><br><span class=\"line\">        <span class=\"comment\">//最后stack2中所有元素弹出到stack1</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!stack2.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> temp = stack2.top();</span><br><span class=\"line\">            stack1.push(temp);</span><br><span class=\"line\">            stack2.pop();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-包含min函数的栈\"><a href=\"#2-包含min函数的栈\" class=\"headerlink\" title=\"2. 包含min函数的栈\"></a>2. 包含min函数的栈</h2><p><strong>题目</strong>：定义栈的数据结构，请在该类型中实现一个能够得到栈的最小元素的<code>min</code>函数。在该栈中，调用<code>min</code>、<code>push</code>及<code>pop</code>的时间复杂度都是$O(1)$。<br><strong>思路</strong>：</p>\n<ul>\n<li>题目要求的是栈在进行任何的入栈和出栈操作后，都能调用<code>min</code>函数返回最小值。两种思路不可行：<ul>\n<li>定义一个变量<code>value</code>存储最小值。因为栈一旦<code>pop</code>后，不知道最小值是什么。</li>\n<li>每次进栈出栈都重新对栈内元素进行排序。因为复杂度太高。</li>\n</ul>\n</li>\n<li>正确解法：采用一个辅助栈，其栈顶保存主栈当前的最小值。主栈每一次<code>push</code>，辅助栈都将主栈当前的最小值压入栈顶。主栈每一次<code>pop</code>，辅助栈都<code>pop</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s1; <span class=\"comment\">//主栈</span></span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s2; <span class=\"comment\">//辅助栈</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//主栈stack1每一次push，辅助栈stack2都将主栈当前的最小值压入栈顶</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">push</span><span class=\"params\">(<span class=\"keyword\">int</span> value)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(s1.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(value);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(value&lt;s2.top())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(value);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s1.push(value);</span><br><span class=\"line\">            s2.push(s2.top());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//主栈stack1每一次pop，辅助栈stack2都pop</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">pop</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        s1.pop();</span><br><span class=\"line\">        s2.pop();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">top</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s1.top();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">min</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s2.top();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-栈的压入、弹出序列\"><a href=\"#3-栈的压入、弹出序列\" class=\"headerlink\" title=\"3. 栈的压入、弹出序列\"></a>3. 栈的压入、弹出序列</h2><p><strong>题目描述</strong><br>输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列$1,2,3,4,5$是某栈的压入顺序，序列$4,5,3,2,1$是该压栈序列对应的一个弹出序列，但$4,3,5,1,2$就不可能是该压栈序列的弹出序列。<br><strong>思路</strong>：</p>\n<ul>\n<li>判断一个序列是不是栈的弹出序列的规律：<ul>\n<li>如果下一个弹出的数字刚好是栈顶数字，那么直接弹出；</li>\n<li>如果下一个弹出的数字不在栈顶，则把压栈序列中还没有入栈的数字压入辅助栈，直到把下一个需要弹出的数字压入栈为止；</li>\n<li>如果所有数字都压入栈后仍然没有找到下一个弹出的数字，那么该序列不可能是一个弹出序列。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;<span class=\"keyword\">int</span>&gt; s;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsPopOrder</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pushV,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; popV)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pushV.size()==<span class=\"number\">0</span> || popV.size()==<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i=<span class=\"number\">0</span>; <span class=\"comment\">//标记pushV</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> j=<span class=\"number\">0</span>; <span class=\"comment\">//标记popV</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;pushV.size())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            s.push(pushV[i++]);</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(!s.empty() &amp;&amp; s.top()==popV[j])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                s.pop();</span><br><span class=\"line\">                j++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> s.empty();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"三、树\"><a href=\"#三、树\" class=\"headerlink\" title=\"三、树\"></a>三、树</h1><h2 id=\"1-二叉树的深度\"><a href=\"#1-二叉树的深度\" class=\"headerlink\" title=\"1. 二叉树的深度\"></a>1. 二叉树的深度</h2><p><strong>题目描述</strong>:<br>输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。<br><strong>思路</strong>：<br><strong>解法1</strong>：</p>\n<ul>\n<li>前序遍历二叉树，计算每一叶结点的深度，找出最大的叶结点的深度，即树的高度。</li>\n<li>在两种情况下，当前深度变量<code>currentDepth</code>进行减一操作：<ul>\n<li>当前结点是叶结点，则将<code>currentDepth</code>与最大的叶结点深度<code>maxDepth</code>比较，更新<code>maxDepth</code>。之后，<code>currentDepth</code>进行减一操作；</li>\n<li>任一结点的左右子树遍历完成，<code>currentDepth</code>进行减一操作。</li>\n</ul>\n</li>\n<li>注：该题规定空树深度为0，根结点深度为1。</li>\n</ul>\n<p><strong>解法2</strong>：</p>\n<ul>\n<li>将结点的深度从该角度计算：后序遍历时，结点的左右子树的深度较大值加一。</li>\n<li>因此，树的深度可以这样计算：后序遍历二叉树，较大子树的深度值加一。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//解法1</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> maxDepth=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> currentDepth=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">        currentDepth++;</span><br><span class=\"line\">        <span class=\"comment\">//当前结点是叶结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot-&gt;left==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//更新maxDepth</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(currentDepth&gt;maxDepth)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                maxDepth = currentDepth;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//currentDepth进行减一操作</span></span><br><span class=\"line\">            currentDepth--;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//任一结点的左右子树遍历完成，currentDepth进行减一操作</span></span><br><span class=\"line\">        currentDepth--;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> maxDepth;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//解法2</span></span><br><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"comment\">//递归后序遍历二叉树</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件：若pRoot为nullptr，则返回0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> left=TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> right=TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//较大子树的深度值加一</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(left&gt;right)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> left+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> right+<span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-二叉树的镜像\"><a href=\"#2-二叉树的镜像\" class=\"headerlink\" title=\"2. 二叉树的镜像\"></a>2. 二叉树的镜像</h2><p><strong>题目描述</strong>:<br>操作给定的二叉树，将其变换为源二叉树的镜像。<br><strong>输入描述</strong>:<br>二叉树的镜像定义：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">源二叉树 </span><br><span class=\"line\">    \t    8</span><br><span class=\"line\">    \t   /  \\</span><br><span class=\"line\">    \t  6   10</span><br><span class=\"line\">    \t / \\  / \\</span><br><span class=\"line\">    \t5  7 9  11</span><br><span class=\"line\">镜像二叉树</span><br><span class=\"line\">    \t    8</span><br><span class=\"line\">    \t   /  \\</span><br><span class=\"line\">    \t  10   6</span><br><span class=\"line\">    \t / \\  / \\</span><br><span class=\"line\">    \t11 9 7   5</span><br></pre></td></tr></table></figure></p>\n<p><strong>思路</strong>：</p>\n<ul>\n<li>前序遍历二叉树，“访问”操作为：交换每一结点的左右子树（左右子树是<code>nullptr</code>也没关系，照样交换）。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Mirror</span><span class=\"params\">(TreeNode *pRoot)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">//交换左右子树</span></span><br><span class=\"line\">        TreeNode* temp = pRoot-&gt;left;</span><br><span class=\"line\">        pRoot-&gt;left = pRoot-&gt;right;</span><br><span class=\"line\">        pRoot-&gt;right = temp;</span><br><span class=\"line\">        Mirror(pRoot-&gt;left);</span><br><span class=\"line\">        Mirror(pRoot-&gt;right);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-平衡二叉树\"><a href=\"#3-平衡二叉树\" class=\"headerlink\" title=\"3. 平衡二叉树\"></a>3. 平衡二叉树</h2><p><strong>题目描述</strong><br>输入一棵二叉树，判断该二叉树是否是平衡二叉树。注意，空树默认为平衡二叉树。<br><strong>思路</strong>：</p>\n<ul>\n<li>依据#1题&lt;二叉树的深度&gt;中解法2的思想，将平衡二叉树的判断准则定为：每一结点的左右子树的深度值相差不超过1。</li>\n<li>后序遍历二叉树，计算每一结点的左右子树的深度，比较差值。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> result=<span class=\"literal\">true</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsBalanced_Solution</span><span class=\"params\">(TreeNode* pRoot)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        TreeDepth(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//后序遍历二叉树，计算树的深度</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">TreeDepth</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> left = TreeDepth(pRoot-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> right = TreeDepth(pRoot-&gt;right);</span><br><span class=\"line\">        <span class=\"comment\">//比较左右子树深度的差值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">abs</span>(left-right)&gt;<span class=\"number\">1</span>)</span><br><span class=\"line\">            result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//计算每一结点的左右子树的深度</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(left&gt;right)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> left+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> right+<span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-把二叉树打印成多行\"><a href=\"#4-把二叉树打印成多行\" class=\"headerlink\" title=\"4. 把二叉树打印成多行\"></a>4. 把二叉树打印成多行</h2><p><strong>题目描述</strong>：<br>从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。<br><strong>思路</strong>：</p>\n<ul>\n<li>层序遍历二叉树，在每一层末尾加入一个换行符。</li>\n<li>通过变量<code>toBePrinted</code>记录当前层要打印结点个数,<code>nextLevel</code>记录下一层要打印结点个数。</li>\n<li>对于根结点，<code>toBePrinted</code>为1，在将根结点的左右子结点入队时记录<code>nextLevel</code>。</li>\n<li>当<code>toBePrinted</code>为0，则打印一个换行，<code>toBePrinted</code>置为<code>nextLevel</code>，<code>nextLevel</code>清零。接着，开始处理下一层。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> toBePrinted=<span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> nextLevel = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;TreeNode*&gt; q; </span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; level;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; Print(TreeNode* pRoot) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        q.push(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pCurrent = q.front();</span><br><span class=\"line\">            q.pop();</span><br><span class=\"line\">            toBePrinted--;</span><br><span class=\"line\">            level.push_back(pCurrent-&gt;val);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                q.push(pCurrent-&gt;left);</span><br><span class=\"line\">                nextLevel++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;right != <span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                q.push(pCurrent-&gt;right);</span><br><span class=\"line\">                nextLevel++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(toBePrinted==<span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                toBePrinted=nextLevel;</span><br><span class=\"line\">                nextLevel=<span class=\"number\">0</span>;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result; <span class=\"comment\">//注意，最后要return</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-对称的二叉树\"><a href=\"#5-对称的二叉树\" class=\"headerlink\" title=\"5. 对称的二叉树\"></a>5. 对称的二叉树</h2><p><strong>题目描述</strong>:<br>请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。<br><strong>思路</strong>：</p>\n<ul>\n<li>一开始的想法：构建该二叉树的镜像二叉树，然后同时遍历两个树，逐一进行比较。但空间复杂度为$O(n)$，不可行。</li>\n<li>正确解法：前序遍历是<code>&lt;root&gt;&lt;left&gt;&lt;right&gt;</code>。定义一种新的和前序遍历对称的遍历方式<code>&lt;root&gt;&lt;right&gt;&lt;left&gt;</code>。对于对称的二叉树，前序遍历的结果，和新定义的遍历方式的结果应该是一样的。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isSymmetrical</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> treversal(pRoot, pRoot);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">treversal</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> || pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1-&gt;val!=pRoot2-&gt;val)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1=treversal(pRoot1-&gt;left, pRoot2-&gt;right);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2=treversal(pRoot1-&gt;right, pRoot2-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"6-二叉树的下一个结点\"><a href=\"#6-二叉树的下一个结点\" class=\"headerlink\" title=\"6. 二叉树的下一个结点\"></a>6. 二叉树的下一个结点</h2><p><strong>题目描述</strong>:<br>给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，<strong>同时包含指向父结点的指针</strong>。<br><strong>思路</strong>：</p>\n<ul>\n<li>在中序遍历顺序<code>&lt;left，root，right&gt;</code>下，二叉树某一结点<code>pNode</code>的下一个结点规律如下：<ul>\n<li>如果<code>pNode</code>含有右子树，则下一结点为<code>pNode</code>的<strong>右子树中最深最左的那个结点</strong>。</li>\n<li>如果<code>pNode</code>不含右子树，则下一结点为<strong>使得<code>pNode</code>在其左子树中的最近的祖先结点</strong>。<br>注：最极端情况是<code>pNode</code>是二叉树中序遍历的最后一个结点，即在二叉树的最右末端，直到回溯到根结点，<code>pNode</code>还是在右子树中，即没有满足题意的下一结点。根结点的父节点为<code>nullptr</code>，祖先结点为<code>nullptr</code>也是终止循环条件之一。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeLinkNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeLinkNode *next;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeLinkNode(int x) :val(x), left(NULL), right(NULL), next(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    TreeLinkNode* pNext=<span class=\"literal\">nullptr</span>; <span class=\"comment\">//记录目标结点</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeLinkNode* <span class=\"title\">GetNext</span><span class=\"params\">(TreeLinkNode* pNode)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pNode==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//如果pNode含有右子树，则下一结点为pNode的右子树中最深最左的那个结点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pNode-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNext=pNode-&gt;right;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pNext-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                pNext=pNext-&gt;left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//如果pNode不含右子树，则下一结点为使得pNode在其左子树中的最近的祖先结点</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(pNode-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeLinkNode* pParent = pNode-&gt;next;</span><br><span class=\"line\">            <span class=\"comment\">//最极端情况：若到根节点还没找到</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(pParent!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(pParent-&gt;left==pNode)</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    pNext=pParent;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">else</span></span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    pNode = pParent;</span><br><span class=\"line\">                    pParent=pParent-&gt;next;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pNext;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-二叉搜索树与双向链表\"><a href=\"#7-二叉搜索树与双向链表\" class=\"headerlink\" title=\"7. 二叉搜索树与双向链表\"></a>7. 二叉搜索树与双向链表</h2><p><strong>题目描述</strong>：<br>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，二叉搜索树的中序遍历结果即为有序序列。</li>\n<li>然后，在中序遍历的“访问”操作中进行如下操作完成双向链表的转换：<ul>\n<li>维护双向链表的尾结点<code>pLastNode</code>，初始化为<code>nullptr</code>。 </li>\n<li>当前结点的<code>left</code>指针指向<code>pLastNode</code>，<code>pLastNode</code>的<code>right</code>指针指向当前结点，更新<code>pLastNode</code>。</li>\n<li>最终结果： <code>nullptr&lt;-1&lt;=&gt;2&lt;=&gt;3&lt;=&gt;4&lt;=&gt;5-&gt;nullptr</code>（自己画图即可知）。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Convert</span><span class=\"params\">(TreeNode* pRoot)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//pLastNode表示双向链表中的最后一个结点</span></span><br><span class=\"line\">        TreeNode* pLastNode=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        InorderTraversal(pRoot,&amp;pLastNode);</span><br><span class=\"line\">        TreeNode* pHead=pLastNode;</span><br><span class=\"line\">        <span class=\"comment\">//找出双向链表中的头结点，并返回</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pHead-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pHead=pHead-&gt;left;    </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pHead;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//中序遍历二叉搜索树</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">InorderTraversal</span><span class=\"params\">(TreeNode* pRoot,TreeNode** pLastNode)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        InorderTraversal(pRoot-&gt;left,pLastNode);</span><br><span class=\"line\">        <span class=\"comment\">//如果pLastNode为nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*pLastNode==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pRoot-&gt;left=*pLastNode;     <span class=\"comment\">//当前结点的left指针指向链表中最后一个结点</span></span><br><span class=\"line\">            *pLastNode=pRoot;           <span class=\"comment\">//更新链表中最后一个结点</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pRoot-&gt;left=*pLastNode;     <span class=\"comment\">//当前结点的left指针指向链表中最后一个结点</span></span><br><span class=\"line\">            (*pLastNode)-&gt;right=pRoot;  <span class=\"comment\">//链表中最后一个结点的right指针指向当前结点</span></span><br><span class=\"line\">            *pLastNode=pRoot;           <span class=\"comment\">//更新链表中最后一个结点</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        InorderTraversal(pRoot-&gt;right,pLastNode);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-从上往下打印二叉树\"><a href=\"#8-从上往下打印二叉树\" class=\"headerlink\" title=\"8. 从上往下打印二叉树\"></a>8. 从上往下打印二叉树</h2><p><strong>题目描述</strong>:<br>从上往下打印出二叉树的每个节点，同层节点从左至右打印。<br><strong>思路</strong>：</p>\n<ul>\n<li>层序遍历二叉树。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">queue</span>&lt;TreeNode*&gt; q;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; PrintFromTopToBottom(TreeNode* root) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root == <span class=\"literal\">nullptr</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> v;</span><br><span class=\"line\">        q.push(root);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pCurrent = q.front();</span><br><span class=\"line\">            q.pop();</span><br><span class=\"line\">            v.push_back(pCurrent-&gt;val);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                q.push(pCurrent-&gt;left);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pCurrent-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                q.push(pCurrent-&gt;right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> v;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"9-二叉树中和为某一值的路径\"><a href=\"#9-二叉树中和为某一值的路径\" class=\"headerlink\" title=\"9. 二叉树中和为某一值的路径\"></a>9. 二叉树中和为某一值的路径</h2><p><strong>题目描述</strong>:<br>输入一颗二叉树和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。<br><strong>思路</strong>：</p>\n<ul>\n<li>前序遍历二叉树，计算每一路径和，与期望值进行比较。</li>\n<li>在两种情况下，从当前状态存储变量（<code>currentSum</code>及 <code>path</code>）中移去当前结点：<ul>\n<li>当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点(<code>path.pop_back()</code>,<code>currentSum-=root-&gt;val</code>)；</li>\n<li>任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点(<code>path.pop_back()</code>,<code>currentSum-=root-&gt;val</code>)。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> currentSum=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; path;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; FindPath(TreeNode* root,<span class=\"keyword\">int</span> expectNumber) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        preOrder(root,expectNumber);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//前序遍历二叉树，计算每一路径和。</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">preOrder</span><span class=\"params\">(TreeNode* root, <span class=\"keyword\">int</span> expectNumber)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        path.push_back(root-&gt;val);</span><br><span class=\"line\">        currentSum+=root-&gt;val;</span><br><span class=\"line\">        <span class=\"comment\">//1.当前结点是叶结点，则将路径和与期望数值比较之后，从当前状态存储变量中移去当前结点；</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root-&gt;left==<span class=\"literal\">nullptr</span> &amp;&amp; root-&gt;right==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(currentSum==expectNumber)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(path);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//下面该段可都不写，都留给情况2去处理，但若写，就需要return，否则会处理两次。</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(path.size()&gt;<span class=\"number\">0</span>)</span><br><span class=\"line\">                path.pop_back();</span><br><span class=\"line\">            currentSum-=root-&gt;val;</span><br><span class=\"line\">            <span class=\"keyword\">return</span>; <span class=\"comment\">//注意，需要return</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        preOrder(root-&gt;left,expectNumber);</span><br><span class=\"line\">        preOrder(root-&gt;right,expectNumber);</span><br><span class=\"line\">        <span class=\"comment\">//2.任一结点的左右子树遍历完成,从当前状态存储变量中移去当前结点。</span></span><br><span class=\"line\">        currentSum-=root-&gt;val;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(path.size()&gt;<span class=\"number\">0</span>)</span><br><span class=\"line\">            path.pop_back();</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"10-按之字形顺序打印二叉树\"><a href=\"#10-按之字形顺序打印二叉树\" class=\"headerlink\" title=\"10. 按之字形顺序打印二叉树\"></a>10. 按之字形顺序打印二叉树</h2><p><strong>题目描述</strong>：<br>请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。<br><strong>思路</strong>：</p>\n<ul>\n<li>按之字形顺序打印二叉树需要两个栈。</li>\n<li>若当前打印的是奇数层（如第1层、第3层），则先保存左子节点再保存右子节点到第一个栈。</li>\n<li>若当前打印的是偶数层（如第2层、第4层），则先保存右子节点再保存左子节点到第二个栈。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;TreeNode*&gt; s1;</span><br><span class=\"line\">    <span class=\"built_in\">stack</span>&lt;TreeNode*&gt; s2;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; level;</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; result;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; Print(TreeNode* pRoot) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">NULL</span>) </span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        s1.push(pRoot);</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(!s1.empty()||!s2.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s1.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(!s1.empty())</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    TreeNode* pTemp = s1.top();</span><br><span class=\"line\">                    s1.pop();</span><br><span class=\"line\">                    level.push_back(pTemp-&gt;val);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s2.push(pTemp-&gt;left);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s2.push(pTemp-&gt;right);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(!s2.empty())</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">while</span>(!s2.empty())</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    TreeNode* pTemp = s2.top();</span><br><span class=\"line\">                    s2.pop();</span><br><span class=\"line\">                    level.push_back(pTemp-&gt;val);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;right!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s1.push(pTemp-&gt;right);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span>(pTemp-&gt;left!=<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">                        s1.push(pTemp-&gt;left);                 </span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                result.push_back(level);</span><br><span class=\"line\">                level.clear();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"11-二叉搜索树的第k个结点\"><a href=\"#11-二叉搜索树的第k个结点\" class=\"headerlink\" title=\"11. 二叉搜索树的第k个结点\"></a>11. 二叉搜索树的第k个结点</h2><p><strong>题目描述</strong>:<br>给定一颗二叉搜索树，请找出其中的第$k$大的结点。例如， 5 / \\ 3 7 / \\ / \\ 2 4 6 8 中，按结点数值大小顺序第三个结点的值为4。<br><strong>思路</strong>：</p>\n<ul>\n<li>中序遍历BST可得有序序列。</li>\n<li>在中序遍历的“访问”操作中计数。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num=<span class=\"number\">0</span>;</span><br><span class=\"line\">    TreeNode* pNode=<span class=\"literal\">nullptr</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">KthNode</span><span class=\"params\">(TreeNode* pRoot, <span class=\"keyword\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        KthNode(pRoot-&gt;left,k);</span><br><span class=\"line\">        <span class=\"comment\">//在“访问”操作中计数</span></span><br><span class=\"line\">        num++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(num==k)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            pNode=pRoot; </span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        KthNode(pRoot-&gt;right,k);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"12-二叉搜索树的后序遍历序列\"><a href=\"#12-二叉搜索树的后序遍历序列\" class=\"headerlink\" title=\"12. 二叉搜索树的后序遍历序列\"></a>12. 二叉搜索树的后序遍历序列</h2><p><strong>题目描述</strong>：<br>输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。<br><strong>思路</strong>：</p>\n<ul>\n<li>后序遍历顺序：<code>&lt;left，right，root&gt;</code>。</li>\n<li>对于二叉搜索树的后续遍历序列，如果去掉最后一个元素x（也就是根）的序列为T，那么T满足：T可以分成两段，前一段（左子树）小于x，后一段（右子树）大于x，且这两段（子树）都是合法的后序序列。</li>\n<li>故以该规律，递归验证每一左右子树。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">VerifySquenceOfBST</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sequence)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(sequence.empty())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Check(sequence,<span class=\"number\">0</span>,sequence.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Check</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sequence, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件1：一个或零个元素，返回true</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;=end)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rootVal = sequence[end];</span><br><span class=\"line\">        <span class=\"comment\">//分出左子树</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sequence[i]&gt;rootVal)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//验证右子树中所有元素都大于root值</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j = i;j&lt;end;j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//递归出口条件2：右子树中存在小于root值的元素</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sequence[j]&lt;rootVal)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//递归验证左右子树，需都返回true</span></span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1 = Check(sequence,start,i<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2 = Check(sequence,i,end<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"13-树的子结构\"><a href=\"#13-树的子结构\" class=\"headerlink\" title=\"13. 树的子结构\"></a>13. 树的子结构</h2><p><strong>题目描述</strong>:<br>输入两棵二叉树A，B，判断B是不是A的子结构。此外，约定空树不是任意一个树的子结构。<br><strong>思路</strong>：</p>\n<ul>\n<li>遍历树A，在树A中找出所有与树B的根节点值相等的结点，保存至vector容器<code>v</code>中。</li>\n<li>函数<code>bool Check(TreeNode* pTest, TreeNode* pRoot2)</code>：检验以<code>pTest</code>为根结点的树是否包含树B。<strong>注意，左右子树都需返回<code>true</code></strong>。</li>\n<li>对于容器<code>v</code>中所有的<code>pTest</code>结点，逐一进行检验，<strong>只要有一个成立即可</strong>，即包含。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;TreeNode*&gt; v;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">HasSubtree</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span> || pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//在树A中找出所有与树B的根节点值相等的结点，保存至容器v中</span></span><br><span class=\"line\">        Find(pRoot1,pRoot2);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//对于容器v中所有的pTest结点，逐一进行检验</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;v.size();i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result = Check(v[i],pRoot2);</span><br><span class=\"line\">            <span class=\"comment\">//只要有一个成立即可，即包含</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(result==<span class=\"literal\">true</span>) </span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Find</span><span class=\"params\">(TreeNode* pRoot1, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot1-&gt;val==pRoot2-&gt;val)</span><br><span class=\"line\">            v.push_back(pRoot1);</span><br><span class=\"line\">        Find(pRoot1-&gt;left,pRoot2);</span><br><span class=\"line\">        Find(pRoot1-&gt;right,pRoot2);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Check</span><span class=\"params\">(TreeNode* pTest, TreeNode* pRoot2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest==<span class=\"literal\">nullptr</span> &amp;&amp; pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pRoot2==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pTest-&gt;val!=pRoot2-&gt;val)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result1 = Check(pTest-&gt;left,pRoot2-&gt;left);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result2 = Check(pTest-&gt;right,pRoot2-&gt;right);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result1 &amp;&amp; result2;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"14-重建二叉树\"><a href=\"#14-重建二叉树\" class=\"headerlink\" title=\"14. 重建二叉树\"></a>14. 重建二叉树</h2><p><strong>题目描述</strong>:<br>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列<script type=\"math/tex\">\\{1,2,4,7,3,5,6,8\\}</script>和中序遍历序列<script type=\"math/tex\">\\{4,7,2,1,5,3,8,6\\}</script>，则重建二叉树并返回。<br><strong>思路</strong>：</p>\n<ul>\n<li>首先，前序遍历序列的首元素给出根结点；然后，通过中序遍历序列得出左右子树长度；最后，可分割出左右子树各自的前序序列和中序序列。</li>\n<li>分别递归重建左子树和右子树，递归终止条件：<ul>\n<li>当序列中只剩一元素(<code>start==end</code>)时，返回该根结点指针；</li>\n<li>当序列中无元素(<code>start&gt;end</code>)时，返回<code>nullptr</code>。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">reConstructBinaryTree</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pre,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; vin)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(pre.empty() || vin.empty() || pre.size()!=vin.size())</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reConstruct(pre, <span class=\"number\">0</span>, pre.size()<span class=\"number\">-1</span>,vin,<span class=\"number\">0</span>, vin.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">reConstruct</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; pre, <span class=\"keyword\">int</span> preStart, <span class=\"keyword\">int</span> preEnd,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; vin,<span class=\"keyword\">int</span> vinStart, <span class=\"keyword\">int</span> vinEnd)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件1：当序列中只剩一结点，返回该结点指针</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(preStart==preEnd)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            TreeNode* pNode = <span class=\"keyword\">new</span> TreeNode(pre[preStart]);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pNode;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件2：当序列无结点时，返回nullptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(preStart&gt;preEnd)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"comment\">//前序遍历序列的首元素给出根结点</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> rootVal = pre[preStart];</span><br><span class=\"line\">        TreeNode* pRoot = <span class=\"keyword\">new</span> TreeNode(rootVal);</span><br><span class=\"line\">        <span class=\"comment\">//通过中序遍历序列得出左右子树长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = vinStart;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(;i&lt;vinEnd;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(vin[i]==rootVal)</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> leftLength = i-vinStart; <span class=\"keyword\">int</span> rightLength = vinEnd-i;</span><br><span class=\"line\">        <span class=\"comment\">//分割出左右子树各自的前序序列和中序序列</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> preStartLeft = preStart+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> preEndLeft=preStartLeft+leftLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> vinStartLeft=vinStart;<span class=\"keyword\">int</span> vinEndLeft=i<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> preStartRight = preEndLeft+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> preEndRight=preEnd;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> vinStartRight = i+<span class=\"number\">1</span>;<span class=\"keyword\">int</span> vinEndRight=vinEnd;</span><br><span class=\"line\">        <span class=\"comment\">//分别递归重建左子树和右子树</span></span><br><span class=\"line\">        pRoot-&gt;left = reConstruct(pre,preStartLeft,preEndLeft,vin,vinStartLeft,vinEndLeft);</span><br><span class=\"line\">        pRoot-&gt;right =reConstruct(pre,preStartRight,preEndRight,vin,vinStartRight,vinEndRight);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"15-序列化二叉树\"><a href=\"#15-序列化二叉树\" class=\"headerlink\" title=\"15. 序列化二叉树\"></a>15. 序列化二叉树</h2><p><strong>题目描述</strong>：<br>请实现两个函数，分别用来序列化和反序列化二叉树<br><strong>思路</strong>：</p>\n<ul>\n<li>对于序列化：<ul>\n<li>使用前序遍历，递归的将二叉树的值转化为字符，并且在每次二叉树的结点不为空时，在转化val所得的字符之后添加一个<code>&#39;，&#39;</code>作为分割。对于空节点则以 <code>&#39;#&#39;</code> 代替。</li>\n</ul>\n</li>\n<li>对于反序列化：<ul>\n<li>按照前序顺序，递归的使用字符串中的字符创建左右子树。注意：在递归时，递归函数的参数一定要是<code>char **</code>，这样才能保证每次递归后指向字符串的指针会随着递归的进行而移动。</li>\n</ul>\n</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">struct TreeNode </span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">    int val;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *left;</span></span><br><span class=\"line\"><span class=\"comment\">    struct TreeNode *right;</span></span><br><span class=\"line\"><span class=\"comment\">    TreeNode(int x) :val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">char</span>* <span class=\"title\">Serialize</span><span class=\"params\">(TreeNode *root)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;    </span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> str;</span><br><span class=\"line\">        Serialize2(root,str);</span><br><span class=\"line\">        <span class=\"keyword\">char</span>* result = <span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[str.size()+<span class=\"number\">1</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;str.size();i++)</span><br><span class=\"line\">            result[i] = str[i];</span><br><span class=\"line\">        result[str.size()] = <span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">Serialize2</span><span class=\"params\">(TreeNode* root, <span class=\"built_in\">string</span>&amp; str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(root==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            str+=<span class=\"string\">'#'</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> r = to_string(root-&gt;val);</span><br><span class=\"line\">        str+=r;</span><br><span class=\"line\">        str+=<span class=\"string\">','</span>;</span><br><span class=\"line\">        Serialize2(root-&gt;left, str);</span><br><span class=\"line\">        Serialize2(root-&gt;right, str);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Deserialize</span><span class=\"params\">(<span class=\"keyword\">char</span> *str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">nullptr</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        TreeNode* result = Deserialize2(&amp;str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">TreeNode* <span class=\"title\">Deserialize2</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str==<span class=\"string\">'#'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">nullptr</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> num=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(**str!= <span class=\"string\">'\\0'</span> &amp;&amp; **str!=<span class=\"string\">','</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num=num*<span class=\"number\">10</span>+((**str)-<span class=\"string\">'0'</span>);</span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        TreeNode* pRoot = <span class=\"keyword\">new</span> TreeNode(num);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str ==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            (*str)++;</span><br><span class=\"line\">        pRoot-&gt;left = Deserialize2(str);</span><br><span class=\"line\">        pRoot-&gt;right= Deserialize2(str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pRoot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"四、字符串\"><a href=\"#四、字符串\" class=\"headerlink\" title=\"四、字符串\"></a>四、字符串</h1><h2 id=\"1-替换空格\"><a href=\"#1-替换空格\" class=\"headerlink\" title=\"1. 替换空格\"></a>1. 替换空格</h2><p><strong>题目描述</strong>：<br>请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为”We Are Happy.”则经过替换之后的字符串为”We%20Are%20Happy.”<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>注意</strong>：假设在原来的字符串上进行替换，并保证输入的字符串后面有足够多的空余内存。</li>\n<li><strong>步骤</strong>：从后向前替换：<ul>\n<li>1.遍历字符串，得到原字符串的长度和空格的个数;</li>\n<li>2.计算新字符串的长度，新串长度为原串长度加上两倍的空格个数；</li>\n<li>3.从后向前替换：设置两个指针，p1指向原字符串末尾，p2指向新字符串末尾。前移指针p1，逐个把它指向的内容复制到p2指向的位置；</li>\n</ul>\n</li>\n<li>所有字符串都只复制一次，时间复杂度：O(n)。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">replaceSpace</span><span class=\"params\">(<span class=\"keyword\">char</span> *str,<span class=\"keyword\">int</span> length)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">nullptr</span> || length&lt;<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.遍历字符串，得到空格的个数</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> numSpace = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;length;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">                numSpace++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.计算新字符串的长度</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> lengthNew = length+<span class=\"number\">2</span>*numSpace;</span><br><span class=\"line\">        <span class=\"comment\">//3.从后向前替换：设置两个指针，i指向原字符串末尾，j指向新字符串末尾</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = length<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> j = lengthNew<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//终止条件，i&lt;0</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&gt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'0'</span>;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'2'</span>;</span><br><span class=\"line\">                str[j--] = <span class=\"string\">'%'</span>;</span><br><span class=\"line\">                i--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                str[j--] = str[i--];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-整数中1出现的次数（从1到n整数中1出现的次数）\"><a href=\"#2-整数中1出现的次数（从1到n整数中1出现的次数）\" class=\"headerlink\" title=\"2. 整数中1出现的次数（从1到n整数中1出现的次数）\"></a>2. 整数中1出现的次数（从1到n整数中1出现的次数）</h2><p><strong>题目描述</strong><br>求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数。<br><strong>思路</strong>：</p>\n<ul>\n<li>对1~n的每一个数：通过对10求余数判断整数的个位数字是不是1，如果这个数字大于10，则除以10之后再判断个位数字是不是1。</li>\n<li>对每个数字都要做除法和求余运算，以求出该数字中1出现的次数。如果输入数字为$n$，$n$有$O(logn)$位，我们需要判断每一位是不是1，那么它的时间复杂度是$O(nlogn)$。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">NumberOf1Between1AndN_Solution</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> number=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">            number+=NumberOf1(i);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">NumberOf1</span><span class=\"params\">(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> number=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(n)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(n%<span class=\"number\">10</span> ==<span class=\"number\">1</span>)</span><br><span class=\"line\">                number++;</span><br><span class=\"line\">            n=n/<span class=\"number\">10</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-翻转单词顺序列\"><a href=\"#3-翻转单词顺序列\" class=\"headerlink\" title=\"3. 翻转单词顺序列\"></a>3. 翻转单词顺序列</h2><p><strong>题目描述</strong>:输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串”I am a student.”，则输出”student. a am I”。<br><strong>思路</strong>：</p>\n<ul>\n<li>第一步翻转句子中所有的字符。比如翻转”I am a student.”中所有的字符得到”.tenduts a ma I”，此时不但翻转了句子中单词的顺序，连单词内的字符顺序也被翻转了。</li>\n<li>第二步再翻转每个单词中字符的顺序，就得到了“studnet. a am I”。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">ReverseSentence</span><span class=\"params\">(<span class=\"built_in\">string</span> str)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//1.先整体翻转</span></span><br><span class=\"line\">        ReverseWord(str,<span class=\"number\">0</span>,str.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i,start,end;</span><br><span class=\"line\">        i=start=end=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;str.size())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//空格跳过</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span>(i&lt;str.size() &amp;&amp; str[i]==<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//不是空格，找单词最后一个字符的位置</span></span><br><span class=\"line\">            start = end = i;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(i&lt;str.size() &amp;&amp; str[i]!=<span class=\"string\">' '</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">                end++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//2.局部翻转</span></span><br><span class=\"line\">            ReverseWord(str,start,end<span class=\"number\">-1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReverseWord</span><span class=\"params\">(<span class=\"built_in\">string</span>&amp; str, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(start&lt;end)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            swap(str[start++],str[end--]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-左旋转字符串\"><a href=\"#4-左旋转字符串\" class=\"headerlink\" title=\"4. 左旋转字符串\"></a>4. 左旋转字符串</h2><p><strong>题目描述</strong><br>汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！<br><strong>思路</strong>：</p>\n<ul>\n<li>以”abcdefg”为例，想把它的前两个字符移到后面，得到”cdefgab”。</li>\n<li>将前两个字符分到第一部分，将后面的所有字符分到第二部分。</li>\n<li>先分别翻转这两部分，于是得到“bagfedc”。</li>\n<li>接下来翻转整个字符串，得到“cdefgab”，刚好就是把原始字符串左旋转两位的结果。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">LeftRotateString</span><span class=\"params\">(<span class=\"built_in\">string</span> str, <span class=\"keyword\">int</span> n)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str.size()&lt;<span class=\"number\">1</span> || n&gt;str.size() || n&lt;<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> startFirst = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endFirst = n<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> startSecond = n;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endSecond = str.size()<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 翻转字符串的前面n个字符</span></span><br><span class=\"line\">        ReverseWord(str,startFirst,endFirst);</span><br><span class=\"line\">        <span class=\"comment\">// 翻转字符串的后面部分</span></span><br><span class=\"line\">        ReverseWord(str,startSecond,endSecond);</span><br><span class=\"line\">        <span class=\"comment\">// 翻转整个字符串</span></span><br><span class=\"line\">        ReverseWord(str,<span class=\"number\">0</span>,str.size()<span class=\"number\">-1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> str;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">ReverseWord</span><span class=\"params\">(<span class=\"built_in\">string</span>&amp; str, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(start&lt;end)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">char</span> temp = str[start];</span><br><span class=\"line\">            str[start] = str[end];</span><br><span class=\"line\">            str[end] = temp;</span><br><span class=\"line\">            start++;</span><br><span class=\"line\">            end--;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-把字符串转换成整数\"><a href=\"#5-把字符串转换成整数\" class=\"headerlink\" title=\"5. 把字符串转换成整数\"></a>5. 把字符串转换成整数</h2><p><strong>题目描述</strong><br>将一个字符串转换成一个整数，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0<br><strong>输入描述</strong>:<br>输入一个字符串,包括数字字母符号,可以为空<br><strong>输出描述</strong>:<br>如果是合法的数值表达则返回该数字，否则返回0<br><strong>示例</strong>:<br>输入:<br>+2147483647<br>    1a33<br>输出:<br>2147483647<br>    0<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">StrToInt</span><span class=\"params\">(<span class=\"built_in\">string</span> str)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* cstr = str.c_str();</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>((cstr != <span class=\"literal\">NULL</span>) &amp;&amp; (*cstr!= <span class=\"string\">'\\0'</span>)) <span class=\"comment\">//字符串不为空</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">bool</span> minus = <span class=\"literal\">false</span>; <span class=\"comment\">//检查第一位是否为正负号</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*cstr==<span class=\"string\">'+'</span>)</span><br><span class=\"line\">                cstr++;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(*cstr==<span class=\"string\">'-'</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                cstr++;</span><br><span class=\"line\">                minus = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*cstr!=<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">                num = StrToIntCore(cstr,minus);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">long</span> <span class=\"keyword\">long</span> <span class=\"title\">StrToIntCore</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* digit, <span class=\"keyword\">bool</span> minus)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> num = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(*digit!=<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">        &#123;   </span><br><span class=\"line\">            <span class=\"comment\">//计算数字大小</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*digit&gt;=<span class=\"string\">'\\0'</span> &amp;&amp; *digit&lt;=<span class=\"string\">'9'</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> flag = minus? <span class=\"number\">-1</span>:<span class=\"number\">1</span>;</span><br><span class=\"line\">                num = num*<span class=\"number\">10</span>+flag*(*digit-<span class=\"string\">'0'</span>);</span><br><span class=\"line\">                <span class=\"comment\">//溢出判断</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span>((!minus &amp;&amp; num&gt;<span class=\"number\">0x7FFFFFFF</span>) || (minus &amp;&amp; num&lt;(<span class=\"keyword\">signed</span> <span class=\"keyword\">int</span>)<span class=\"number\">0x80000000</span>))</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    num=<span class=\"number\">0</span>;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">         \t\tdigit++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//非法输入</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                num=<span class=\"number\">0</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">truetrue<span class=\"keyword\">return</span> num;        </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"6-正则表达式匹配\"><a href=\"#6-正则表达式匹配\" class=\"headerlink\" title=\"6. 正则表达式匹配\"></a>6. 正则表达式匹配</h2><p><strong>题目描述</strong>:<br>请实现一个函数用来匹配包括’.’和’*‘的正则表达式。模式中的字符’.’表示任意一个字符，而’*‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”ab*ac*a”匹配，但是与”aa.a”和”ab*a”均不匹配<br><strong>思路</strong>：<br>A：下一个字符是<code>*</code><br>　　1.若当前字符匹配<br>　　　　选择1：匹配了，但我当作0匹配(匹配0次)。<code>s不动，p加2</code><br>　　　　选择2：匹配了，匹配结束(匹配1次)。<code>s+1,p+2</code><br>　　　　选择3：匹配了，我继续匹配下一个(匹配多次)。<code>s+1，p不动</code><br>　　2.当前字符不匹配。<code>s不动，p加2</code><br>B:下一个字符不是<code>*</code>，当前字符匹配。<code>s+1,p+1</code><br>C:下一个字符不是<code>*</code>，当前字符不匹配。<code>返回false</code><br>递归出口条件：<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">match</span><span class=\"params\">(<span class=\"keyword\">char</span>* str, <span class=\"keyword\">char</span>* pattern)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(str==<span class=\"literal\">NULL</span> || pattern==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">        \t<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> matchCore(str,pattern);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">matchCore</span><span class=\"params\">(<span class=\"keyword\">char</span>* str, <span class=\"keyword\">char</span>* pattern)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件:字符串和模式串同时走完</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'\\0'</span> &amp;&amp; *pattern==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"comment\">//递归出口条件：字符串没走完，模式串走完，返回false</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str!=<span class=\"string\">'\\0'</span> &amp;&amp; *pattern==<span class=\"string\">'\\0'</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//A：下一个字符是*</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*(pattern+<span class=\"number\">1</span>)==<span class=\"string\">'*'</span>) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//1.若当前字符匹配</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(*pattern==*str || (*pattern==<span class=\"string\">'.'</span> &amp;&amp; *str!=<span class=\"string\">'\\0'</span>))</span><br><span class=\"line\">            \t<span class=\"keyword\">return</span> matchCore(str,pattern+<span class=\"number\">2</span>)    <span class=\"comment\">//选择1：匹配了，但我当作0匹配(匹配0次)</span></span><br><span class=\"line\">            \t\t|| matchCore(str+<span class=\"number\">1</span>,pattern+<span class=\"number\">2</span>)  <span class=\"comment\">//选择2：匹配了，匹配结束(匹配1次)    \t</span></span><br><span class=\"line\">            \t\t|| matchCore(str+<span class=\"number\">1</span>,pattern);    <span class=\"comment\">//选择3：匹配了，我继续匹配下一个(匹配多次)</span></span><br><span class=\"line\">            <span class=\"comment\">//2.当前字符不匹配</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> </span><br><span class=\"line\">            \t<span class=\"keyword\">return</span> matchCore(str,pattern+<span class=\"number\">2</span>); <span class=\"comment\">//匹配结束</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//B:下一个字符不是*，当前字符匹配</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*pattern==*str || (*pattern==<span class=\"string\">'.'</span> &amp;&amp; *str!=<span class=\"string\">'\\0'</span>))</span><br><span class=\"line\">             \t<span class=\"keyword\">return</span> matchCore(str+<span class=\"number\">1</span>,pattern+<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"comment\">//C:下一个字符不是*，当前字符不匹配</span></span><br><span class=\"line\">truetrue<span class=\"keyword\">return</span> <span class=\"literal\">false</span>;           </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"7-表示数值的字符串\"><a href=\"#7-表示数值的字符串\" class=\"headerlink\" title=\"7. 表示数值的字符串\"></a>7. 表示数值的字符串</h2><p><strong>题目描述</strong><br>请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。<br><strong>思路</strong>：</p>\n<ul>\n<li>表示数值的字符串: A<code>.</code>B<code>e/E</code>C 例如：“+123.45e+6”<ul>\n<li>其中，A、C可能是以+/-开头的0~9的数位串，即整型；B也是0~9的数位串，但前面不能有正负号，即无符号整型。</li>\n</ul>\n</li>\n<li>故步骤为：扫描A部分；遇到小数点<code>.</code>，扫描B部分；遇到<code>e/E</code>，扫描C部分。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isNumeric</span><span class=\"params\">(<span class=\"keyword\">char</span>* str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(str==<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> numeric = scanInteger(&amp;str);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'.'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ++str;</span><br><span class=\"line\">            numeric = scanUnsignedInteger(&amp;str) || numeric;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(*str==<span class=\"string\">'e'</span> || *str==<span class=\"string\">'E'</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            ++str;</span><br><span class=\"line\">            numeric = numeric &amp;&amp; scanInteger(&amp;str);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> numeric &amp;&amp; *str==<span class=\"string\">'\\0'</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">true<span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">scanInteger</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(**str==<span class=\"string\">'+'</span> || **str==<span class=\"string\">'-'</span>)</span><br><span class=\"line\">            ++(*str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> scanUnsignedInteger(str);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">scanUnsignedInteger</span><span class=\"params\">(<span class=\"keyword\">char</span>** str)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>* before = *str;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(**str!=<span class=\"string\">'\\0'</span> &amp;&amp; **str&gt;=<span class=\"string\">'0'</span> &amp;&amp; **str&lt;=<span class=\"string\">'9'</span>)</span><br><span class=\"line\">            ++(*str);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> *str&gt;before;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"8-字符串的排列\"><a href=\"#8-字符串的排列\" class=\"headerlink\" title=\"8. 字符串的排列\"></a>8. 字符串的排列</h2><p><strong>题目描述</strong><br>输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。<br><strong>输入描述</strong>:<br>输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">待</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"五、数组\"><a href=\"#五、数组\" class=\"headerlink\" title=\"五、数组\"></a>五、数组</h1><h2 id=\"1-构建乘积数组\"><a href=\"#1-构建乘积数组\" class=\"headerlink\" title=\"1. 构建乘积数组\"></a>1. 构建乘积数组</h2><p><strong>题目描述</strong><br>给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素<code>B[i]=A[0]*A[1]*...*A[i-1]*A[i+1]*...*A[n-1]</code>。不能使用除法。<br><strong>思路</strong>：</p>\n<ul>\n<li>把数组B看成一个矩阵来创建（见书中）。B[i]的值可以看作图中的矩阵中每行的乘积。</li>\n<li>下三角用自上而下的顺序计算，<code>C[i] =C[i-1]*A[i-1]</code>。</li>\n<li>上三角用自下而上的顺序计算，<code>D[i]= D[i+1]*A[i+1]</code>。</li>\n<li>因此，先算下三角中的连乘，即先算出B[i]中的一部分，然后倒过来按上三角中的分布规律，把另一部分也乘进去。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; multiply(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; A) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> length = A.size();</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; B(length); <span class=\"comment\">//vector容器的构造函数</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> B;</span><br><span class=\"line\">        <span class=\"comment\">//计算下三角连乘</span></span><br><span class=\"line\">        B[<span class=\"number\">0</span>]=<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>;i&lt;length;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            B[i]=B[i<span class=\"number\">-1</span>]*A[i<span class=\"number\">-1</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//计算上三角</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=length<span class=\"number\">-2</span>;j&gt;=<span class=\"number\">0</span>;j--)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            temp *= A[j+<span class=\"number\">1</span>];</span><br><span class=\"line\">            B[j] *= temp;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> B;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-连续子数组的最大和\"><a href=\"#2-连续子数组的最大和\" class=\"headerlink\" title=\"2. 连续子数组的最大和\"></a>2. 连续子数组的最大和</h2><p><strong>题目</strong>：输入一个整型数组，数组里有正数也有负数。数组中一个或连续的多个整数组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为 O(n)。<br><strong>说明</strong>：例如输入的数组为{1, -2, 3, 10, -4, 7, 2, -5}，和最大的子数组为｛3, 10, -4, 7, 2}。因此输出为该子数组的和18。<br><strong>思路</strong>：</p>\n<ul>\n<li>从头到尾逐个累加数组中的每个数字。若加上<code>arr[i]</code>后的当前和<code>sumCurrent</code>小于<code>arr[i]</code>，则抛弃当前和<code>sumCurrent</code>及之前的所有数字，置当前和<code>sumCurrent</code>为<code>arr[i]</code>。同时每一步累加都记录下最大和<code>sumMax</code>。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">FindGreatestSumOfSubArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; <span class=\"built_in\">array</span>)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> sumCurrent=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> sumMax = <span class=\"number\">0x80000000</span>;<span class=\"comment\">//int的最小值</span></span><br><span class=\"line\">        <span class=\"comment\">//从头到尾逐个累加数组中的每个数字</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            sumCurrent += <span class=\"built_in\">array</span>[i];</span><br><span class=\"line\">            <span class=\"comment\">//若当前和sumCurrent小于arr[i]</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]&gt;sumCurrent)</span><br><span class=\"line\">                sumCurrent=<span class=\"built_in\">array</span>[i];</span><br><span class=\"line\">            <span class=\"comment\">//记录下最大和sumMax</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(sumCurrent&gt;sumMax) </span><br><span class=\"line\">                sumMax = sumCurrent;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sumMax;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-旋转数组的最小数字\"><a href=\"#3-旋转数组的最小数字\" class=\"headerlink\" title=\"3. 旋转数组的最小数字\"></a>3. 旋转数组的最小数字</h2><p><strong>题目描述</strong><br>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序（递增，可能相等）的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。<br><strong>思路</strong>：<br><strong>思路1</strong>：顺序查找，遍历数组，找到<code>arr[i]&gt;arr[i+1]</code>（稍微优化），时间复杂度$O(n)$，需改进。<br><strong>思路2</strong>：旋转数组是两个排序的子数组，采用二分查找。时间复杂度$O(logn)$：</p>\n<ul>\n<li><strong>情况1</strong>：<ul>\n<li>用指针<code>p1</code>指向第一个数组的第一个元素，用指针<code>p2</code>指向第二个数组的第2个元素。对于旋转数组，有特性：<code>arr[p1]&gt;arr[p2]</code>（<code>第一个数组&gt;=第二个数组</code>）；</li>\n<li>计算中间元素为指针<code>p</code>，如果<code>arr[p]&gt;=arr[p1]</code>，则指针<code>p</code>在第一个数组中，此时最小元素应该位于中间元素的后面，令<code>p1=p;</code>如果<code>arr[p]&lt;=arr[p1]</code>，则指针<code>p</code>在第二个数组中，此时最小元素应该位于中间元素的前面，令<code>p2 = p;</code>；</li>\n<li><code>p1</code>始终在第一个数组，<code>p2</code>始终在第二个数组，故循环终止条件为：<code>(p1+1)=p2</code>，<code>arr[p2]</code>即为最小元素。</li>\n</ul>\n</li>\n<li><strong>情况2</strong>：若旋转数组是将原来的0个元素搬到最后面，即数组有序，即<code>arr[p1]&lt;arr[p2]</code>，该情况是情况1中的特例，情况1中的做法是不适用的，直接返回最小元素<code>arr[0]</code>。</li>\n<li><strong>情况3</strong>：当指针<code>p</code>，<code>p1</code>，<code>p2</code>指向的元素相同时，即<code>arr[p]==arr[p1] &amp;&amp; arr[p]==arr[p2]</code>时，无法判断该将中间的数字是位于第一个数组还是第二个数组，无法继续用二分法，转而对<code>[p1，p2]</code>采用顺序查找法。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路1：顺序查找，时间复杂度O(n)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">minNumberInRotateArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; rotateArray)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> min = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(!rotateArray.empty())</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> size = rotateArray.size();</span><br><span class=\"line\">            <span class=\"comment\">//顺序查找，遍历数组，找到arr[i+1]&lt;arr[i]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;size<span class=\"number\">-1</span>;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(rotateArray[i+<span class=\"number\">1</span>]&lt;rotateArray[i])</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    min = rotateArray[i+<span class=\"number\">1</span>];</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路2：二分查找，时间复杂度O(logn)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">minNumberInRotateArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; rotateArray)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rotateArray.empty())  <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = rotateArray.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> p1 = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> p2 = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> minIndex=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//情况2，数组有序，直接返回arr[0]</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rotateArray[p1]&lt;rotateArray[p2]) <span class=\"keyword\">return</span> rotateArray[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"comment\">//情况1，二分查找</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>((p1+<span class=\"number\">1</span>)!=p2)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> p = (p1+p2)/<span class=\"number\">2</span>;</span><br><span class=\"line\">            <span class=\"comment\">//情况3，转为对[p1,p2]采用顺序查找</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rotateArray[p1]==rotateArray[p] &amp;&amp; rotateArray[p]==rotateArray[p2])</span><br><span class=\"line\">                <span class=\"keyword\">return</span> MinInOrder(rotateArray,p1,p2);</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(rotateArray[p]&gt;=rotateArray[p1]) p1 = p;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(rotateArray[p]&lt;=rotateArray[p2]) p2 = p;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> rotateArray[p2];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MinInOrder</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; rotateArray,<span class=\"keyword\">int</span> p1, <span class=\"keyword\">int</span> p2)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> min = <span class=\"number\">0</span>;</span><br><span class=\"line\">    \t<span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = p1;i&lt;p2;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            \t<span class=\"keyword\">if</span>(rotateArray[i+<span class=\"number\">1</span>]&lt;rotateArray[i])</span><br><span class=\"line\">            \t&#123;</span><br><span class=\"line\">                \tmin = rotateArray[i+<span class=\"number\">1</span>];</span><br><span class=\"line\">                \t<span class=\"keyword\">break</span>;</span><br><span class=\"line\">            \t&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> min;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-数字在排序数组中出现的次数\"><a href=\"#4-数字在排序数组中出现的次数\" class=\"headerlink\" title=\"4. 数字在排序数组中出现的次数\"></a>4. 数字在排序数组中出现的次数</h2><p><strong>题目描述</strong><br>统计一个数字在排序数组中出现的次数。<br><strong>思路</strong>：</p>\n<ul>\n<li><strong>思路1</strong>：顺序遍历数组，时间复杂度$O(n)$，需改进。</li>\n<li><strong>思路2</strong>：有序数组，使用二分查找。分两次二分查找：<ul>\n<li><strong>第一次</strong>找出该数字第一次出现的位置:<code>(mid==start) || (data[mid-1]!=target))</code>即已经是最左边的位置或其左边的一个数不等于该数；</li>\n<li><strong>第二次</strong>找出该数字最后一次出现的位置：<code>(mid==end) || (data[mid+1]!=target)</code>即已经是最右边的位置或其右边的一个数不等于该数。</li>\n</ul>\n</li>\n<li>可用递归实现，也可以用循环实现。</li>\n</ul>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路2，递归实现</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">GetNumberOfK</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data ,<span class=\"keyword\">int</span> k)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> number = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data.empty()) <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> firstIndex = getFirst(data,<span class=\"number\">0</span>,size<span class=\"number\">-1</span>,k);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> lastIndex = getLast(data,<span class=\"number\">0</span>,size<span class=\"number\">-1</span>,k);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (firstIndex &gt; <span class=\"number\">-1</span> &amp;&amp; lastIndex &gt; <span class=\"number\">-1</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \tnumber = lastIndex - firstIndex + <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> number;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getFirst</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end, <span class=\"keyword\">int</span> target)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mid = (start+end)/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data[mid]==target)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>((mid==start) || (data[mid<span class=\"number\">-1</span>]!=target))<span class=\"comment\">//让它是第一个出现的位置</span></span><br><span class=\"line\">            <span class=\"comment\">//if((mid==start) || (mid-1&gt;start&amp;&amp;data[mid-1]!=target))//等价</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> mid;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(data[mid]&gt;target) end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> getFirst(data,start,end,target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getLast</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end, <span class=\"keyword\">int</span> target)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mid = (start+end)/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data[mid]==target)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">           <span class=\"keyword\">if</span>((mid==end) || (data[mid+<span class=\"number\">1</span>]!=target))<span class=\"comment\">//让它是最后一个出现的位置</span></span><br><span class=\"line\">           <span class=\"comment\">//if((mid==end) || (mid+1&lt;end&amp;&amp;data[mid+1]!=target))//等价</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> mid;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(data[mid]&gt;target) end = mid<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> start = mid+<span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> getLast(data,start,end,target);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"5-数组中重复的数字\"><a href=\"#5-数组中重复的数字\" class=\"headerlink\" title=\"5. 数组中重复的数字\"></a>5. 数组中重复的数字</h2><p>题目描述<br>在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。</p>\n<h2 id=\"6-数组中只出现一次的数字\"><a href=\"#6-数组中只出现一次的数字\" class=\"headerlink\" title=\"6. 数组中只出现一次的数字\"></a>6. 数组中只出现一次的数字</h2><p>题目描述<br>一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。</p>\n<h2 id=\"7-数组中出现次数超过一半的数字\"><a href=\"#7-数组中出现次数超过一半的数字\" class=\"headerlink\" title=\"7. 数组中出现次数超过一半的数字\"></a>7. 数组中出现次数超过一半的数字</h2><p>题目描述<br>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。</p>\n<h2 id=\"8-把数组排成最小的数\"><a href=\"#8-把数组排成最小的数\" class=\"headerlink\" title=\"8. 把数组排成最小的数\"></a>8. 把数组排成最小的数</h2><p><strong>题目描述</strong><br>输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。<br><strong>思路</strong>：<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">PrintMinNumber</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; numbers)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> length = numbers.size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(length==<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"string\">\"\"</span>;</span><br><span class=\"line\">        sort(numbers.begin(),numbers.end(),compare);</span><br><span class=\"line\">        <span class=\"built_in\">string</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;length;i++)</span><br><span class=\"line\">            result += to_string(numbers[i]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">bool</span> <span class=\"title\">compare</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"built_in\">string</span> A = to_string(a)+to_string(b);</span><br><span class=\"line\">        <span class=\"built_in\">string</span> B = to_string(b)+to_string(a);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> A&lt;B;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"9-调整数组顺序使奇数位于偶数前面\"><a href=\"#9-调整数组顺序使奇数位于偶数前面\" class=\"headerlink\" title=\"9. 调整数组顺序使奇数位于偶数前面\"></a>9. 调整数组顺序使奇数位于偶数前面</h2><p><strong>题目描述</strong><br>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。<br><strong>思路</strong>：<br>1.剑指offer书中，是要求调整数组顺序，使得奇数位于偶数前面，没有要求奇数和奇数，偶数和偶数的相对位置不变。<br>解法是：指针<code>p1</code>指向数组头部，<code>p1</code>只后移。指针<code>p2</code>指向数组尾部，<code>p2</code>只前移。当<code>arr[p1]</code>为偶数，<code>arr[p2]</code>为奇数，则交换。<code>p1</code>继续后移，<code>p2</code>继续前移，一直循环。终止条件是：<code>p1</code>与<code>p2</code>交叉。<br>2.本题目中，要求奇数在前，偶数在后，且奇数相对于奇数，偶数相对于偶数的相对位置不变。则解法是：新建一个数组，先把原数组中的奇数push进去，再把偶数push进去，然后用新数组数据覆盖原数组即可。复杂度O(n)。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">reOrderArray</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &amp;<span class=\"built_in\">array</span>)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"comment\">//新建一个数组</span></span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"comment\">//先把原数组中的奇数push进去</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]%<span class=\"number\">2</span>==<span class=\"number\">1</span>)</span><br><span class=\"line\">                result.push_back(<span class=\"built_in\">array</span>[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//再把原数组中的偶数push进去</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \t<span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i]%<span class=\"number\">2</span>==<span class=\"number\">0</span>)</span><br><span class=\"line\">                result.push_back(<span class=\"built_in\">array</span>[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//用新数组覆盖原数组</span></span><br><span class=\"line\">        <span class=\"built_in\">array</span>=result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"10-二维数组中的查找\"><a href=\"#10-二维数组中的查找\" class=\"headerlink\" title=\"10. 二维数组中的查找\"></a>10. 二维数组中的查找</h2><p><strong>题目描述</strong><br>在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。<br><strong>思路</strong>：首先选取数组中右上角的数字。如果该数字等于要查找的数字，则查找过程结束；如果该数字大于要查找的数字，则去除该数字所在列；如果该数字小于要查找的数字，则去除该数字所在行。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">Find</span><span class=\"params\">(<span class=\"keyword\">int</span> target, <span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt; <span class=\"built_in\">array</span>)</span> </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"comment\">//防御型编程</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>.empty()) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"comment\">//计算二维数组的行和列</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows = <span class=\"built_in\">array</span>.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols = <span class=\"built_in\">array</span>[<span class=\"number\">0</span>].size();</span><br><span class=\"line\">        <span class=\"comment\">//首先选取数组中右上角的数字</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> j = cols<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> result = <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i&lt;rows &amp;&amp; j&gt;=<span class=\"number\">0</span>)<span class=\"comment\">//注意二维数组行列的取值范围为[0~rows-1, 0~cols-1]</span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字等于要查找的数字，则查找过程结束</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i][j]== target)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字大于要查找的数字，则去除该数字所在列</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> <span class=\"keyword\">if</span>(<span class=\"built_in\">array</span>[i][j]&gt;target)   </span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                j--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果该数字小于要查找的数字，则去除该数字所在行</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \ti++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"11-数组中的逆序对\"><a href=\"#11-数组中的逆序对\" class=\"headerlink\" title=\"11. 数组中的逆序对\"></a>11. 数组中的逆序对</h2><p><strong>题目描述</strong><br>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007<br><strong>输入描述</strong>:<br>题目保证输入的数组中没有的相同的数字<br><strong>数据范围</strong>：<br>对于%50的数据,$size&lt;=10^4$<br>对于%75的数据,$size&lt;=10^5$<br>对于%100的数据,$size&lt;=2*10^5$<br><strong>示例</strong>:<br>输入<br>1,2,3,4,5,6,7,0<br>输出<br>7<br><strong>思路</strong>：</p>\n<p><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//不对，未完成</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count=<span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">InversePairs</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> n = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> InversePairs2(data, n);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">InversePairs2</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"keyword\">int</span> n)</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"keyword\">if</span>(n&lt;<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;<span class=\"comment\">//就是为了返回，返回的值无所谓</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> leftLength= n/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rightLength= n-leftLength;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; left;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; right;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;leftLength;i++) left.push_back(data[i]);</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = leftLength;i&lt;n;i++) right.push_back(data[i]);</span><br><span class=\"line\">        InversePairs2(left,leftLength);    <span class=\"comment\">//sorting the left subarray</span></span><br><span class=\"line\">        InversePairs2(right,rightLength);  <span class=\"comment\">//sorting the right subarray</span></span><br><span class=\"line\">        mergeNew(data,left,leftLength,right,rightLength); <span class=\"comment\">//merge left and right into A</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> count%<span class=\"number\">1000000007</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mergeNew</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; data, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; left, <span class=\"keyword\">int</span> leftLength, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; right,<span class=\"keyword\">int</span> rightLength)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> i=leftLength+rightLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">truetrue<span class=\"keyword\">int</span> j = leftLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> k = rightLength<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&gt;=<span class=\"number\">0</span> &amp;&amp; k&gt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(left[j]&gt;right[k]) </span><br><span class=\"line\">            &#123; </span><br><span class=\"line\">            \tdata[i--] = left[j--];</span><br><span class=\"line\">            \tcount+=(k+<span class=\"number\">1</span>);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> </span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tdata[i--] = right[k--];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(j&gt;=<span class=\"number\">0</span>) data[i--]=left[j--];</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(k&gt;=<span class=\"number\">0</span>) data[i--]=right[k--];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"12-顺时针打印矩阵\"><a href=\"#12-顺时针打印矩阵\" class=\"headerlink\" title=\"12. 顺时针打印矩阵\"></a>12. 顺时针打印矩阵</h2><p><strong>题目描述</strong><br>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下矩阵：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1   2  3  4</span><br><span class=\"line\">5   6  7  8</span><br><span class=\"line\">9  10 11 12</span><br><span class=\"line\">13 14 15 16</span><br></pre></td></tr></table></figure></p>\n<p>则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.<br><strong>思路</strong>：分解成若干个简单的问题。<br>1.每次打印矩阵的一个圈。关键：循环继续的条件是：<code>cols&gt;start*2 &amp;&amp; row&gt;start*2</code><br>2.将打印一圈分成四步：第一步，从左到右打印一行；第二步，从上到下打印一列；第三步；从右到左打印一行；第四步，从下到上打印一列。<br>3.四步的前提条件：<br>第一步总是需要；<br>第二步的前提条件是终止行号大于起始行号；<br>第三步的前提条件是该圈内至少两行两列，即终止行号大于起始行号，终止列号大于起始列号；<br>第四步的前提条件：该圈内至少有三行二列，即终止行号比起始行号至少大2，终止列号大于起始列号。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; printMatrix(<span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; &gt; matrix) &#123;</span><br><span class=\"line\">truetrue<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> rows = matrix.size();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> cols = matrix[<span class=\"number\">0</span>].size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(rows&lt;=<span class=\"number\">0</span> || cols&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">//每次打印矩阵的一个圈</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(cols&gt;start*<span class=\"number\">2</span> &amp;&amp; rows&gt; start*<span class=\"number\">2</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            PrintMatrixInCircle(matrix,rows,cols,start,result);</span><br><span class=\"line\">            start++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">PrintMatrixInCircle</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&gt;&amp; matrix,<span class=\"keyword\">int</span> rows,<span class=\"keyword\">int</span> cols,<span class=\"keyword\">int</span> start,<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; result)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endX = cols-start<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> endY = rows-start<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//1.从左到右打印矩阵</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;=endX;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result.push_back(matrix[start][i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//2.从上到下打印一列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endY)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start+<span class=\"number\">1</span>;i&lt;=endY;i++)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[i][endX]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//3.从右到左打印一行</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endX &amp;&amp; start&lt; endY)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = endX<span class=\"number\">-1</span>;i&gt;=start;i--)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[endY][i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//4.从下到上打印一列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&lt;endX &amp;&amp; start &lt;endY <span class=\"number\">-1</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = endY<span class=\"number\">-1</span>; i&gt;=start+<span class=\"number\">1</span>;i--)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                result.push_back(matrix[i][start]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h1 id=\"六、排序\"><a href=\"#六、排序\" class=\"headerlink\" title=\"六、排序\"></a>六、排序</h1><h2 id=\"1-数组中出现次数超过一半的数字\"><a href=\"#1-数组中出现次数超过一半的数字\" class=\"headerlink\" title=\"1.数组中出现次数超过一半的数字\"></a>1.数组中出现次数超过一半的数字</h2><p>题目描述<br>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。<br><strong>思路</strong>：结合数组特性：数组中有一个数字出现的次数超过了数组长度的一半，如果将这个数组排序，那么排序之后位于数组中间的数字一定就是那个出现次数超过数组长度一半的数字。这个数字就是统计学上的中位数，即长度为$n$的数组中第$n/2$大的数字。已经有成熟的时间复杂度为$O(n)$的算法得到数组中任意第$k$大的数字。<br>第一，防御性编程，判断数组是否有效；第二，利用快速排序中的分割(partition)方法，选主元位置及重排数组。如果返回的主元位置(pIndex)小于数组中间位置((length-1)/2)，则对左半部分进行分割，否则对右半部分进行分割，直到返回的pIndex等于((length-1)/2)；第三，遍历数组，验证该数是否出现了超过一半的次数。<br><!-- more --><br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MoreThanHalfNum_Solution</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; numbers)</span> </span>&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">int</span> size = numbers.size();</span><br><span class=\"line\">        <span class=\"comment\">//1.防御性编程，判断数组是否有效；</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(size==<span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> end = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> middle = end/<span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.利用快速排序中的分割(partition)方法，选主元位置及重排数组</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = partition(numbers,start,end);</span><br><span class=\"line\">        <span class=\"comment\">//直到返回的pIndex等于((length-1)/2)</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span>(pIndex!=middle)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(pIndex&lt;middle)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                start = pIndex+<span class=\"number\">1</span>;</span><br><span class=\"line\">                pIndex = partition(numbers,start,end);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                end = pIndex<span class=\"number\">-1</span>;</span><br><span class=\"line\">                pIndex = partition(numbers,start,end);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> result=numbers[middle];</span><br><span class=\"line\">        <span class=\"comment\">//3.遍历数组，验证该数是否出现了超过一半的次数。</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(isMoreThanHalf(numbers,result,size))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start,<span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pivot = numbers[end];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]&lt;=pivot)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = numbers[i];</span><br><span class=\"line\">                numbers[i] = numbers[pIndex];</span><br><span class=\"line\">                numbers[pIndex] = temp;</span><br><span class=\"line\">                pIndex++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = numbers[pIndex];</span><br><span class=\"line\">        numbers[pIndex] = pivot;</span><br><span class=\"line\">        numbers[end] = temp;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">isMoreThanHalf</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers,<span class=\"keyword\">int</span> result,<span class=\"keyword\">int</span> size)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;size;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]==result)</span><br><span class=\"line\">                count++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"number\">2</span>*count&lt;=size) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-最小的k个数\"><a href=\"#2-最小的k个数\" class=\"headerlink\" title=\"2.最小的k个数\"></a>2.最小的k个数</h2><p><strong>题目描述</strong>：<br>输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。<br><strong>思路</strong>：<br>思路1：利用快速排序排序数组，位于前面的$k$个数即是最小的$k$个数。时间复杂度为$O(nlogn)$。<br>第一，防御性编程，如果数组为空或$k&gt;length$，则返回空；第二，利用快速排序，对数组进行排序；第三，输出数组中的前$k$个数。<br>思路2：<br>由上题“数组中出现次数超过一半的数字”得到启发，基于快速排序中的分割(partition)方法来解决问题。利用partiton函数，如果返回的$pIndex&lt;(k-1)$，则对右半部分进行partition，否则，对左半部分进行partition，直到返回的主元位置pIndex等于$(k-1)$。这样调整后，位于数组中左边的k个数字就是最小的$k$个数字，但这$k$个数字不一定是排序的。时间复杂度为$O(n)$。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//实现思路1</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; GetLeastNumbers_Solution(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; input, <span class=\"keyword\">int</span> k) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> size = input.size();</span><br><span class=\"line\">        <span class=\"comment\">//1.防御性编程，如果数组为空或k&gt;size，则返回</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(size==<span class=\"number\">0</span> || k&gt;size) <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> end = size<span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"comment\">//2.利用快速排序，对数组进行排序</span></span><br><span class=\"line\">        quickSort(input,start,end);</span><br><span class=\"line\">        <span class=\"comment\">//3.输出数组中的前k个数</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>;i&lt;k;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            result.push_back(input[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start, <span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(start&gt;end) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = partition(numbers,start,end);</span><br><span class=\"line\">        quickSort(numbers,start,pIndex<span class=\"number\">-1</span>);</span><br><span class=\"line\">        quickSort(numbers,pIndex+<span class=\"number\">1</span>,end);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">partition</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; numbers, <span class=\"keyword\">int</span> start,<span class=\"keyword\">int</span> end)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pivot = numbers[end];</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pIndex = start;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i = start;i&lt;end;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(numbers[i]&lt;=pivot)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> temp = numbers[i];</span><br><span class=\"line\">                numbers[i] = numbers[pIndex];</span><br><span class=\"line\">                numbers[pIndex] = temp;</span><br><span class=\"line\">                pIndex++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp = numbers[pIndex];</span><br><span class=\"line\">        numbers[pIndex] = pivot;</span><br><span class=\"line\">        numbers[end] = temp;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> pIndex;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"七、位运算\"><a href=\"#七、位运算\" class=\"headerlink\" title=\"七、位运算\"></a>七、位运算</h1><h2 id=\"1-数组中只出现一次的数字（-56）\"><a href=\"#1-数组中只出现一次的数字（-56）\" class=\"headerlink\" title=\"1.数组中只出现一次的数字（#56）\"></a>1.数组中只出现一次的数字（#56）</h2><p><strong>题目描述</strong><br>一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。<br><strong>思路</strong>：核心思想：<a href=\"http://blog.csdn.net/ns_code/article/details/27568975\" target=\"_blank\" rel=\"noopener\">异或去重</a>；异或的性质：交换律，结合律，以及<code>a^a=0</code>，<code>a^0=a</code><br><strong>1.考虑简单情况</strong>：数组中只有一个数字<code>n</code>出现了一次，其他都出现了两次。<br>将数组中所有元素逐个异或，则结果为只出现一次的<code>n</code>，即<code>a^a^b^b^...^n^...^c^c=n</code>。<br><strong>2.本题求解思路</strong>：故将数组分成两部分解决，一部分包含只出现一次的数字<code>n_1</code>，一部分包含只出现一次的数字<code>n_2</code>，同时保证出现两次的数字在同一数组,而不是分散在l不同的数组。对两数组分别逐元素异或，即分别得到<code>n_1</code>，<code>n_2</code>。<br><strong>3.数组划分方法</strong>：对整个数组，逐元素异或，则结果为<code>n_1^n_2</code>，即<code>n_1</code>和 <code>n_2</code>异或的结果。<code>n_1</code>和<code>n_2</code>不相同，故结果定不为0，则结果的二进制表示定至少有一位为1（即<code>n_1</code>和<code>n_2</code>的二进制表示的该位不相同），找出结果的二进制表示中第一次为1的下标索引<code>index</code>，通过这个下标索引<code>index</code>，对整个数组中的元素进行数组划分。数组中每个元素的二进制表示的第<code>index</code>位是1的分为一组，是0的分为另一组。这样保证了<code>n_1</code>和<code>n_2</code>分别在两个组，且出现两次的数字在同一个组，不会被分到不同的组(因此相同数字的二进制表示的<code>index</code>位必定是相同的)。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">FindNumsAppearOnce</span><span class=\"params\">(<span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; data,<span class=\"keyword\">int</span>* num1,<span class=\"keyword\">int</span> *num2)</span> </span>&#123;</span><br><span class=\"line\">truetrue<span class=\"keyword\">int</span> length = data.size();</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(data.size()&lt;<span class=\"number\">2</span>) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> result = <span class=\"number\">0</span>; <span class=\"comment\">//初始值为0,a^0=a</span></span><br><span class=\"line\">        <span class=\"comment\">// get num1 ^ num2</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i =<span class=\"number\">0</span>;i&lt;length;i++)</span><br><span class=\"line\">            result ^=data[i];</span><br><span class=\"line\">        <span class=\"comment\">// get index of the first bit, which is 1 in resultExclusiveOR</span></span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> indexOf1 = FindFirstBitIs1(result);</span><br><span class=\"line\">        *num1 = *num2 = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"comment\">// divide the numbers in data into two groups,</span></span><br><span class=\"line\">        <span class=\"comment\">// the indexOf1 bit of numbers in the first group is 1,</span></span><br><span class=\"line\">        <span class=\"comment\">// while in the second group is 0</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;length;j++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(IsBit1(data[j],indexOf1))</span><br><span class=\"line\">                *num1^=data[j];</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                *num2^=data[j];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//Find the index of first bit which is 1 in num (assuming not 0)</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">FindFirstBitIs1</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> indexBit=<span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(((num&amp;<span class=\"number\">1</span>)==<span class=\"number\">0</span>) &amp;&amp; (indexBit&lt;<span class=\"number\">8</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">int</span>)))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num = num&gt;&gt;<span class=\"number\">1</span>;</span><br><span class=\"line\">            ++indexBit;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> indexBit;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Is the indexBit bit of num 1?</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">IsBit1</span><span class=\"params\">(<span class=\"keyword\">int</span> num, <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> indexBit)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        num=num&gt;&gt;indexBit;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (num&amp;<span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2-二进制中1的个数\"><a href=\"#2-二进制中1的个数\" class=\"headerlink\" title=\"2.二进制中1的个数\"></a>2.二进制中1的个数</h2><p><strong>题目描述</strong><br>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。<br><strong>思路</strong>：<br><strong>首先</strong>，直观的思路是：先判断整数二进制表示中的最后一位是不是1；然后将整数右移一位，再次判断，直到整数变为0。判断二进制表示中最后一位是不是1的方法是：<code>n&amp;1</code>，因为1的二进制表示中除了最后一位为1以外，其余全为0。<br><strong>然后</strong>，右移整数n的做法存在隐患，就是当n是负数的时候，<a href=\"http://blog.csdn.net/morewindows/article/details/7354571\" target=\"_blank\" rel=\"noopener\">n右移会在开头补符号位1（算术右移）</a>，而不是补0。故采用将1循环左移的方法，逐个判断n的二进制表示的第0位到最高位是否为1。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">int</span>  <span class=\"title\">NumberOf1</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span> </span>&#123;</span><br><span class=\"line\">         <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">         <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> flag = <span class=\"number\">1</span>;</span><br><span class=\"line\">         <span class=\"comment\">//直到1的循环左移为0</span></span><br><span class=\"line\">         <span class=\"keyword\">while</span>(flag)</span><br><span class=\"line\">         &#123;</span><br><span class=\"line\">             <span class=\"keyword\">if</span>(n &amp; flag)</span><br><span class=\"line\">             \tcount++;</span><br><span class=\"line\">             <span class=\"comment\">//左移1</span></span><br><span class=\"line\">             flag =flag&lt;&lt;<span class=\"number\">1</span>;</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         <span class=\"keyword\">return</span> count;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"八、递归\"><a href=\"#八、递归\" class=\"headerlink\" title=\"八、递归\"></a>八、递归</h1><h2 id=\"1-斐波那契数列（-10）\"><a href=\"#1-斐波那契数列（-10）\" class=\"headerlink\" title=\"1.斐波那契数列（#10）\"></a>1.斐波那契数列（#10）</h2><p><strong>题目描述</strong><br>大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。(n&lt;=39)<br><strong>注</strong>：本题中<code>n=0</code>时，输出是0。斐波那契数列从第1项开始。即本题斐波那契数列是<code>0,1,1,2,3,5,...</code><br><strong>思路</strong>：<br><strong>思路1</strong>：最直观的递归，返回<code>Fibonacci(n-1)+Fibonacci(n-2)</code>。但有大量冗余计算，时间复杂度过高，无法通过。<br><strong>思路2</strong>：带记忆的递归，用辅助数组存储下已经计算过的结果。<br><strong>思路3</strong>：迭代计算。<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//思路1：最直观的递归，时间复杂度过高</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">Fibonacci</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(n&lt;=<span class=\"number\">1</span>) <span class=\"keyword\">return</span> n;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Fibonacci(n<span class=\"number\">-1</span>)+Fibonacci(n<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//思路2：带记忆的递归，用辅助数组存储下已经计算过的结果</span><br><span class=\"line\">class Solution &#123;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    int F[40];//默认为0</span><br><span class=\"line\">public:</span><br><span class=\"line\">    int Fibonacci(int n) &#123;</span><br><span class=\"line\">        if(F[n]!= 0) </span><br><span class=\"line\">            return F[n];</span><br><span class=\"line\">        if(n&lt;=1) </span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">         \tF[n]=n;</span><br><span class=\"line\">        \treturn F[n];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        else</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            F[n]=Fibonacci(n-1)+Fibonacci(n-2);</span><br><span class=\"line\">        \treturn F[n];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//思路3：迭代计算。</span><br><span class=\"line\">class Solution &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    int Fibonacci(int n) &#123;</span><br><span class=\"line\">    \tint num1=0;</span><br><span class=\"line\">    \tint num2=1;</span><br><span class=\"line\">    \tint num3;</span><br><span class=\"line\">        if(n&lt;=1) </span><br><span class=\"line\">            return n;</span><br><span class=\"line\">truetruefor(int i = 2;i&lt;=n;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            num3 = num1+num2;</span><br><span class=\"line\">            num1 = num2;</span><br><span class=\"line\">            num2 = num3;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return num3;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-青蛙跳台阶问题（-10）\"><a href=\"#2-青蛙跳台阶问题（-10）\" class=\"headerlink\" title=\"2. 青蛙跳台阶问题（#10）\"></a>2. 青蛙跳台阶问题（#10）</h2><p><strong>题目描述</strong><br>一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。<br><strong>思路</strong>：类似斐波那契数列<br>f(n)=　1, (n=1)<br>　　　 2, (n=2)<br>　　　 f(n-1)+f(n-2) ,(n&gt;2,n为整数)<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">jumpFloor</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> jumpFloor(number<span class=\"number\">-1</span>)+jumpFloor(number<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-变态跳台阶（-10）\"><a href=\"#3-变态跳台阶（-10）\" class=\"headerlink\" title=\"3.变态跳台阶（#10）\"></a>3.变态跳台阶（#10）</h2><p><strong>题目描述</strong><br>一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。<br><strong>思路</strong>：<br>因为n级台阶，第一步有n种跳法：跳1级，跳2级，…，跳n级<br>跳1级，剩下n-1级，则剩下跳法是f(n-1)<br>跳2级，剩下n-2级，则剩下跳法是f(n-2)<br>所以f(n)=f(n-1)+f(n-2)+…+f(1)+f(0)<br>因为f(n-1)=f(n-2)+f(n-3)+…+f(1)+f(0)<br>所以f(n)=2xf(n-1)<br>故：<br>f(n)=　1, (n=1)<br>　　　 2xf(n-1),(n&gt;1,n为整数)<br><strong>代码</strong>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">jumpFloorII</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">truetrue<span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">2</span>*jumpFloorII(number<span class=\"number\">-1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"4-矩形覆盖（-10）\"><a href=\"#4-矩形覆盖（-10）\" class=\"headerlink\" title=\"4.矩形覆盖（#10）\"></a>4.矩形覆盖（#10）</h2><p><strong>题目描述</strong><br>我们可以用2<em>1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2</em>1的小矩形无重叠地覆盖一个2<em>n的大矩形，总共有多少种方法？<br><strong>思路</strong>：仍旧是斐波那契数列<br>第一块有两种方式：横着放和竖着放。<br>横着放后，覆盖方法为f(n-2)，因为下方也被占用，下方必须也横着放。<br>竖着放后，覆盖方法为f(n-1);<br>所以总的覆盖方法为f(n)=f(n-1)+f(n-2);<br>故：<br>f(n)=　1, (n=1)<br>　　　 2, (n=2)<br>　　　 f(n-1)+f(n-2) ,(n&gt;2,n为整数)<br><em>*代码</em></em>：<br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">rectCover</span><span class=\"params\">(<span class=\"keyword\">int</span> number)</span> </span>&#123;</span><br><span class=\"line\"> \t\t<span class=\"keyword\">if</span>(number&lt;=<span class=\"number\">0</span>) <span class=\"keyword\">return</span> number; <span class=\"comment\">//defensive</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(number==<span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> rectCover(number<span class=\"number\">-1</span>)+rectCover(number<span class=\"number\">-2</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"九、回溯\"><a href=\"#九、回溯\" class=\"headerlink\" title=\"九、回溯\"></a>九、回溯</h1><h1 id=\"十、动态规划与贪婪算法\"><a href=\"#十、动态规划与贪婪算法\" class=\"headerlink\" title=\"十、动态规划与贪婪算法\"></a>十、动态规划与贪婪算法</h1>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjqxl4vuf0000qslpvhrt3q3n","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vv4000eqslpfvanb4xa"},{"post_id":"cjqxl4vv1000cqslpjj6ea60i","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4vva000kqslpzvn04y6d"},{"post_id":"cjqxl4vun0002qslp3fjiq25e","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4vvb000pqslpr2zfkphj"},{"post_id":"cjqxl4vv3000dqslpcnixclga","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4vvd000rqslpv8mdglb4"},{"post_id":"cjqxl4vv7000hqslpu9smfc4r","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vve000vqslp3ory052x"},{"post_id":"cjqxl4vuv0006qslp4z0ctwjx","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvf000xqslp11244b1a"},{"post_id":"cjqxl4vvb000oqslpnsntcz41","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvh0010qslpfcth9kys"},{"post_id":"cjqxl4vuy0008qslphbwpqyyi","category_id":"cjqxl4vva000mqslpgbfqyu2a","_id":"cjqxl4vvj0013qslp9bwlhs4x"},{"post_id":"cjqxl4vvc000qqslpe0gcb1qi","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4vvk0015qslprkhfqaag"},{"post_id":"cjqxl4vvd000uqslpw54jq3ll","category_id":"cjqxl4vva000mqslpgbfqyu2a","_id":"cjqxl4vvm0018qslp4qxwiu52"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","category_id":"cjqxl4vvd000sqslpfogvbgpt","_id":"cjqxl4vvn001aqslpl5t0qfh1"},{"post_id":"cjqxl4vvf000wqslpbb8m37ea","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvo001dqslp1ttdw4ut"},{"post_id":"cjqxl4vvg000zqslpbm1miy2s","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4vvp001eqslpxez354tx"},{"post_id":"cjqxl4vv9000jqslpys4de3c4","category_id":"cjqxl4vva000mqslpgbfqyu2a","_id":"cjqxl4vvq001gqslp1tyt7a2a"},{"post_id":"cjqxl4vvi0012qslpy3m2d5nc","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvq001hqslp0upnnqgz"},{"post_id":"cjqxl4vvj0014qslp93pg7es3","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvq001iqslpv7aeyvj4"},{"post_id":"cjqxl4vvl0017qslp9th7w79s","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvr001kqslpm0by6tch"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvr001lqslpum2bpcni"},{"post_id":"cjqxl4vvo001cqslplvulxu8p","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4vvr001nqslp5078wvmh"},{"post_id":"cjqxl4w00002jqslpml5o2c63","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4w07002oqslpg83vabbl"},{"post_id":"cjqxl4w02002kqslpj74z6p1u","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4w08002qqslp9vxa14wr"},{"post_id":"cjqxl4w04002mqslpao12uiv6","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4w09002tqslpals4m1ey"},{"post_id":"cjqxl4w06002nqslpsw79ezxc","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4w0b002vqslprsvt3tbj"},{"post_id":"cjqxl4w08002pqslpwdf6k6p5","category_id":"cjqxl4vv0000aqslprqpg4etn","_id":"cjqxl4w0c002yqslpybju3j9j"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4w0c0030qslpllserdmp"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","category_id":"cjqxl4w0b002xqslp1xp57vmp","_id":"cjqxl4w0d0032qslpc1wgq0j1"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","category_id":"cjqxl4vvd000sqslpfogvbgpt","_id":"cjqxl4w1i004yqslp5aicwone"},{"post_id":"cjqxl4w1f004uqslp6rk57en2","category_id":"cjqxl4w0b002xqslp1xp57vmp","_id":"cjqxl4w1i004zqslpwii4ytgl"},{"post_id":"cjqxl4w1g004wqslphkt7jd36","category_id":"cjqxl4w0b002xqslp1xp57vmp","_id":"cjqxl4w1j0051qslpdxnpz5m0"},{"post_id":"cjqxl4w1h004xqslpx2zkdg8q","category_id":"cjqxl4w0b002xqslp1xp57vmp","_id":"cjqxl4w1j0052qslppwvz7f4a"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","category_id":"cjqxl4vur0004qslpfndmvizt","_id":"cjqxl4w2r005xqslp2pch6bpz"},{"post_id":"cjqxl4w2q005uqslpy6wjd7po","category_id":"cjqxl4w2r005wqslp8x8k5dbd","_id":"cjqxl4w2s0060qslpahfu3sva"},{"post_id":"cjqxl4w430068qslps4orsy6w","category_id":"cjqxl4w2r005wqslp8x8k5dbd","_id":"cjqxl4w440069qslp799l97wn"},{"post_id":"cjqxl4w46006aqslphsd333eu","category_id":"cjqxl4w47006bqslp3ictv36t","_id":"cjqxl4w47006cqslpwdcou03o"},{"post_id":"cjqxl4w49006dqslp0wnse0yl","category_id":"cjqxl4w2r005wqslp8x8k5dbd","_id":"cjqxl4w4a006eqslp900fk4kc"},{"post_id":"cjqxl4w4e006fqslpmt8nb8pr","category_id":"cjqxl4w2r005wqslp8x8k5dbd","_id":"cjqxl4w4f006gqslpunili64q"},{"post_id":"cjqxl4w4g006hqslp5b3a4i9n","category_id":"cjqxl4w0b002xqslp1xp57vmp","_id":"cjqxl4w4h006iqslpwekd0owe"}],"PostTag":[{"post_id":"cjqxl4vuf0000qslpvhrt3q3n","tag_id":"cjqxl4vuv0005qslpiqgtbj8n","_id":"cjqxl4vv8000iqslpjtaazs62"},{"post_id":"cjqxl4vuf0000qslpvhrt3q3n","tag_id":"cjqxl4vv0000bqslps2hs6die","_id":"cjqxl4vva000lqslpdp4y99dv"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vv4000gqslpym2a10a1","_id":"cjqxl4vvs001rqslp0rm6f8op"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vva000nqslpa8o0webo","_id":"cjqxl4vvs001sqslp1i4akx52"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvd000tqslp5v35xklp","_id":"cjqxl4vvs001uqslpxi3jmn4a"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvh0011qslpwf901st4","_id":"cjqxl4vvs001vqslpi4sbez0m"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvk0016qslpy3cy05ta","_id":"cjqxl4vvs001xqslp9cig4x96"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvn001bqslp1fisve04","_id":"cjqxl4vvt001yqslpd0c2o5uh"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvp001fqslp7ho0d9jj","_id":"cjqxl4vvt0020qslpren6iff0"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvq001jqslphagxds9r","_id":"cjqxl4vvt0021qslprxb4wuuc"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvr001mqslpcqcwh2kp","_id":"cjqxl4vvt0022qslpdvivhf3w"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvr001oqslpg74rsw2j","_id":"cjqxl4vvt0024qslp73pgvnl0"},{"post_id":"cjqxl4vuz0009qslpiuznh8bc","tag_id":"cjqxl4vvr001pqslp22m50fcl","_id":"cjqxl4vvu0025qslpr03rlqtq"},{"post_id":"cjqxl4vvb000oqslpnsntcz41","tag_id":"cjqxl4vvr001qqslpwrtpof4r","_id":"cjqxl4vvu0027qslp9xn6e6sl"},{"post_id":"cjqxl4vvb000oqslpnsntcz41","tag_id":"cjqxl4vvs001tqslpb5zaenkf","_id":"cjqxl4vvu0028qslp4x3om1as"},{"post_id":"cjqxl4vvj0014qslp93pg7es3","tag_id":"cjqxl4vvs001wqslpj07cfs52","_id":"cjqxl4vvu002aqslpiodd1uph"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvt001zqslp64g8xsu1","_id":"cjqxl4vvv002dqslpt1kdyl5y"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvt0023qslp154rk2aj","_id":"cjqxl4vvv002eqslpzawfqs2z"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvu0026qslp1rllkqxl","_id":"cjqxl4vvv002fqslpek878b4c"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvu0029qslpbi8iywcc","_id":"cjqxl4vvw002gqslpaqhxfjh0"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvv002bqslpcr5ccz1e","_id":"cjqxl4vvw002hqslpl0inwcoe"},{"post_id":"cjqxl4vvm0019qslpjlnb44gj","tag_id":"cjqxl4vvv002cqslpkz83cn4k","_id":"cjqxl4vvw002iqslpd3x5jyyu"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w04002lqslpze9f2mzp","_id":"cjqxl4w0g0035qslp2nct06af"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w08002rqslpeaps802f","_id":"cjqxl4w0g0036qslp4gcg6tfc"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w0b002wqslpush80m6m","_id":"cjqxl4w0h0038qslpurzw95br"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w0c002zqslpg90vnxmm","_id":"cjqxl4w0h0039qslp7ybw8ht2"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w0d0031qslpqwr10v7f","_id":"cjqxl4w0h003bqslpfipw1ddh"},{"post_id":"cjqxl4w00002jqslpml5o2c63","tag_id":"cjqxl4w0f0033qslpyswn0m9w","_id":"cjqxl4w0h003cqslpdqh31pqu"},{"post_id":"cjqxl4w02002kqslpj74z6p1u","tag_id":"cjqxl4w0f0034qslpcwyy1l30","_id":"cjqxl4w0i003eqslpdiila21q"},{"post_id":"cjqxl4w02002kqslpj74z6p1u","tag_id":"cjqxl4w0g0037qslpyrnen57u","_id":"cjqxl4w0i003fqslpyctsl9r8"},{"post_id":"cjqxl4w02002kqslpj74z6p1u","tag_id":"cjqxl4w0h003aqslp9o37jezb","_id":"cjqxl4w0i003hqslp8m24afol"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0h003dqslpxfk0wz89","_id":"cjqxl4w0n003sqslp20s9zlp2"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0i003gqslpy7ep7tmi","_id":"cjqxl4w0o003tqslpjue0muli"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0i003iqslpr8x4bkeb","_id":"cjqxl4w0o003vqslpnrnx0lxi"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0j003jqslpue4dtm84","_id":"cjqxl4w0p003wqslpzjlc5931"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0j003kqslpahs7uoes","_id":"cjqxl4w0p003yqslpr4cfu8pm"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0k003lqslpd1pnli19","_id":"cjqxl4w0p003zqslpw4vpl02j"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0k003mqslpitk3cpmb","_id":"cjqxl4w0q0041qslpi5g1f4to"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0l003nqslp1ifgkxjb","_id":"cjqxl4w0q0042qslpy2qz9unh"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0m003oqslpeng0bl5a","_id":"cjqxl4w0q0043qslpautov8jf"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0m003pqslplel3smfd","_id":"cjqxl4w0q0045qslpfjkfjksq"},{"post_id":"cjqxl4w04002mqslpao12uiv6","tag_id":"cjqxl4w0n003qqslpqpxm1msb","_id":"cjqxl4w0r0046qslptfahvb43"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0n003rqslp1o5aholu","_id":"cjqxl4w0t004bqslpciu09c4b"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0o003uqslp0fbc1k9f","_id":"cjqxl4w0t004cqslpdrfmcxdn"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0p003xqslpnlz89cpr","_id":"cjqxl4w0t004eqslpknxi6rqs"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0p0040qslpwwj49bdy","_id":"cjqxl4w0t004fqslpb9u1hja9"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0q0044qslpau3smj05","_id":"cjqxl4w0u004hqslp6vxqapju"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0r0047qslpjo61u4hj","_id":"cjqxl4w0u004iqslpbu4itkbw"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0r0048qslp8ic8etdc","_id":"cjqxl4w0u004kqslps7tnsii6"},{"post_id":"cjqxl4w09002sqslpq7ezyudu","tag_id":"cjqxl4w0s0049qslpo54wogu5","_id":"cjqxl4w0u004lqslpo5dm4pvz"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4w0s004aqslple96563o","_id":"cjqxl4w0v004mqslp0dnk0982"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4w0t004dqslpggn3w9g3","_id":"cjqxl4w0v004nqslprwjaquuc"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4w0u004gqslp9xs1c589","_id":"cjqxl4w0v004oqslptamw9jkd"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4vvu0026qslp1rllkqxl","_id":"cjqxl4w0v004pqslpmq836jcl"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4vvu0029qslpbi8iywcc","_id":"cjqxl4w0v004qqslpg8xkecbn"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4w0u004jqslpwlahty07","_id":"cjqxl4w0w004rqslpqbyi6lnc"},{"post_id":"cjqxl4w0a002uqslpuxvgdp7p","tag_id":"cjqxl4vvv002cqslpkz83cn4k","_id":"cjqxl4w0w004sqslp5eq1k8yy"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4vv4000gqslpym2a10a1","_id":"cjqxl4w1m005cqslphf365zs4"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4vva000nqslpa8o0webo","_id":"cjqxl4w1m005dqslp3iejcvv2"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1g004vqslp09skd47x","_id":"cjqxl4w1n005fqslptr33n5z0"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1i0050qslpluupnrb0","_id":"cjqxl4w1n005gqslpw395gd4u"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1j0053qslptu3ufv95","_id":"cjqxl4w1n005hqslpm2tjwft1"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1j0054qslpcjwkvjm0","_id":"cjqxl4w1n005iqslps9cw0toj"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1k0055qslppa1ft5j3","_id":"cjqxl4w1n005jqslpg56dxggv"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1k0056qslp4dtc46zv","_id":"cjqxl4w1n005kqslpugw1fdex"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1l0057qslp80id3y0z","_id":"cjqxl4w1n005lqslp095djia1"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1m0058qslp5duarbuf","_id":"cjqxl4w1n005mqslpjitie4s5"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1m0059qslpu3ef0swe","_id":"cjqxl4w1n005nqslpmeubabu2"},{"post_id":"cjqxl4w1e004tqslp3x1xfz5s","tag_id":"cjqxl4w1m005aqslpwxauop0d","_id":"cjqxl4w1n005oqslpk6qfarbq"},{"post_id":"cjqxl4w1g004wqslphkt7jd36","tag_id":"cjqxl4vvk0016qslpy3cy05ta","_id":"cjqxl4w1n005pqslp4we2b2jg"},{"post_id":"cjqxl4w1g004wqslphkt7jd36","tag_id":"cjqxl4w1m005bqslp3ez7vvgu","_id":"cjqxl4w1n005qqslp0es7rm22"},{"post_id":"cjqxl4w1h004xqslpx2zkdg8q","tag_id":"cjqxl4vvk0016qslpy3cy05ta","_id":"cjqxl4w1n005rqslpxaa7l9uq"},{"post_id":"cjqxl4w1h004xqslpx2zkdg8q","tag_id":"cjqxl4w1m005bqslp3ez7vvgu","_id":"cjqxl4w1o005sqslpo8eiezzy"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","tag_id":"cjqxl4w2r005vqslp9o2g0wjx","_id":"cjqxl4w2t0063qslpim09nhky"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","tag_id":"cjqxl4w2s005yqslpxulae4av","_id":"cjqxl4w2t0064qslpl1q1nuga"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","tag_id":"cjqxl4w2s005zqslp2m1h87nb","_id":"cjqxl4w2t0065qslp5wjp27pv"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","tag_id":"cjqxl4w2s0061qslpt9p0rfqm","_id":"cjqxl4w2t0066qslpnn1zkk15"},{"post_id":"cjqxl4w2n005tqslppv6kx5eo","tag_id":"cjqxl4w2s0062qslp8d1q8xp7","_id":"cjqxl4w2t0067qslp98cvc0hr"}],"Tag":[{"name":"Boosting","_id":"cjqxl4vuv0005qslpiqgtbj8n"},{"name":"AdaBoost","_id":"cjqxl4vv0000bqslps2hs6die"},{"name":"C","_id":"cjqxl4vv4000gqslpym2a10a1"},{"name":"C++","_id":"cjqxl4vva000nqslpa8o0webo"},{"name":"内存管理","_id":"cjqxl4vvd000tqslp5v35xklp"},{"name":"堆","_id":"cjqxl4vvh0011qslpwf901st4"},{"name":"栈","_id":"cjqxl4vvk0016qslpy3cy05ta"},{"name":"自由存储区","_id":"cjqxl4vvn001bqslp1fisve04"},{"name":"malloc","_id":"cjqxl4vvp001fqslp7ho0d9jj"},{"name":"free","_id":"cjqxl4vvq001jqslphagxds9r"},{"name":"new","_id":"cjqxl4vvr001mqslpcqcwh2kp"},{"name":"delete","_id":"cjqxl4vvr001oqslpg74rsw2j"},{"name":"delete[]","_id":"cjqxl4vvr001pqslp22m50fcl"},{"name":"softmax","_id":"cjqxl4vvr001qqslpwrtpof4r"},{"name":"多分类","_id":"cjqxl4vvs001tqslpb5zaenkf"},{"name":"机器学习","_id":"cjqxl4vvs001wqslpj07cfs52"},{"name":"线性回归","_id":"cjqxl4vvt001zqslp64g8xsu1"},{"name":"linear regression","_id":"cjqxl4vvt0023qslp154rk2aj"},{"name":"似然估计","_id":"cjqxl4vvu0026qslp1rllkqxl"},{"name":"梯度下降","_id":"cjqxl4vvu0029qslpbi8iywcc"},{"name":"正规方程","_id":"cjqxl4vvv002bqslpcr5ccz1e"},{"name":"正则化","_id":"cjqxl4vvv002cqslpkz83cn4k"},{"name":"CART","_id":"cjqxl4w04002lqslpze9f2mzp"},{"name":"二叉树","_id":"cjqxl4w08002rqslpeaps802f"},{"name":"回归树","_id":"cjqxl4w0b002wqslpush80m6m"},{"name":"分类树","_id":"cjqxl4w0c002zqslpg90vnxmm"},{"name":"平方误差","_id":"cjqxl4w0d0031qslpqwr10v7f"},{"name":"基尼指数","_id":"cjqxl4w0f0033qslpyswn0m9w"},{"name":"提升树","_id":"cjqxl4w0f0034qslpcwyy1l30"},{"name":"梯度提升树","_id":"cjqxl4w0g0037qslpyrnen57u"},{"name":"GBDT","_id":"cjqxl4w0h003aqslp9o37jezb"},{"name":"决策树","_id":"cjqxl4w0h003dqslpxfk0wz89"},{"name":"ID3","_id":"cjqxl4w0i003gqslpy7ep7tmi"},{"name":"C4.5","_id":"cjqxl4w0i003iqslpr8x4bkeb"},{"name":"熵","_id":"cjqxl4w0j003jqslpue4dtm84"},{"name":"条件熵","_id":"cjqxl4w0j003kqslpahs7uoes"},{"name":"信息增益","_id":"cjqxl4w0k003lqslpd1pnli19"},{"name":"信息增益比","_id":"cjqxl4w0k003mqslpitk3cpmb"},{"name":"预剪枝","_id":"cjqxl4w0l003nqslp1ifgkxjb"},{"name":"后剪枝","_id":"cjqxl4w0m003oqslpeng0bl5a"},{"name":"连续值","_id":"cjqxl4w0m003pqslplel3smfd"},{"name":"缺失值","_id":"cjqxl4w0n003qqslpqpxm1msb"},{"name":"线性表","_id":"cjqxl4w0n003rqslp1o5aholu"},{"name":"顺序存储结构","_id":"cjqxl4w0o003uqslp0fbc1k9f"},{"name":"数组","_id":"cjqxl4w0p003xqslpnlz89cpr"},{"name":"链式存储结构","_id":"cjqxl4w0p0040qslpwwj49bdy"},{"name":"链表","_id":"cjqxl4w0q0044qslpau3smj05"},{"name":"单链表","_id":"cjqxl4w0r0047qslpjo61u4hj"},{"name":"双向链表","_id":"cjqxl4w0r0048qslp8ic8etdc"},{"name":"循环链表","_id":"cjqxl4w0s0049qslpo54wogu5"},{"name":"逻辑回归","_id":"cjqxl4w0s004aqslple96563o"},{"name":"Logistic Regression","_id":"cjqxl4w0t004dqslpggn3w9g3"},{"name":"sigmoid函数","_id":"cjqxl4w0u004gqslp9xs1c589"},{"name":"决策边界","_id":"cjqxl4w0u004jqslpwlahty07"},{"name":"const","_id":"cjqxl4w1g004vqslp09skd47x"},{"name":"const对象","_id":"cjqxl4w1i0050qslpluupnrb0"},{"name":"const引用","_id":"cjqxl4w1j0053qslptu3ufv95"},{"name":"常引用","_id":"cjqxl4w1j0054qslpcjwkvjm0"},{"name":"const指针","_id":"cjqxl4w1k0055qslppa1ft5j3"},{"name":"常量指针","_id":"cjqxl4w1k0056qslp4dtc46zv"},{"name":"指针常量","_id":"cjqxl4w1l0057qslp80id3y0z"},{"name":"常成员函数","_id":"cjqxl4w1m0058qslp5duarbuf"},{"name":"const成员函数","_id":"cjqxl4w1m0059qslpu3ef0swe"},{"name":"函数重载","_id":"cjqxl4w1m005aqslpwxauop0d"},{"name":"队列","_id":"cjqxl4w1m005bqslp3ez7vvgu"},{"name":"线性可分支持向量机","_id":"cjqxl4w2r005vqslp9o2g0wjx"},{"name":"线性支持向量机","_id":"cjqxl4w2s005yqslpxulae4av"},{"name":"非线性支持向量机","_id":"cjqxl4w2s005zqslp2m1h87nb"},{"name":"核函数","_id":"cjqxl4w2s0061qslpt9p0rfqm"},{"name":"smo算法","_id":"cjqxl4w2s0062qslp8d1q8xp7"}]}}